{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f19017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d782ddf",
   "metadata": {},
   "source": [
    "### Check Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03faa827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac4996",
   "metadata": {},
   "source": [
    "### GPU Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1e955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2835bd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f935a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be867b6",
   "metadata": {},
   "source": [
    "### Pandas Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92db292",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_column', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0907c",
   "metadata": {},
   "source": [
    "### Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0fd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VAL_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf19fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_WIDTH = 227\n",
    "CROP_HEIGHT = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d40847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldFiles = [\"adience/unprocessed/fold_0_data.txt\",\n",
    "             \"adience/unprocessed/fold_1_data.txt\",\n",
    "             \"adience/unprocessed/fold_2_data.txt\",\n",
    "             \"adience/unprocessed/fold_3_data.txt\",\n",
    "             \"adience/unprocessed/fold_4_data.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f61c7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genderMap = defaultdict(lambda : np.NaN)\n",
    "genderMap['m'] = 0\n",
    "genderMap['f'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d26242",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = ['(0, 2)', '(4, 6)', '(8, 13)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
    "ageMap = defaultdict(lambda : np.NaN)\n",
    "for i,a in enumerate(ages):\n",
    "    ageMap[a] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b1fc3",
   "metadata": {},
   "source": [
    "### Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd634a3",
   "metadata": {},
   "source": [
    "Dataset generation pipeline:\n",
    "Input: \n",
    "- foldFile - Path to fold file. Fold file Describes which images are in the fold and its corresponding labels\n",
    "- imgBaseFolder - Base folder to search image from\n",
    "- imgPrefix - Prefix of image file\n",
    "- genderMap - Map from ['m', 'f', 'u', None], to one hot index\n",
    "- ageMap - Map from age category to one hot index\n",
    "- imgWidth - Resulting image width\n",
    "- imgHeigh - Resulting image height\n",
    "- batchSize - Int or None, batch size\n",
    "- configureDs - Function accepting dataset for performance configurations\n",
    "- preBatch - List of (name, functions) pair that will be mapped before batching. name is used as name parameters for tf graph \n",
    "- postBatch - List of (name, functions) that will be mapped after batching. name is used as name parameters for tf graph\n",
    "\n",
    "The processing functions should have signature function(img, label) -> (img, label)\n",
    "\n",
    "Pipeline\n",
    "\n",
    "Read Fold File -> Preprocess filename and labels (dataframe) -> Convert filename and labels to numpy array -> Convert filename and labels to tf dataset -> Parse images and labels -> Configure Dataset for performance -> Pre-Batching preprocessing -> Batch -> Post-Batching preprocessing -> Output\n",
    "\n",
    "Some preprocessing steps can only be done before and some can only be done after batching, thats why there are seperated pre and post batching list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0795464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, batchSize, configureDs=None, preBatch=[], postBatch=[]):\n",
    "    \n",
    "    def parseImage(filename):\n",
    "        img = tf.io.read_file(filename)\n",
    "        img = tf.image.decode_jpeg(img)\n",
    "        img = tf.image.resize(img, [imgHeight, imgWidth])\n",
    "         \n",
    "        return img\n",
    "    \n",
    "    # Read Fold File\n",
    "    foldData = []\n",
    "    for f in foldFiles:\n",
    "        foldData.append(pd.read_csv(f, sep=\"\\t\"))\n",
    "    foldData = pd.concat(foldData)\n",
    "    \n",
    "    # Form File Name\n",
    "    foldData['filename'] = foldData.apply(lambda r: os.path.join(imgBaseFolder, r['user_id'], f\"{imgPrefix}.{r['face_id']}.{r['original_image']}\"), axis=1)\n",
    "    \n",
    "    # Generate Label One Hot Index\n",
    "    foldData['gender_ind'] = foldData['gender'].map(genderMap)\n",
    "    foldData['age_ind'] = foldData['age'].map(ageMap)\n",
    "    \n",
    "    # Remove dirty data\n",
    "    foldData.dropna(subset=['gender_ind', 'age_ind'], inplace=True)\n",
    "    \n",
    "    # Dataframe to numpy\n",
    "    filenames = foldData['filename'].to_numpy()\n",
    "    \n",
    "    genderIndex = foldData['gender_ind'].to_numpy().astype(int)\n",
    "    ageIndex = foldData['age_ind'].to_numpy().astype(int)\n",
    "    \n",
    "    # Numpy to Dataset\n",
    "    fnDs = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    genderIndDs = tf.data.Dataset.from_tensor_slices(genderIndex)\n",
    "    ageIndDs = tf.data.Dataset.from_tensor_slices(ageIndex)\n",
    "    \n",
    "    # Parse Images\n",
    "    imageDs = fnDs.map(parseImage, num_parallel_calls=tf.data.AUTOTUNE, name=\"parse_image\")\n",
    "    \n",
    "    # Parse Labels\n",
    "    genderLabDs = genderIndDs.map(lambda x: tf.one_hot(x, genderDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"gender_one_hot\")\n",
    "    ageLabDs = ageIndDs.map(lambda x: tf.one_hot(x, ageDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"age_one_hot\")\n",
    "    \n",
    "    # Combine Labels\n",
    "    labelDs = tf.data.Dataset.zip((genderLabDs, ageLabDs), name=\"label_zip\")\n",
    "    labelDs = labelDs.map(lambda g,a: {\"gender\": g, \"age\": a}, num_parallel_calls=tf.data.AUTOTUNE, name='label_dict')\n",
    "    \n",
    "    # Combine Images and Labels into dataset\n",
    "    ds = tf.data.Dataset.zip((imageDs, labelDs))\n",
    "    \n",
    "    # Configure Performance\n",
    "    if(configureDs is not None):\n",
    "        ds = configureDs(ds)\n",
    "    \n",
    "    # Pre Batch Preprocessing\n",
    "    for n,f in preBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    # Batch\n",
    "    if(batchSize is not None):\n",
    "        ds = ds.batch(batchSize, name=\"ds_batch\")\n",
    "    \n",
    "    # Post Batch Preprocessing\n",
    "    for n,f in postBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320ed92",
   "metadata": {},
   "source": [
    "### Preprocessings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "472b7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=100)\n",
    "    ds = ds.repeat()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adb98feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313da7f1",
   "metadata": {},
   "source": [
    "#### Preprocessing steps according to the reference paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7724a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainPreprocessA(img, lab):\n",
    "        \n",
    "        img = tf.image.random_crop(img, [CROP_HEIGHT, CROP_WIDTH, 3])\n",
    "        \n",
    "        ud = tf.random.uniform([], dtype=tf.float32)\n",
    "        udCond = tf.less(ud, 0.5)\n",
    "        \n",
    "        img = tf.cond(udCond, lambda: tf.image.flip_up_down(img), lambda: img)\n",
    "        \n",
    "        lr = tf.random.uniform([], dtype=tf.float32)\n",
    "        lrCond = tf.less(lr, 0.5)\n",
    "        \n",
    "        img = tf.cond(lrCond, lambda: tf.image.flip_left_right(img), lambda: img)\n",
    "        \n",
    "        img = tf.image.random_brightness(img, 63/255)\n",
    "        \n",
    "        img = tf.image.random_contrast(img, 0.2, 1.8) \n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14ee59ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valPreprocessA(img, lab):\n",
    "        \n",
    "        img = tf.image.crop_to_bounding_box(img,\n",
    "                                            (IMG_HEIGHT-CROP_HEIGHT) // 2,\n",
    "                                            (IMG_WIDTH-CROP_WIDTH) // 2,\n",
    "                                            CROP_HEIGHT,\n",
    "                                            CROP_WIDTH)\n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a03ab680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageStandardize(img, lab):\n",
    "    \n",
    "    img = tf.image.per_image_standardization(img)\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ec104",
   "metadata": {},
   "source": [
    "#### Label extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "294a2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractGenderLabel(img, lab):\n",
    "    \n",
    "    lab = lab['gender']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a98897ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAgeLabel(img, lab):\n",
    "    \n",
    "    lab = lab['age']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7778c",
   "metadata": {},
   "source": [
    "### Generate Folds for K-Folds validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4172d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFoldDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, valBatchSize, trainConfigureDs=None, trainPreBatch=[], trainPostBatch=[], valConfigureDs=None, valPreBatch=[], valPostBatch=[]):\n",
    "    '''\n",
    "        Returns list of (train, validation) datasets\n",
    "    '''\n",
    "    \n",
    "    N = len(foldFiles)\n",
    "    \n",
    "    folds = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        trainFiles = foldFiles[:i]\n",
    "        if(i < N-1):\n",
    "            trainFiles.extend(foldFiles[i+1:])\n",
    "            \n",
    "        valFiles = foldFiles[i]\n",
    "        \n",
    "        trainDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, configureDs=trainConfigureDs, preBatch=trainPreBatch, postBatch=trainPostBatch)\n",
    "        valDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, valBatchSize, configureDs=valConfigureDs, preBatch=valPreBatch, postBatch=valPostBatch)\n",
    "        \n",
    "        folds.append((trainDs, valDs))\n",
    "        \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4f43dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPreBatch = [(\"train_process_a\", trainPreprocessA), \n",
    "                 (\"train_standardize\", imageStandardize), \n",
    "                 (\"train_extract_gender\", extractGenderLabel)]\n",
    "\n",
    "valPreBatch = [(\"val_process_a\", valPreprocessA), \n",
    "               (\"val_standardize\", imageStandardize), \n",
    "               (\"val_extract_gender\", extractGenderLabel)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10474d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 21:37:48.796619: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 21:37:49.289926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4274 MB memory:  -> device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "folds = generateFoldDs(foldFiles, \"adience/faces\", \"coarse_tilt_aligned_face\", genderMap, ageMap, 2, 8, \n",
    "                       IMG_WIDTH, IMG_HEIGHT, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE, \n",
    "                       trainConfigureDs=trainConfigPerformance, trainPreBatch=trainPreBatch, \n",
    "                       valConfigureDs=valConfigPerformance, valPreBatch=valPreBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57d814af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b5f9bc",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d0df0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in folds[0][0].take(1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c9e2833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 227, 227, 3), dtype=float32, numpy=\n",
       "array([[[[-1.4543149e+00, -1.5454352e+00, -1.6145902e+00],\n",
       "         [-1.4543149e+00, -1.5332162e+00, -1.6145902e+00],\n",
       "         [-1.4482555e+00, -1.5454352e+00, -1.6145902e+00],\n",
       "         ...,\n",
       "         [-1.4543149e+00, -1.5454352e+00, -1.6145902e+00],\n",
       "         [-1.4543149e+00, -1.5454352e+00, -1.6145902e+00],\n",
       "         [-1.4543149e+00, -1.5454352e+00, -1.6145902e+00]],\n",
       "\n",
       "        [[-1.4543149e+00, -1.5454352e+00, -1.6145902e+00],\n",
       "         [-1.4543149e+00, -1.5356700e+00, -1.6084807e+00],\n",
       "         [-1.4543149e+00, -1.5326153e+00, -1.6145902e+00],\n",
       "         ...,\n",
       "         [-1.4543149e+00, -1.5454352e+00, -1.6145902e+00],\n",
       "         [-1.4543149e+00, -1.5454352e+00, -1.6145902e+00],\n",
       "         [-1.4543149e+00, -1.5454352e+00, -1.6145902e+00]],\n",
       "\n",
       "        [[-1.4543149e+00, -1.5454352e+00, -1.6145902e+00],\n",
       "         [-1.4543149e+00, -1.5448343e+00, -1.5901524e+00],\n",
       "         [-1.4543149e+00, -1.5335668e+00, -1.6145902e+00],\n",
       "         ...,\n",
       "         [-1.4543149e+00, -1.5454352e+00, -1.6145902e+00],\n",
       "         [-1.4543149e+00, -1.5454352e+00, -1.6145902e+00],\n",
       "         [-1.4543149e+00, -1.5454352e+00, -1.6145902e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 8.9851636e-01,  2.5539070e-03, -6.8976277e-01],\n",
       "         [ 9.0622813e-01, -4.1564838e-03, -6.6482443e-01],\n",
       "         [ 8.6356229e-01, -4.8024178e-02, -6.8124974e-01],\n",
       "         ...,\n",
       "         [-1.4543149e+00, -1.5454352e+00, -1.6145902e+00],\n",
       "         [-1.4543149e+00, -1.5454352e+00, -1.6145902e+00],\n",
       "         [-1.4543149e+00, -1.5454352e+00, -1.6145902e+00]],\n",
       "\n",
       "        [[ 8.5575044e-01, -3.0897679e-02, -6.9421977e-01],\n",
       "         [ 8.7768412e-01, -2.9796051e-02, -6.6131890e-01],\n",
       "         [ 8.3436733e-01, -6.4399451e-02, -6.8480515e-01],\n",
       "         ...,\n",
       "         [-1.4543149e+00, -1.5454352e+00, -1.6145902e+00],\n",
       "         [-1.4543149e+00, -1.5454352e+00, -1.6145902e+00],\n",
       "         [-1.4543149e+00, -1.5454352e+00, -1.6145902e+00]],\n",
       "\n",
       "        [[ 8.2400125e-01, -5.1379248e-02, -6.5756315e-01],\n",
       "         [ 8.6150920e-01, -2.7642723e-02, -6.2881881e-01],\n",
       "         [ 8.8920200e-01,  5.0056580e-05, -6.0112602e-01],\n",
       "         ...,\n",
       "         [-1.4543149e+00, -1.5454352e+00, -1.6145902e+00],\n",
       "         [-1.4543149e+00, -1.5454352e+00, -1.6145902e+00],\n",
       "         [-1.4543149e+00, -1.5454352e+00, -1.6145902e+00]]],\n",
       "\n",
       "\n",
       "       [[[ 1.8893523e+00,  1.3431259e+00,  9.1898429e-01],\n",
       "         [ 1.8710891e+00,  1.3248619e+00,  9.0072030e-01],\n",
       "         [ 1.8814384e+00,  1.3488257e+00,  9.3829846e-01],\n",
       "         ...,\n",
       "         [ 1.4689014e+00,  8.6821961e-01,  4.0323621e-01],\n",
       "         [ 1.4316096e+00,  8.3092779e-01,  3.6594439e-01],\n",
       "         [ 1.4425378e+00,  8.8269776e-01,  4.3132800e-01]],\n",
       "\n",
       "        [[ 1.8851284e+00,  1.3389012e+00,  9.1476029e-01],\n",
       "         [ 1.8793484e+00,  1.3331212e+00,  9.0898037e-01],\n",
       "         [ 1.9276479e+00,  1.3950351e+00,  9.8450792e-01],\n",
       "         ...,\n",
       "         [ 1.4893389e+00,  8.8865703e-01,  4.2367363e-01],\n",
       "         [ 1.4452304e+00,  8.4454852e-01,  3.7956512e-01],\n",
       "         [ 1.4180259e+00,  8.1734324e-01,  3.5236061e-01]],\n",
       "\n",
       "        [[ 1.8747051e+00,  1.3557060e+00,  9.1795075e-01],\n",
       "         [ 1.8622973e+00,  1.3432990e+00,  9.0554291e-01],\n",
       "         [ 1.9008690e+00,  1.3682562e+00,  9.5772898e-01],\n",
       "         ...,\n",
       "         [ 1.4871355e+00,  8.8645297e-01,  4.2147034e-01],\n",
       "         [ 1.4277176e+00,  8.2703573e-01,  3.6205229e-01],\n",
       "         [ 1.4609710e+00,  8.6028916e-01,  3.9530575e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-4.5517296e-02, -6.1897182e-01, -1.0294998e+00],\n",
       "         [-4.4641888e-01, -1.0198730e+00, -1.4304006e+00],\n",
       "         [-1.2737700e-01, -6.8721747e-01, -1.1385868e+00],\n",
       "         ...,\n",
       "         [-1.1779907e+00, -1.7899468e+00, -2.0832677e+00],\n",
       "         [-1.1711842e+00, -1.7582520e+00, -2.0598688e+00],\n",
       "         [-1.1611866e+00, -1.7290366e+00, -2.0402625e+00]],\n",
       "\n",
       "        [[-2.5963011e-01, -8.2521391e-01, -1.2593533e+00],\n",
       "         [-3.0224645e-01, -8.6783028e-01, -1.3019695e+00],\n",
       "         [-9.2099644e-02, -6.5193969e-01, -1.1033090e+00],\n",
       "         ...,\n",
       "         [-1.1587501e+00, -1.7799295e+00, -2.0701756e+00],\n",
       "         [-1.1313694e+00, -1.7420492e+00, -2.0357955e+00],\n",
       "         [-1.1534818e+00, -1.7641617e+00, -2.0579078e+00]],\n",
       "\n",
       "        [[ 1.0698051e-01, -4.5286036e-01, -9.0422970e-01],\n",
       "         [ 4.9380280e-02, -5.1045978e-01, -9.6182913e-01],\n",
       "         [-1.9411987e-01, -7.5396073e-01, -1.2053297e+00],\n",
       "         ...,\n",
       "         [-1.0680164e+00, -1.7084764e+00, -1.9964792e+00],\n",
       "         [-1.0314293e+00, -1.6718891e+00, -1.9598922e+00],\n",
       "         [-1.1286870e+00, -1.7565966e+00, -2.0445998e+00]]],\n",
       "\n",
       "\n",
       "       [[[-5.2616847e-01, -1.3081528e+00, -1.7955705e+00],\n",
       "         [-5.2616847e-01, -1.3081528e+00, -1.7955705e+00],\n",
       "         [-5.2616847e-01, -1.3081528e+00, -1.7955705e+00],\n",
       "         ...,\n",
       "         [ 1.8856878e+00,  9.3333548e-01,  4.9657868e-03],\n",
       "         [ 1.8759401e+00,  9.2358786e-01, -4.7818790e-03],\n",
       "         [ 1.8657057e+00,  9.1335350e-01, -3.5059918e-02]],\n",
       "\n",
       "        [[-5.2616847e-01, -1.3081528e+00, -1.7955705e+00],\n",
       "         [-5.2616847e-01, -1.3081528e+00, -1.7955705e+00],\n",
       "         [-5.2616847e-01, -1.3081528e+00, -1.7955705e+00],\n",
       "         ...,\n",
       "         [ 1.4776629e+00,  5.2531117e-01, -4.2310226e-01],\n",
       "         [ 1.8135595e+00,  8.6120725e-01, -8.7206148e-02],\n",
       "         [ 1.9945874e+00,  1.0423456e+00,  9.3601987e-02]],\n",
       "\n",
       "        [[-5.2616847e-01, -1.3081528e+00, -1.7955705e+00],\n",
       "         [-5.2616847e-01, -1.3081528e+00, -1.7955705e+00],\n",
       "         [-5.2616847e-01, -1.3081528e+00, -1.7955705e+00],\n",
       "         ...,\n",
       "         [ 1.2382762e+00,  2.8592452e-01, -6.6248888e-01],\n",
       "         [ 1.2864443e+00,  3.3409262e-01, -6.1432076e-01],\n",
       "         [ 1.7264596e+00,  7.8412920e-01, -1.9434917e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-5.2616847e-01, -1.3081528e+00, -1.7955705e+00],\n",
       "         [-5.2616847e-01, -1.3081528e+00, -1.7955705e+00],\n",
       "         [-5.2616847e-01, -1.3081528e+00, -1.7955705e+00],\n",
       "         ...,\n",
       "         [ 1.3187947e+00,  5.8831298e-01,  2.1920530e-01],\n",
       "         [ 9.8938471e-01,  2.7931115e-01, -7.1911812e-02],\n",
       "         [ 7.7271515e-01,  7.7637620e-02, -2.4567090e-01]],\n",
       "\n",
       "        [[-5.2616847e-01, -1.3081528e+00, -1.7955705e+00],\n",
       "         [-5.2616847e-01, -1.3081528e+00, -1.7955705e+00],\n",
       "         [-5.2616847e-01, -1.3081528e+00, -1.7955705e+00],\n",
       "         ...,\n",
       "         [ 6.6584182e-01, -5.9430767e-02, -3.7118366e-01],\n",
       "         [ 7.4626666e-01,  2.9993206e-02, -2.4543345e-01],\n",
       "         [ 6.7544258e-01,  3.8062716e-03, -2.6291505e-01]],\n",
       "\n",
       "        [[-5.2616847e-01, -1.3081528e+00, -1.7955705e+00],\n",
       "         [-5.2616847e-01, -1.3081528e+00, -1.7955705e+00],\n",
       "         [-5.2616847e-01, -1.3081528e+00, -1.7955705e+00],\n",
       "         ...,\n",
       "         [ 6.2311524e-01, -8.8717498e-02, -3.8572413e-01],\n",
       "         [ 5.5507278e-01, -1.4673840e-01, -4.0960887e-01],\n",
       "         [ 5.8381850e-01, -7.6966189e-02, -3.2292500e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 2.3893866e-01,  1.4691333e-01,  1.3056798e-01],\n",
       "         [ 3.6579943e-01,  2.7377412e-01,  2.6831433e-01],\n",
       "         [ 3.8595545e-01,  2.9392999e-01,  2.8847036e-01],\n",
       "         ...,\n",
       "         [ 5.2035898e-01, -1.0997863e+00, -1.1211282e+00],\n",
       "         [ 4.8855752e-01, -1.1315877e+00, -1.1326630e+00],\n",
       "         [ 5.0442624e-01, -1.1203153e+00, -1.0793290e+00]],\n",
       "\n",
       "        [[ 2.1622744e-01,  1.3968401e-01,  1.6518831e-01],\n",
       "         [ 3.1535599e-01,  2.2333065e-01,  2.4883480e-01],\n",
       "         [ 3.4712473e-01,  2.5509939e-01,  2.8060371e-01],\n",
       "         ...,\n",
       "         [ 4.5329529e-01, -1.1230348e+00, -1.1639640e+00],\n",
       "         [ 4.0521342e-01, -1.1720238e+00, -1.1796002e+00],\n",
       "         [ 5.0339532e-01, -1.0749003e+00, -1.0493960e+00]],\n",
       "\n",
       "        [[ 1.3459079e-01,  5.8047354e-02,  8.3551824e-02],\n",
       "         [ 1.2172510e-01,  2.9699937e-02,  5.5204090e-02],\n",
       "         [ 4.9422926e-01,  4.0220395e-01,  4.2770824e-01],\n",
       "         ...,\n",
       "         [ 5.9563136e-01, -9.6718216e-01, -1.0126169e+00],\n",
       "         [ 5.5042213e-01, -1.0268151e+00, -1.0343914e+00],\n",
       "         [ 4.1678461e-01, -1.1615108e+00, -1.1360066e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.5777789e+00,  1.6560552e+00,  1.1861361e+00],\n",
       "         [ 1.6124830e+00,  1.6907594e+00,  1.2208402e+00],\n",
       "         [ 1.5719584e+00,  1.6502351e+00,  1.1803157e+00],\n",
       "         ...,\n",
       "         [-1.5537997e+00, -1.5838971e+00, -1.5583929e+00],\n",
       "         [-1.5611874e+00, -1.5912848e+00, -1.5657804e+00],\n",
       "         [-1.6766448e+00, -1.7067419e+00, -1.6812378e+00]],\n",
       "\n",
       "        [[ 1.5920693e+00,  1.6703457e+00,  1.2004265e+00],\n",
       "         [ 1.5843416e+00,  1.6626179e+00,  1.1926988e+00],\n",
       "         [ 1.5910201e+00,  1.6692964e+00,  1.1993772e+00],\n",
       "         ...,\n",
       "         [-1.5949234e+00, -1.6250205e+00, -1.5995165e+00],\n",
       "         [-1.5873208e+00, -1.6174181e+00, -1.5919139e+00],\n",
       "         [-1.6906314e+00, -1.7207285e+00, -1.6952244e+00]],\n",
       "\n",
       "        [[ 1.5597113e+00,  1.6844341e+00,  1.1644403e+00],\n",
       "         [ 1.5039065e+00,  1.6286287e+00,  1.1086351e+00],\n",
       "         [ 1.5051353e+00,  1.6298578e+00,  1.1098639e+00],\n",
       "         ...,\n",
       "         [-1.6594278e+00, -1.6740431e+00, -1.6485389e+00],\n",
       "         [-1.5803735e+00, -1.5949889e+00, -1.5694846e+00],\n",
       "         [-1.6133199e+00, -1.6261210e+00, -1.6042454e+00]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "819ce578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78c5d50",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a70f6af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    inp = tf.keras.Input(shape=(CROP_HEIGHT, CROP_WIDTH, 3))\n",
    "\n",
    "    backbone = tf.keras.applications.MobileNetV3Large(include_top=False, input_shape=(CROP_HEIGHT, CROP_WIDTH, 3))\n",
    "    backbone.trainable = True\n",
    "    \n",
    "    finetune_layer_no = 10\n",
    "    for layer in backbone.layers[:finetune_layer_no]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    flat1 = tf.keras.layers.Flatten(name='flat1')\n",
    "    fc1 = tf.keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc1')\n",
    "    do1 = tf.keras.layers.Dropout(0.5, name='do1')\n",
    "\n",
    "    fc2 = tf.keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc2')\n",
    "    do2 = tf.keras.layers.Dropout(0.5, name='do2')\n",
    "\n",
    "    fc3 = tf.keras.layers.Dense(2, activation='softmax', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='fc3')\n",
    "\n",
    "    o = tf.keras.applications.mobilenet_v3.preprocess_input(inp)\n",
    "    o = backbone(o, training=False)\n",
    "    o = flat1(o)\n",
    "    o = fc1(o)\n",
    "    o = do1(o)\n",
    "\n",
    "    o = fc2(o)\n",
    "    o = do2(o)\n",
    "\n",
    "    o = fc3(o)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=o, name='baseline_1')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e962234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "model = createModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b73a21c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"baseline_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 227, 227, 3)]     0         \n",
      "                                                                 \n",
      " MobilenetV3large (Functiona  (None, 8, 8, 960)        2996352   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flat1 (Flatten)             (None, 61440)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 128)               7864448   \n",
      "                                                                 \n",
      " do1 (Dropout)               (None, 128)               0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 128)               16512     \n",
      "                                                                 \n",
      " do2 (Dropout)               (None, 128)               0         \n",
      "                                                                 \n",
      " fc3 (Dense)                 (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,877,570\n",
      "Trainable params: 10,852,530\n",
      "Non-trainable params: 25,040\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fcc28d",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ffbbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = 1000\n",
    "EPOCH = 100\n",
    "\n",
    "START_EPOCH = 0\n",
    "END_EPOCH = START_EPOCH + EPOCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cc17f1",
   "metadata": {},
   "source": [
    "#### Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1ab143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(epoch, lr):\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "222f6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logBasePath = \"log/baseline_mobilenet_5\"\n",
    "logPrefix = \"log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1b72905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 21:38:25.489921: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-09 21:38:25.490061: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-09 21:38:25.490099: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1665] Profiler found 1 GPUs\n",
      "2022-11-09 21:38:25.490547: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/home/ntcadmin/env/trt-11.0/TensorRT-7.1.3.4/lib:\n",
      "2022-11-09 21:38:25.490669: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so'; dlerror: libcupti.so: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/home/ntcadmin/env/trt-11.0/TensorRT-7.1.3.4/lib:\n",
      "2022-11-09 21:38:25.490705: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:135] cuptiGetTimestamp: error 999: \n",
      "2022-11-09 21:38:25.490734: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-09 21:38:25.490762: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-09 21:38:25.490785: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-11-09 21:38:25.490824: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-09 21:38:25.490857: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-09 21:38:25.490865: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-09 21:38:25.490870: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2022-11-09 21:38:27.417155: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 47s 12ms/step - loss: 0.6937 - accuracy: 0.5232\n",
      "Epoch 1/100\n",
      "   5/1000 [..............................] - ETA: 36s - loss: 0.7014 - accuracy: 0.5000   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 21:39:17.220892: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-09 21:39:17.220941: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-09 21:39:17.221010: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-09 21:39:17.221042: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-09 21:39:17.221064: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-09 21:39:17.221085: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   9/1000 [..............................] - ETA: 36s - loss: 0.7344 - accuracy: 0.3889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 21:39:17.551670: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-09 21:39:17.552825: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-09 21:39:17.552845: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-09 21:39:17.552852: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2022-11-09 21:39:17.626994: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-09 21:39:17.627023: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-09 21:39:17.627029: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-11-09 21:39:17.648017: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-09 21:39:17.665783: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_5/log_0/plugins/profile/2022_11_09_21_39_17\n",
      "\n",
      "2022-11-09 21:39:17.671872: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_mobilenet_5/log_0/plugins/profile/2022_11_09_21_39_17/ntcadmin-scse.trace.json.gz\n",
      "2022-11-09 21:39:17.742967: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_5/log_0/plugins/profile/2022_11_09_21_39_17\n",
      "\n",
      "2022-11-09 21:39:17.751721: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_mobilenet_5/log_0/plugins/profile/2022_11_09_21_39_17/ntcadmin-scse.memory_profile.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  16/1000 [..............................] - ETA: 47s - loss: 0.7314 - accuracy: 0.4219"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 21:39:17.753534: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_mobilenet_5/log_0/plugins/profile/2022_11_09_21_39_17\n",
      "Dumped tool data for xplane.pb to log/baseline_mobilenet_5/log_0/plugins/profile/2022_11_09_21_39_17/ntcadmin-scse.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_mobilenet_5/log_0/plugins/profile/2022_11_09_21_39_17/ntcadmin-scse.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_mobilenet_5/log_0/plugins/profile/2022_11_09_21_39_17/ntcadmin-scse.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_mobilenet_5/log_0/plugins/profile/2022_11_09_21_39_17/ntcadmin-scse.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_mobilenet_5/log_0/plugins/profile/2022_11_09_21_39_17/ntcadmin-scse.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 0.6717 - accuracy: 0.5840"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 21:40:35.541825: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1887436800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 84s 79ms/step - loss: 0.6717 - accuracy: 0.5840 - val_loss: 0.6941 - val_accuracy: 0.4808 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.6029 - accuracy: 0.6827"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 21:41:53.901880: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1887436800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.6028 - accuracy: 0.6830 - val_loss: 0.6399 - val_accuracy: 0.6696 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.5766 - accuracy: 0.7115"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 21:43:14.533852: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1887436800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.5766 - accuracy: 0.7115 - val_loss: 0.6089 - val_accuracy: 0.6672 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.5110 - accuracy: 0.7470"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 21:44:35.181479: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1887436800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.5111 - accuracy: 0.7470 - val_loss: 0.5416 - val_accuracy: 0.7310 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.4767 - accuracy: 0.7763"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 21:45:54.345522: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1887436800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.4767 - accuracy: 0.7763 - val_loss: 0.5328 - val_accuracy: 0.7364 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 77s 77ms/step - loss: 0.4542 - accuracy: 0.7908 - val_loss: 0.5050 - val_accuracy: 0.7563 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.5117 - accuracy: 0.7467 - val_loss: 0.4540 - val_accuracy: 0.7914 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.3981 - accuracy: 0.8202 - val_loss: 0.4497 - val_accuracy: 0.7863 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.4122 - accuracy: 0.8170 - val_loss: 0.4475 - val_accuracy: 0.7861 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.4241 - accuracy: 0.7985 - val_loss: 0.4295 - val_accuracy: 0.7936 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.3933 - accuracy: 0.8213 - val_loss: 0.4196 - val_accuracy: 0.8071 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.3619 - accuracy: 0.8393 - val_loss: 0.3993 - val_accuracy: 0.8132 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.3598 - accuracy: 0.8393 - val_loss: 0.4629 - val_accuracy: 0.7743 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.4054 - accuracy: 0.8105 - val_loss: 0.4020 - val_accuracy: 0.8133 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.3099 - accuracy: 0.8725 - val_loss: 0.4538 - val_accuracy: 0.7760 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.3122 - accuracy: 0.8698 - val_loss: 0.3746 - val_accuracy: 0.8335 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.3611 - accuracy: 0.8357 - val_loss: 0.4335 - val_accuracy: 0.7866 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.3194 - accuracy: 0.8630 - val_loss: 0.8107 - val_accuracy: 0.6588 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.3112 - accuracy: 0.8645 - val_loss: 0.3647 - val_accuracy: 0.8369 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.3031 - accuracy: 0.8668 - val_loss: 0.3550 - val_accuracy: 0.8386 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.3590 - accuracy: 0.8405 - val_loss: 0.5074 - val_accuracy: 0.7729 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.2664 - accuracy: 0.8905 - val_loss: 0.3729 - val_accuracy: 0.8406 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.2700 - accuracy: 0.8865 - val_loss: 0.3758 - val_accuracy: 0.8479 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.3016 - accuracy: 0.8710 - val_loss: 0.3562 - val_accuracy: 0.8323 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.2773 - accuracy: 0.8755 - val_loss: 0.3668 - val_accuracy: 0.8447 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.2617 - accuracy: 0.8865 - val_loss: 0.3140 - val_accuracy: 0.8626 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.2574 - accuracy: 0.8890 - val_loss: 0.3100 - val_accuracy: 0.8672 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.3090 - accuracy: 0.8635 - val_loss: 0.6824 - val_accuracy: 0.7293 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.2241 - accuracy: 0.9045 - val_loss: 0.3019 - val_accuracy: 0.8759 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.2421 - accuracy: 0.9005 - val_loss: 0.3195 - val_accuracy: 0.8679 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.2570 - accuracy: 0.8945 - val_loss: 0.2955 - val_accuracy: 0.8661 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.2515 - accuracy: 0.8885 - val_loss: 0.3880 - val_accuracy: 0.8495 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.2376 - accuracy: 0.8978 - val_loss: 0.3602 - val_accuracy: 0.8410 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.2311 - accuracy: 0.9068 - val_loss: 0.3470 - val_accuracy: 0.8488 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.2608 - accuracy: 0.8913 - val_loss: 0.3205 - val_accuracy: 0.8662 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.2071 - accuracy: 0.9160 - val_loss: 0.2728 - val_accuracy: 0.8886 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.2001 - accuracy: 0.9178 - val_loss: 0.3748 - val_accuracy: 0.8632 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.2349 - accuracy: 0.9020 - val_loss: 0.2627 - val_accuracy: 0.8865 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.2346 - accuracy: 0.8997 - val_loss: 0.3286 - val_accuracy: 0.8685 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.2120 - accuracy: 0.9135 - val_loss: 0.2752 - val_accuracy: 0.8835 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.2178 - accuracy: 0.9095 - val_loss: 0.2801 - val_accuracy: 0.8839 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.2281 - accuracy: 0.9015 - val_loss: 0.2573 - val_accuracy: 0.8886 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1840 - accuracy: 0.9225 - val_loss: 0.2299 - val_accuracy: 0.9009 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.1871 - accuracy: 0.9252 - val_loss: 0.3315 - val_accuracy: 0.8740 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.1966 - accuracy: 0.9218 - val_loss: 0.2524 - val_accuracy: 0.8944 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.2242 - accuracy: 0.8992 - val_loss: 0.2999 - val_accuracy: 0.8792 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1690 - accuracy: 0.9340 - val_loss: 0.3101 - val_accuracy: 0.8812 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1859 - accuracy: 0.9275 - val_loss: 0.2686 - val_accuracy: 0.8875 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.2006 - accuracy: 0.9190 - val_loss: 0.2520 - val_accuracy: 0.8901 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1565 - accuracy: 0.9337 - val_loss: 0.2723 - val_accuracy: 0.8909 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1727 - accuracy: 0.9330 - val_loss: 0.3136 - val_accuracy: 0.8815 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1654 - accuracy: 0.9310 - val_loss: 0.2633 - val_accuracy: 0.8970 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.2066 - accuracy: 0.9118 - val_loss: 0.2775 - val_accuracy: 0.8865 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1472 - accuracy: 0.9450 - val_loss: 0.4367 - val_accuracy: 0.8540 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1825 - accuracy: 0.9300 - val_loss: 0.3235 - val_accuracy: 0.8807 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1860 - accuracy: 0.9245 - val_loss: 0.2279 - val_accuracy: 0.9046 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1464 - accuracy: 0.9413 - val_loss: 0.2635 - val_accuracy: 0.9010 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1642 - accuracy: 0.9373 - val_loss: 0.2936 - val_accuracy: 0.8749 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1461 - accuracy: 0.9438 - val_loss: 0.2478 - val_accuracy: 0.9070 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1927 - accuracy: 0.9195 - val_loss: 0.2622 - val_accuracy: 0.8974 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1353 - accuracy: 0.9517 - val_loss: 0.2739 - val_accuracy: 0.8978 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1512 - accuracy: 0.9442 - val_loss: 0.2131 - val_accuracy: 0.9162 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1782 - accuracy: 0.9252 - val_loss: 0.5086 - val_accuracy: 0.7925 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1296 - accuracy: 0.9480 - val_loss: 0.2706 - val_accuracy: 0.8964 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 81s 82ms/step - loss: 0.1507 - accuracy: 0.9417 - val_loss: 0.2383 - val_accuracy: 0.9048 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1386 - accuracy: 0.9475 - val_loss: 0.2886 - val_accuracy: 0.8936 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1661 - accuracy: 0.9315 - val_loss: 0.2193 - val_accuracy: 0.9140 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1294 - accuracy: 0.9452 - val_loss: 0.2079 - val_accuracy: 0.9183 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.1267 - accuracy: 0.9513 - val_loss: 0.2067 - val_accuracy: 0.9208 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1612 - accuracy: 0.9380 - val_loss: 0.2357 - val_accuracy: 0.9019 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1232 - accuracy: 0.9523 - val_loss: 0.2166 - val_accuracy: 0.9096 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1254 - accuracy: 0.9548 - val_loss: 0.3211 - val_accuracy: 0.8907 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1304 - accuracy: 0.9480 - val_loss: 0.2226 - val_accuracy: 0.9140 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1479 - accuracy: 0.9417 - val_loss: 0.3369 - val_accuracy: 0.8749 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1198 - accuracy: 0.9535 - val_loss: 0.1878 - val_accuracy: 0.9240 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1109 - accuracy: 0.9585 - val_loss: 0.2028 - val_accuracy: 0.9202 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.1466 - accuracy: 0.9405 - val_loss: 0.2487 - val_accuracy: 0.8939 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.1172 - accuracy: 0.9535 - val_loss: 0.1878 - val_accuracy: 0.9235 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1186 - accuracy: 0.9535 - val_loss: 0.3177 - val_accuracy: 0.8901 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1168 - accuracy: 0.9553 - val_loss: 0.2609 - val_accuracy: 0.8970 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1443 - accuracy: 0.9438 - val_loss: 0.2750 - val_accuracy: 0.8933 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.0976 - accuracy: 0.9655 - val_loss: 0.1950 - val_accuracy: 0.9245 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1049 - accuracy: 0.9620 - val_loss: 0.1945 - val_accuracy: 0.9296 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1232 - accuracy: 0.9553 - val_loss: 0.1710 - val_accuracy: 0.9337 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1038 - accuracy: 0.9588 - val_loss: 0.3896 - val_accuracy: 0.8629 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1114 - accuracy: 0.9563 - val_loss: 0.2227 - val_accuracy: 0.9130 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1064 - accuracy: 0.9615 - val_loss: 0.2408 - val_accuracy: 0.9175 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1115 - accuracy: 0.9590 - val_loss: 0.2700 - val_accuracy: 0.9121 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.0933 - accuracy: 0.9655 - val_loss: 0.1843 - val_accuracy: 0.9286 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.0989 - accuracy: 0.9638 - val_loss: 0.1657 - val_accuracy: 0.9373 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.1156 - accuracy: 0.9572 - val_loss: 0.2502 - val_accuracy: 0.9060 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.0993 - accuracy: 0.9647 - val_loss: 0.2023 - val_accuracy: 0.9246 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1044 - accuracy: 0.9630 - val_loss: 0.2896 - val_accuracy: 0.8999 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.0987 - accuracy: 0.9622 - val_loss: 0.2182 - val_accuracy: 0.9241 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.1083 - accuracy: 0.9590 - val_loss: 0.3486 - val_accuracy: 0.8948 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 81s 82ms/step - loss: 0.0879 - accuracy: 0.9688 - val_loss: 0.8838 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.0911 - accuracy: 0.9668 - val_loss: 0.3088 - val_accuracy: 0.9008 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1011 - accuracy: 0.9625 - val_loss: 0.1721 - val_accuracy: 0.9314 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.1026 - accuracy: 0.9640 - val_loss: 0.1474 - val_accuracy: 0.9411 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.0916 - accuracy: 0.9635 - val_loss: 0.2112 - val_accuracy: 0.9244 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "for i, (train, val) in enumerate([folds[0]]):\n",
    "    \n",
    "    model = createModel()\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    metrics = ['accuracy']\n",
    "    \n",
    "    model.compile(optimizer=opt, loss=loss, metrics=metrics)\n",
    "    \n",
    "    tboardCb = tf.keras.callbacks.TensorBoard(log_dir=f\"{logBasePath}/{logPrefix}_{i}\", histogram_freq=1, profile_batch=(2,10))\n",
    "    lrSchedule = tf.keras.callbacks.LearningRateScheduler(schedule)\n",
    "    \n",
    "    cbs = [tboardCb, lrSchedule]\n",
    "    \n",
    "    model.evaluate(val)\n",
    "    model.fit(train, initial_epoch=START_EPOCH, epochs=END_EPOCH, steps_per_epoch=STEPS_PER_EPOCH, callbacks=cbs, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e841a27f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
