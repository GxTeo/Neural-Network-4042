{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f19017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d782ddf",
   "metadata": {},
   "source": [
    "### Check Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03faa827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac4996",
   "metadata": {},
   "source": [
    "### GPU Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1e955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2835bd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f935a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be867b6",
   "metadata": {},
   "source": [
    "### Pandas Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92db292",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_column', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0907c",
   "metadata": {},
   "source": [
    "### Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0fd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VAL_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf19fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_WIDTH = 227\n",
    "CROP_HEIGHT = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d40847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldFiles = [\"adience/unprocessed/fold_0_data.txt\",\n",
    "             \"adience/unprocessed/fold_1_data.txt\",\n",
    "             \"adience/unprocessed/fold_2_data.txt\",\n",
    "             \"adience/unprocessed/fold_3_data.txt\",\n",
    "             \"adience/unprocessed/fold_4_data.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f61c7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genderMap = defaultdict(lambda : np.NaN)\n",
    "genderMap['m'] = 0\n",
    "genderMap['f'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d26242",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = ['(0, 2)', '(4, 6)', '(8, 13)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
    "ageMap = defaultdict(lambda : np.NaN)\n",
    "for i,a in enumerate(ages):\n",
    "    ageMap[a] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b1fc3",
   "metadata": {},
   "source": [
    "### Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd634a3",
   "metadata": {},
   "source": [
    "Dataset generation pipeline:\n",
    "Input: \n",
    "- foldFile - Path to fold file. Fold file Describes which images are in the fold and its corresponding labels\n",
    "- imgBaseFolder - Base folder to search image from\n",
    "- imgPrefix - Prefix of image file\n",
    "- genderMap - Map from ['m', 'f', 'u', None], to one hot index\n",
    "- ageMap - Map from age category to one hot index\n",
    "- imgWidth - Resulting image width\n",
    "- imgHeigh - Resulting image height\n",
    "- batchSize - Int or None, batch size\n",
    "- configureDs - Function accepting dataset for performance configurations\n",
    "- preBatch - List of (name, functions) pair that will be mapped before batching. name is used as name parameters for tf graph \n",
    "- postBatch - List of (name, functions) that will be mapped after batching. name is used as name parameters for tf graph\n",
    "\n",
    "The processing functions should have signature function(img, label) -> (img, label)\n",
    "\n",
    "Pipeline\n",
    "\n",
    "Read Fold File -> Preprocess filename and labels (dataframe) -> Convert filename and labels to numpy array -> Convert filename and labels to tf dataset -> Parse images and labels -> Configure Dataset for performance -> Pre-Batching preprocessing -> Batch -> Post-Batching preprocessing -> Output\n",
    "\n",
    "Some preprocessing steps can only be done before and some can only be done after batching, thats why there are seperated pre and post batching list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0795464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, batchSize, configureDs=None, preBatch=[], postBatch=[]):\n",
    "    \n",
    "    def parseImage(filename):\n",
    "        img = tf.io.read_file(filename)\n",
    "        img = tf.image.decode_jpeg(img)\n",
    "        img = tf.image.resize(img, [imgHeight, imgWidth])\n",
    "         \n",
    "        return img\n",
    "    \n",
    "    # Read Fold File\n",
    "    foldData = []\n",
    "    for f in foldFiles:\n",
    "        foldData.append(pd.read_csv(f, sep=\"\\t\"))\n",
    "    foldData = pd.concat(foldData)\n",
    "    \n",
    "    # Form File Name\n",
    "    foldData['filename'] = foldData.apply(lambda r: os.path.join(imgBaseFolder, r['user_id'], f\"{imgPrefix}.{r['face_id']}.{r['original_image']}\"), axis=1)\n",
    "    \n",
    "    # Generate Label One Hot Index\n",
    "    foldData['gender_ind'] = foldData['gender'].map(genderMap)\n",
    "    foldData['age_ind'] = foldData['age'].map(ageMap)\n",
    "    \n",
    "    # Remove dirty data\n",
    "    foldData.dropna(subset=['gender_ind', 'age_ind'], inplace=True)\n",
    "    \n",
    "    # Dataframe to numpy\n",
    "    filenames = foldData['filename'].to_numpy()\n",
    "    \n",
    "    genderIndex = foldData['gender_ind'].to_numpy().astype(int)\n",
    "    ageIndex = foldData['age_ind'].to_numpy().astype(int)\n",
    "    \n",
    "    # Numpy to Dataset\n",
    "    fnDs = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    genderIndDs = tf.data.Dataset.from_tensor_slices(genderIndex)\n",
    "    ageIndDs = tf.data.Dataset.from_tensor_slices(ageIndex)\n",
    "    \n",
    "    # Parse Images\n",
    "    imageDs = fnDs.map(parseImage, num_parallel_calls=tf.data.AUTOTUNE, name=\"parse_image\")\n",
    "    \n",
    "    # Parse Labels\n",
    "    genderLabDs = genderIndDs.map(lambda x: tf.one_hot(x, genderDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"gender_one_hot\")\n",
    "    ageLabDs = ageIndDs.map(lambda x: tf.one_hot(x, ageDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"age_one_hot\")\n",
    "    \n",
    "    # Combine Labels\n",
    "    labelDs = tf.data.Dataset.zip((genderLabDs, ageLabDs), name=\"label_zip\")\n",
    "    labelDs = labelDs.map(lambda g,a: {\"gender\": g, \"age\": a}, num_parallel_calls=tf.data.AUTOTUNE, name='label_dict')\n",
    "    \n",
    "    # Combine Images and Labels into dataset\n",
    "    ds = tf.data.Dataset.zip((imageDs, labelDs))\n",
    "    \n",
    "    # Configure Performance\n",
    "    if(configureDs is not None):\n",
    "        ds = configureDs(ds)\n",
    "    \n",
    "    # Pre Batch Preprocessing\n",
    "    for n,f in preBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    # Batch\n",
    "    if(batchSize is not None):\n",
    "        ds = ds.batch(batchSize, name=\"ds_batch\")\n",
    "    \n",
    "    # Post Batch Preprocessing\n",
    "    for n,f in postBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320ed92",
   "metadata": {},
   "source": [
    "### Preprocessings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "472b7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=100)\n",
    "    ds = ds.repeat()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adb98feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313da7f1",
   "metadata": {},
   "source": [
    "#### Preprocessing steps according to the reference paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7724a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainPreprocessA(img, lab):\n",
    "        \n",
    "        img = tf.image.random_crop(img, [CROP_HEIGHT, CROP_WIDTH, 3])\n",
    "        \n",
    "        ud = tf.random.uniform([], dtype=tf.float32)\n",
    "        udCond = tf.less(ud, 0.5)\n",
    "        \n",
    "        img = tf.cond(udCond, lambda: tf.image.flip_up_down(img), lambda: img)\n",
    "        \n",
    "        lr = tf.random.uniform([], dtype=tf.float32)\n",
    "        lrCond = tf.less(lr, 0.5)\n",
    "        \n",
    "        img = tf.cond(lrCond, lambda: tf.image.flip_left_right(img), lambda: img)\n",
    "        \n",
    "        img = tf.image.random_brightness(img, 63/255)\n",
    "        \n",
    "        img = tf.image.random_contrast(img, 0.2, 1.8) \n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14ee59ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valPreprocessA(img, lab):\n",
    "        \n",
    "        img = tf.image.crop_to_bounding_box(img,\n",
    "                                            (IMG_HEIGHT-CROP_HEIGHT) // 2,\n",
    "                                            (IMG_WIDTH-CROP_WIDTH) // 2,\n",
    "                                            CROP_HEIGHT,\n",
    "                                            CROP_WIDTH)\n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a03ab680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageStandardize(img, lab):\n",
    "    \n",
    "    img = tf.image.per_image_standardization(img)\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ec104",
   "metadata": {},
   "source": [
    "#### Label extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "294a2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractGenderLabel(img, lab):\n",
    "    \n",
    "    lab = lab['gender']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a98897ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAgeLabel(img, lab):\n",
    "    \n",
    "    lab = lab['age']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7778c",
   "metadata": {},
   "source": [
    "### Generate Folds for K-Folds validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4172d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFoldDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, valBatchSize, trainConfigureDs=None, trainPreBatch=[], trainPostBatch=[], valConfigureDs=None, valPreBatch=[], valPostBatch=[]):\n",
    "    '''\n",
    "        Returns list of (train, validation) datasets\n",
    "    '''\n",
    "    \n",
    "    N = len(foldFiles)\n",
    "    \n",
    "    folds = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        trainFiles = foldFiles[:i]\n",
    "        if(i < N-1):\n",
    "            trainFiles.extend(foldFiles[i+1:])\n",
    "            \n",
    "        valFiles = foldFiles[i]\n",
    "        \n",
    "        trainDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, configureDs=trainConfigureDs, preBatch=trainPreBatch, postBatch=trainPostBatch)\n",
    "        valDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, valBatchSize, configureDs=valConfigureDs, preBatch=valPreBatch, postBatch=valPostBatch)\n",
    "        \n",
    "        folds.append((trainDs, valDs))\n",
    "        \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4f43dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPreBatch = [(\"train_process_a\", trainPreprocessA), \n",
    "                 (\"train_standardize\", imageStandardize), \n",
    "                 (\"train_extract_gender\", extractGenderLabel)]\n",
    "\n",
    "valPreBatch = [(\"val_process_a\", valPreprocessA), \n",
    "               (\"val_standardize\", imageStandardize), \n",
    "               (\"val_extract_gender\", extractGenderLabel)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10474d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 22:05:03.836252: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-07 22:05:04.338998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 626 MB memory:  -> device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "folds = generateFoldDs(foldFiles, \"adience/faces\", \"coarse_tilt_aligned_face\", genderMap, ageMap, 2, 8, \n",
    "                       IMG_WIDTH, IMG_HEIGHT, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE, \n",
    "                       trainConfigureDs=trainConfigPerformance, trainPreBatch=trainPreBatch, \n",
    "                       valConfigureDs=valConfigPerformance, valPreBatch=valPreBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57d814af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b5f9bc",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d0df0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in folds[0][0].take(1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c9e2833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 227, 227, 3), dtype=float32, numpy=\n",
       "array([[[[-0.02438345, -0.08879495, -1.2779995 ],\n",
       "         [-0.02807008, -0.09248158, -1.2816862 ],\n",
       "         [-0.07603936, -0.14044984, -1.2990865 ],\n",
       "         ...,\n",
       "         [ 1.3476785 ,  1.3291203 ,  0.27747446],\n",
       "         [ 1.3217552 ,  1.3031969 ,  0.25155115],\n",
       "         [ 1.3844782 ,  1.36592   ,  0.31427518]],\n",
       "\n",
       "        [[-0.02426042, -0.08867192, -1.2778765 ],\n",
       "         [ 0.04464967, -0.01976183, -1.1783974 ],\n",
       "         [-0.05166822, -0.11607972, -1.2747158 ],\n",
       "         ...,\n",
       "         [ 1.3809823 ,  1.362424  ,  0.3413467 ],\n",
       "         [ 1.382232  ,  1.3636737 ,  0.34259745],\n",
       "         [ 1.3233935 ,  1.3048352 ,  0.28375795]],\n",
       "\n",
       "        [[ 0.49992624,  0.43551576, -0.7536898 ],\n",
       "         [ 0.3764015 ,  0.31199   , -0.84664553],\n",
       "         [ 0.4521661 ,  0.42090252, -0.74878216],\n",
       "         ...,\n",
       "         [ 1.4469931 ,  1.4284348 ,  0.4073575 ],\n",
       "         [ 1.4017929 ,  1.3832346 ,  0.36215732],\n",
       "         [ 1.3489764 ,  1.3304181 ,  0.3093419 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.5599049 ,  1.5719162 ,  0.559914  ],\n",
       "         [ 1.5899588 ,  1.6019701 ,  0.6114612 ],\n",
       "         [ 1.5314442 ,  1.5434555 ,  0.5529467 ],\n",
       "         ...,\n",
       "         [ 1.5187502 ,  1.5001919 ,  0.29066166],\n",
       "         [ 1.5410053 ,  1.522447  ,  0.30267295],\n",
       "         [ 0.5512346 ,  0.5326764 , -0.68709666]],\n",
       "\n",
       "        [[ 1.6557153 ,  1.6677266 ,  0.6576354 ],\n",
       "         [ 1.6597536 ,  1.6717639 ,  0.66167265],\n",
       "         [ 1.5973997 ,  1.6094099 ,  0.59931874],\n",
       "         ...,\n",
       "         [ 1.4236225 ,  1.4050642 ,  0.1852902 ],\n",
       "         [ 1.5054994 ,  1.4869411 ,  0.2671681 ],\n",
       "         [ 1.2964399 ,  1.2778826 ,  0.05810855]],\n",
       "\n",
       "        [[ 1.5695059 ,  1.5815172 ,  0.56043994],\n",
       "         [ 1.603594  ,  1.6156042 ,  0.59452796],\n",
       "         [ 1.6088256 ,  1.6208358 ,  0.5997596 ],\n",
       "         ...,\n",
       "         [ 1.535867  ,  1.5323546 ,  0.26744387],\n",
       "         [ 1.5267652 ,  1.5173753 ,  0.2700971 ],\n",
       "         [ 1.2231491 ,  1.2045908 , -0.01518224]]],\n",
       "\n",
       "\n",
       "       [[[-1.3532013 , -1.3172456 , -1.2732618 ],\n",
       "         [-1.3532013 , -1.3172456 , -1.2732618 ],\n",
       "         [-1.3532013 , -1.3172456 , -1.2732618 ],\n",
       "         ...,\n",
       "         [-1.1553886 , -1.1761012 , -1.1476779 ],\n",
       "         [-1.1955056 , -1.15955   , -1.1452937 ],\n",
       "         [-1.224032  , -1.1880764 , -1.1738201 ]],\n",
       "\n",
       "        [[-1.3532013 , -1.3172456 , -1.2732618 ],\n",
       "         [-1.3532013 , -1.3172456 , -1.2732618 ],\n",
       "         [-1.3532013 , -1.3172456 , -1.2732618 ],\n",
       "         ...,\n",
       "         [-1.1729087 , -1.1511202 , -1.1368638 ],\n",
       "         [-1.2103695 , -1.1744137 , -1.1601576 ],\n",
       "         [-1.2342908 , -1.1983352 , -1.1840789 ]],\n",
       "\n",
       "        [[-1.2928171 , -1.2568613 , -1.2426051 ],\n",
       "         [-1.3011779 , -1.2652223 , -1.2509661 ],\n",
       "         [-1.293746  , -1.2577904 , -1.2435341 ],\n",
       "         ...,\n",
       "         [-1.1755323 , -1.1537437 , -1.1394876 ],\n",
       "         [-1.1938798 , -1.1579242 , -1.1436679 ],\n",
       "         [-1.241955  , -1.2059993 , -1.191743  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.3532013 , -1.3172456 , -1.2732618 ],\n",
       "         [-1.3532013 , -1.3172456 , -1.2732618 ],\n",
       "         [-1.3532013 , -1.3172456 , -1.2732618 ],\n",
       "         ...,\n",
       "         [ 0.5282783 , -0.07751151, -0.1641121 ],\n",
       "         [ 0.4751735 , -0.2601846 , -0.21790995],\n",
       "         [ 0.47837785, -0.39700353, -0.26716802]],\n",
       "\n",
       "        [[-1.3532013 , -1.3172456 , -1.2732618 ],\n",
       "         [-1.3532013 , -1.3172456 , -1.2732618 ],\n",
       "         [-1.3532013 , -1.3172456 , -1.2732618 ],\n",
       "         ...,\n",
       "         [ 0.61532366,  0.0532435 , -0.04792695],\n",
       "         [ 0.55281657, -0.18036428, -0.14135554],\n",
       "         [ 0.49827117, -0.37989345, -0.25693828]],\n",
       "\n",
       "        [[-1.3532013 , -1.3172456 , -1.2732618 ],\n",
       "         [-1.3532013 , -1.3172456 , -1.2732618 ],\n",
       "         [-1.3532013 , -1.3172456 , -1.2732618 ],\n",
       "         ...,\n",
       "         [ 0.701716  ,  0.2045887 ,  0.04164055],\n",
       "         [ 0.6189307 , -0.03395798, -0.07497652],\n",
       "         [ 0.5593195 , -0.25707108, -0.20077807]]],\n",
       "\n",
       "\n",
       "       [[[-1.9355255 , -2.0544608 , -2.1104178 ],\n",
       "         [-1.9058642 , -2.0247996 , -2.0807564 ],\n",
       "         [-1.9088291 , -2.0277643 , -2.0837214 ],\n",
       "         ...,\n",
       "         [ 0.36761388, -0.06182418, -0.4972844 ],\n",
       "         [ 0.42459914, -0.00483894, -0.4057988 ],\n",
       "         [ 0.4390613 ,  0.00962323, -0.39133677]],\n",
       "\n",
       "        [[-1.9282902 , -2.0472255 , -2.1031826 ],\n",
       "         [-1.8611217 , -1.9800569 , -2.043022  ],\n",
       "         [-1.9052366 , -2.024172  , -2.097017  ],\n",
       "         ...,\n",
       "         [ 0.3336905 , -0.09574758, -0.49670744],\n",
       "         [ 0.3605891 , -0.0653449 , -0.4663049 ],\n",
       "         [ 0.29407328, -0.1318607 , -0.5328209 ]],\n",
       "\n",
       "        [[-1.9034132 , -2.0223484 , -2.0783055 ],\n",
       "         [-1.9319837 , -2.050919  , -2.1228037 ],\n",
       "         [-1.8876497 , -2.006585  , -2.0970423 ],\n",
       "         ...,\n",
       "         [ 0.26979423, -0.16907759, -0.5417364 ],\n",
       "         [ 0.25462034, -0.1575676 , -0.5585276 ],\n",
       "         [ 0.26040682, -0.15178113, -0.552741  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.73501   , -1.3557918 , -0.9263567 ],\n",
       "         [-0.87019813, -1.4375615 , -1.0331551 ],\n",
       "         [-0.8546198 , -1.3785379 , -1.0381373 ],\n",
       "         ...,\n",
       "         [-1.4304702 , -1.4976549 , -1.4296012 ],\n",
       "         [-1.389981  , -1.457166  , -1.3578717 ],\n",
       "         [-1.3830954 , -1.4494085 , -1.350114  ]],\n",
       "\n",
       "        [[-0.7297627 , -1.3834528 , -0.904655  ],\n",
       "         [-0.7285961 , -1.3512897 , -0.92424256],\n",
       "         [-0.7196425 , -1.332633  , -0.9241836 ],\n",
       "         ...,\n",
       "         [-1.4394995 , -1.4835044 , -1.4303005 ],\n",
       "         [-1.4456608 , -1.5128456 , -1.4135514 ],\n",
       "         [-1.3944706 , -1.4616554 , -1.362361  ]],\n",
       "\n",
       "        [[-0.664784  , -1.3529743 , -0.85692644],\n",
       "         [-0.72236735, -1.3943603 , -0.907085  ],\n",
       "         [-0.70224077, -1.3386807 , -0.91163343],\n",
       "         ...,\n",
       "         [-1.4219209 , -1.4891056 , -1.4243116 ],\n",
       "         [-1.463071  , -1.5130056 , -1.4137113 ],\n",
       "         [-1.4438415 , -1.4937761 , -1.3944818 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.6034566 , -1.6039261 , -1.6319624 ],\n",
       "         [-1.603839  , -1.6043086 , -1.632345  ],\n",
       "         [-1.5944301 , -1.5948995 , -1.6229359 ],\n",
       "         ...,\n",
       "         [-1.5191867 , -1.4976726 , -1.6422    ],\n",
       "         [-1.4521024 , -1.4670765 , -1.5531318 ],\n",
       "         [-1.4899507 , -1.5049249 , -1.5909802 ]],\n",
       "\n",
       "        [[-1.6115658 , -1.5760003 , -1.6160483 ],\n",
       "         [-1.6080283 , -1.5724626 , -1.6125106 ],\n",
       "         [-1.6109744 , -1.5754089 , -1.6154569 ],\n",
       "         ...,\n",
       "         [-1.4665185 , -1.4524834 , -1.5820528 ],\n",
       "         [-1.4462488 , -1.461223  , -1.5472784 ],\n",
       "         [-1.4443861 , -1.4593605 , -1.5454156 ]],\n",
       "\n",
       "        [[-1.5831478 , -1.5401031 , -1.5826442 ],\n",
       "         [-1.5504626 , -1.5074179 , -1.5499591 ],\n",
       "         [-1.5776484 , -1.5346037 , -1.5771447 ],\n",
       "         ...,\n",
       "         [-1.5686431 , -1.5546079 , -1.6551679 ],\n",
       "         [-1.5040022 , -1.5189763 , -1.6050316 ],\n",
       "         [-1.4829249 , -1.4978993 , -1.5839545 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.6449246 ,  1.760493  ,  1.6309236 ],\n",
       "         [ 1.6234579 ,  1.7390262 ,  1.6094569 ],\n",
       "         [ 1.636663  ,  1.7522314 ,  1.6226621 ],\n",
       "         ...,\n",
       "         [-0.11071161, -0.06766691, -0.3422838 ],\n",
       "         [ 0.03667293,  0.05070818, -0.20940404],\n",
       "         [-0.04342887, -0.02939376, -0.28950584]],\n",
       "\n",
       "        [[ 1.839843  ,  1.911897  ,  1.7968324 ],\n",
       "         [ 1.8213258 ,  1.89338   ,  1.7783152 ],\n",
       "         [ 1.8803506 ,  1.9403929 ,  1.83734   ],\n",
       "         ...,\n",
       "         [-0.49395037, -0.40739158, -0.6965131 ],\n",
       "         [-0.5067234 , -0.4926883 , -0.7528004 ],\n",
       "         [-0.500661  , -0.48662576, -0.746738  ]],\n",
       "\n",
       "        [[ 1.8962752 ,  1.9513315 ,  1.8437461 ],\n",
       "         [ 1.8847063 ,  1.9397626 ,  1.8321769 ],\n",
       "         [ 1.8925995 ,  1.9476559 ,  1.8400705 ],\n",
       "         ...,\n",
       "         [-0.5228714 , -0.44025388, -0.7214927 ],\n",
       "         [-0.41393712, -0.37126777, -0.64569694],\n",
       "         [-0.50224733, -0.48322624, -0.7458313 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "819ce578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78c5d50",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a70f6af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    inp = tf.keras.Input(shape=(CROP_HEIGHT, CROP_WIDTH, 3))\n",
    "\n",
    "    backbone = tf.keras.applications.MobileNetV3Large(include_top=False, input_shape=(CROP_HEIGHT, CROP_WIDTH, 3))\n",
    "    backbone.trainable = False    \n",
    "    \n",
    "    flat1 = tf.keras.layers.Flatten(name='flat1')\n",
    "    fc1 = tf.keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc1')\n",
    "    do1 = tf.keras.layers.Dropout(0.5, name='do1')\n",
    "\n",
    "    fc2 = tf.keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc2')\n",
    "    do2 = tf.keras.layers.Dropout(0.5, name='do2')\n",
    "\n",
    "    fc3 = tf.keras.layers.Dense(2, activation='softmax', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='fc3')\n",
    "\n",
    "    o = tf.keras.applications.mobilenet_v3.preprocess_input(inp)\n",
    "    o = backbone(o, training=False)\n",
    "    o = flat1(o)\n",
    "    o = fc1(o)\n",
    "    o = do1(o)\n",
    "\n",
    "    o = fc2(o)\n",
    "    o = do2(o)\n",
    "\n",
    "    o = fc3(o)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=o, name='baseline_1')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e962234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5\n",
      "12683000/12683000 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = createModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b73a21c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"baseline_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 227, 227, 3)]     0         \n",
      "                                                                 \n",
      " MobilenetV3large (Functiona  (None, 8, 8, 960)        2996352   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flat1 (Flatten)             (None, 61440)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 128)               7864448   \n",
      "                                                                 \n",
      " do1 (Dropout)               (None, 128)               0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 128)               16512     \n",
      "                                                                 \n",
      " do2 (Dropout)               (None, 128)               0         \n",
      "                                                                 \n",
      " fc3 (Dense)                 (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,877,570\n",
      "Trainable params: 7,881,218\n",
      "Non-trainable params: 2,996,352\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fcc28d",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ffbbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = 1000\n",
    "EPOCH = 100\n",
    "\n",
    "START_EPOCH = 0\n",
    "END_EPOCH = START_EPOCH + EPOCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cc17f1",
   "metadata": {},
   "source": [
    "#### Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1ab143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(epoch, lr):\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "222f6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logBasePath = \"log/baseline_mobilenet_1\"\n",
    "logPrefix = \"log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1b72905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 22:07:22.562911: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-07 22:07:22.562933: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-07 22:07:22.562957: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1665] Profiler found 1 GPUs\n",
      "2022-11-07 22:07:22.563195: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/home/ntcadmin/env/trt-11.0/TensorRT-7.1.3.4/lib:\n",
      "2022-11-07 22:07:22.563300: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so'; dlerror: libcupti.so: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/home/ntcadmin/env/trt-11.0/TensorRT-7.1.3.4/lib:\n",
      "2022-11-07 22:07:22.563314: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:135] cuptiGetTimestamp: error 999: \n",
      "2022-11-07 22:07:22.563325: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-07 22:07:22.563329: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-07 22:07:22.563333: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-11-07 22:07:22.563371: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-07 22:07:22.563390: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-07 22:07:22.563394: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-07 22:07:22.563397: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2022-11-07 22:07:24.723113: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-11-07 22:07:25.688388: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.689499: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 230.40M (241592064 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.690595: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 207.36M (217433088 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.691706: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 186.62M (195689984 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.692829: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 167.96M (176121088 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.692864: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 154.13MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-07 22:07:25.694003: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.694030: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 154.13MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-07 22:07:25.700788: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.700832: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 73.76MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-07 22:07:25.702022: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.702061: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 73.76MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-07 22:07:25.707372: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.707404: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 74.79MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-07 22:07:25.708508: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.708533: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 74.79MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-07 22:07:25.713801: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.713835: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 80.97MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-07 22:07:25.714930: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.714945: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 80.97MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-07 22:07:25.757019: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.757062: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 97.05MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-07 22:07:25.759117: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.759165: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 97.05MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-07 22:07:25.766019: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.768188: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.794676: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.795808: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.802496: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.803631: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.808997: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.810159: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.816799: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.818983: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.825680: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.827061: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 256.00M (268435456 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.834437: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.836438: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.842471: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.844403: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.851337: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.852458: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.858596: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.859751: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.865401: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.866528: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.882164: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:07:25.884312: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 49s 13ms/step - loss: 0.7092 - accuracy: 0.4768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 22:08:11.602696: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.604214: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.609488: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.610599: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.615961: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.618162: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.623332: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.624444: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.662612: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.663723: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.694405: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.696570: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.702892: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.704064: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.709089: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.710212: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.715426: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.716521: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.721780: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.722909: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.728332: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.729430: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.734469: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.735566: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.740894: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.742006: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.747676: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.748772: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.753910: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.755082: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.769940: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-11-07 22:08:11.771051: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 372.31M (390397952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   9/1000 [..............................] - ETA: 14s - loss: 0.6356 - accuracy: 0.7222 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 22:08:14.972161: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-07 22:08:14.972185: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-07 22:08:14.972457: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-07 22:08:14.972472: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-07 22:08:14.972479: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-07 22:08:14.972485: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-11-07 22:08:15.101062: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-07 22:08:15.101502: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-07 22:08:15.101512: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-07 22:08:15.101517: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2022-11-07 22:08:15.129823: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-07 22:08:15.129856: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-07 22:08:15.129862: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-11-07 22:08:15.138897: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-07 22:08:15.148889: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_1/log_0/plugins/profile/2022_11_07_22_08_15\n",
      "\n",
      "2022-11-07 22:08:15.156562: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_mobilenet_1/log_0/plugins/profile/2022_11_07_22_08_15/ntcadmin-scse.trace.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  24/1000 [..............................] - ETA: 17s - loss: 0.6480 - accuracy: 0.6771"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 22:08:15.197369: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_1/log_0/plugins/profile/2022_11_07_22_08_15\n",
      "\n",
      "2022-11-07 22:08:15.203681: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_mobilenet_1/log_0/plugins/profile/2022_11_07_22_08_15/ntcadmin-scse.memory_profile.json.gz\n",
      "2022-11-07 22:08:15.204810: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_mobilenet_1/log_0/plugins/profile/2022_11_07_22_08_15\n",
      "Dumped tool data for xplane.pb to log/baseline_mobilenet_1/log_0/plugins/profile/2022_11_07_22_08_15/ntcadmin-scse.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_mobilenet_1/log_0/plugins/profile/2022_11_07_22_08_15/ntcadmin-scse.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_mobilenet_1/log_0/plugins/profile/2022_11_07_22_08_15/ntcadmin-scse.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_mobilenet_1/log_0/plugins/profile/2022_11_07_22_08_15/ntcadmin-scse.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_mobilenet_1/log_0/plugins/profile/2022_11_07_22_08_15/ntcadmin-scse.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 0.6767 - accuracy: 0.5832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 22:09:07.891757: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 27095040 exceeds 10% of free system memory.\n",
      "2022-11-07 22:09:07.907596: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 27095040 exceeds 10% of free system memory.\n",
      "2022-11-07 22:09:07.987345: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 27095040 exceeds 10% of free system memory.\n",
      "2022-11-07 22:09:08.003648: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 27095040 exceeds 10% of free system memory.\n",
      "2022-11-07 22:09:08.015493: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 25804800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 57s 54ms/step - loss: 0.6767 - accuracy: 0.5832 - val_loss: 0.6734 - val_accuracy: 0.5611 - lr: 5.0000e-05\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.6434 - accuracy: 0.6463 - val_loss: 0.6587 - val_accuracy: 0.6069 - lr: 5.0000e-05\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.6209 - accuracy: 0.6520 - val_loss: 0.6304 - val_accuracy: 0.6478 - lr: 5.0000e-05\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.6207 - accuracy: 0.6600 - val_loss: 0.7223 - val_accuracy: 0.5396 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.5875 - accuracy: 0.6948 - val_loss: 0.5876 - val_accuracy: 0.6919 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.5712 - accuracy: 0.7010 - val_loss: 0.6193 - val_accuracy: 0.6546 - lr: 5.0000e-05\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.6050 - accuracy: 0.6658 - val_loss: 0.5793 - val_accuracy: 0.6873 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.5783 - accuracy: 0.6952 - val_loss: 0.5615 - val_accuracy: 0.7077 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.5754 - accuracy: 0.6998 - val_loss: 0.5810 - val_accuracy: 0.6931 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.5706 - accuracy: 0.6935 - val_loss: 0.5632 - val_accuracy: 0.7017 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.5791 - accuracy: 0.6975 - val_loss: 0.5643 - val_accuracy: 0.7157 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.5610 - accuracy: 0.7117 - val_loss: 0.5547 - val_accuracy: 0.7141 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.5507 - accuracy: 0.7207 - val_loss: 0.5491 - val_accuracy: 0.7180 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.5784 - accuracy: 0.6873 - val_loss: 0.5736 - val_accuracy: 0.6793 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.5368 - accuracy: 0.7337 - val_loss: 0.5298 - val_accuracy: 0.7310 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.5492 - accuracy: 0.7325 - val_loss: 0.6323 - val_accuracy: 0.6321 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5490 - accuracy: 0.7140 - val_loss: 0.5316 - val_accuracy: 0.7339 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.5566 - accuracy: 0.7078 - val_loss: 0.8642 - val_accuracy: 0.5674 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 58s 59ms/step - loss: 0.5454 - accuracy: 0.7362 - val_loss: 0.5446 - val_accuracy: 0.7142 - lr: 5.0000e-05\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5348 - accuracy: 0.7245 - val_loss: 0.5513 - val_accuracy: 0.7150 - lr: 5.0000e-05\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.5693 - accuracy: 0.6957 - val_loss: 0.7161 - val_accuracy: 0.6024 - lr: 5.0000e-05\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 58s 59ms/step - loss: 0.5276 - accuracy: 0.7370 - val_loss: 0.5095 - val_accuracy: 0.7480 - lr: 5.0000e-05\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 58s 59ms/step - loss: 0.5228 - accuracy: 0.7467 - val_loss: 0.5127 - val_accuracy: 0.7417 - lr: 5.0000e-05\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5385 - accuracy: 0.7215 - val_loss: 0.6205 - val_accuracy: 0.6599 - lr: 5.0000e-05\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5469 - accuracy: 0.7170 - val_loss: 0.5106 - val_accuracy: 0.7412 - lr: 5.0000e-05\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5160 - accuracy: 0.7490 - val_loss: 0.5084 - val_accuracy: 0.7515 - lr: 5.0000e-05\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5415 - accuracy: 0.7270 - val_loss: 0.5370 - val_accuracy: 0.7196 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5594 - accuracy: 0.7090 - val_loss: 0.5746 - val_accuracy: 0.6875 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5215 - accuracy: 0.7433 - val_loss: 0.5008 - val_accuracy: 0.7539 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.5092 - accuracy: 0.7592 - val_loss: 0.6651 - val_accuracy: 0.6406 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5308 - accuracy: 0.7275 - val_loss: 0.5144 - val_accuracy: 0.7377 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5241 - accuracy: 0.7358 - val_loss: 0.5255 - val_accuracy: 0.7245 - lr: 5.0000e-05\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5026 - accuracy: 0.7585 - val_loss: 0.6163 - val_accuracy: 0.6621 - lr: 5.0000e-05\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5300 - accuracy: 0.7285 - val_loss: 0.8241 - val_accuracy: 0.5790 - lr: 5.0000e-05\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5385 - accuracy: 0.7157 - val_loss: 0.5298 - val_accuracy: 0.7167 - lr: 5.0000e-05\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5074 - accuracy: 0.7527 - val_loss: 0.4860 - val_accuracy: 0.7599 - lr: 5.0000e-05\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4985 - accuracy: 0.7565 - val_loss: 0.5442 - val_accuracy: 0.7138 - lr: 5.0000e-05\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5247 - accuracy: 0.7272 - val_loss: 0.5068 - val_accuracy: 0.7571 - lr: 5.0000e-05\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5162 - accuracy: 0.7370 - val_loss: 0.4918 - val_accuracy: 0.7582 - lr: 5.0000e-05\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4973 - accuracy: 0.7692 - val_loss: 0.5070 - val_accuracy: 0.7462 - lr: 5.0000e-05\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5218 - accuracy: 0.7393 - val_loss: 0.5277 - val_accuracy: 0.7212 - lr: 5.0000e-05\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5195 - accuracy: 0.7365 - val_loss: 0.5057 - val_accuracy: 0.7442 - lr: 5.0000e-05\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4915 - accuracy: 0.7675 - val_loss: 0.4846 - val_accuracy: 0.7651 - lr: 5.0000e-05\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4847 - accuracy: 0.7710 - val_loss: 0.5650 - val_accuracy: 0.7144 - lr: 5.0000e-05\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5078 - accuracy: 0.7380 - val_loss: 0.4822 - val_accuracy: 0.7663 - lr: 5.0000e-05\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.5273 - accuracy: 0.7228 - val_loss: 0.4809 - val_accuracy: 0.7662 - lr: 5.0000e-05\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4738 - accuracy: 0.7782 - val_loss: 0.5562 - val_accuracy: 0.7164 - lr: 5.0000e-05\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5311 - accuracy: 0.7395 - val_loss: 0.4850 - val_accuracy: 0.7698 - lr: 5.0000e-05\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5134 - accuracy: 0.7340 - val_loss: 0.4930 - val_accuracy: 0.7541 - lr: 5.0000e-05\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5053 - accuracy: 0.7525 - val_loss: 0.4720 - val_accuracy: 0.7698 - lr: 5.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4823 - accuracy: 0.7692 - val_loss: 0.6629 - val_accuracy: 0.6704 - lr: 5.0000e-05\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4882 - accuracy: 0.7648 - val_loss: 0.4753 - val_accuracy: 0.7683 - lr: 5.0000e-05\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5207 - accuracy: 0.7355 - val_loss: 0.4639 - val_accuracy: 0.7756 - lr: 5.0000e-05\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4723 - accuracy: 0.7763 - val_loss: 0.4791 - val_accuracy: 0.7728 - lr: 5.0000e-05\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5317 - accuracy: 0.7265 - val_loss: 0.4777 - val_accuracy: 0.7698 - lr: 5.0000e-05\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.5081 - accuracy: 0.7408 - val_loss: 0.4661 - val_accuracy: 0.7778 - lr: 5.0000e-05\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.4909 - accuracy: 0.7670 - val_loss: 0.4653 - val_accuracy: 0.7713 - lr: 5.0000e-05\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.4790 - accuracy: 0.7678 - val_loss: 0.6372 - val_accuracy: 0.6698 - lr: 5.0000e-05\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.4847 - accuracy: 0.7667 - val_loss: 0.5025 - val_accuracy: 0.7505 - lr: 5.0000e-05\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.5254 - accuracy: 0.7222 - val_loss: 0.4645 - val_accuracy: 0.7724 - lr: 5.0000e-05\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.4568 - accuracy: 0.7853 - val_loss: 0.4920 - val_accuracy: 0.7683 - lr: 5.0000e-05\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4981 - accuracy: 0.7567 - val_loss: 0.4528 - val_accuracy: 0.7838 - lr: 5.0000e-05\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 58s 59ms/step - loss: 0.4974 - accuracy: 0.7542 - val_loss: 0.4901 - val_accuracy: 0.7554 - lr: 5.0000e-05\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4780 - accuracy: 0.7680 - val_loss: 0.4591 - val_accuracy: 0.7732 - lr: 5.0000e-05\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.4768 - accuracy: 0.7717 - val_loss: 0.4537 - val_accuracy: 0.7872 - lr: 5.0000e-05\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4789 - accuracy: 0.7705 - val_loss: 0.4730 - val_accuracy: 0.7634 - lr: 5.0000e-05\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5191 - accuracy: 0.7327 - val_loss: 0.4711 - val_accuracy: 0.7715 - lr: 5.0000e-05\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4613 - accuracy: 0.7885 - val_loss: 0.4430 - val_accuracy: 0.7873 - lr: 5.0000e-05\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4866 - accuracy: 0.7663 - val_loss: 0.4496 - val_accuracy: 0.7879 - lr: 5.0000e-05\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4888 - accuracy: 0.7567 - val_loss: 0.4503 - val_accuracy: 0.7807 - lr: 5.0000e-05\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4862 - accuracy: 0.7538 - val_loss: 0.5830 - val_accuracy: 0.7019 - lr: 5.0000e-05\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4713 - accuracy: 0.7780 - val_loss: 0.4643 - val_accuracy: 0.7755 - lr: 5.0000e-05\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4778 - accuracy: 0.7642 - val_loss: 0.4564 - val_accuracy: 0.7810 - lr: 5.0000e-05\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5186 - accuracy: 0.7280 - val_loss: 0.4581 - val_accuracy: 0.7729 - lr: 5.0000e-05\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4445 - accuracy: 0.7900 - val_loss: 0.4404 - val_accuracy: 0.7870 - lr: 5.0000e-05\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4827 - accuracy: 0.7660 - val_loss: 0.4605 - val_accuracy: 0.7754 - lr: 5.0000e-05\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4864 - accuracy: 0.7548 - val_loss: 0.4522 - val_accuracy: 0.7802 - lr: 5.0000e-05\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4766 - accuracy: 0.7625 - val_loss: 0.5840 - val_accuracy: 0.7187 - lr: 5.0000e-05\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4634 - accuracy: 0.7800 - val_loss: 0.4498 - val_accuracy: 0.7846 - lr: 5.0000e-05\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4732 - accuracy: 0.7760 - val_loss: 0.4991 - val_accuracy: 0.7429 - lr: 5.0000e-05\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5130 - accuracy: 0.7385 - val_loss: 0.4901 - val_accuracy: 0.7436 - lr: 5.0000e-05\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4472 - accuracy: 0.7883 - val_loss: 0.4431 - val_accuracy: 0.7818 - lr: 5.0000e-05\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4645 - accuracy: 0.7840 - val_loss: 0.5510 - val_accuracy: 0.7133 - lr: 5.0000e-05\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4840 - accuracy: 0.7548 - val_loss: 0.4687 - val_accuracy: 0.7641 - lr: 5.0000e-05\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4793 - accuracy: 0.7607 - val_loss: 0.6630 - val_accuracy: 0.6755 - lr: 5.0000e-05\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 58s 59ms/step - loss: 0.4566 - accuracy: 0.7925 - val_loss: 0.4354 - val_accuracy: 0.7898 - lr: 5.0000e-05\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4664 - accuracy: 0.7685 - val_loss: 0.5228 - val_accuracy: 0.7507 - lr: 5.0000e-05\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5009 - accuracy: 0.7455 - val_loss: 0.5563 - val_accuracy: 0.7039 - lr: 5.0000e-05\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4442 - accuracy: 0.7915 - val_loss: 0.4241 - val_accuracy: 0.7914 - lr: 5.0000e-05\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.4666 - accuracy: 0.7747 - val_loss: 0.4332 - val_accuracy: 0.7905 - lr: 5.0000e-05\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4769 - accuracy: 0.7625 - val_loss: 0.5412 - val_accuracy: 0.7158 - lr: 5.0000e-05\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4740 - accuracy: 0.7682 - val_loss: 0.4288 - val_accuracy: 0.7917 - lr: 5.0000e-05\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4502 - accuracy: 0.7918 - val_loss: 0.4861 - val_accuracy: 0.7524 - lr: 5.0000e-05\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4638 - accuracy: 0.7720 - val_loss: 0.5701 - val_accuracy: 0.7012 - lr: 5.0000e-05\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4947 - accuracy: 0.7452 - val_loss: 0.4803 - val_accuracy: 0.7626 - lr: 5.0000e-05\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4439 - accuracy: 0.7922 - val_loss: 0.4971 - val_accuracy: 0.7409 - lr: 5.0000e-05\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4536 - accuracy: 0.7847 - val_loss: 0.5878 - val_accuracy: 0.6776 - lr: 5.0000e-05\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4671 - accuracy: 0.7775 - val_loss: 0.4432 - val_accuracy: 0.7870 - lr: 5.0000e-05\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.4786 - accuracy: 0.7607 - val_loss: 0.4398 - val_accuracy: 0.7853 - lr: 5.0000e-05\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4531 - accuracy: 0.7893 - val_loss: 0.4577 - val_accuracy: 0.7687 - lr: 5.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 23:45:27.560899: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-07 23:45:27.560924: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-07 23:45:27.563726: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-07 23:45:27.563940: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-07 23:45:27.563981: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-07 23:45:27.563989: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-11-07 23:45:27.564547: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-07 23:45:27.564630: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-07 23:45:27.564647: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-07 23:45:27.564659: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 50s 14ms/step - loss: 0.6941 - accuracy: 0.4768\n",
      "Epoch 1/100\n",
      "   8/1000 [..............................] - ETA: 16s - loss: 0.6972 - accuracy: 0.5000 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 23:46:20.196911: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-07 23:46:20.196931: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-07 23:46:20.197065: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-07 23:46:20.197074: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-07 23:46:20.197078: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-07 23:46:20.197083: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  10/1000 [..............................] - ETA: 57s - loss: 0.6998 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 23:46:20.574473: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-07 23:46:20.579588: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-07 23:46:20.579608: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-07 23:46:20.579613: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2022-11-07 23:46:20.612407: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-07 23:46:20.612435: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-07 23:46:20.612442: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-11-07 23:46:20.626755: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-07 23:46:20.643455: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_1/log_1/plugins/profile/2022_11_07_23_46_20\n",
      "\n",
      "2022-11-07 23:46:20.649579: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_mobilenet_1/log_1/plugins/profile/2022_11_07_23_46_20/ntcadmin-scse.trace.json.gz\n",
      "2022-11-07 23:46:20.696775: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_1/log_1/plugins/profile/2022_11_07_23_46_20\n",
      "\n",
      "2022-11-07 23:46:20.702496: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_mobilenet_1/log_1/plugins/profile/2022_11_07_23_46_20/ntcadmin-scse.memory_profile.json.gz\n",
      "2022-11-07 23:46:20.703241: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_mobilenet_1/log_1/plugins/profile/2022_11_07_23_46_20\n",
      "Dumped tool data for xplane.pb to log/baseline_mobilenet_1/log_1/plugins/profile/2022_11_07_23_46_20/ntcadmin-scse.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_mobilenet_1/log_1/plugins/profile/2022_11_07_23_46_20/ntcadmin-scse.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_mobilenet_1/log_1/plugins/profile/2022_11_07_23_46_20/ntcadmin-scse.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_mobilenet_1/log_1/plugins/profile/2022_11_07_23_46_20/ntcadmin-scse.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_mobilenet_1/log_1/plugins/profile/2022_11_07_23_46_20/ntcadmin-scse.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 62s 59ms/step - loss: 0.6727 - accuracy: 0.5838 - val_loss: 0.6721 - val_accuracy: 0.5876 - lr: 5.0000e-05\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.6453 - accuracy: 0.6382 - val_loss: 0.6497 - val_accuracy: 0.6350 - lr: 5.0000e-05\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.6162 - accuracy: 0.6497 - val_loss: 0.6255 - val_accuracy: 0.6596 - lr: 5.0000e-05\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.6135 - accuracy: 0.6665 - val_loss: 0.7184 - val_accuracy: 0.5493 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.5882 - accuracy: 0.6875 - val_loss: 0.5968 - val_accuracy: 0.6987 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5713 - accuracy: 0.7117 - val_loss: 0.6295 - val_accuracy: 0.6442 - lr: 5.0000e-05\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.6017 - accuracy: 0.6710 - val_loss: 0.5742 - val_accuracy: 0.6971 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5647 - accuracy: 0.7105 - val_loss: 0.5535 - val_accuracy: 0.7143 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5757 - accuracy: 0.7060 - val_loss: 0.5611 - val_accuracy: 0.7209 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5707 - accuracy: 0.6960 - val_loss: 0.5571 - val_accuracy: 0.7045 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5695 - accuracy: 0.7097 - val_loss: 0.6121 - val_accuracy: 0.6445 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5510 - accuracy: 0.7215 - val_loss: 0.5524 - val_accuracy: 0.7131 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5569 - accuracy: 0.7135 - val_loss: 0.5623 - val_accuracy: 0.7052 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5751 - accuracy: 0.6870 - val_loss: 0.5646 - val_accuracy: 0.6834 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.5367 - accuracy: 0.7402 - val_loss: 0.5244 - val_accuracy: 0.7352 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.5432 - accuracy: 0.7337 - val_loss: 0.5861 - val_accuracy: 0.6567 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5430 - accuracy: 0.7275 - val_loss: 0.5345 - val_accuracy: 0.7255 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5498 - accuracy: 0.7170 - val_loss: 0.7836 - val_accuracy: 0.6027 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5359 - accuracy: 0.7402 - val_loss: 0.5537 - val_accuracy: 0.6964 - lr: 5.0000e-05\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5361 - accuracy: 0.7243 - val_loss: 0.5265 - val_accuracy: 0.7327 - lr: 5.0000e-05\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5682 - accuracy: 0.6967 - val_loss: 0.6190 - val_accuracy: 0.6390 - lr: 5.0000e-05\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.5185 - accuracy: 0.7452 - val_loss: 0.5163 - val_accuracy: 0.7454 - lr: 5.0000e-05\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5334 - accuracy: 0.7385 - val_loss: 0.5147 - val_accuracy: 0.7447 - lr: 5.0000e-05\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5296 - accuracy: 0.7308 - val_loss: 0.5975 - val_accuracy: 0.6776 - lr: 5.0000e-05\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.5476 - accuracy: 0.7080 - val_loss: 0.5246 - val_accuracy: 0.7250 - lr: 5.0000e-05\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.5158 - accuracy: 0.7567 - val_loss: 0.5140 - val_accuracy: 0.7457 - lr: 5.0000e-05\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.5292 - accuracy: 0.7385 - val_loss: 0.5490 - val_accuracy: 0.7126 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.5508 - accuracy: 0.7115 - val_loss: 0.5394 - val_accuracy: 0.7165 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.5168 - accuracy: 0.7510 - val_loss: 0.5043 - val_accuracy: 0.7498 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.5176 - accuracy: 0.7492 - val_loss: 0.5913 - val_accuracy: 0.6631 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.5107 - accuracy: 0.7440 - val_loss: 0.5185 - val_accuracy: 0.7354 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5272 - accuracy: 0.7297 - val_loss: 0.5423 - val_accuracy: 0.7250 - lr: 5.0000e-05\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4937 - accuracy: 0.7682 - val_loss: 0.5611 - val_accuracy: 0.7034 - lr: 5.0000e-05\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5234 - accuracy: 0.7385 - val_loss: 0.6395 - val_accuracy: 0.6248 - lr: 5.0000e-05\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5324 - accuracy: 0.7335 - val_loss: 0.5293 - val_accuracy: 0.7279 - lr: 5.0000e-05\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5003 - accuracy: 0.7565 - val_loss: 0.4873 - val_accuracy: 0.7585 - lr: 5.0000e-05\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4855 - accuracy: 0.7692 - val_loss: 0.5557 - val_accuracy: 0.6977 - lr: 5.0000e-05\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5089 - accuracy: 0.7410 - val_loss: 0.5127 - val_accuracy: 0.7462 - lr: 5.0000e-05\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.5115 - accuracy: 0.7435 - val_loss: 0.4856 - val_accuracy: 0.7570 - lr: 5.0000e-05\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4961 - accuracy: 0.7625 - val_loss: 0.5087 - val_accuracy: 0.7447 - lr: 5.0000e-05\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5209 - accuracy: 0.7462 - val_loss: 0.5547 - val_accuracy: 0.6855 - lr: 5.0000e-05\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5138 - accuracy: 0.7398 - val_loss: 0.4994 - val_accuracy: 0.7668 - lr: 5.0000e-05\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5002 - accuracy: 0.7567 - val_loss: 0.4747 - val_accuracy: 0.7668 - lr: 5.0000e-05\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4822 - accuracy: 0.7695 - val_loss: 0.5031 - val_accuracy: 0.7495 - lr: 5.0000e-05\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5034 - accuracy: 0.7475 - val_loss: 0.4770 - val_accuracy: 0.7649 - lr: 5.0000e-05\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5153 - accuracy: 0.7383 - val_loss: 0.4741 - val_accuracy: 0.7717 - lr: 5.0000e-05\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.4682 - accuracy: 0.7780 - val_loss: 0.6115 - val_accuracy: 0.6866 - lr: 5.0000e-05\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5111 - accuracy: 0.7505 - val_loss: 0.4777 - val_accuracy: 0.7649 - lr: 5.0000e-05\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5030 - accuracy: 0.7402 - val_loss: 0.4687 - val_accuracy: 0.7773 - lr: 5.0000e-05\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4865 - accuracy: 0.7650 - val_loss: 0.4879 - val_accuracy: 0.7590 - lr: 5.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4885 - accuracy: 0.7650 - val_loss: 0.5955 - val_accuracy: 0.7014 - lr: 5.0000e-05\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4862 - accuracy: 0.7655 - val_loss: 0.4981 - val_accuracy: 0.7443 - lr: 5.0000e-05\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5224 - accuracy: 0.7347 - val_loss: 0.4689 - val_accuracy: 0.7687 - lr: 5.0000e-05\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4573 - accuracy: 0.7828 - val_loss: 0.4721 - val_accuracy: 0.7754 - lr: 5.0000e-05\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5196 - accuracy: 0.7435 - val_loss: 0.4824 - val_accuracy: 0.7602 - lr: 5.0000e-05\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5034 - accuracy: 0.7448 - val_loss: 0.4677 - val_accuracy: 0.7726 - lr: 5.0000e-05\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4872 - accuracy: 0.7617 - val_loss: 0.4555 - val_accuracy: 0.7814 - lr: 5.0000e-05\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4888 - accuracy: 0.7582 - val_loss: 0.5471 - val_accuracy: 0.7019 - lr: 5.0000e-05\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4661 - accuracy: 0.7740 - val_loss: 0.4759 - val_accuracy: 0.7633 - lr: 5.0000e-05\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5153 - accuracy: 0.7437 - val_loss: 0.4458 - val_accuracy: 0.7858 - lr: 5.0000e-05\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4391 - accuracy: 0.8010 - val_loss: 0.4982 - val_accuracy: 0.7654 - lr: 5.0000e-05\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4949 - accuracy: 0.7607 - val_loss: 0.4493 - val_accuracy: 0.7866 - lr: 5.0000e-05\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4931 - accuracy: 0.7555 - val_loss: 0.5344 - val_accuracy: 0.7137 - lr: 5.0000e-05\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4845 - accuracy: 0.7607 - val_loss: 0.4774 - val_accuracy: 0.7617 - lr: 5.0000e-05\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4813 - accuracy: 0.7680 - val_loss: 0.4720 - val_accuracy: 0.7648 - lr: 5.0000e-05\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4690 - accuracy: 0.7765 - val_loss: 0.4582 - val_accuracy: 0.7775 - lr: 5.0000e-05\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5026 - accuracy: 0.7455 - val_loss: 0.4728 - val_accuracy: 0.7610 - lr: 5.0000e-05\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4534 - accuracy: 0.7922 - val_loss: 0.4529 - val_accuracy: 0.7801 - lr: 5.0000e-05\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4923 - accuracy: 0.7663 - val_loss: 0.4527 - val_accuracy: 0.7845 - lr: 5.0000e-05\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4852 - accuracy: 0.7615 - val_loss: 0.4543 - val_accuracy: 0.7726 - lr: 5.0000e-05\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4894 - accuracy: 0.7517 - val_loss: 0.5344 - val_accuracy: 0.7010 - lr: 5.0000e-05\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4760 - accuracy: 0.7803 - val_loss: 0.4664 - val_accuracy: 0.7672 - lr: 5.0000e-05\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4685 - accuracy: 0.7797 - val_loss: 0.4522 - val_accuracy: 0.7776 - lr: 5.0000e-05\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5000 - accuracy: 0.7430 - val_loss: 0.4524 - val_accuracy: 0.7798 - lr: 5.0000e-05\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4471 - accuracy: 0.7947 - val_loss: 0.4427 - val_accuracy: 0.7825 - lr: 5.0000e-05\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4725 - accuracy: 0.7845 - val_loss: 0.4552 - val_accuracy: 0.7811 - lr: 5.0000e-05\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4809 - accuracy: 0.7657 - val_loss: 0.4401 - val_accuracy: 0.7900 - lr: 5.0000e-05\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4711 - accuracy: 0.7732 - val_loss: 0.6651 - val_accuracy: 0.6586 - lr: 5.0000e-05\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4718 - accuracy: 0.7738 - val_loss: 0.4640 - val_accuracy: 0.7665 - lr: 5.0000e-05\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 58s 59ms/step - loss: 0.4544 - accuracy: 0.7880 - val_loss: 0.4612 - val_accuracy: 0.7690 - lr: 5.0000e-05\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4957 - accuracy: 0.7533 - val_loss: 0.4534 - val_accuracy: 0.7762 - lr: 5.0000e-05\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4403 - accuracy: 0.7980 - val_loss: 0.4475 - val_accuracy: 0.7822 - lr: 5.0000e-05\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4782 - accuracy: 0.7673 - val_loss: 0.5762 - val_accuracy: 0.6746 - lr: 5.0000e-05\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4770 - accuracy: 0.7605 - val_loss: 0.4351 - val_accuracy: 0.7899 - lr: 5.0000e-05\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4697 - accuracy: 0.7720 - val_loss: 0.4858 - val_accuracy: 0.7651 - lr: 5.0000e-05\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4497 - accuracy: 0.7887 - val_loss: 0.4313 - val_accuracy: 0.7959 - lr: 5.0000e-05\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4619 - accuracy: 0.7800 - val_loss: 0.4797 - val_accuracy: 0.7678 - lr: 5.0000e-05\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5038 - accuracy: 0.7525 - val_loss: 0.5741 - val_accuracy: 0.6992 - lr: 5.0000e-05\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4438 - accuracy: 0.7900 - val_loss: 0.4573 - val_accuracy: 0.7756 - lr: 5.0000e-05\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4582 - accuracy: 0.7825 - val_loss: 0.4345 - val_accuracy: 0.7911 - lr: 5.0000e-05\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4752 - accuracy: 0.7642 - val_loss: 0.4439 - val_accuracy: 0.7819 - lr: 5.0000e-05\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4742 - accuracy: 0.7625 - val_loss: 0.4351 - val_accuracy: 0.7855 - lr: 5.0000e-05\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4443 - accuracy: 0.7940 - val_loss: 0.5823 - val_accuracy: 0.6985 - lr: 5.0000e-05\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4641 - accuracy: 0.7722 - val_loss: 0.5421 - val_accuracy: 0.7230 - lr: 5.0000e-05\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4718 - accuracy: 0.7800 - val_loss: 0.4576 - val_accuracy: 0.7726 - lr: 5.0000e-05\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4484 - accuracy: 0.7895 - val_loss: 0.5379 - val_accuracy: 0.7392 - lr: 5.0000e-05\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4421 - accuracy: 0.8050 - val_loss: 0.6454 - val_accuracy: 0.6630 - lr: 5.0000e-05\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4619 - accuracy: 0.7782 - val_loss: 0.4231 - val_accuracy: 0.8021 - lr: 5.0000e-05\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4767 - accuracy: 0.7613 - val_loss: 0.4359 - val_accuracy: 0.7849 - lr: 5.0000e-05\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4404 - accuracy: 0.8048 - val_loss: 0.4427 - val_accuracy: 0.7897 - lr: 5.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 01:24:05.321704: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-08 01:24:05.321769: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-08 01:24:05.321837: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 01:24:05.321856: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-08 01:24:05.321867: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 01:24:05.321879: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-11-08 01:24:05.321922: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-08 01:24:05.321981: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-08 01:24:05.321996: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 01:24:05.322007: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 52s 14ms/step - loss: 0.6966 - accuracy: 0.5232\n",
      "Epoch 1/100\n",
      "   9/1000 [..............................] - ETA: 14s - loss: 0.7415 - accuracy: 0.3611 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 01:25:00.346233: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-08 01:25:00.346254: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-08 01:25:00.346468: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 01:25:00.346478: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-08 01:25:00.346483: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 01:25:00.346487: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-11-08 01:25:00.766182: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-08 01:25:00.784093: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-08 01:25:00.784116: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 01:25:00.784121: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2022-11-08 01:25:00.822696: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 01:25:00.822730: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 01:25:00.822736: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-11-08 01:25:00.844062: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-08 01:25:00.865357: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_1/log_2/plugins/profile/2022_11_08_01_25_00\n",
      "\n",
      "2022-11-08 01:25:00.871331: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_mobilenet_1/log_2/plugins/profile/2022_11_08_01_25_00/ntcadmin-scse.trace.json.gz\n",
      "2022-11-08 01:25:00.947929: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_1/log_2/plugins/profile/2022_11_08_01_25_00\n",
      "\n",
      "2022-11-08 01:25:00.957934: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_mobilenet_1/log_2/plugins/profile/2022_11_08_01_25_00/ntcadmin-scse.memory_profile.json.gz\n",
      "2022-11-08 01:25:00.958745: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_mobilenet_1/log_2/plugins/profile/2022_11_08_01_25_00\n",
      "Dumped tool data for xplane.pb to log/baseline_mobilenet_1/log_2/plugins/profile/2022_11_08_01_25_00/ntcadmin-scse.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_mobilenet_1/log_2/plugins/profile/2022_11_08_01_25_00/ntcadmin-scse.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_mobilenet_1/log_2/plugins/profile/2022_11_08_01_25_00/ntcadmin-scse.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_mobilenet_1/log_2/plugins/profile/2022_11_08_01_25_00/ntcadmin-scse.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_mobilenet_1/log_2/plugins/profile/2022_11_08_01_25_00/ntcadmin-scse.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 63s 60ms/step - loss: 0.6771 - accuracy: 0.5757 - val_loss: 0.6648 - val_accuracy: 0.6102 - lr: 5.0000e-05\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.6365 - accuracy: 0.6515 - val_loss: 0.6653 - val_accuracy: 0.5847 - lr: 5.0000e-05\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.6170 - accuracy: 0.6560 - val_loss: 0.6280 - val_accuracy: 0.6596 - lr: 5.0000e-05\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.6222 - accuracy: 0.6643 - val_loss: 0.7268 - val_accuracy: 0.5457 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.6037 - accuracy: 0.6777 - val_loss: 0.6030 - val_accuracy: 0.6779 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5738 - accuracy: 0.7035 - val_loss: 0.5993 - val_accuracy: 0.6738 - lr: 5.0000e-05\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.6097 - accuracy: 0.6628 - val_loss: 0.5807 - val_accuracy: 0.6963 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5805 - accuracy: 0.6950 - val_loss: 0.5582 - val_accuracy: 0.7082 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5708 - accuracy: 0.7110 - val_loss: 0.5726 - val_accuracy: 0.6969 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5717 - accuracy: 0.6973 - val_loss: 0.5712 - val_accuracy: 0.6875 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5790 - accuracy: 0.6940 - val_loss: 0.5566 - val_accuracy: 0.7088 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5625 - accuracy: 0.7200 - val_loss: 0.5644 - val_accuracy: 0.6972 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5615 - accuracy: 0.7125 - val_loss: 0.5773 - val_accuracy: 0.6920 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5806 - accuracy: 0.6837 - val_loss: 0.5460 - val_accuracy: 0.7176 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5456 - accuracy: 0.7253 - val_loss: 0.5323 - val_accuracy: 0.7286 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5535 - accuracy: 0.7322 - val_loss: 0.6507 - val_accuracy: 0.6253 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5546 - accuracy: 0.7078 - val_loss: 0.5314 - val_accuracy: 0.7314 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5570 - accuracy: 0.7125 - val_loss: 0.7795 - val_accuracy: 0.5822 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5388 - accuracy: 0.7318 - val_loss: 0.5311 - val_accuracy: 0.7360 - lr: 5.0000e-05\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5413 - accuracy: 0.7295 - val_loss: 0.5549 - val_accuracy: 0.7103 - lr: 5.0000e-05\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5674 - accuracy: 0.7040 - val_loss: 0.6240 - val_accuracy: 0.6280 - lr: 5.0000e-05\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5287 - accuracy: 0.7412 - val_loss: 0.5164 - val_accuracy: 0.7411 - lr: 5.0000e-05\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5422 - accuracy: 0.7287 - val_loss: 0.5162 - val_accuracy: 0.7452 - lr: 5.0000e-05\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5428 - accuracy: 0.7255 - val_loss: 0.6272 - val_accuracy: 0.6508 - lr: 5.0000e-05\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5536 - accuracy: 0.7067 - val_loss: 0.5244 - val_accuracy: 0.7327 - lr: 5.0000e-05\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5212 - accuracy: 0.7540 - val_loss: 0.5431 - val_accuracy: 0.7141 - lr: 5.0000e-05\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5477 - accuracy: 0.7188 - val_loss: 0.5411 - val_accuracy: 0.7212 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5538 - accuracy: 0.7165 - val_loss: 0.5397 - val_accuracy: 0.7081 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 59s 60ms/step - loss: 0.5216 - accuracy: 0.7410 - val_loss: 0.5143 - val_accuracy: 0.7379 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5073 - accuracy: 0.7567 - val_loss: 0.6273 - val_accuracy: 0.6515 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5276 - accuracy: 0.7220 - val_loss: 0.5231 - val_accuracy: 0.7313 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5363 - accuracy: 0.7247 - val_loss: 0.5549 - val_accuracy: 0.7138 - lr: 5.0000e-05\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5024 - accuracy: 0.7615 - val_loss: 0.6009 - val_accuracy: 0.6720 - lr: 5.0000e-05\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5301 - accuracy: 0.7265 - val_loss: 0.7329 - val_accuracy: 0.5973 - lr: 5.0000e-05\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5447 - accuracy: 0.7185 - val_loss: 0.5247 - val_accuracy: 0.7313 - lr: 5.0000e-05\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5133 - accuracy: 0.7508 - val_loss: 0.4854 - val_accuracy: 0.7624 - lr: 5.0000e-05\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4981 - accuracy: 0.7635 - val_loss: 0.5247 - val_accuracy: 0.7341 - lr: 5.0000e-05\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5244 - accuracy: 0.7375 - val_loss: 0.4892 - val_accuracy: 0.7644 - lr: 5.0000e-05\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5300 - accuracy: 0.7287 - val_loss: 0.4823 - val_accuracy: 0.7590 - lr: 5.0000e-05\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5022 - accuracy: 0.7625 - val_loss: 0.5209 - val_accuracy: 0.7246 - lr: 5.0000e-05\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5247 - accuracy: 0.7345 - val_loss: 0.5106 - val_accuracy: 0.7344 - lr: 5.0000e-05\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5203 - accuracy: 0.7318 - val_loss: 0.4880 - val_accuracy: 0.7670 - lr: 5.0000e-05\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5016 - accuracy: 0.7590 - val_loss: 0.4720 - val_accuracy: 0.7707 - lr: 5.0000e-05\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4859 - accuracy: 0.7707 - val_loss: 0.5030 - val_accuracy: 0.7503 - lr: 5.0000e-05\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5073 - accuracy: 0.7520 - val_loss: 0.5044 - val_accuracy: 0.7390 - lr: 5.0000e-05\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5173 - accuracy: 0.7350 - val_loss: 0.4788 - val_accuracy: 0.7661 - lr: 5.0000e-05\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4845 - accuracy: 0.7717 - val_loss: 0.7064 - val_accuracy: 0.6510 - lr: 5.0000e-05\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5314 - accuracy: 0.7312 - val_loss: 0.5016 - val_accuracy: 0.7430 - lr: 5.0000e-05\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5195 - accuracy: 0.7375 - val_loss: 0.4807 - val_accuracy: 0.7706 - lr: 5.0000e-05\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 59s 60ms/step - loss: 0.4944 - accuracy: 0.7605 - val_loss: 0.4794 - val_accuracy: 0.7608 - lr: 5.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4881 - accuracy: 0.7660 - val_loss: 0.5884 - val_accuracy: 0.6941 - lr: 5.0000e-05\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4820 - accuracy: 0.7665 - val_loss: 0.4793 - val_accuracy: 0.7647 - lr: 5.0000e-05\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 59s 60ms/step - loss: 0.5226 - accuracy: 0.7385 - val_loss: 0.4630 - val_accuracy: 0.7742 - lr: 5.0000e-05\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4788 - accuracy: 0.7770 - val_loss: 0.5242 - val_accuracy: 0.7454 - lr: 5.0000e-05\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5254 - accuracy: 0.7355 - val_loss: 0.5080 - val_accuracy: 0.7341 - lr: 5.0000e-05\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5081 - accuracy: 0.7412 - val_loss: 0.4751 - val_accuracy: 0.7684 - lr: 5.0000e-05\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4949 - accuracy: 0.7592 - val_loss: 0.4561 - val_accuracy: 0.7789 - lr: 5.0000e-05\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4778 - accuracy: 0.7768 - val_loss: 0.5615 - val_accuracy: 0.7066 - lr: 5.0000e-05\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4829 - accuracy: 0.7632 - val_loss: 0.4688 - val_accuracy: 0.7701 - lr: 5.0000e-05\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5277 - accuracy: 0.7398 - val_loss: 0.4560 - val_accuracy: 0.7795 - lr: 5.0000e-05\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4674 - accuracy: 0.7763 - val_loss: 0.4751 - val_accuracy: 0.7693 - lr: 5.0000e-05\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5010 - accuracy: 0.7535 - val_loss: 0.4666 - val_accuracy: 0.7726 - lr: 5.0000e-05\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4995 - accuracy: 0.7467 - val_loss: 0.4942 - val_accuracy: 0.7368 - lr: 5.0000e-05\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5026 - accuracy: 0.7462 - val_loss: 0.4586 - val_accuracy: 0.7772 - lr: 5.0000e-05\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4771 - accuracy: 0.7682 - val_loss: 0.4614 - val_accuracy: 0.7780 - lr: 5.0000e-05\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4848 - accuracy: 0.7632 - val_loss: 0.4656 - val_accuracy: 0.7685 - lr: 5.0000e-05\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5208 - accuracy: 0.7305 - val_loss: 0.4978 - val_accuracy: 0.7350 - lr: 5.0000e-05\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4690 - accuracy: 0.7803 - val_loss: 0.4526 - val_accuracy: 0.7786 - lr: 5.0000e-05\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4765 - accuracy: 0.7768 - val_loss: 0.4533 - val_accuracy: 0.7773 - lr: 5.0000e-05\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4855 - accuracy: 0.7567 - val_loss: 0.4463 - val_accuracy: 0.7851 - lr: 5.0000e-05\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4855 - accuracy: 0.7588 - val_loss: 0.6328 - val_accuracy: 0.6833 - lr: 5.0000e-05\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4707 - accuracy: 0.7747 - val_loss: 0.4471 - val_accuracy: 0.7822 - lr: 5.0000e-05\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4810 - accuracy: 0.7620 - val_loss: 0.4542 - val_accuracy: 0.7803 - lr: 5.0000e-05\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5117 - accuracy: 0.7350 - val_loss: 0.4578 - val_accuracy: 0.7682 - lr: 5.0000e-05\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4576 - accuracy: 0.7872 - val_loss: 0.4387 - val_accuracy: 0.7888 - lr: 5.0000e-05\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4870 - accuracy: 0.7625 - val_loss: 0.4557 - val_accuracy: 0.7815 - lr: 5.0000e-05\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4825 - accuracy: 0.7648 - val_loss: 0.4472 - val_accuracy: 0.7874 - lr: 5.0000e-05\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4761 - accuracy: 0.7675 - val_loss: 0.5834 - val_accuracy: 0.7046 - lr: 5.0000e-05\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4583 - accuracy: 0.7857 - val_loss: 0.4694 - val_accuracy: 0.7693 - lr: 5.0000e-05\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4604 - accuracy: 0.7883 - val_loss: 0.4929 - val_accuracy: 0.7404 - lr: 5.0000e-05\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5111 - accuracy: 0.7410 - val_loss: 0.4375 - val_accuracy: 0.7878 - lr: 5.0000e-05\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4541 - accuracy: 0.7885 - val_loss: 0.4470 - val_accuracy: 0.7821 - lr: 5.0000e-05\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4635 - accuracy: 0.7847 - val_loss: 0.5607 - val_accuracy: 0.7021 - lr: 5.0000e-05\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4762 - accuracy: 0.7625 - val_loss: 0.4674 - val_accuracy: 0.7633 - lr: 5.0000e-05\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.4720 - accuracy: 0.7703 - val_loss: 0.6065 - val_accuracy: 0.6826 - lr: 5.0000e-05\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4465 - accuracy: 0.7990 - val_loss: 0.4621 - val_accuracy: 0.7720 - lr: 5.0000e-05\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4635 - accuracy: 0.7697 - val_loss: 0.5070 - val_accuracy: 0.7515 - lr: 5.0000e-05\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5061 - accuracy: 0.7445 - val_loss: 0.5506 - val_accuracy: 0.6946 - lr: 5.0000e-05\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4321 - accuracy: 0.8008 - val_loss: 0.4256 - val_accuracy: 0.7980 - lr: 5.0000e-05\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4526 - accuracy: 0.7903 - val_loss: 0.4357 - val_accuracy: 0.7909 - lr: 5.0000e-05\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4736 - accuracy: 0.7632 - val_loss: 0.4981 - val_accuracy: 0.7345 - lr: 5.0000e-05\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4698 - accuracy: 0.7675 - val_loss: 0.4376 - val_accuracy: 0.7814 - lr: 5.0000e-05\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4676 - accuracy: 0.7818 - val_loss: 0.5463 - val_accuracy: 0.7031 - lr: 5.0000e-05\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4723 - accuracy: 0.7722 - val_loss: 0.5342 - val_accuracy: 0.7252 - lr: 5.0000e-05\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4948 - accuracy: 0.7558 - val_loss: 0.4350 - val_accuracy: 0.7973 - lr: 5.0000e-05\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4528 - accuracy: 0.7905 - val_loss: 0.4775 - val_accuracy: 0.7635 - lr: 5.0000e-05\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4377 - accuracy: 0.7972 - val_loss: 0.5336 - val_accuracy: 0.7327 - lr: 5.0000e-05\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4765 - accuracy: 0.7588 - val_loss: 0.4349 - val_accuracy: 0.7949 - lr: 5.0000e-05\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4712 - accuracy: 0.7717 - val_loss: 0.5422 - val_accuracy: 0.7342 - lr: 5.0000e-05\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4603 - accuracy: 0.7868 - val_loss: 0.4373 - val_accuracy: 0.7887 - lr: 5.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 03:04:34.531029: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-08 03:04:34.531054: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-08 03:04:34.531910: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 03:04:34.531931: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-08 03:04:34.531936: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 03:04:34.531941: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-11-08 03:04:34.531995: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-08 03:04:34.532021: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-08 03:04:34.532026: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 03:04:34.532030: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 51s 14ms/step - loss: 0.6925 - accuracy: 0.5232\n",
      "Epoch 1/100\n",
      "   9/1000 [..............................] - ETA: 14s - loss: 0.7123 - accuracy: 0.3889 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 03:05:29.021333: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-08 03:05:29.021353: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-08 03:05:29.021471: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 03:05:29.021481: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-08 03:05:29.021485: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 03:05:29.021489: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-11-08 03:05:29.446876: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-08 03:05:29.463427: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-08 03:05:29.463452: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 03:05:29.463458: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2022-11-08 03:05:29.505618: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 03:05:29.505652: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 03:05:29.505659: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-11-08 03:05:29.528211: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-08 03:05:29.554004: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_1/log_3/plugins/profile/2022_11_08_03_05_29\n",
      "\n",
      "2022-11-08 03:05:29.562037: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_mobilenet_1/log_3/plugins/profile/2022_11_08_03_05_29/ntcadmin-scse.trace.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  17/1000 [..............................] - ETA: 47s - loss: 0.6890 - accuracy: 0.5147"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 03:05:29.651653: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_1/log_3/plugins/profile/2022_11_08_03_05_29\n",
      "\n",
      "2022-11-08 03:05:29.665000: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_mobilenet_1/log_3/plugins/profile/2022_11_08_03_05_29/ntcadmin-scse.memory_profile.json.gz\n",
      "2022-11-08 03:05:29.666781: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_mobilenet_1/log_3/plugins/profile/2022_11_08_03_05_29\n",
      "Dumped tool data for xplane.pb to log/baseline_mobilenet_1/log_3/plugins/profile/2022_11_08_03_05_29/ntcadmin-scse.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_mobilenet_1/log_3/plugins/profile/2022_11_08_03_05_29/ntcadmin-scse.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_mobilenet_1/log_3/plugins/profile/2022_11_08_03_05_29/ntcadmin-scse.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_mobilenet_1/log_3/plugins/profile/2022_11_08_03_05_29/ntcadmin-scse.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_mobilenet_1/log_3/plugins/profile/2022_11_08_03_05_29/ntcadmin-scse.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 63s 60ms/step - loss: 0.6729 - accuracy: 0.5870 - val_loss: 0.6810 - val_accuracy: 0.5491 - lr: 5.0000e-05\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 59s 60ms/step - loss: 0.6476 - accuracy: 0.6417 - val_loss: 0.6598 - val_accuracy: 0.6215 - lr: 5.0000e-05\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.6197 - accuracy: 0.6543 - val_loss: 0.6282 - val_accuracy: 0.6614 - lr: 5.0000e-05\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.6248 - accuracy: 0.6562 - val_loss: 0.6887 - val_accuracy: 0.5773 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5977 - accuracy: 0.6787 - val_loss: 0.5873 - val_accuracy: 0.6857 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5833 - accuracy: 0.6933 - val_loss: 0.6254 - val_accuracy: 0.6476 - lr: 5.0000e-05\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.6048 - accuracy: 0.6605 - val_loss: 0.5667 - val_accuracy: 0.7063 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5778 - accuracy: 0.7028 - val_loss: 0.5663 - val_accuracy: 0.7024 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5780 - accuracy: 0.7048 - val_loss: 0.5726 - val_accuracy: 0.7035 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 59s 60ms/step - loss: 0.5660 - accuracy: 0.7023 - val_loss: 0.5570 - val_accuracy: 0.7127 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5855 - accuracy: 0.6892 - val_loss: 0.5550 - val_accuracy: 0.7160 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5584 - accuracy: 0.7247 - val_loss: 0.5813 - val_accuracy: 0.6725 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5640 - accuracy: 0.7125 - val_loss: 0.5830 - val_accuracy: 0.6838 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5790 - accuracy: 0.6867 - val_loss: 0.5725 - val_accuracy: 0.6882 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5487 - accuracy: 0.7218 - val_loss: 0.5941 - val_accuracy: 0.6708 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5495 - accuracy: 0.7368 - val_loss: 0.6426 - val_accuracy: 0.6034 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5528 - accuracy: 0.7082 - val_loss: 0.5290 - val_accuracy: 0.7340 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5485 - accuracy: 0.7132 - val_loss: 0.9660 - val_accuracy: 0.5395 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5473 - accuracy: 0.7312 - val_loss: 0.5308 - val_accuracy: 0.7279 - lr: 5.0000e-05\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5474 - accuracy: 0.7237 - val_loss: 0.5364 - val_accuracy: 0.7328 - lr: 5.0000e-05\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5700 - accuracy: 0.6952 - val_loss: 0.6063 - val_accuracy: 0.6584 - lr: 5.0000e-05\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 59s 60ms/step - loss: 0.5241 - accuracy: 0.7473 - val_loss: 0.5154 - val_accuracy: 0.7378 - lr: 5.0000e-05\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5347 - accuracy: 0.7415 - val_loss: 0.5148 - val_accuracy: 0.7428 - lr: 5.0000e-05\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5394 - accuracy: 0.7272 - val_loss: 0.6887 - val_accuracy: 0.6095 - lr: 5.0000e-05\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5416 - accuracy: 0.7135 - val_loss: 0.5228 - val_accuracy: 0.7329 - lr: 5.0000e-05\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 59s 60ms/step - loss: 0.5239 - accuracy: 0.7458 - val_loss: 0.5167 - val_accuracy: 0.7409 - lr: 5.0000e-05\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5320 - accuracy: 0.7333 - val_loss: 0.5812 - val_accuracy: 0.6678 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5566 - accuracy: 0.7020 - val_loss: 0.5489 - val_accuracy: 0.7033 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5214 - accuracy: 0.7420 - val_loss: 0.5045 - val_accuracy: 0.7499 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 59s 60ms/step - loss: 0.5265 - accuracy: 0.7470 - val_loss: 0.6031 - val_accuracy: 0.6669 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5370 - accuracy: 0.7170 - val_loss: 0.5091 - val_accuracy: 0.7518 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5205 - accuracy: 0.7425 - val_loss: 0.5914 - val_accuracy: 0.6792 - lr: 5.0000e-05\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5147 - accuracy: 0.7573 - val_loss: 0.6008 - val_accuracy: 0.6656 - lr: 5.0000e-05\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5325 - accuracy: 0.7250 - val_loss: 0.7258 - val_accuracy: 0.6196 - lr: 5.0000e-05\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5393 - accuracy: 0.7258 - val_loss: 0.5544 - val_accuracy: 0.7160 - lr: 5.0000e-05\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 59s 60ms/step - loss: 0.4947 - accuracy: 0.7580 - val_loss: 0.4982 - val_accuracy: 0.7558 - lr: 5.0000e-05\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5081 - accuracy: 0.7520 - val_loss: 0.5059 - val_accuracy: 0.7393 - lr: 5.0000e-05\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5205 - accuracy: 0.7297 - val_loss: 0.5052 - val_accuracy: 0.7581 - lr: 5.0000e-05\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5153 - accuracy: 0.7405 - val_loss: 0.4924 - val_accuracy: 0.7594 - lr: 5.0000e-05\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5066 - accuracy: 0.7655 - val_loss: 0.5177 - val_accuracy: 0.7262 - lr: 5.0000e-05\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5348 - accuracy: 0.7280 - val_loss: 0.5146 - val_accuracy: 0.7342 - lr: 5.0000e-05\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5221 - accuracy: 0.7215 - val_loss: 0.5009 - val_accuracy: 0.7688 - lr: 5.0000e-05\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5025 - accuracy: 0.7642 - val_loss: 0.4865 - val_accuracy: 0.7530 - lr: 5.0000e-05\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4929 - accuracy: 0.7648 - val_loss: 0.5304 - val_accuracy: 0.7236 - lr: 5.0000e-05\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5097 - accuracy: 0.7450 - val_loss: 0.4908 - val_accuracy: 0.7540 - lr: 5.0000e-05\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5226 - accuracy: 0.7345 - val_loss: 0.4821 - val_accuracy: 0.7671 - lr: 5.0000e-05\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4797 - accuracy: 0.7812 - val_loss: 0.6312 - val_accuracy: 0.6630 - lr: 5.0000e-05\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 59s 60ms/step - loss: 0.5299 - accuracy: 0.7310 - val_loss: 0.4773 - val_accuracy: 0.7693 - lr: 5.0000e-05\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5130 - accuracy: 0.7375 - val_loss: 0.4865 - val_accuracy: 0.7612 - lr: 5.0000e-05\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4930 - accuracy: 0.7625 - val_loss: 0.4670 - val_accuracy: 0.7700 - lr: 5.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4860 - accuracy: 0.7670 - val_loss: 0.5684 - val_accuracy: 0.7087 - lr: 5.0000e-05\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4900 - accuracy: 0.7495 - val_loss: 0.4767 - val_accuracy: 0.7628 - lr: 5.0000e-05\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5333 - accuracy: 0.7295 - val_loss: 0.4739 - val_accuracy: 0.7659 - lr: 5.0000e-05\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4607 - accuracy: 0.7912 - val_loss: 0.4892 - val_accuracy: 0.7699 - lr: 5.0000e-05\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5126 - accuracy: 0.7427 - val_loss: 0.4918 - val_accuracy: 0.7440 - lr: 5.0000e-05\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5106 - accuracy: 0.7372 - val_loss: 0.4879 - val_accuracy: 0.7554 - lr: 5.0000e-05\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4930 - accuracy: 0.7610 - val_loss: 0.4651 - val_accuracy: 0.7682 - lr: 5.0000e-05\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4752 - accuracy: 0.7713 - val_loss: 0.6024 - val_accuracy: 0.6838 - lr: 5.0000e-05\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4748 - accuracy: 0.7653 - val_loss: 0.4686 - val_accuracy: 0.7712 - lr: 5.0000e-05\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5379 - accuracy: 0.7290 - val_loss: 0.4658 - val_accuracy: 0.7701 - lr: 5.0000e-05\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 59s 60ms/step - loss: 0.4644 - accuracy: 0.7843 - val_loss: 0.5159 - val_accuracy: 0.7348 - lr: 5.0000e-05\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5136 - accuracy: 0.7460 - val_loss: 0.4649 - val_accuracy: 0.7766 - lr: 5.0000e-05\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4968 - accuracy: 0.7540 - val_loss: 0.5374 - val_accuracy: 0.7180 - lr: 5.0000e-05\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4907 - accuracy: 0.7577 - val_loss: 0.4578 - val_accuracy: 0.7786 - lr: 5.0000e-05\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4836 - accuracy: 0.7680 - val_loss: 0.4655 - val_accuracy: 0.7793 - lr: 5.0000e-05\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4780 - accuracy: 0.7725 - val_loss: 0.4510 - val_accuracy: 0.7834 - lr: 5.0000e-05\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5232 - accuracy: 0.7297 - val_loss: 0.4936 - val_accuracy: 0.7486 - lr: 5.0000e-05\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4585 - accuracy: 0.7880 - val_loss: 0.4470 - val_accuracy: 0.7858 - lr: 5.0000e-05\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4921 - accuracy: 0.7598 - val_loss: 0.4643 - val_accuracy: 0.7661 - lr: 5.0000e-05\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4937 - accuracy: 0.7555 - val_loss: 0.4443 - val_accuracy: 0.7853 - lr: 5.0000e-05\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4956 - accuracy: 0.7558 - val_loss: 0.6229 - val_accuracy: 0.6749 - lr: 5.0000e-05\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 59s 60ms/step - loss: 0.4765 - accuracy: 0.7673 - val_loss: 0.4575 - val_accuracy: 0.7806 - lr: 5.0000e-05\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4732 - accuracy: 0.7747 - val_loss: 0.4563 - val_accuracy: 0.7764 - lr: 5.0000e-05\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5182 - accuracy: 0.7402 - val_loss: 0.4443 - val_accuracy: 0.7901 - lr: 5.0000e-05\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4528 - accuracy: 0.7912 - val_loss: 0.4524 - val_accuracy: 0.7709 - lr: 5.0000e-05\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4835 - accuracy: 0.7645 - val_loss: 0.4736 - val_accuracy: 0.7566 - lr: 5.0000e-05\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4834 - accuracy: 0.7523 - val_loss: 0.4528 - val_accuracy: 0.7776 - lr: 5.0000e-05\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4861 - accuracy: 0.7610 - val_loss: 0.5670 - val_accuracy: 0.7075 - lr: 5.0000e-05\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4706 - accuracy: 0.7785 - val_loss: 0.4587 - val_accuracy: 0.7865 - lr: 5.0000e-05\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4707 - accuracy: 0.7692 - val_loss: 0.5241 - val_accuracy: 0.7160 - lr: 5.0000e-05\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5074 - accuracy: 0.7492 - val_loss: 0.4592 - val_accuracy: 0.7722 - lr: 5.0000e-05\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4514 - accuracy: 0.7832 - val_loss: 0.4490 - val_accuracy: 0.7831 - lr: 5.0000e-05\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4662 - accuracy: 0.7770 - val_loss: 0.5867 - val_accuracy: 0.6850 - lr: 5.0000e-05\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4934 - accuracy: 0.7505 - val_loss: 0.5280 - val_accuracy: 0.7157 - lr: 5.0000e-05\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 59s 60ms/step - loss: 0.4762 - accuracy: 0.7623 - val_loss: 0.6765 - val_accuracy: 0.6800 - lr: 5.0000e-05\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4619 - accuracy: 0.7887 - val_loss: 0.4443 - val_accuracy: 0.7806 - lr: 5.0000e-05\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.4759 - accuracy: 0.7630 - val_loss: 0.5177 - val_accuracy: 0.7527 - lr: 5.0000e-05\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.5059 - accuracy: 0.7418 - val_loss: 0.5419 - val_accuracy: 0.7226 - lr: 5.0000e-05\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.4487 - accuracy: 0.7885 - val_loss: 0.4223 - val_accuracy: 0.8014 - lr: 5.0000e-05\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.4659 - accuracy: 0.7868 - val_loss: 0.4345 - val_accuracy: 0.7904 - lr: 5.0000e-05\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.4815 - accuracy: 0.7580 - val_loss: 0.5103 - val_accuracy: 0.7183 - lr: 5.0000e-05\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.4827 - accuracy: 0.7655 - val_loss: 0.4427 - val_accuracy: 0.7798 - lr: 5.0000e-05\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4531 - accuracy: 0.7860 - val_loss: 0.5680 - val_accuracy: 0.7109 - lr: 5.0000e-05\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4748 - accuracy: 0.7623 - val_loss: 0.5160 - val_accuracy: 0.7291 - lr: 5.0000e-05\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4918 - accuracy: 0.7567 - val_loss: 0.4611 - val_accuracy: 0.7770 - lr: 5.0000e-05\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4453 - accuracy: 0.8035 - val_loss: 0.4465 - val_accuracy: 0.7793 - lr: 5.0000e-05\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4593 - accuracy: 0.7885 - val_loss: 0.5678 - val_accuracy: 0.6707 - lr: 5.0000e-05\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4769 - accuracy: 0.7680 - val_loss: 0.4477 - val_accuracy: 0.7942 - lr: 5.0000e-05\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4699 - accuracy: 0.7730 - val_loss: 0.4406 - val_accuracy: 0.7843 - lr: 5.0000e-05\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4564 - accuracy: 0.7850 - val_loss: 0.4339 - val_accuracy: 0.7929 - lr: 5.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 04:44:27.653978: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-08 04:44:27.654003: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-08 04:44:27.658148: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 04:44:27.658297: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-08 04:44:27.658338: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 04:44:27.658346: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-11-08 04:44:27.658863: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-08 04:44:27.658897: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-08 04:44:27.658904: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 04:44:27.658907: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 52s 14ms/step - loss: 0.7239 - accuracy: 0.4768\n",
      "Epoch 1/100\n",
      "   9/1000 [..............................] - ETA: 15s - loss: 0.5769 - accuracy: 0.8056 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 04:45:22.755356: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-08 04:45:22.755382: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-08 04:45:22.755526: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 04:45:22.755536: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-08 04:45:22.755540: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 04:45:22.755544: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-11-08 04:45:23.259836: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-08 04:45:23.284854: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-08 04:45:23.284876: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 04:45:23.284881: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2022-11-08 04:45:23.325635: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 04:45:23.325665: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 04:45:23.325912: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-11-08 04:45:23.351476: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-08 04:45:23.378705: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_1/log_4/plugins/profile/2022_11_08_04_45_23\n",
      "\n",
      "2022-11-08 04:45:23.385061: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_mobilenet_1/log_4/plugins/profile/2022_11_08_04_45_23/ntcadmin-scse.trace.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  18/1000 [..............................] - ETA: 50s - loss: 0.6290 - accuracy: 0.7222 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 04:45:23.484949: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_1/log_4/plugins/profile/2022_11_08_04_45_23\n",
      "\n",
      "2022-11-08 04:45:23.497508: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_mobilenet_1/log_4/plugins/profile/2022_11_08_04_45_23/ntcadmin-scse.memory_profile.json.gz\n",
      "2022-11-08 04:45:23.498788: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_mobilenet_1/log_4/plugins/profile/2022_11_08_04_45_23\n",
      "Dumped tool data for xplane.pb to log/baseline_mobilenet_1/log_4/plugins/profile/2022_11_08_04_45_23/ntcadmin-scse.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_mobilenet_1/log_4/plugins/profile/2022_11_08_04_45_23/ntcadmin-scse.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_mobilenet_1/log_4/plugins/profile/2022_11_08_04_45_23/ntcadmin-scse.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_mobilenet_1/log_4/plugins/profile/2022_11_08_04_45_23/ntcadmin-scse.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_mobilenet_1/log_4/plugins/profile/2022_11_08_04_45_23/ntcadmin-scse.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 64s 61ms/step - loss: 0.6699 - accuracy: 0.6010 - val_loss: 0.6674 - val_accuracy: 0.5960 - lr: 5.0000e-05\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.6370 - accuracy: 0.6482 - val_loss: 0.6372 - val_accuracy: 0.6469 - lr: 5.0000e-05\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.6112 - accuracy: 0.6543 - val_loss: 0.6136 - val_accuracy: 0.6767 - lr: 5.0000e-05\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.6091 - accuracy: 0.6685 - val_loss: 0.7301 - val_accuracy: 0.5472 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5920 - accuracy: 0.6955 - val_loss: 0.5962 - val_accuracy: 0.6907 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 60s 61ms/step - loss: 0.5752 - accuracy: 0.7010 - val_loss: 0.5972 - val_accuracy: 0.6769 - lr: 5.0000e-05\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5980 - accuracy: 0.6720 - val_loss: 0.5657 - val_accuracy: 0.7067 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5697 - accuracy: 0.7157 - val_loss: 0.5550 - val_accuracy: 0.7132 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5685 - accuracy: 0.7063 - val_loss: 0.5642 - val_accuracy: 0.7201 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5630 - accuracy: 0.6977 - val_loss: 0.5621 - val_accuracy: 0.7029 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5719 - accuracy: 0.7060 - val_loss: 0.6251 - val_accuracy: 0.6272 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5484 - accuracy: 0.7315 - val_loss: 0.5795 - val_accuracy: 0.6769 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5547 - accuracy: 0.7215 - val_loss: 0.5460 - val_accuracy: 0.7223 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5695 - accuracy: 0.7042 - val_loss: 0.5488 - val_accuracy: 0.7206 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5432 - accuracy: 0.7240 - val_loss: 0.5373 - val_accuracy: 0.7238 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5424 - accuracy: 0.7287 - val_loss: 0.6018 - val_accuracy: 0.6551 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5394 - accuracy: 0.7258 - val_loss: 0.5390 - val_accuracy: 0.7240 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5428 - accuracy: 0.7220 - val_loss: 0.9545 - val_accuracy: 0.5707 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5313 - accuracy: 0.7425 - val_loss: 0.5512 - val_accuracy: 0.7076 - lr: 5.0000e-05\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5360 - accuracy: 0.7268 - val_loss: 0.5454 - val_accuracy: 0.7156 - lr: 5.0000e-05\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5660 - accuracy: 0.7057 - val_loss: 0.6441 - val_accuracy: 0.6343 - lr: 5.0000e-05\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5231 - accuracy: 0.7430 - val_loss: 0.5102 - val_accuracy: 0.7492 - lr: 5.0000e-05\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5320 - accuracy: 0.7355 - val_loss: 0.5254 - val_accuracy: 0.7321 - lr: 5.0000e-05\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5392 - accuracy: 0.7250 - val_loss: 0.6139 - val_accuracy: 0.6695 - lr: 5.0000e-05\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5363 - accuracy: 0.7235 - val_loss: 0.5150 - val_accuracy: 0.7391 - lr: 5.0000e-05\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5107 - accuracy: 0.7570 - val_loss: 0.5044 - val_accuracy: 0.7491 - lr: 5.0000e-05\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5255 - accuracy: 0.7355 - val_loss: 0.5314 - val_accuracy: 0.7297 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5469 - accuracy: 0.7250 - val_loss: 0.5930 - val_accuracy: 0.6720 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5070 - accuracy: 0.7590 - val_loss: 0.4966 - val_accuracy: 0.7525 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5168 - accuracy: 0.7517 - val_loss: 0.6734 - val_accuracy: 0.6059 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5260 - accuracy: 0.7358 - val_loss: 0.4992 - val_accuracy: 0.7577 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5340 - accuracy: 0.7243 - val_loss: 0.5096 - val_accuracy: 0.7394 - lr: 5.0000e-05\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5111 - accuracy: 0.7623 - val_loss: 0.6280 - val_accuracy: 0.6565 - lr: 5.0000e-05\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5220 - accuracy: 0.7390 - val_loss: 0.7738 - val_accuracy: 0.5817 - lr: 5.0000e-05\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5279 - accuracy: 0.7315 - val_loss: 0.5282 - val_accuracy: 0.7265 - lr: 5.0000e-05\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4904 - accuracy: 0.7660 - val_loss: 0.5060 - val_accuracy: 0.7505 - lr: 5.0000e-05\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4991 - accuracy: 0.7590 - val_loss: 0.4936 - val_accuracy: 0.7528 - lr: 5.0000e-05\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5204 - accuracy: 0.7347 - val_loss: 0.5065 - val_accuracy: 0.7640 - lr: 5.0000e-05\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5159 - accuracy: 0.7385 - val_loss: 0.4965 - val_accuracy: 0.7511 - lr: 5.0000e-05\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4938 - accuracy: 0.7653 - val_loss: 0.4946 - val_accuracy: 0.7600 - lr: 5.0000e-05\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5290 - accuracy: 0.7387 - val_loss: 0.5073 - val_accuracy: 0.7381 - lr: 5.0000e-05\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5142 - accuracy: 0.7405 - val_loss: 0.4847 - val_accuracy: 0.7714 - lr: 5.0000e-05\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4899 - accuracy: 0.7645 - val_loss: 0.4807 - val_accuracy: 0.7614 - lr: 5.0000e-05\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4745 - accuracy: 0.7742 - val_loss: 0.5045 - val_accuracy: 0.7588 - lr: 5.0000e-05\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5079 - accuracy: 0.7435 - val_loss: 0.4797 - val_accuracy: 0.7728 - lr: 5.0000e-05\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5110 - accuracy: 0.7350 - val_loss: 0.4959 - val_accuracy: 0.7610 - lr: 5.0000e-05\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4700 - accuracy: 0.7793 - val_loss: 0.5372 - val_accuracy: 0.7129 - lr: 5.0000e-05\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5264 - accuracy: 0.7375 - val_loss: 0.4843 - val_accuracy: 0.7632 - lr: 5.0000e-05\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5021 - accuracy: 0.7425 - val_loss: 0.4855 - val_accuracy: 0.7690 - lr: 5.0000e-05\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4902 - accuracy: 0.7552 - val_loss: 0.4640 - val_accuracy: 0.7752 - lr: 5.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4912 - accuracy: 0.7595 - val_loss: 0.5720 - val_accuracy: 0.7036 - lr: 5.0000e-05\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4936 - accuracy: 0.7552 - val_loss: 0.4730 - val_accuracy: 0.7658 - lr: 5.0000e-05\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 60s 61ms/step - loss: 0.5320 - accuracy: 0.7283 - val_loss: 0.4587 - val_accuracy: 0.7780 - lr: 5.0000e-05\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4605 - accuracy: 0.7815 - val_loss: 0.5675 - val_accuracy: 0.7311 - lr: 5.0000e-05\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5212 - accuracy: 0.7465 - val_loss: 0.4808 - val_accuracy: 0.7647 - lr: 5.0000e-05\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5007 - accuracy: 0.7523 - val_loss: 0.5673 - val_accuracy: 0.6877 - lr: 5.0000e-05\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4849 - accuracy: 0.7673 - val_loss: 0.4562 - val_accuracy: 0.7768 - lr: 5.0000e-05\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4752 - accuracy: 0.7770 - val_loss: 0.5606 - val_accuracy: 0.7169 - lr: 5.0000e-05\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4652 - accuracy: 0.7805 - val_loss: 0.4529 - val_accuracy: 0.7839 - lr: 5.0000e-05\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5150 - accuracy: 0.7398 - val_loss: 0.4518 - val_accuracy: 0.7780 - lr: 5.0000e-05\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4502 - accuracy: 0.7975 - val_loss: 0.5360 - val_accuracy: 0.7416 - lr: 5.0000e-05\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5068 - accuracy: 0.7523 - val_loss: 0.4574 - val_accuracy: 0.7824 - lr: 5.0000e-05\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4948 - accuracy: 0.7508 - val_loss: 0.4866 - val_accuracy: 0.7581 - lr: 5.0000e-05\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4842 - accuracy: 0.7605 - val_loss: 0.4650 - val_accuracy: 0.7700 - lr: 5.0000e-05\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4814 - accuracy: 0.7713 - val_loss: 0.4824 - val_accuracy: 0.7513 - lr: 5.0000e-05\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4750 - accuracy: 0.7740 - val_loss: 0.4687 - val_accuracy: 0.7675 - lr: 5.0000e-05\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5162 - accuracy: 0.7375 - val_loss: 0.5051 - val_accuracy: 0.7308 - lr: 5.0000e-05\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4477 - accuracy: 0.7900 - val_loss: 0.4456 - val_accuracy: 0.7856 - lr: 5.0000e-05\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4776 - accuracy: 0.7722 - val_loss: 0.4426 - val_accuracy: 0.7866 - lr: 5.0000e-05\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4844 - accuracy: 0.7602 - val_loss: 0.4623 - val_accuracy: 0.7717 - lr: 5.0000e-05\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4792 - accuracy: 0.7665 - val_loss: 0.6453 - val_accuracy: 0.6387 - lr: 5.0000e-05\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4762 - accuracy: 0.7700 - val_loss: 0.4681 - val_accuracy: 0.7677 - lr: 5.0000e-05\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4820 - accuracy: 0.7707 - val_loss: 0.4598 - val_accuracy: 0.7819 - lr: 5.0000e-05\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5046 - accuracy: 0.7487 - val_loss: 0.4494 - val_accuracy: 0.7817 - lr: 5.0000e-05\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4469 - accuracy: 0.7900 - val_loss: 0.4438 - val_accuracy: 0.7856 - lr: 5.0000e-05\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4827 - accuracy: 0.7673 - val_loss: 0.4672 - val_accuracy: 0.7790 - lr: 5.0000e-05\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4832 - accuracy: 0.7655 - val_loss: 0.4648 - val_accuracy: 0.7639 - lr: 5.0000e-05\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4769 - accuracy: 0.7688 - val_loss: 0.6126 - val_accuracy: 0.6790 - lr: 5.0000e-05\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4666 - accuracy: 0.7732 - val_loss: 0.4858 - val_accuracy: 0.7448 - lr: 5.0000e-05\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4661 - accuracy: 0.7717 - val_loss: 0.4598 - val_accuracy: 0.7719 - lr: 5.0000e-05\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5123 - accuracy: 0.7365 - val_loss: 0.4490 - val_accuracy: 0.7776 - lr: 5.0000e-05\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4490 - accuracy: 0.7912 - val_loss: 0.4288 - val_accuracy: 0.7949 - lr: 5.0000e-05\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4636 - accuracy: 0.7832 - val_loss: 0.6870 - val_accuracy: 0.6401 - lr: 5.0000e-05\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4799 - accuracy: 0.7602 - val_loss: 0.4626 - val_accuracy: 0.7748 - lr: 5.0000e-05\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4628 - accuracy: 0.7728 - val_loss: 0.5218 - val_accuracy: 0.7369 - lr: 5.0000e-05\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 60s 61ms/step - loss: 0.4445 - accuracy: 0.7990 - val_loss: 0.4457 - val_accuracy: 0.7858 - lr: 5.0000e-05\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4711 - accuracy: 0.7660 - val_loss: 0.4637 - val_accuracy: 0.7663 - lr: 5.0000e-05\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5010 - accuracy: 0.7430 - val_loss: 0.6041 - val_accuracy: 0.6614 - lr: 5.0000e-05\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4463 - accuracy: 0.7895 - val_loss: 0.4421 - val_accuracy: 0.7814 - lr: 5.0000e-05\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 60s 61ms/step - loss: 0.4585 - accuracy: 0.7810 - val_loss: 0.4311 - val_accuracy: 0.7963 - lr: 5.0000e-05\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4658 - accuracy: 0.7735 - val_loss: 0.4717 - val_accuracy: 0.7570 - lr: 5.0000e-05\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4718 - accuracy: 0.7690 - val_loss: 0.4762 - val_accuracy: 0.7535 - lr: 5.0000e-05\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4509 - accuracy: 0.7928 - val_loss: 0.5585 - val_accuracy: 0.7187 - lr: 5.0000e-05\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4724 - accuracy: 0.7722 - val_loss: 0.5326 - val_accuracy: 0.7193 - lr: 5.0000e-05\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4874 - accuracy: 0.7515 - val_loss: 0.4600 - val_accuracy: 0.7732 - lr: 5.0000e-05\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4394 - accuracy: 0.7997 - val_loss: 0.4920 - val_accuracy: 0.7587 - lr: 5.0000e-05\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4435 - accuracy: 0.7903 - val_loss: 0.5114 - val_accuracy: 0.7355 - lr: 5.0000e-05\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4637 - accuracy: 0.7742 - val_loss: 0.4503 - val_accuracy: 0.7685 - lr: 5.0000e-05\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4589 - accuracy: 0.7722 - val_loss: 0.4370 - val_accuracy: 0.7904 - lr: 5.0000e-05\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4460 - accuracy: 0.7945 - val_loss: 0.4404 - val_accuracy: 0.7892 - lr: 5.0000e-05\n"
     ]
    }
   ],
   "source": [
    "for i, (train, val) in enumerate(folds):\n",
    "    \n",
    "    model = createModel()\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.00005)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    metrics = ['accuracy']\n",
    "    \n",
    "    model.compile(optimizer=opt, loss=loss, metrics=metrics)\n",
    "    \n",
    "    tboardCb = tf.keras.callbacks.TensorBoard(log_dir=f\"{logBasePath}/{logPrefix}_{i}\", histogram_freq=1, profile_batch=(2,10))\n",
    "    lrSchedule = tf.keras.callbacks.LearningRateScheduler(schedule)\n",
    "    \n",
    "    cbs = [tboardCb, lrSchedule]\n",
    "    \n",
    "    model.evaluate(val)\n",
    "    model.fit(train, initial_epoch=START_EPOCH, epochs=END_EPOCH, steps_per_epoch=STEPS_PER_EPOCH, callbacks=cbs, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e841a27f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
