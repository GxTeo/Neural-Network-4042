{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f19017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d782ddf",
   "metadata": {},
   "source": [
    "### Check Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03faa827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac4996",
   "metadata": {},
   "source": [
    "### GPU Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1e955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2835bd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f935a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be867b6",
   "metadata": {},
   "source": [
    "### Pandas Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92db292",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_column', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0907c",
   "metadata": {},
   "source": [
    "### Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0fd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VAL_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf19fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_WIDTH = 227\n",
    "CROP_HEIGHT = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d40847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldFiles = [\"adience/unprocessed/fold_0_data.txt\",\n",
    "             \"adience/unprocessed/fold_1_data.txt\",\n",
    "             \"adience/unprocessed/fold_2_data.txt\",\n",
    "             \"adience/unprocessed/fold_3_data.txt\",\n",
    "             \"adience/unprocessed/fold_4_data.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f61c7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genderMap = defaultdict(lambda : np.NaN)\n",
    "genderMap['m'] = 0\n",
    "genderMap['f'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d26242",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = ['(0, 2)', '(4, 6)', '(8, 13)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
    "ageMap = defaultdict(lambda : np.NaN)\n",
    "for i,a in enumerate(ages):\n",
    "    ageMap[a] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b1fc3",
   "metadata": {},
   "source": [
    "### Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd634a3",
   "metadata": {},
   "source": [
    "Dataset generation pipeline:\n",
    "Input: \n",
    "- foldFile - Path to fold file. Fold file Describes which images are in the fold and its corresponding labels\n",
    "- imgBaseFolder - Base folder to search image from\n",
    "- imgPrefix - Prefix of image file\n",
    "- genderMap - Map from ['m', 'f', 'u', None], to one hot index\n",
    "- ageMap - Map from age category to one hot index\n",
    "- imgWidth - Resulting image width\n",
    "- imgHeigh - Resulting image height\n",
    "- batchSize - Int or None, batch size\n",
    "- configureDs - Function accepting dataset for performance configurations\n",
    "- preBatch - List of (name, functions) pair that will be mapped before batching. name is used as name parameters for tf graph \n",
    "- postBatch - List of (name, functions) that will be mapped after batching. name is used as name parameters for tf graph\n",
    "\n",
    "The processing functions should have signature function(img, label) -> (img, label)\n",
    "\n",
    "Pipeline\n",
    "\n",
    "Read Fold File -> Preprocess filename and labels (dataframe) -> Convert filename and labels to numpy array -> Convert filename and labels to tf dataset -> Parse images and labels -> Configure Dataset for performance -> Pre-Batching preprocessing -> Batch -> Post-Batching preprocessing -> Output\n",
    "\n",
    "Some preprocessing steps can only be done before and some can only be done after batching, thats why there are seperated pre and post batching list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0795464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, batchSize, configureDs=None, preBatch=[], postBatch=[]):\n",
    "    \n",
    "    def parseImage(filename):\n",
    "        img = tf.io.read_file(filename)\n",
    "        img = tf.image.decode_jpeg(img)\n",
    "        img = tf.image.resize(img, [imgHeight, imgWidth])\n",
    "         \n",
    "        return img\n",
    "    \n",
    "    # Read Fold File\n",
    "    foldData = []\n",
    "    for f in foldFiles:\n",
    "        foldData.append(pd.read_csv(f, sep=\"\\t\"))\n",
    "    foldData = pd.concat(foldData)\n",
    "    \n",
    "    # Form File Name\n",
    "    foldData['filename'] = foldData.apply(lambda r: os.path.join(imgBaseFolder, r['user_id'], f\"{imgPrefix}.{r['face_id']}.{r['original_image']}\"), axis=1)\n",
    "    \n",
    "    # Generate Label One Hot Index\n",
    "    foldData['gender_ind'] = foldData['gender'].map(genderMap)\n",
    "    foldData['age_ind'] = foldData['age'].map(ageMap)\n",
    "    \n",
    "    # Remove dirty data\n",
    "    foldData.dropna(subset=['gender_ind', 'age_ind'], inplace=True)\n",
    "    \n",
    "    # Dataframe to numpy\n",
    "    filenames = foldData['filename'].to_numpy()\n",
    "    \n",
    "    genderIndex = foldData['gender_ind'].to_numpy().astype(int)\n",
    "    ageIndex = foldData['age_ind'].to_numpy().astype(int)\n",
    "    \n",
    "    # Numpy to Dataset\n",
    "    fnDs = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    genderIndDs = tf.data.Dataset.from_tensor_slices(genderIndex)\n",
    "    ageIndDs = tf.data.Dataset.from_tensor_slices(ageIndex)\n",
    "    \n",
    "    # Parse Images\n",
    "    imageDs = fnDs.map(parseImage, num_parallel_calls=tf.data.AUTOTUNE, name=\"parse_image\")\n",
    "    \n",
    "    # Parse Labels\n",
    "    genderLabDs = genderIndDs.map(lambda x: tf.one_hot(x, genderDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"gender_one_hot\")\n",
    "    ageLabDs = ageIndDs.map(lambda x: tf.one_hot(x, ageDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"age_one_hot\")\n",
    "    \n",
    "    # Combine Labels\n",
    "    labelDs = tf.data.Dataset.zip((genderLabDs, ageLabDs), name=\"label_zip\")\n",
    "    labelDs = labelDs.map(lambda g,a: {\"gender\": g, \"age\": a}, num_parallel_calls=tf.data.AUTOTUNE, name='label_dict')\n",
    "    \n",
    "    # Combine Images and Labels into dataset\n",
    "    ds = tf.data.Dataset.zip((imageDs, labelDs))\n",
    "    \n",
    "    # Configure Performance\n",
    "    if(configureDs is not None):\n",
    "        ds = configureDs(ds)\n",
    "    \n",
    "    # Pre Batch Preprocessing\n",
    "    for n,f in preBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    # Batch\n",
    "    if(batchSize is not None):\n",
    "        ds = ds.batch(batchSize, name=\"ds_batch\")\n",
    "    \n",
    "    # Post Batch Preprocessing\n",
    "    for n,f in postBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320ed92",
   "metadata": {},
   "source": [
    "### Preprocessings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "472b7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=100)\n",
    "    ds = ds.repeat()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adb98feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313da7f1",
   "metadata": {},
   "source": [
    "#### Preprocessing steps according to the reference paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7724a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainPreprocessA(img, lab):\n",
    "        \n",
    "        img = tf.image.random_crop(img, [CROP_HEIGHT, CROP_WIDTH, 3])\n",
    "        \n",
    "        ud = tf.random.uniform([], dtype=tf.float32)\n",
    "        udCond = tf.less(ud, 0.5)\n",
    "        \n",
    "        img = tf.cond(udCond, lambda: tf.image.flip_up_down(img), lambda: img)\n",
    "        \n",
    "        lr = tf.random.uniform([], dtype=tf.float32)\n",
    "        lrCond = tf.less(lr, 0.5)\n",
    "        \n",
    "        img = tf.cond(lrCond, lambda: tf.image.flip_left_right(img), lambda: img)\n",
    "        \n",
    "        img = tf.image.random_brightness(img, 63/255)\n",
    "        \n",
    "        img = tf.image.random_contrast(img, 0.2, 1.8) \n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14ee59ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valPreprocessA(img, lab):\n",
    "        \n",
    "        img = tf.image.crop_to_bounding_box(img,\n",
    "                                            (IMG_HEIGHT-CROP_HEIGHT) // 2,\n",
    "                                            (IMG_WIDTH-CROP_WIDTH) // 2,\n",
    "                                            CROP_HEIGHT,\n",
    "                                            CROP_WIDTH)\n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a03ab680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageStandardize(img, lab):\n",
    "    \n",
    "    img = tf.image.per_image_standardization(img)\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ec104",
   "metadata": {},
   "source": [
    "#### Label extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "294a2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractGenderLabel(img, lab):\n",
    "    \n",
    "    lab = lab['gender']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a98897ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAgeLabel(img, lab):\n",
    "    \n",
    "    lab = lab['age']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7778c",
   "metadata": {},
   "source": [
    "### Generate Folds for K-Folds validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4172d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFoldDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, valBatchSize, trainConfigureDs=None, trainPreBatch=[], trainPostBatch=[], valConfigureDs=None, valPreBatch=[], valPostBatch=[]):\n",
    "    '''\n",
    "        Returns list of (train, validation) datasets\n",
    "    '''\n",
    "    \n",
    "    N = len(foldFiles)\n",
    "    \n",
    "    folds = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        trainFiles = foldFiles[:i]\n",
    "        if(i < N-1):\n",
    "            trainFiles.extend(foldFiles[i+1:])\n",
    "            \n",
    "        valFiles = foldFiles[i]\n",
    "        \n",
    "        trainDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, configureDs=trainConfigureDs, preBatch=trainPreBatch, postBatch=trainPostBatch)\n",
    "        valDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, valBatchSize, configureDs=valConfigureDs, preBatch=valPreBatch, postBatch=valPostBatch)\n",
    "        \n",
    "        folds.append((trainDs, valDs))\n",
    "        \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4f43dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPreBatch = [(\"train_process_a\", trainPreprocessA), \n",
    "                 (\"train_standardize\", imageStandardize), \n",
    "                 (\"train_extract_gender\", extractGenderLabel)]\n",
    "\n",
    "valPreBatch = [(\"val_process_a\", valPreprocessA), \n",
    "               (\"val_standardize\", imageStandardize), \n",
    "               (\"val_extract_gender\", extractGenderLabel)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10474d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 18:50:56.046532: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-08 18:50:56.530763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10092 MB memory:  -> device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "folds = generateFoldDs(foldFiles, \"adience/faces\", \"coarse_tilt_aligned_face\", genderMap, ageMap, 2, 8, \n",
    "                       IMG_WIDTH, IMG_HEIGHT, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE, \n",
    "                       trainConfigureDs=trainConfigPerformance, trainPreBatch=trainPreBatch, \n",
    "                       valConfigureDs=valConfigPerformance, valPreBatch=valPreBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57d814af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b5f9bc",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d0df0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in folds[0][0].take(1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c9e2833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 227, 227, 3), dtype=float32, numpy=\n",
       "array([[[[-1.40617144e+00, -1.39283395e+00, -1.13546455e+00],\n",
       "         [-1.46679461e+00, -1.45345736e+00, -1.19608796e+00],\n",
       "         [-1.39987886e+00, -1.38654149e+00, -1.12917221e+00],\n",
       "         ...,\n",
       "         [ 1.95723367e+00,  7.59137213e-01,  1.64015979e-01],\n",
       "         [ 1.97690582e+00,  7.78809369e-01,  2.28556111e-01],\n",
       "         [ 2.11343622e+00,  8.70471656e-01,  3.42652500e-01]],\n",
       "\n",
       "        [[-1.44007492e+00, -1.38257074e+00, -1.19215262e+00],\n",
       "         [-1.37766409e+00, -1.36432660e+00, -1.15182519e+00],\n",
       "         [-1.36730623e+00, -1.35396886e+00, -1.14146745e+00],\n",
       "         ...,\n",
       "         [ 2.06246042e+00,  8.70531797e-01,  2.56907254e-01],\n",
       "         [ 2.11943889e+00,  9.21342432e-01,  3.71089309e-01],\n",
       "         [ 2.14533687e+00,  9.02372658e-01,  4.19421375e-01]],\n",
       "\n",
       "        [[-1.39911687e+00, -1.34091163e+00, -1.15084410e+00],\n",
       "         [-1.30537796e+00, -1.24717271e+00, -1.05710530e+00],\n",
       "         [-1.31631708e+00, -1.25811172e+00, -1.06804430e+00],\n",
       "         ...,\n",
       "         [ 2.06000686e+00,  8.84344399e-01,  2.21921310e-01],\n",
       "         [ 2.00238490e+00,  8.04288387e-01,  2.15182513e-01],\n",
       "         [ 2.08358479e+00,  8.40620279e-01,  3.49318027e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.01425433e+00, -1.75414336e+00, -1.63137782e+00],\n",
       "         [-2.01425433e+00, -1.75414336e+00, -1.63137782e+00],\n",
       "         [-2.01425433e+00, -1.75414336e+00, -1.63137782e+00],\n",
       "         ...,\n",
       "         [-3.18164110e-01, -4.61864382e-01, -8.23970199e-01],\n",
       "         [-2.98432380e-01, -4.89917755e-01, -8.56555223e-01],\n",
       "         [-2.07120553e-01, -3.96976531e-01, -8.08762491e-01]],\n",
       "\n",
       "        [[-2.01425433e+00, -1.75414336e+00, -1.63137782e+00],\n",
       "         [-2.01425433e+00, -1.75414336e+00, -1.63137782e+00],\n",
       "         [-2.01425433e+00, -1.75414336e+00, -1.63137782e+00],\n",
       "         ...,\n",
       "         [-3.31302792e-01, -4.75003123e-01, -8.01509559e-01],\n",
       "         [-3.03594470e-01, -4.47294772e-01, -8.13641191e-01],\n",
       "         [-2.31830180e-01, -4.29492295e-01, -8.17859888e-01]],\n",
       "\n",
       "        [[-2.01425433e+00, -1.75414336e+00, -1.63137782e+00],\n",
       "         [-2.01425433e+00, -1.75414336e+00, -1.63137782e+00],\n",
       "         [-2.01425433e+00, -1.75414336e+00, -1.63137782e+00],\n",
       "         ...,\n",
       "         [-3.87397319e-01, -5.53356946e-01, -8.12492371e-01],\n",
       "         [-2.74730474e-01, -4.52213168e-01, -7.66865909e-01],\n",
       "         [-2.00359106e-01, -4.11361247e-01, -7.30553150e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 1.56812429e+00,  1.51528609e+00,  1.05684018e+00],\n",
       "         [ 1.39842772e+00,  1.34558928e+00,  8.87143254e-01],\n",
       "         [ 1.41392672e+00,  1.36108828e+00,  9.02642250e-01],\n",
       "         ...,\n",
       "         [ 1.97009587e+00,  2.00198507e+00,  1.99006402e+00],\n",
       "         [ 1.98539221e+00,  2.01728153e+00,  2.03595304e+00],\n",
       "         [ 1.98539221e+00,  2.01728153e+00,  2.03595304e+00]],\n",
       "\n",
       "        [[ 1.43011284e+00,  1.38552046e+00,  9.14705694e-01],\n",
       "         [ 1.34895682e+00,  1.30436456e+00,  8.33549678e-01],\n",
       "         [ 1.37374091e+00,  1.32914829e+00,  8.58333647e-01],\n",
       "         ...,\n",
       "         [ 1.97009587e+00,  2.00198507e+00,  1.99006402e+00],\n",
       "         [ 1.98539221e+00,  2.01728153e+00,  2.03595304e+00],\n",
       "         [ 1.98539221e+00,  2.01728153e+00,  2.03595304e+00]],\n",
       "\n",
       "        [[ 1.40129375e+00,  1.32610834e+00,  9.01183069e-01],\n",
       "         [ 1.42988038e+00,  1.35469496e+00,  9.29769635e-01],\n",
       "         [ 1.40813720e+00,  1.33295202e+00,  9.08026516e-01],\n",
       "         ...,\n",
       "         [ 1.97009587e+00,  2.00198507e+00,  1.99006402e+00],\n",
       "         [ 1.98539221e+00,  2.01728153e+00,  2.03595304e+00],\n",
       "         [ 1.98539221e+00,  2.01728153e+00,  2.03595304e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.68042612e+00, -1.55466640e+00, -1.22833347e+00],\n",
       "         [-1.58877635e+00, -1.45693123e+00, -1.13364100e+00],\n",
       "         [-1.66937017e+00, -1.53247237e+00, -1.20661747e+00],\n",
       "         ...,\n",
       "         [ 5.61448872e-01, -3.39744061e-01, -1.00941253e+00],\n",
       "         [ 5.33420563e-01, -3.67772222e-01, -1.06803358e+00],\n",
       "         [ 6.33916497e-01, -2.82572836e-01, -9.82834160e-01]],\n",
       "\n",
       "        [[-1.35449731e+00, -1.17919695e+00, -7.29655802e-01],\n",
       "         [-1.41189063e+00, -1.23418617e+00, -8.05439651e-01],\n",
       "         [-1.62310648e+00, -1.44062102e+00, -1.02929401e+00],\n",
       "         ...,\n",
       "         [ 4.63821203e-01, -3.91482472e-01, -1.09700203e+00],\n",
       "         [ 4.64214236e-01, -4.36978698e-01, -1.13724017e+00],\n",
       "         [ 5.55234790e-01, -3.30661774e-01, -1.07681239e+00]],\n",
       "\n",
       "        [[-1.07385755e+00, -8.28380466e-01, -3.21512371e-01],\n",
       "         [-1.24823534e+00, -9.99387145e-01, -5.31980336e-01],\n",
       "         [-1.40023351e+00, -1.15037596e+00, -7.16111898e-01],\n",
       "         ...,\n",
       "         [ 4.72657949e-01, -3.52052867e-01, -1.08290708e+00],\n",
       "         [ 4.55987126e-01, -3.93699765e-01, -1.14265883e+00],\n",
       "         [ 4.53364670e-01, -4.01939005e-01, -1.14808977e+00]]],\n",
       "\n",
       "\n",
       "       [[[-2.21549845e+00, -2.41350508e+00, -2.94249845e+00],\n",
       "         [-2.21899366e+00, -2.41944742e+00, -2.95367622e+00],\n",
       "         [-2.22849250e+00, -2.41989112e+00, -2.95367622e+00],\n",
       "         ...,\n",
       "         [-1.95290029e+00, -1.94973624e+00, -2.44014597e+00],\n",
       "         [-1.83477449e+00, -1.87859929e+00, -2.35334611e+00],\n",
       "         [-1.83415508e+00, -1.85668814e+00, -2.34562922e+00]],\n",
       "\n",
       "        [[-2.18546915e+00, -2.43389058e+00, -2.95367622e+00],\n",
       "         [-2.17302585e+00, -2.39746356e+00, -2.94580650e+00],\n",
       "         [-1.88934207e+00, -2.11378002e+00, -2.68348312e+00],\n",
       "         ...,\n",
       "         [-1.92568886e+00, -1.92252505e+00, -2.41293478e+00],\n",
       "         [-1.74513340e+00, -1.78895819e+00, -2.26370502e+00],\n",
       "         [-1.80829346e+00, -1.83082688e+00, -2.31976795e+00]],\n",
       "\n",
       "        [[-2.52174795e-01, -5.63982189e-01, -1.27140141e+00],\n",
       "         [-3.20986688e-01, -6.03368640e-01, -1.28002048e+00],\n",
       "         [-3.84285033e-01, -6.59542978e-01, -1.29487622e+00],\n",
       "         ...,\n",
       "         [-1.93453741e+00, -1.93137360e+00, -2.42178345e+00],\n",
       "         [-1.75241423e+00, -1.79623902e+00, -2.27098584e+00],\n",
       "         [-1.86361110e+00, -1.88614380e+00, -2.37508535e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-7.10150599e-01, -4.94068801e-01, -7.25551367e-01],\n",
       "         [-7.20505893e-01, -4.87537950e-01, -7.42735922e-01],\n",
       "         [-8.98369253e-01, -7.54239023e-01, -1.00149894e+00],\n",
       "         ...,\n",
       "         [ 1.51227689e+00,  1.39013743e+00, -5.57099208e-02],\n",
       "         [ 1.56556714e+00,  1.44856727e+00, -3.03188264e-02],\n",
       "         [ 1.47158206e+00,  1.39643145e+00, -9.64041427e-02]],\n",
       "\n",
       "        [[-7.42768884e-01, -5.30358255e-01, -7.69182742e-01],\n",
       "         [-7.66182780e-01, -5.33214808e-01, -7.90394247e-01],\n",
       "         [-8.22460234e-01, -6.78330004e-01, -9.33795810e-01],\n",
       "         ...,\n",
       "         [ 1.53960240e+00,  1.41746294e+00, -2.83837393e-02],\n",
       "         [ 1.62959528e+00,  1.51259542e+00,  3.37093510e-02],\n",
       "         [ 1.52868879e+00,  1.45353830e+00, -3.92973684e-02]],\n",
       "\n",
       "        [[-7.25576401e-01, -5.16993284e-01, -7.57129788e-01],\n",
       "         [-7.70071864e-01, -5.33677399e-01, -7.92569757e-01],\n",
       "         [-8.45361531e-01, -6.54242992e-01, -9.09303606e-01],\n",
       "         ...,\n",
       "         [ 1.54465401e+00,  1.42080164e+00, -2.16191672e-02],\n",
       "         [ 1.60935104e+00,  1.52006352e+00,  6.96393847e-02],\n",
       "         [ 1.60029626e+00,  1.52498519e+00,  3.49597447e-02]]],\n",
       "\n",
       "\n",
       "       [[[-2.18746686e+00, -2.32546186e+00, -2.19374895e+00],\n",
       "         [-2.26124573e+00, -2.37056065e+00, -2.24840784e+00],\n",
       "         [-2.14655113e+00, -2.30547476e+00, -2.19985819e+00],\n",
       "         ...,\n",
       "         [-5.79704414e-04, -4.57156301e-01, -9.58537161e-01],\n",
       "         [ 1.45063981e-01, -3.28048855e-01, -8.59762132e-01],\n",
       "         [ 1.30364254e-01, -3.75821233e-01, -9.15119410e-01]],\n",
       "\n",
       "        [[-2.16693735e+00, -2.30493212e+00, -2.17321944e+00],\n",
       "         [-2.22248888e+00, -2.33180356e+00, -2.20965099e+00],\n",
       "         [-2.09133244e+00, -2.25025582e+00, -2.14463925e+00],\n",
       "         ...,\n",
       "         [ 1.24247849e-01, -3.32328737e-01, -7.88945556e-01],\n",
       "         [ 3.66179943e-02, -4.53031451e-01, -9.26184297e-01],\n",
       "         [ 1.37565047e-01, -3.68620455e-01, -8.75785708e-01]],\n",
       "\n",
       "        [[-2.17479920e+00, -2.31279421e+00, -2.18108153e+00],\n",
       "         [-2.23455071e+00, -2.34386587e+00, -2.22171307e+00],\n",
       "         [-2.12300920e+00, -2.28193307e+00, -2.17631650e+00],\n",
       "         ...,\n",
       "         [-3.19628092e-03, -4.59772974e-01, -9.45263565e-01],\n",
       "         [ 4.52240780e-02, -4.29988205e-01, -9.46451902e-01],\n",
       "         [ 8.25841576e-02, -4.23601329e-01, -9.59159970e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 5.55065036e-01, -1.72655862e-02, -1.26620471e-01],\n",
       "         [ 5.69474101e-01, -2.85628787e-03, -1.12211369e-01],\n",
       "         [ 6.04025364e-01,  3.16947475e-02, -1.10732600e-01],\n",
       "         ...,\n",
       "         [-1.26920551e-01, -3.35453093e-01, -6.76315904e-01],\n",
       "         [-5.90640865e-02, -2.67596632e-01, -6.08459532e-01],\n",
       "         [ 7.86241889e-02, -1.29908353e-01, -4.70771164e-01]],\n",
       "\n",
       "        [[ 6.70809746e-01,  9.84791666e-02, -1.08757252e-02],\n",
       "         [ 7.08215773e-01,  1.61206424e-01,  3.91907953e-02],\n",
       "         [ 6.57153964e-01,  8.48235190e-02, -2.45313700e-02],\n",
       "         ...,\n",
       "         [-1.24033019e-01, -3.32565486e-01, -6.73428297e-01],\n",
       "         [ 8.73294026e-02, -1.21203154e-01, -4.62066054e-01],\n",
       "         [ 8.39128867e-02, -1.28236935e-01, -4.69099849e-01]],\n",
       "\n",
       "        [[ 7.36313879e-01,  1.97055906e-01,  6.77039176e-02],\n",
       "         [ 7.64770508e-01,  2.25512534e-01,  7.23774210e-02],\n",
       "         [ 7.00835824e-01,  1.36708796e-01,  1.50485933e-02],\n",
       "         ...,\n",
       "         [ 9.02365968e-02, -1.59572020e-01, -4.96333033e-01],\n",
       "         [-5.56633845e-02, -2.97268391e-01, -6.38131320e-01],\n",
       "         [ 3.99756897e-03, -2.38056198e-01, -5.77573240e-01]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "819ce578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78c5d50",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a70f6af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    inp = tf.keras.Input(shape=(CROP_HEIGHT, CROP_WIDTH, 3))\n",
    "\n",
    "    backbone = tf.keras.applications.MobileNetV3Large(include_top=False, input_shape=(CROP_HEIGHT, CROP_WIDTH, 3))\n",
    "    backbone.trainable = False    \n",
    "    \n",
    "    flat1 = tf.keras.layers.Flatten(name='flat1')\n",
    "    fc1 = tf.keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc1')\n",
    "    do1 = tf.keras.layers.Dropout(0.5, name='do1')\n",
    "\n",
    "    fc2 = tf.keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc2')\n",
    "    do2 = tf.keras.layers.Dropout(0.5, name='do2')\n",
    "\n",
    "    fc3 = tf.keras.layers.Dense(2, activation='softmax', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='fc3')\n",
    "\n",
    "    o = tf.keras.applications.mobilenet_v3.preprocess_input(inp)\n",
    "    o = backbone(o, training=False)\n",
    "    o = flat1(o)\n",
    "    o = fc1(o)\n",
    "    o = do1(o)\n",
    "\n",
    "    o = fc2(o)\n",
    "    o = do2(o)\n",
    "\n",
    "    o = fc3(o)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=o, name='baseline_1')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e962234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "model = createModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b73a21c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"baseline_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 227, 227, 3)]     0         \n",
      "                                                                 \n",
      " MobilenetV3large (Functiona  (None, 8, 8, 960)        2996352   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flat1 (Flatten)             (None, 61440)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 128)               7864448   \n",
      "                                                                 \n",
      " do1 (Dropout)               (None, 128)               0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 128)               16512     \n",
      "                                                                 \n",
      " do2 (Dropout)               (None, 128)               0         \n",
      "                                                                 \n",
      " fc3 (Dense)                 (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,877,570\n",
      "Trainable params: 7,881,218\n",
      "Non-trainable params: 2,996,352\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fcc28d",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ffbbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = 1000\n",
    "EPOCH = 100\n",
    "\n",
    "START_EPOCH = 0\n",
    "END_EPOCH = START_EPOCH + EPOCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cc17f1",
   "metadata": {},
   "source": [
    "#### Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1ab143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(epoch, lr):\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "222f6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logBasePath = \"log/baseline_mobilenet_3\"\n",
    "logPrefix = \"log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1b72905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 18:51:12.808110: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-08 18:51:12.808135: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-08 18:51:12.808158: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1665] Profiler found 1 GPUs\n",
      "2022-11-08 18:51:12.808464: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/home/ntcadmin/env/trt-11.0/TensorRT-7.1.3.4/lib:\n",
      "2022-11-08 18:51:12.808540: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so'; dlerror: libcupti.so: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/home/ntcadmin/env/trt-11.0/TensorRT-7.1.3.4/lib:\n",
      "2022-11-08 18:51:12.808549: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:135] cuptiGetTimestamp: error 999: \n",
      "2022-11-08 18:51:12.808556: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-08 18:51:12.808560: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 18:51:12.808564: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-11-08 18:51:12.808703: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-08 18:51:12.808724: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-08 18:51:12.808729: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 18:51:12.808733: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2022-11-08 18:51:15.000906: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 51s 14ms/step - loss: 0.7021 - accuracy: 0.4768\n",
      "Epoch 1/100\n",
      "   8/1000 [..............................] - ETA: 15s - loss: 0.6801 - accuracy: 0.5312 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 18:52:07.360551: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-08 18:52:07.360600: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-08 18:52:07.360683: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 18:52:07.360710: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-08 18:52:07.360727: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 18:52:07.360744: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-11-08 18:52:07.502512: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-08 18:52:07.503039: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-08 18:52:07.503055: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 18:52:07.503062: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2022-11-08 18:52:07.534630: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 18:52:07.534662: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 18:52:07.534668: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-11-08 18:52:07.543045: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-08 18:52:07.552803: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_3/log_0/plugins/profile/2022_11_08_18_52_07\n",
      "\n",
      "2022-11-08 18:52:07.558793: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_mobilenet_3/log_0/plugins/profile/2022_11_08_18_52_07/ntcadmin-scse.trace.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  25/1000 [..............................] - ETA: 17s - loss: 0.6628 - accuracy: 0.6400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 18:52:07.596117: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_3/log_0/plugins/profile/2022_11_08_18_52_07\n",
      "\n",
      "2022-11-08 18:52:07.601708: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_mobilenet_3/log_0/plugins/profile/2022_11_08_18_52_07/ntcadmin-scse.memory_profile.json.gz\n",
      "2022-11-08 18:52:07.602524: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_mobilenet_3/log_0/plugins/profile/2022_11_08_18_52_07\n",
      "Dumped tool data for xplane.pb to log/baseline_mobilenet_3/log_0/plugins/profile/2022_11_08_18_52_07/ntcadmin-scse.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_mobilenet_3/log_0/plugins/profile/2022_11_08_18_52_07/ntcadmin-scse.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_mobilenet_3/log_0/plugins/profile/2022_11_08_18_52_07/ntcadmin-scse.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_mobilenet_3/log_0/plugins/profile/2022_11_08_18_52_07/ntcadmin-scse.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_mobilenet_3/log_0/plugins/profile/2022_11_08_18_52_07/ntcadmin-scse.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 996/1000 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 18:53:04.130883: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1887436800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s 57ms/step - loss: 0.6934 - accuracy: 0.5280 - val_loss: 0.6866 - val_accuracy: 0.6234 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      " 997/1000 [============================>.] - ETA: 0s - loss: 0.6748 - accuracy: 0.5838"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 18:54:01.248178: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1887436800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.6749 - accuracy: 0.5832 - val_loss: 0.6781 - val_accuracy: 0.5281 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.6520 - accuracy: 0.6206"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 18:54:58.161862: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1887436800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.6520 - accuracy: 0.6205 - val_loss: 0.6516 - val_accuracy: 0.6513 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.6501 - accuracy: 0.6226"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 18:55:56.761718: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1887436800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.6498 - accuracy: 0.6230 - val_loss: 0.6812 - val_accuracy: 0.5404 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      " 997/1000 [============================>.] - ETA: 0s - loss: 0.6337 - accuracy: 0.6344"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 18:56:53.572487: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1887436800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.6339 - accuracy: 0.6340 - val_loss: 0.6172 - val_accuracy: 0.6674 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5966 - accuracy: 0.6823 - val_loss: 0.6382 - val_accuracy: 0.6365 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.6109 - accuracy: 0.6578 - val_loss: 0.5951 - val_accuracy: 0.6756 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.6009 - accuracy: 0.6760 - val_loss: 0.5782 - val_accuracy: 0.6956 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.5768 - accuracy: 0.7057 - val_loss: 0.5797 - val_accuracy: 0.6856 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5721 - accuracy: 0.6955 - val_loss: 0.5753 - val_accuracy: 0.6883 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5903 - accuracy: 0.6842 - val_loss: 0.5775 - val_accuracy: 0.6973 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5641 - accuracy: 0.7107 - val_loss: 0.5629 - val_accuracy: 0.7005 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5621 - accuracy: 0.7065 - val_loss: 0.5665 - val_accuracy: 0.7090 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 59s 60ms/step - loss: 0.5776 - accuracy: 0.6923 - val_loss: 0.5801 - val_accuracy: 0.6722 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5477 - accuracy: 0.7225 - val_loss: 0.5620 - val_accuracy: 0.7110 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5529 - accuracy: 0.7218 - val_loss: 0.5757 - val_accuracy: 0.6783 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5491 - accuracy: 0.7082 - val_loss: 0.5392 - val_accuracy: 0.7284 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5553 - accuracy: 0.7153 - val_loss: 0.7541 - val_accuracy: 0.5898 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5491 - accuracy: 0.7258 - val_loss: 0.5479 - val_accuracy: 0.7095 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5399 - accuracy: 0.7262 - val_loss: 0.5547 - val_accuracy: 0.7042 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5660 - accuracy: 0.7030 - val_loss: 0.6469 - val_accuracy: 0.6204 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5212 - accuracy: 0.7380 - val_loss: 0.5264 - val_accuracy: 0.7379 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5374 - accuracy: 0.7337 - val_loss: 0.5223 - val_accuracy: 0.7417 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5306 - accuracy: 0.7352 - val_loss: 0.6130 - val_accuracy: 0.6603 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5418 - accuracy: 0.7195 - val_loss: 0.5159 - val_accuracy: 0.7426 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5175 - accuracy: 0.7510 - val_loss: 0.5257 - val_accuracy: 0.7374 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5401 - accuracy: 0.7132 - val_loss: 0.5793 - val_accuracy: 0.6728 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5467 - accuracy: 0.7185 - val_loss: 0.5631 - val_accuracy: 0.6902 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 58s 59ms/step - loss: 0.5106 - accuracy: 0.7465 - val_loss: 0.5231 - val_accuracy: 0.7400 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5065 - accuracy: 0.7582 - val_loss: 0.6437 - val_accuracy: 0.6450 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5255 - accuracy: 0.7360 - val_loss: 0.5143 - val_accuracy: 0.7419 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5185 - accuracy: 0.7360 - val_loss: 0.5448 - val_accuracy: 0.7143 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5031 - accuracy: 0.7673 - val_loss: 0.6079 - val_accuracy: 0.6754 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5246 - accuracy: 0.7340 - val_loss: 0.7315 - val_accuracy: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5247 - accuracy: 0.7322 - val_loss: 0.5099 - val_accuracy: 0.7417 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5052 - accuracy: 0.7550 - val_loss: 0.4946 - val_accuracy: 0.7550 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4898 - accuracy: 0.7632 - val_loss: 0.4882 - val_accuracy: 0.7604 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5103 - accuracy: 0.7433 - val_loss: 0.4908 - val_accuracy: 0.7647 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5040 - accuracy: 0.7495 - val_loss: 0.5034 - val_accuracy: 0.7465 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4960 - accuracy: 0.7602 - val_loss: 0.5143 - val_accuracy: 0.7362 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5191 - accuracy: 0.7393 - val_loss: 0.5400 - val_accuracy: 0.7053 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5082 - accuracy: 0.7437 - val_loss: 0.5031 - val_accuracy: 0.7428 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4856 - accuracy: 0.7665 - val_loss: 0.4819 - val_accuracy: 0.7607 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4760 - accuracy: 0.7810 - val_loss: 0.4825 - val_accuracy: 0.7638 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5040 - accuracy: 0.7427 - val_loss: 0.4778 - val_accuracy: 0.7675 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5057 - accuracy: 0.7445 - val_loss: 0.4901 - val_accuracy: 0.7591 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4709 - accuracy: 0.7755 - val_loss: 0.6486 - val_accuracy: 0.6802 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5182 - accuracy: 0.7440 - val_loss: 0.4703 - val_accuracy: 0.7777 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4942 - accuracy: 0.7550 - val_loss: 0.4746 - val_accuracy: 0.7722 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4759 - accuracy: 0.7775 - val_loss: 0.4665 - val_accuracy: 0.7706 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4660 - accuracy: 0.7810 - val_loss: 0.6364 - val_accuracy: 0.6637 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4755 - accuracy: 0.7703 - val_loss: 0.4778 - val_accuracy: 0.7617 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5069 - accuracy: 0.7458 - val_loss: 0.4545 - val_accuracy: 0.7802 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4418 - accuracy: 0.8010 - val_loss: 0.4708 - val_accuracy: 0.7737 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.5149 - accuracy: 0.7560 - val_loss: 0.4616 - val_accuracy: 0.7804 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4908 - accuracy: 0.7598 - val_loss: 0.4742 - val_accuracy: 0.7657 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4688 - accuracy: 0.7738 - val_loss: 0.4942 - val_accuracy: 0.7552 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4631 - accuracy: 0.7755 - val_loss: 0.5467 - val_accuracy: 0.7138 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4682 - accuracy: 0.7715 - val_loss: 0.4536 - val_accuracy: 0.7810 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5067 - accuracy: 0.7530 - val_loss: 0.4565 - val_accuracy: 0.7767 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4455 - accuracy: 0.7928 - val_loss: 0.5314 - val_accuracy: 0.7437 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4897 - accuracy: 0.7632 - val_loss: 0.4492 - val_accuracy: 0.7857 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4874 - accuracy: 0.7635 - val_loss: 0.5153 - val_accuracy: 0.7276 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4699 - accuracy: 0.7760 - val_loss: 0.4512 - val_accuracy: 0.7807 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4562 - accuracy: 0.7803 - val_loss: 0.4434 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4577 - accuracy: 0.7785 - val_loss: 0.4563 - val_accuracy: 0.7768 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5013 - accuracy: 0.7462 - val_loss: 0.5036 - val_accuracy: 0.7300 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4397 - accuracy: 0.7993 - val_loss: 0.4382 - val_accuracy: 0.7872 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4627 - accuracy: 0.7768 - val_loss: 0.4361 - val_accuracy: 0.7936 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4584 - accuracy: 0.7725 - val_loss: 0.4353 - val_accuracy: 0.7903 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4625 - accuracy: 0.7797 - val_loss: 0.5548 - val_accuracy: 0.7031 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4459 - accuracy: 0.7890 - val_loss: 0.4561 - val_accuracy: 0.7731 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4482 - accuracy: 0.7943 - val_loss: 0.4401 - val_accuracy: 0.7865 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4844 - accuracy: 0.7540 - val_loss: 0.4597 - val_accuracy: 0.7720 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4242 - accuracy: 0.8030 - val_loss: 0.4335 - val_accuracy: 0.7885 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4509 - accuracy: 0.7943 - val_loss: 0.4426 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4566 - accuracy: 0.7763 - val_loss: 0.4273 - val_accuracy: 0.7990 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4606 - accuracy: 0.7728 - val_loss: 0.5716 - val_accuracy: 0.7124 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4416 - accuracy: 0.7925 - val_loss: 0.4355 - val_accuracy: 0.7907 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4517 - accuracy: 0.7878 - val_loss: 0.4803 - val_accuracy: 0.7545 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4897 - accuracy: 0.7555 - val_loss: 0.4336 - val_accuracy: 0.7897 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4242 - accuracy: 0.8005 - val_loss: 0.4207 - val_accuracy: 0.8011 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4385 - accuracy: 0.7925 - val_loss: 0.6194 - val_accuracy: 0.6681 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4661 - accuracy: 0.7695 - val_loss: 0.4262 - val_accuracy: 0.7982 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4445 - accuracy: 0.7778 - val_loss: 0.5659 - val_accuracy: 0.7223 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4213 - accuracy: 0.8110 - val_loss: 0.4177 - val_accuracy: 0.7985 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4338 - accuracy: 0.7837 - val_loss: 0.5036 - val_accuracy: 0.7486 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4929 - accuracy: 0.7585 - val_loss: 0.5561 - val_accuracy: 0.7052 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4215 - accuracy: 0.8040 - val_loss: 0.4137 - val_accuracy: 0.8014 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4301 - accuracy: 0.8005 - val_loss: 0.4125 - val_accuracy: 0.8035 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4474 - accuracy: 0.7803 - val_loss: 0.4499 - val_accuracy: 0.7715 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4541 - accuracy: 0.7795 - val_loss: 0.4371 - val_accuracy: 0.7864 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4292 - accuracy: 0.8073 - val_loss: 0.4857 - val_accuracy: 0.7500 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4500 - accuracy: 0.7805 - val_loss: 0.4867 - val_accuracy: 0.7474 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4683 - accuracy: 0.7688 - val_loss: 0.4269 - val_accuracy: 0.7949 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4138 - accuracy: 0.8037 - val_loss: 0.5521 - val_accuracy: 0.7370 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4287 - accuracy: 0.7952 - val_loss: 0.5115 - val_accuracy: 0.7337 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4409 - accuracy: 0.7922 - val_loss: 0.4187 - val_accuracy: 0.7968 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4409 - accuracy: 0.7818 - val_loss: 0.4203 - val_accuracy: 0.7998 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4239 - accuracy: 0.8027 - val_loss: 0.4457 - val_accuracy: 0.7747 - lr: 1.0000e-05\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 20:30:09.778641: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-08 20:30:09.778667: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-08 20:30:09.778694: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 20:30:09.778701: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-08 20:30:09.778705: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 20:30:09.778709: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-11-08 20:30:09.778790: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-08 20:30:09.778812: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-08 20:30:09.778816: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 20:30:09.778820: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 51s 14ms/step - loss: 0.6921 - accuracy: 0.5232\n",
      "Epoch 1/100\n",
      "   9/1000 [..............................] - ETA: 15s - loss: 0.6861 - accuracy: 0.5000 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 20:31:04.151965: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-08 20:31:04.151984: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-08 20:31:04.152076: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 20:31:04.152085: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-08 20:31:04.152089: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 20:31:04.152094: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  14/1000 [..............................] - ETA: 42s - loss: 0.6920 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 20:31:04.514025: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-08 20:31:04.519186: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-08 20:31:04.519199: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 20:31:04.519204: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2022-11-08 20:31:04.549832: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 20:31:04.549860: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 20:31:04.549866: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-11-08 20:31:04.562952: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-08 20:31:04.578080: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_3/log_1/plugins/profile/2022_11_08_20_31_04\n",
      "\n",
      "2022-11-08 20:31:04.584079: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_mobilenet_3/log_1/plugins/profile/2022_11_08_20_31_04/ntcadmin-scse.trace.json.gz\n",
      "2022-11-08 20:31:04.626800: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_3/log_1/plugins/profile/2022_11_08_20_31_04\n",
      "\n",
      "2022-11-08 20:31:04.632545: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_mobilenet_3/log_1/plugins/profile/2022_11_08_20_31_04/ntcadmin-scse.memory_profile.json.gz\n",
      "2022-11-08 20:31:04.633298: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_mobilenet_3/log_1/plugins/profile/2022_11_08_20_31_04\n",
      "Dumped tool data for xplane.pb to log/baseline_mobilenet_3/log_1/plugins/profile/2022_11_08_20_31_04/ntcadmin-scse.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_mobilenet_3/log_1/plugins/profile/2022_11_08_20_31_04/ntcadmin-scse.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_mobilenet_3/log_1/plugins/profile/2022_11_08_20_31_04/ntcadmin-scse.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_mobilenet_3/log_1/plugins/profile/2022_11_08_20_31_04/ntcadmin-scse.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_mobilenet_3/log_1/plugins/profile/2022_11_08_20_31_04/ntcadmin-scse.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 64s 61ms/step - loss: 0.6939 - accuracy: 0.5205 - val_loss: 0.6834 - val_accuracy: 0.5309 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.6724 - accuracy: 0.5853 - val_loss: 0.6712 - val_accuracy: 0.5515 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.6477 - accuracy: 0.6233 - val_loss: 0.6476 - val_accuracy: 0.6402 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.6507 - accuracy: 0.6220 - val_loss: 0.6914 - val_accuracy: 0.5355 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 60s 61ms/step - loss: 0.6382 - accuracy: 0.6367 - val_loss: 0.6158 - val_accuracy: 0.6593 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5922 - accuracy: 0.6902 - val_loss: 0.6448 - val_accuracy: 0.6268 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.6124 - accuracy: 0.6572 - val_loss: 0.5923 - val_accuracy: 0.6773 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.6001 - accuracy: 0.6787 - val_loss: 0.5787 - val_accuracy: 0.6980 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5825 - accuracy: 0.7003 - val_loss: 0.5796 - val_accuracy: 0.7007 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5732 - accuracy: 0.7030 - val_loss: 0.5687 - val_accuracy: 0.7024 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5907 - accuracy: 0.6970 - val_loss: 0.5992 - val_accuracy: 0.6765 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5693 - accuracy: 0.7003 - val_loss: 0.6047 - val_accuracy: 0.6511 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5683 - accuracy: 0.7013 - val_loss: 0.5606 - val_accuracy: 0.7156 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5774 - accuracy: 0.6963 - val_loss: 0.5771 - val_accuracy: 0.6759 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5497 - accuracy: 0.7253 - val_loss: 0.5522 - val_accuracy: 0.7164 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5498 - accuracy: 0.7250 - val_loss: 0.6198 - val_accuracy: 0.6359 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5514 - accuracy: 0.7128 - val_loss: 0.5413 - val_accuracy: 0.7270 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5550 - accuracy: 0.7145 - val_loss: 0.7703 - val_accuracy: 0.5817 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5530 - accuracy: 0.7193 - val_loss: 0.5509 - val_accuracy: 0.7068 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5444 - accuracy: 0.7205 - val_loss: 0.5800 - val_accuracy: 0.6763 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5673 - accuracy: 0.7055 - val_loss: 0.6529 - val_accuracy: 0.6099 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5324 - accuracy: 0.7360 - val_loss: 0.5226 - val_accuracy: 0.7351 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5314 - accuracy: 0.7385 - val_loss: 0.5220 - val_accuracy: 0.7369 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5413 - accuracy: 0.7197 - val_loss: 0.6073 - val_accuracy: 0.6673 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5433 - accuracy: 0.7180 - val_loss: 0.5423 - val_accuracy: 0.7135 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5092 - accuracy: 0.7592 - val_loss: 0.5283 - val_accuracy: 0.7337 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5308 - accuracy: 0.7318 - val_loss: 0.5837 - val_accuracy: 0.6710 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5475 - accuracy: 0.7193 - val_loss: 0.5456 - val_accuracy: 0.7093 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5127 - accuracy: 0.7465 - val_loss: 0.5244 - val_accuracy: 0.7373 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 60s 61ms/step - loss: 0.5088 - accuracy: 0.7610 - val_loss: 0.6058 - val_accuracy: 0.6696 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 60s 61ms/step - loss: 0.5183 - accuracy: 0.7370 - val_loss: 0.5180 - val_accuracy: 0.7394 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5242 - accuracy: 0.7395 - val_loss: 0.5018 - val_accuracy: 0.7457 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5000 - accuracy: 0.7592 - val_loss: 0.5882 - val_accuracy: 0.6863 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5167 - accuracy: 0.7335 - val_loss: 0.7657 - val_accuracy: 0.5811 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5293 - accuracy: 0.7285 - val_loss: 0.5230 - val_accuracy: 0.7281 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 60s 61ms/step - loss: 0.4948 - accuracy: 0.7655 - val_loss: 0.5052 - val_accuracy: 0.7425 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4875 - accuracy: 0.7678 - val_loss: 0.5034 - val_accuracy: 0.7446 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5113 - accuracy: 0.7427 - val_loss: 0.4910 - val_accuracy: 0.7632 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5117 - accuracy: 0.7433 - val_loss: 0.4988 - val_accuracy: 0.7498 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4941 - accuracy: 0.7655 - val_loss: 0.5157 - val_accuracy: 0.7345 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5102 - accuracy: 0.7452 - val_loss: 0.5226 - val_accuracy: 0.7243 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5108 - accuracy: 0.7412 - val_loss: 0.4972 - val_accuracy: 0.7542 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4810 - accuracy: 0.7632 - val_loss: 0.4772 - val_accuracy: 0.7642 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4853 - accuracy: 0.7707 - val_loss: 0.5138 - val_accuracy: 0.7408 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4925 - accuracy: 0.7573 - val_loss: 0.4807 - val_accuracy: 0.7622 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5165 - accuracy: 0.7387 - val_loss: 0.4686 - val_accuracy: 0.7716 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4716 - accuracy: 0.7795 - val_loss: 0.5377 - val_accuracy: 0.7313 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5202 - accuracy: 0.7402 - val_loss: 0.4858 - val_accuracy: 0.7561 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 60s 61ms/step - loss: 0.4937 - accuracy: 0.7510 - val_loss: 0.4807 - val_accuracy: 0.7618 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4839 - accuracy: 0.7660 - val_loss: 0.4661 - val_accuracy: 0.7731 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4699 - accuracy: 0.7803 - val_loss: 0.6404 - val_accuracy: 0.6693 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4775 - accuracy: 0.7657 - val_loss: 0.4583 - val_accuracy: 0.7795 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5081 - accuracy: 0.7395 - val_loss: 0.4605 - val_accuracy: 0.7768 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4484 - accuracy: 0.7843 - val_loss: 0.4636 - val_accuracy: 0.7779 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5038 - accuracy: 0.7508 - val_loss: 0.4621 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4844 - accuracy: 0.7500 - val_loss: 0.4661 - val_accuracy: 0.7741 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4655 - accuracy: 0.7763 - val_loss: 0.4523 - val_accuracy: 0.7783 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4678 - accuracy: 0.7788 - val_loss: 0.5742 - val_accuracy: 0.6977 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4634 - accuracy: 0.7757 - val_loss: 0.4778 - val_accuracy: 0.7608 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5044 - accuracy: 0.7485 - val_loss: 0.4529 - val_accuracy: 0.7810 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4346 - accuracy: 0.8000 - val_loss: 0.4719 - val_accuracy: 0.7723 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4857 - accuracy: 0.7678 - val_loss: 0.4425 - val_accuracy: 0.7885 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 60s 61ms/step - loss: 0.4812 - accuracy: 0.7605 - val_loss: 0.5235 - val_accuracy: 0.7237 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4733 - accuracy: 0.7728 - val_loss: 0.4452 - val_accuracy: 0.7833 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4467 - accuracy: 0.7920 - val_loss: 0.4426 - val_accuracy: 0.7907 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4578 - accuracy: 0.7738 - val_loss: 0.4473 - val_accuracy: 0.7847 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5003 - accuracy: 0.7487 - val_loss: 0.4735 - val_accuracy: 0.7570 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4319 - accuracy: 0.7975 - val_loss: 0.4410 - val_accuracy: 0.7872 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4560 - accuracy: 0.7853 - val_loss: 0.4354 - val_accuracy: 0.7916 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4650 - accuracy: 0.7717 - val_loss: 0.4372 - val_accuracy: 0.7874 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4662 - accuracy: 0.7745 - val_loss: 0.7035 - val_accuracy: 0.6332 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4458 - accuracy: 0.7925 - val_loss: 0.4458 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4566 - accuracy: 0.7830 - val_loss: 0.4399 - val_accuracy: 0.7812 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4956 - accuracy: 0.7565 - val_loss: 0.4320 - val_accuracy: 0.7942 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4310 - accuracy: 0.8065 - val_loss: 0.4302 - val_accuracy: 0.7938 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4472 - accuracy: 0.7908 - val_loss: 0.4293 - val_accuracy: 0.7946 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4676 - accuracy: 0.7717 - val_loss: 0.4306 - val_accuracy: 0.7938 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4636 - accuracy: 0.7688 - val_loss: 0.6047 - val_accuracy: 0.6977 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4467 - accuracy: 0.7905 - val_loss: 0.4896 - val_accuracy: 0.7437 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 60s 61ms/step - loss: 0.4519 - accuracy: 0.7912 - val_loss: 0.4936 - val_accuracy: 0.7493 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4925 - accuracy: 0.7563 - val_loss: 0.4240 - val_accuracy: 0.7970 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4192 - accuracy: 0.8100 - val_loss: 0.4216 - val_accuracy: 0.7964 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4503 - accuracy: 0.7818 - val_loss: 0.6571 - val_accuracy: 0.6401 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4658 - accuracy: 0.7663 - val_loss: 0.4292 - val_accuracy: 0.7929 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4500 - accuracy: 0.7775 - val_loss: 0.7270 - val_accuracy: 0.6547 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4216 - accuracy: 0.8058 - val_loss: 0.4206 - val_accuracy: 0.7977 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4385 - accuracy: 0.7920 - val_loss: 0.4609 - val_accuracy: 0.7713 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4845 - accuracy: 0.7638 - val_loss: 0.5231 - val_accuracy: 0.7231 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4309 - accuracy: 0.8015 - val_loss: 0.4217 - val_accuracy: 0.7949 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4275 - accuracy: 0.8075 - val_loss: 0.4405 - val_accuracy: 0.7850 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4543 - accuracy: 0.7755 - val_loss: 0.4599 - val_accuracy: 0.7668 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4471 - accuracy: 0.7812 - val_loss: 0.4199 - val_accuracy: 0.7946 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4266 - accuracy: 0.8090 - val_loss: 0.4839 - val_accuracy: 0.7583 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4468 - accuracy: 0.7818 - val_loss: 0.4684 - val_accuracy: 0.7595 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4711 - accuracy: 0.7630 - val_loss: 0.4476 - val_accuracy: 0.7754 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4226 - accuracy: 0.8075 - val_loss: 0.5395 - val_accuracy: 0.7318 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4241 - accuracy: 0.7995 - val_loss: 0.5761 - val_accuracy: 0.7058 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4408 - accuracy: 0.7810 - val_loss: 0.4112 - val_accuracy: 0.8056 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4434 - accuracy: 0.7832 - val_loss: 0.4134 - val_accuracy: 0.8001 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4212 - accuracy: 0.8062 - val_loss: 0.4137 - val_accuracy: 0.8009 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 22:12:11.455042: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-08 22:12:11.455068: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-08 22:12:11.455095: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 22:12:11.455103: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-08 22:12:11.455107: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 22:12:11.455111: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-11-08 22:12:11.455189: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-08 22:12:11.455209: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-08 22:12:11.455214: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 22:12:11.455218: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 52s 14ms/step - loss: 0.7053 - accuracy: 0.4768\n",
      "Epoch 1/100\n",
      "   9/1000 [..............................] - ETA: 14s - loss: 0.6535 - accuracy: 0.7222 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 22:13:06.739237: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-08 22:13:06.739258: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-08 22:13:06.739347: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 22:13:06.739357: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-08 22:13:06.739361: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 22:13:06.739366: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  10/1000 [..............................] - ETA: 57s - loss: 0.6531 - accuracy: 0.7250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 22:13:07.110742: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-08 22:13:07.117083: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-08 22:13:07.117096: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 22:13:07.117101: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2022-11-08 22:13:07.150125: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 22:13:07.150153: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 22:13:07.150160: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-11-08 22:13:07.164908: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-08 22:13:07.182152: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_3/log_2/plugins/profile/2022_11_08_22_13_07\n",
      "\n",
      "2022-11-08 22:13:07.188974: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_mobilenet_3/log_2/plugins/profile/2022_11_08_22_13_07/ntcadmin-scse.trace.json.gz\n",
      "2022-11-08 22:13:07.232809: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_3/log_2/plugins/profile/2022_11_08_22_13_07\n",
      "\n",
      "2022-11-08 22:13:07.238388: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_mobilenet_3/log_2/plugins/profile/2022_11_08_22_13_07/ntcadmin-scse.memory_profile.json.gz\n",
      "2022-11-08 22:13:07.239121: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_mobilenet_3/log_2/plugins/profile/2022_11_08_22_13_07\n",
      "Dumped tool data for xplane.pb to log/baseline_mobilenet_3/log_2/plugins/profile/2022_11_08_22_13_07/ntcadmin-scse.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_mobilenet_3/log_2/plugins/profile/2022_11_08_22_13_07/ntcadmin-scse.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_mobilenet_3/log_2/plugins/profile/2022_11_08_22_13_07/ntcadmin-scse.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_mobilenet_3/log_2/plugins/profile/2022_11_08_22_13_07/ntcadmin-scse.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_mobilenet_3/log_2/plugins/profile/2022_11_08_22_13_07/ntcadmin-scse.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 64s 61ms/step - loss: 0.6923 - accuracy: 0.5332 - val_loss: 0.6820 - val_accuracy: 0.5468 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.6769 - accuracy: 0.5755 - val_loss: 0.6689 - val_accuracy: 0.6184 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.6463 - accuracy: 0.6220 - val_loss: 0.6463 - val_accuracy: 0.6480 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.6437 - accuracy: 0.6392 - val_loss: 0.6791 - val_accuracy: 0.5448 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.6319 - accuracy: 0.6467 - val_loss: 0.6115 - val_accuracy: 0.6723 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5885 - accuracy: 0.6967 - val_loss: 0.6283 - val_accuracy: 0.6506 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.6098 - accuracy: 0.6578 - val_loss: 0.5912 - val_accuracy: 0.6849 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5946 - accuracy: 0.6830 - val_loss: 0.5834 - val_accuracy: 0.6969 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5803 - accuracy: 0.6992 - val_loss: 0.5758 - val_accuracy: 0.7046 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5710 - accuracy: 0.7007 - val_loss: 0.5821 - val_accuracy: 0.6783 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5832 - accuracy: 0.6950 - val_loss: 0.5799 - val_accuracy: 0.6912 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5657 - accuracy: 0.7042 - val_loss: 0.5758 - val_accuracy: 0.6847 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5633 - accuracy: 0.7088 - val_loss: 0.5645 - val_accuracy: 0.7086 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5757 - accuracy: 0.6865 - val_loss: 0.5607 - val_accuracy: 0.7006 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5552 - accuracy: 0.7178 - val_loss: 0.5416 - val_accuracy: 0.7282 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5476 - accuracy: 0.7310 - val_loss: 0.6322 - val_accuracy: 0.6335 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5475 - accuracy: 0.7143 - val_loss: 0.5410 - val_accuracy: 0.7294 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5440 - accuracy: 0.7203 - val_loss: 0.7803 - val_accuracy: 0.5886 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5498 - accuracy: 0.7182 - val_loss: 0.5330 - val_accuracy: 0.7251 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5320 - accuracy: 0.7245 - val_loss: 0.5837 - val_accuracy: 0.6751 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5578 - accuracy: 0.7188 - val_loss: 0.6765 - val_accuracy: 0.6097 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5222 - accuracy: 0.7360 - val_loss: 0.5191 - val_accuracy: 0.7373 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5340 - accuracy: 0.7360 - val_loss: 0.5191 - val_accuracy: 0.7435 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5312 - accuracy: 0.7232 - val_loss: 0.6336 - val_accuracy: 0.6491 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5445 - accuracy: 0.7160 - val_loss: 0.5115 - val_accuracy: 0.7450 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5141 - accuracy: 0.7563 - val_loss: 0.5153 - val_accuracy: 0.7414 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5288 - accuracy: 0.7283 - val_loss: 0.5557 - val_accuracy: 0.7014 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.5494 - accuracy: 0.7168 - val_loss: 0.5464 - val_accuracy: 0.7099 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.5188 - accuracy: 0.7442 - val_loss: 0.5135 - val_accuracy: 0.7447 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5027 - accuracy: 0.7535 - val_loss: 0.6325 - val_accuracy: 0.6541 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5266 - accuracy: 0.7327 - val_loss: 0.5093 - val_accuracy: 0.7476 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5233 - accuracy: 0.7365 - val_loss: 0.5153 - val_accuracy: 0.7350 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5053 - accuracy: 0.7625 - val_loss: 0.5741 - val_accuracy: 0.6914 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5164 - accuracy: 0.7375 - val_loss: 0.7559 - val_accuracy: 0.5859 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5286 - accuracy: 0.7303 - val_loss: 0.5161 - val_accuracy: 0.7329 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5014 - accuracy: 0.7580 - val_loss: 0.4963 - val_accuracy: 0.7576 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4927 - accuracy: 0.7638 - val_loss: 0.5140 - val_accuracy: 0.7355 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5152 - accuracy: 0.7402 - val_loss: 0.4891 - val_accuracy: 0.7633 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5101 - accuracy: 0.7452 - val_loss: 0.4834 - val_accuracy: 0.7603 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4901 - accuracy: 0.7700 - val_loss: 0.4981 - val_accuracy: 0.7542 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5250 - accuracy: 0.7350 - val_loss: 0.5320 - val_accuracy: 0.7141 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5051 - accuracy: 0.7480 - val_loss: 0.5003 - val_accuracy: 0.7491 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4876 - accuracy: 0.7620 - val_loss: 0.4757 - val_accuracy: 0.7640 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 59s 60ms/step - loss: 0.4687 - accuracy: 0.7768 - val_loss: 0.5079 - val_accuracy: 0.7476 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4919 - accuracy: 0.7615 - val_loss: 0.4724 - val_accuracy: 0.7667 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5044 - accuracy: 0.7473 - val_loss: 0.4699 - val_accuracy: 0.7710 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4679 - accuracy: 0.7865 - val_loss: 0.7118 - val_accuracy: 0.6473 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5148 - accuracy: 0.7450 - val_loss: 0.4761 - val_accuracy: 0.7706 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.5014 - accuracy: 0.7423 - val_loss: 0.4805 - val_accuracy: 0.7610 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4698 - accuracy: 0.7735 - val_loss: 0.4660 - val_accuracy: 0.7722 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4663 - accuracy: 0.7750 - val_loss: 0.6121 - val_accuracy: 0.6873 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4774 - accuracy: 0.7657 - val_loss: 0.4618 - val_accuracy: 0.7734 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5091 - accuracy: 0.7427 - val_loss: 0.4636 - val_accuracy: 0.7741 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4409 - accuracy: 0.7945 - val_loss: 0.4641 - val_accuracy: 0.7737 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5057 - accuracy: 0.7558 - val_loss: 0.4586 - val_accuracy: 0.7780 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4876 - accuracy: 0.7475 - val_loss: 0.4607 - val_accuracy: 0.7818 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4690 - accuracy: 0.7763 - val_loss: 0.4494 - val_accuracy: 0.7827 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4719 - accuracy: 0.7763 - val_loss: 0.5902 - val_accuracy: 0.6863 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.4660 - accuracy: 0.7648 - val_loss: 0.4616 - val_accuracy: 0.7729 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5031 - accuracy: 0.7433 - val_loss: 0.4451 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4441 - accuracy: 0.7945 - val_loss: 0.4992 - val_accuracy: 0.7564 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4806 - accuracy: 0.7730 - val_loss: 0.4552 - val_accuracy: 0.7769 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4822 - accuracy: 0.7577 - val_loss: 0.4808 - val_accuracy: 0.7565 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4648 - accuracy: 0.7772 - val_loss: 0.4514 - val_accuracy: 0.7797 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4551 - accuracy: 0.7790 - val_loss: 0.4460 - val_accuracy: 0.7882 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4488 - accuracy: 0.7835 - val_loss: 0.4485 - val_accuracy: 0.7819 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4992 - accuracy: 0.7500 - val_loss: 0.4612 - val_accuracy: 0.7727 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4331 - accuracy: 0.7985 - val_loss: 0.4461 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4661 - accuracy: 0.7770 - val_loss: 0.4467 - val_accuracy: 0.7799 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4569 - accuracy: 0.7738 - val_loss: 0.4326 - val_accuracy: 0.7912 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.6233 - val_accuracy: 0.6635 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4535 - accuracy: 0.7850 - val_loss: 0.4482 - val_accuracy: 0.7866 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 61s 62ms/step - loss: 0.4534 - accuracy: 0.7862 - val_loss: 0.4347 - val_accuracy: 0.7933 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4949 - accuracy: 0.7462 - val_loss: 0.4312 - val_accuracy: 0.7977 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4269 - accuracy: 0.8027 - val_loss: 0.4262 - val_accuracy: 0.7953 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4462 - accuracy: 0.7987 - val_loss: 0.4425 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4474 - accuracy: 0.7835 - val_loss: 0.4389 - val_accuracy: 0.7881 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4545 - accuracy: 0.7770 - val_loss: 0.7163 - val_accuracy: 0.6586 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4306 - accuracy: 0.7887 - val_loss: 0.4736 - val_accuracy: 0.7578 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4320 - accuracy: 0.8002 - val_loss: 0.4315 - val_accuracy: 0.7873 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4891 - accuracy: 0.7585 - val_loss: 0.4792 - val_accuracy: 0.7552 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4134 - accuracy: 0.8085 - val_loss: 0.4209 - val_accuracy: 0.8004 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4305 - accuracy: 0.8008 - val_loss: 0.6409 - val_accuracy: 0.6773 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4583 - accuracy: 0.7745 - val_loss: 0.4727 - val_accuracy: 0.7530 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4537 - accuracy: 0.7763 - val_loss: 0.6134 - val_accuracy: 0.7060 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4278 - accuracy: 0.8023 - val_loss: 0.4283 - val_accuracy: 0.7908 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4354 - accuracy: 0.7860 - val_loss: 0.5223 - val_accuracy: 0.7405 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.4865 - accuracy: 0.7620 - val_loss: 0.5833 - val_accuracy: 0.6858 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4187 - accuracy: 0.8140 - val_loss: 0.4333 - val_accuracy: 0.7912 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4329 - accuracy: 0.7965 - val_loss: 0.4232 - val_accuracy: 0.7980 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4626 - accuracy: 0.7690 - val_loss: 0.4810 - val_accuracy: 0.7439 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4405 - accuracy: 0.7895 - val_loss: 0.4344 - val_accuracy: 0.7904 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4183 - accuracy: 0.8077 - val_loss: 0.4774 - val_accuracy: 0.7622 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4484 - accuracy: 0.7790 - val_loss: 0.5263 - val_accuracy: 0.7079 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4583 - accuracy: 0.7803 - val_loss: 0.4178 - val_accuracy: 0.7997 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4198 - accuracy: 0.8070 - val_loss: 0.4082 - val_accuracy: 0.8021 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4239 - accuracy: 0.8087 - val_loss: 0.6727 - val_accuracy: 0.6683 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4397 - accuracy: 0.7825 - val_loss: 0.4171 - val_accuracy: 0.8041 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4493 - accuracy: 0.7788 - val_loss: 0.4284 - val_accuracy: 0.7979 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4224 - accuracy: 0.8075 - val_loss: 0.4231 - val_accuracy: 0.7941 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 23:54:41.008800: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-08 23:54:41.008825: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-08 23:54:41.008853: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 23:54:41.008860: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-08 23:54:41.008864: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 23:54:41.008869: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-11-08 23:54:41.008953: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-08 23:54:41.008977: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-08 23:54:41.008982: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 23:54:41.008985: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 52s 14ms/step - loss: 0.6957 - accuracy: 0.4768\n",
      "Epoch 1/100\n",
      "   9/1000 [..............................] - ETA: 15s - loss: 0.6856 - accuracy: 0.5000 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 23:55:36.362536: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-08 23:55:36.362556: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-08 23:55:36.362681: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 23:55:36.362692: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-08 23:55:36.362696: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 23:55:36.362700: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-11-08 23:55:36.777834: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-08 23:55:36.793314: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-08 23:55:36.793336: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 23:55:36.793341: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2022-11-08 23:55:36.830821: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 23:55:36.830852: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 23:55:36.830858: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-11-08 23:55:36.850992: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-08 23:55:36.872237: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_3/log_3/plugins/profile/2022_11_08_23_55_36\n",
      "\n",
      "2022-11-08 23:55:36.878269: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_mobilenet_3/log_3/plugins/profile/2022_11_08_23_55_36/ntcadmin-scse.trace.json.gz\n",
      "2022-11-08 23:55:36.956164: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_3/log_3/plugins/profile/2022_11_08_23_55_36\n",
      "\n",
      "2022-11-08 23:55:36.965843: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_mobilenet_3/log_3/plugins/profile/2022_11_08_23_55_36/ntcadmin-scse.memory_profile.json.gz\n",
      "2022-11-08 23:55:36.966676: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_mobilenet_3/log_3/plugins/profile/2022_11_08_23_55_36\n",
      "Dumped tool data for xplane.pb to log/baseline_mobilenet_3/log_3/plugins/profile/2022_11_08_23_55_36/ntcadmin-scse.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_mobilenet_3/log_3/plugins/profile/2022_11_08_23_55_36/ntcadmin-scse.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_mobilenet_3/log_3/plugins/profile/2022_11_08_23_55_36/ntcadmin-scse.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_mobilenet_3/log_3/plugins/profile/2022_11_08_23_55_36/ntcadmin-scse.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_mobilenet_3/log_3/plugins/profile/2022_11_08_23_55_36/ntcadmin-scse.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 64s 61ms/step - loss: 0.6975 - accuracy: 0.5142 - val_loss: 0.6831 - val_accuracy: 0.5375 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.6768 - accuracy: 0.5715 - val_loss: 0.6697 - val_accuracy: 0.6021 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.6439 - accuracy: 0.6285 - val_loss: 0.6489 - val_accuracy: 0.6496 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.6477 - accuracy: 0.6240 - val_loss: 0.6853 - val_accuracy: 0.5378 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.6310 - accuracy: 0.6495 - val_loss: 0.6144 - val_accuracy: 0.6685 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5942 - accuracy: 0.6827 - val_loss: 0.6247 - val_accuracy: 0.6554 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.6144 - accuracy: 0.6640 - val_loss: 0.5938 - val_accuracy: 0.6886 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.6017 - accuracy: 0.6842 - val_loss: 0.5790 - val_accuracy: 0.6932 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5860 - accuracy: 0.6990 - val_loss: 0.5820 - val_accuracy: 0.6908 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5680 - accuracy: 0.7053 - val_loss: 0.5755 - val_accuracy: 0.6864 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5941 - accuracy: 0.6805 - val_loss: 0.6297 - val_accuracy: 0.6439 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5709 - accuracy: 0.7060 - val_loss: 0.5663 - val_accuracy: 0.6954 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5633 - accuracy: 0.7070 - val_loss: 0.5784 - val_accuracy: 0.6944 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5810 - accuracy: 0.6885 - val_loss: 0.5726 - val_accuracy: 0.6861 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5623 - accuracy: 0.7180 - val_loss: 0.5611 - val_accuracy: 0.7087 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5572 - accuracy: 0.7195 - val_loss: 0.5846 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5519 - accuracy: 0.7080 - val_loss: 0.5453 - val_accuracy: 0.7205 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5629 - accuracy: 0.6988 - val_loss: 0.7937 - val_accuracy: 0.5636 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5499 - accuracy: 0.7272 - val_loss: 0.5385 - val_accuracy: 0.7226 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5390 - accuracy: 0.7270 - val_loss: 0.5753 - val_accuracy: 0.6782 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5766 - accuracy: 0.6892 - val_loss: 0.6466 - val_accuracy: 0.6128 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5343 - accuracy: 0.7270 - val_loss: 0.5242 - val_accuracy: 0.7367 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5315 - accuracy: 0.7423 - val_loss: 0.5229 - val_accuracy: 0.7380 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5358 - accuracy: 0.7300 - val_loss: 0.6356 - val_accuracy: 0.6469 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5502 - accuracy: 0.7160 - val_loss: 0.5503 - val_accuracy: 0.7074 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5274 - accuracy: 0.7440 - val_loss: 0.5215 - val_accuracy: 0.7407 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5280 - accuracy: 0.7197 - val_loss: 0.6042 - val_accuracy: 0.6618 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5507 - accuracy: 0.7147 - val_loss: 0.5338 - val_accuracy: 0.7245 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5170 - accuracy: 0.7487 - val_loss: 0.5087 - val_accuracy: 0.7482 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5109 - accuracy: 0.7555 - val_loss: 0.6635 - val_accuracy: 0.6352 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5220 - accuracy: 0.7402 - val_loss: 0.5153 - val_accuracy: 0.7394 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5283 - accuracy: 0.7310 - val_loss: 0.5056 - val_accuracy: 0.7428 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5148 - accuracy: 0.7500 - val_loss: 0.5903 - val_accuracy: 0.6829 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.5231 - accuracy: 0.7350 - val_loss: 0.7237 - val_accuracy: 0.5927 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.5336 - accuracy: 0.7153 - val_loss: 0.5406 - val_accuracy: 0.7067 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5043 - accuracy: 0.7567 - val_loss: 0.4924 - val_accuracy: 0.7544 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4938 - accuracy: 0.7628 - val_loss: 0.4895 - val_accuracy: 0.7560 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5050 - accuracy: 0.7370 - val_loss: 0.4927 - val_accuracy: 0.7576 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 56s 57ms/step - loss: 0.5071 - accuracy: 0.7533 - val_loss: 0.4955 - val_accuracy: 0.7501 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.5036 - accuracy: 0.7550 - val_loss: 0.4942 - val_accuracy: 0.7554 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.5275 - accuracy: 0.7305 - val_loss: 0.5358 - val_accuracy: 0.7084 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.5067 - accuracy: 0.7477 - val_loss: 0.4864 - val_accuracy: 0.7608 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4864 - accuracy: 0.7685 - val_loss: 0.4778 - val_accuracy: 0.7613 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4777 - accuracy: 0.7790 - val_loss: 0.4936 - val_accuracy: 0.7567 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5031 - accuracy: 0.7485 - val_loss: 0.4751 - val_accuracy: 0.7719 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.5164 - accuracy: 0.7385 - val_loss: 0.4737 - val_accuracy: 0.7691 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4741 - accuracy: 0.7772 - val_loss: 0.5975 - val_accuracy: 0.6970 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5241 - accuracy: 0.7360 - val_loss: 0.4868 - val_accuracy: 0.7576 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5035 - accuracy: 0.7420 - val_loss: 0.4923 - val_accuracy: 0.7494 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4816 - accuracy: 0.7732 - val_loss: 0.4645 - val_accuracy: 0.7715 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4677 - accuracy: 0.7820 - val_loss: 0.6225 - val_accuracy: 0.6784 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4796 - accuracy: 0.7617 - val_loss: 0.4624 - val_accuracy: 0.7766 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5156 - accuracy: 0.7377 - val_loss: 0.4575 - val_accuracy: 0.7773 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4587 - accuracy: 0.7887 - val_loss: 0.4653 - val_accuracy: 0.7739 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5037 - accuracy: 0.7517 - val_loss: 0.4622 - val_accuracy: 0.7793 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4892 - accuracy: 0.7542 - val_loss: 0.4594 - val_accuracy: 0.7817 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4696 - accuracy: 0.7673 - val_loss: 0.4695 - val_accuracy: 0.7679 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4707 - accuracy: 0.7778 - val_loss: 0.5432 - val_accuracy: 0.7141 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4622 - accuracy: 0.7765 - val_loss: 0.4546 - val_accuracy: 0.7797 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.5062 - accuracy: 0.7523 - val_loss: 0.4485 - val_accuracy: 0.7853 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4398 - accuracy: 0.7952 - val_loss: 0.5339 - val_accuracy: 0.7394 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4905 - accuracy: 0.7560 - val_loss: 0.4455 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4857 - accuracy: 0.7623 - val_loss: 0.4890 - val_accuracy: 0.7505 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4784 - accuracy: 0.7697 - val_loss: 0.4538 - val_accuracy: 0.7811 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4563 - accuracy: 0.7837 - val_loss: 0.4478 - val_accuracy: 0.7835 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4612 - accuracy: 0.7735 - val_loss: 0.4474 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4965 - accuracy: 0.7540 - val_loss: 0.4780 - val_accuracy: 0.7535 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4301 - accuracy: 0.8067 - val_loss: 0.4405 - val_accuracy: 0.7851 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4707 - accuracy: 0.7768 - val_loss: 0.4396 - val_accuracy: 0.7885 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4680 - accuracy: 0.7753 - val_loss: 0.4382 - val_accuracy: 0.7878 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4663 - accuracy: 0.7735 - val_loss: 0.6850 - val_accuracy: 0.6413 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4471 - accuracy: 0.7905 - val_loss: 0.4484 - val_accuracy: 0.7843 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4555 - accuracy: 0.7782 - val_loss: 0.4338 - val_accuracy: 0.7914 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4938 - accuracy: 0.7602 - val_loss: 0.4562 - val_accuracy: 0.7717 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4294 - accuracy: 0.8002 - val_loss: 0.4319 - val_accuracy: 0.7915 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4538 - accuracy: 0.7895 - val_loss: 0.4340 - val_accuracy: 0.7890 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4576 - accuracy: 0.7765 - val_loss: 0.4284 - val_accuracy: 0.7919 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4579 - accuracy: 0.7763 - val_loss: 0.5671 - val_accuracy: 0.7154 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4466 - accuracy: 0.7935 - val_loss: 0.4504 - val_accuracy: 0.7745 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4482 - accuracy: 0.7860 - val_loss: 0.4743 - val_accuracy: 0.7625 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4932 - accuracy: 0.7523 - val_loss: 0.4306 - val_accuracy: 0.7933 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4292 - accuracy: 0.8010 - val_loss: 0.4366 - val_accuracy: 0.7881 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4425 - accuracy: 0.7922 - val_loss: 0.6136 - val_accuracy: 0.6754 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4608 - accuracy: 0.7775 - val_loss: 0.4394 - val_accuracy: 0.7862 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4578 - accuracy: 0.7782 - val_loss: 0.5472 - val_accuracy: 0.7297 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4344 - accuracy: 0.7997 - val_loss: 0.4462 - val_accuracy: 0.7823 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4442 - accuracy: 0.7812 - val_loss: 0.4462 - val_accuracy: 0.7812 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4743 - accuracy: 0.7715 - val_loss: 0.4883 - val_accuracy: 0.7474 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4212 - accuracy: 0.8052 - val_loss: 0.4248 - val_accuracy: 0.7973 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4379 - accuracy: 0.8000 - val_loss: 0.4115 - val_accuracy: 0.8017 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4547 - accuracy: 0.7818 - val_loss: 0.4942 - val_accuracy: 0.7420 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4443 - accuracy: 0.7893 - val_loss: 0.4258 - val_accuracy: 0.7931 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4240 - accuracy: 0.8052 - val_loss: 0.4828 - val_accuracy: 0.7568 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4422 - accuracy: 0.7870 - val_loss: 0.5404 - val_accuracy: 0.7137 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4745 - accuracy: 0.7682 - val_loss: 0.4513 - val_accuracy: 0.7732 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4072 - accuracy: 0.8152 - val_loss: 0.4991 - val_accuracy: 0.7599 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4272 - accuracy: 0.7918 - val_loss: 0.5725 - val_accuracy: 0.7041 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4475 - accuracy: 0.7807 - val_loss: 0.4129 - val_accuracy: 0.8092 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4428 - accuracy: 0.7887 - val_loss: 0.4491 - val_accuracy: 0.7779 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.4186 - accuracy: 0.8040 - val_loss: 0.4465 - val_accuracy: 0.7758 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 01:35:17.881353: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-09 01:35:17.881382: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-09 01:35:17.881411: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-09 01:35:17.881419: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-09 01:35:17.881423: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-09 01:35:17.881427: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-11-09 01:35:17.881507: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-09 01:35:17.881530: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-09 01:35:17.881535: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-09 01:35:17.881539: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 52s 14ms/step - loss: 0.6941 - accuracy: 0.5232\n",
      "Epoch 1/100\n",
      "   9/1000 [..............................] - ETA: 14s - loss: 0.7251 - accuracy: 0.3611 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 01:36:13.331641: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-09 01:36:13.331667: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-09 01:36:13.331877: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-09 01:36:13.331896: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-09 01:36:13.331905: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-09 01:36:13.331914: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-11-09 01:36:13.741933: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-09 01:36:13.757559: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-09 01:36:13.757583: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-09 01:36:13.757588: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2022-11-09 01:36:13.796476: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-09 01:36:13.796507: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-09 01:36:13.796513: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-11-09 01:36:13.818487: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-09 01:36:13.843545: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_3/log_4/plugins/profile/2022_11_09_01_36_13\n",
      "\n",
      "2022-11-09 01:36:13.851571: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_mobilenet_3/log_4/plugins/profile/2022_11_09_01_36_13/ntcadmin-scse.trace.json.gz\n",
      "2022-11-09 01:36:13.936906: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_3/log_4/plugins/profile/2022_11_09_01_36_13\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  17/1000 [..............................] - ETA: 46s - loss: 0.7126 - accuracy: 0.4118"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 01:36:13.947759: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_mobilenet_3/log_4/plugins/profile/2022_11_09_01_36_13/ntcadmin-scse.memory_profile.json.gz\n",
      "2022-11-09 01:36:13.948717: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_mobilenet_3/log_4/plugins/profile/2022_11_09_01_36_13\n",
      "Dumped tool data for xplane.pb to log/baseline_mobilenet_3/log_4/plugins/profile/2022_11_09_01_36_13/ntcadmin-scse.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_mobilenet_3/log_4/plugins/profile/2022_11_09_01_36_13/ntcadmin-scse.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_mobilenet_3/log_4/plugins/profile/2022_11_09_01_36_13/ntcadmin-scse.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_mobilenet_3/log_4/plugins/profile/2022_11_09_01_36_13/ntcadmin-scse.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_mobilenet_3/log_4/plugins/profile/2022_11_09_01_36_13/ntcadmin-scse.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 65s 61ms/step - loss: 0.6982 - accuracy: 0.5107 - val_loss: 0.6830 - val_accuracy: 0.5263 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.6688 - accuracy: 0.5913 - val_loss: 0.6679 - val_accuracy: 0.5971 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.6418 - accuracy: 0.6438 - val_loss: 0.6459 - val_accuracy: 0.6517 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.6464 - accuracy: 0.6342 - val_loss: 0.6823 - val_accuracy: 0.5435 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.6261 - accuracy: 0.6510 - val_loss: 0.6114 - val_accuracy: 0.6648 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5893 - accuracy: 0.6923 - val_loss: 0.6377 - val_accuracy: 0.6360 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.6086 - accuracy: 0.6687 - val_loss: 0.5936 - val_accuracy: 0.6756 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5954 - accuracy: 0.6793 - val_loss: 0.5754 - val_accuracy: 0.6982 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5842 - accuracy: 0.6952 - val_loss: 0.5797 - val_accuracy: 0.7036 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5694 - accuracy: 0.6970 - val_loss: 0.5760 - val_accuracy: 0.6863 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5867 - accuracy: 0.6925 - val_loss: 0.5888 - val_accuracy: 0.6878 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5701 - accuracy: 0.7063 - val_loss: 0.5867 - val_accuracy: 0.6707 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5630 - accuracy: 0.7028 - val_loss: 0.5653 - val_accuracy: 0.7101 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5849 - accuracy: 0.6898 - val_loss: 0.5760 - val_accuracy: 0.6785 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5498 - accuracy: 0.7182 - val_loss: 0.5445 - val_accuracy: 0.7252 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5524 - accuracy: 0.7305 - val_loss: 0.6136 - val_accuracy: 0.6430 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5515 - accuracy: 0.7048 - val_loss: 0.5423 - val_accuracy: 0.7263 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5517 - accuracy: 0.7097 - val_loss: 0.7628 - val_accuracy: 0.5796 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5479 - accuracy: 0.7260 - val_loss: 0.5472 - val_accuracy: 0.7119 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5426 - accuracy: 0.7278 - val_loss: 0.5656 - val_accuracy: 0.6898 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5654 - accuracy: 0.7163 - val_loss: 0.6367 - val_accuracy: 0.6260 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5273 - accuracy: 0.7405 - val_loss: 0.5241 - val_accuracy: 0.7365 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5276 - accuracy: 0.7418 - val_loss: 0.5232 - val_accuracy: 0.7364 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5401 - accuracy: 0.7188 - val_loss: 0.6205 - val_accuracy: 0.6559 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5368 - accuracy: 0.7343 - val_loss: 0.5186 - val_accuracy: 0.7392 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5110 - accuracy: 0.7575 - val_loss: 0.5178 - val_accuracy: 0.7406 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5385 - accuracy: 0.7220 - val_loss: 0.5733 - val_accuracy: 0.6773 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5475 - accuracy: 0.7225 - val_loss: 0.5364 - val_accuracy: 0.7159 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5109 - accuracy: 0.7535 - val_loss: 0.5527 - val_accuracy: 0.7156 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5031 - accuracy: 0.7588 - val_loss: 0.6180 - val_accuracy: 0.6561 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5228 - accuracy: 0.7312 - val_loss: 0.5226 - val_accuracy: 0.7331 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5280 - accuracy: 0.7318 - val_loss: 0.5410 - val_accuracy: 0.7141 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4988 - accuracy: 0.7590 - val_loss: 0.5592 - val_accuracy: 0.7090 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5192 - accuracy: 0.7335 - val_loss: 0.7396 - val_accuracy: 0.5832 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5265 - accuracy: 0.7193 - val_loss: 0.5476 - val_accuracy: 0.7038 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4917 - accuracy: 0.7592 - val_loss: 0.4917 - val_accuracy: 0.7547 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4926 - accuracy: 0.7638 - val_loss: 0.4964 - val_accuracy: 0.7512 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5152 - accuracy: 0.7362 - val_loss: 0.4893 - val_accuracy: 0.7628 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5048 - accuracy: 0.7460 - val_loss: 0.4814 - val_accuracy: 0.7616 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5005 - accuracy: 0.7663 - val_loss: 0.4876 - val_accuracy: 0.7634 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5095 - accuracy: 0.7460 - val_loss: 0.5244 - val_accuracy: 0.7187 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5018 - accuracy: 0.7418 - val_loss: 0.4899 - val_accuracy: 0.7619 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4902 - accuracy: 0.7703 - val_loss: 0.4781 - val_accuracy: 0.7644 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4775 - accuracy: 0.7725 - val_loss: 0.4951 - val_accuracy: 0.7554 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4983 - accuracy: 0.7550 - val_loss: 0.4824 - val_accuracy: 0.7625 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5039 - accuracy: 0.7550 - val_loss: 0.4715 - val_accuracy: 0.7705 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4632 - accuracy: 0.7840 - val_loss: 0.5733 - val_accuracy: 0.7073 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5191 - accuracy: 0.7423 - val_loss: 0.4743 - val_accuracy: 0.7729 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4897 - accuracy: 0.7582 - val_loss: 0.4928 - val_accuracy: 0.7484 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4783 - accuracy: 0.7660 - val_loss: 0.4708 - val_accuracy: 0.7676 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4649 - accuracy: 0.7795 - val_loss: 0.5876 - val_accuracy: 0.6987 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4818 - accuracy: 0.7575 - val_loss: 0.4692 - val_accuracy: 0.7673 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5073 - accuracy: 0.7430 - val_loss: 0.4560 - val_accuracy: 0.7803 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4443 - accuracy: 0.8002 - val_loss: 0.4621 - val_accuracy: 0.7763 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5004 - accuracy: 0.7533 - val_loss: 0.4622 - val_accuracy: 0.7788 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4895 - accuracy: 0.7533 - val_loss: 0.4657 - val_accuracy: 0.7715 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4731 - accuracy: 0.7725 - val_loss: 0.4817 - val_accuracy: 0.7662 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4636 - accuracy: 0.7853 - val_loss: 0.5622 - val_accuracy: 0.7055 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4643 - accuracy: 0.7778 - val_loss: 0.4514 - val_accuracy: 0.7800 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.5122 - accuracy: 0.7410 - val_loss: 0.4472 - val_accuracy: 0.7877 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4413 - accuracy: 0.8055 - val_loss: 0.5048 - val_accuracy: 0.7532 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4859 - accuracy: 0.7660 - val_loss: 0.4480 - val_accuracy: 0.7859 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4782 - accuracy: 0.7613 - val_loss: 0.4783 - val_accuracy: 0.7603 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4706 - accuracy: 0.7707 - val_loss: 0.4632 - val_accuracy: 0.7741 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4553 - accuracy: 0.7815 - val_loss: 0.4692 - val_accuracy: 0.7625 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4613 - accuracy: 0.7832 - val_loss: 0.4529 - val_accuracy: 0.7804 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4958 - accuracy: 0.7560 - val_loss: 0.4934 - val_accuracy: 0.7350 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4314 - accuracy: 0.8083 - val_loss: 0.4477 - val_accuracy: 0.7815 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4630 - accuracy: 0.7840 - val_loss: 0.4683 - val_accuracy: 0.7649 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4690 - accuracy: 0.7688 - val_loss: 0.4350 - val_accuracy: 0.7912 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4625 - accuracy: 0.7820 - val_loss: 0.5477 - val_accuracy: 0.7001 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4426 - accuracy: 0.7910 - val_loss: 0.4824 - val_accuracy: 0.7464 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4528 - accuracy: 0.7840 - val_loss: 0.4332 - val_accuracy: 0.7907 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4934 - accuracy: 0.7555 - val_loss: 0.4357 - val_accuracy: 0.7931 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4241 - accuracy: 0.8098 - val_loss: 0.4313 - val_accuracy: 0.7934 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4581 - accuracy: 0.7843 - val_loss: 0.4292 - val_accuracy: 0.7987 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4589 - accuracy: 0.7703 - val_loss: 0.4357 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4521 - accuracy: 0.7918 - val_loss: 0.6414 - val_accuracy: 0.6793 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4470 - accuracy: 0.7845 - val_loss: 0.4652 - val_accuracy: 0.7634 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4376 - accuracy: 0.7940 - val_loss: 0.5537 - val_accuracy: 0.7155 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4964 - accuracy: 0.7455 - val_loss: 0.4372 - val_accuracy: 0.7881 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4263 - accuracy: 0.8035 - val_loss: 0.4452 - val_accuracy: 0.7874 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4395 - accuracy: 0.7970 - val_loss: 0.6614 - val_accuracy: 0.6640 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4510 - accuracy: 0.7810 - val_loss: 0.5264 - val_accuracy: 0.7219 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4515 - accuracy: 0.7820 - val_loss: 0.5293 - val_accuracy: 0.7372 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4280 - accuracy: 0.8037 - val_loss: 0.4235 - val_accuracy: 0.7963 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4445 - accuracy: 0.7870 - val_loss: 0.4668 - val_accuracy: 0.7665 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4832 - accuracy: 0.7653 - val_loss: 0.5372 - val_accuracy: 0.7159 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4150 - accuracy: 0.8140 - val_loss: 0.4170 - val_accuracy: 0.7993 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4341 - accuracy: 0.8010 - val_loss: 0.4285 - val_accuracy: 0.7938 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4608 - accuracy: 0.7797 - val_loss: 0.4830 - val_accuracy: 0.7498 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.4376 - val_accuracy: 0.7870 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4209 - accuracy: 0.8080 - val_loss: 0.4921 - val_accuracy: 0.7569 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4482 - accuracy: 0.7878 - val_loss: 0.4526 - val_accuracy: 0.7725 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4551 - accuracy: 0.7747 - val_loss: 0.4361 - val_accuracy: 0.7873 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4229 - accuracy: 0.7995 - val_loss: 0.5995 - val_accuracy: 0.7089 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.4244 - accuracy: 0.8077 - val_loss: 0.6039 - val_accuracy: 0.6839 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4391 - accuracy: 0.7918 - val_loss: 0.4015 - val_accuracy: 0.8122 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4322 - accuracy: 0.7915 - val_loss: 0.4176 - val_accuracy: 0.8019 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4189 - accuracy: 0.8085 - val_loss: 0.4457 - val_accuracy: 0.7829 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "for i, (train, val) in enumerate(folds):\n",
    "    \n",
    "    model = createModel()\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    metrics = ['accuracy']\n",
    "    \n",
    "    model.compile(optimizer=opt, loss=loss, metrics=metrics)\n",
    "    \n",
    "    tboardCb = tf.keras.callbacks.TensorBoard(log_dir=f\"{logBasePath}/{logPrefix}_{i}\", histogram_freq=1, profile_batch=(2,10))\n",
    "    lrSchedule = tf.keras.callbacks.LearningRateScheduler(schedule)\n",
    "    \n",
    "    cbs = [tboardCb, lrSchedule]\n",
    "    \n",
    "    model.evaluate(val)\n",
    "    model.fit(train, initial_epoch=START_EPOCH, epochs=END_EPOCH, steps_per_epoch=STEPS_PER_EPOCH, callbacks=cbs, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e841a27f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
