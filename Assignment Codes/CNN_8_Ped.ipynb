{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f19017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d782ddf",
   "metadata": {},
   "source": [
    "### Check Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03faa827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac4996",
   "metadata": {},
   "source": [
    "### GPU Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1e955b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 01:35:31.100968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 01:35:31.107692: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 01:35:31.108130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2835bd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f935a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be867b6",
   "metadata": {},
   "source": [
    "### Pandas Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92db292",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_column', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0907c",
   "metadata": {},
   "source": [
    "### Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0fd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VAL_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc35c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_WIDTH = 227\n",
    "CROP_HEIGHT = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d40847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldFiles = [\"adience/unprocessed/fold_0_data.txt\",\n",
    "             \"adience/unprocessed/fold_1_data.txt\",\n",
    "             \"adience/unprocessed/fold_2_data.txt\",\n",
    "             \"adience/unprocessed/fold_3_data.txt\",\n",
    "             \"adience/unprocessed/fold_4_data.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f61c7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genderMap = defaultdict(lambda : np.NaN)\n",
    "genderMap['m'] = 0\n",
    "genderMap['f'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d26242",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = ['(0, 2)', '(4, 6)', '(8, 13)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
    "ageMap = defaultdict(lambda : np.NaN)\n",
    "for i,a in enumerate(ages):\n",
    "    ageMap[a] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b1fc3",
   "metadata": {},
   "source": [
    "### Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd634a3",
   "metadata": {},
   "source": [
    "Dataset generation pipeline:\n",
    "Input: \n",
    "- foldFile - Path to fold file. Fold file Describes which images are in the fold and its corresponding labels\n",
    "- imgBaseFolder - Base folder to search image from\n",
    "- imgPrefix - Prefix of image file\n",
    "- genderMap - Map from ['m', 'f', 'u', None], to one hot index\n",
    "- ageMap - Map from age category to one hot index\n",
    "- imgWidth - Resulting image width\n",
    "- imgHeigh - Resulting image height\n",
    "- batchSize - Int or None, batch size\n",
    "- configureDs - Function accepting dataset for performance configurations\n",
    "- preBatch - List of (name, functions) pair that will be mapped before batching. name is used as name parameters for tf graph \n",
    "- postBatch - List of (name, functions) that will be mapped after batching. name is used as name parameters for tf graph\n",
    "\n",
    "The processing functions should have signature function(img, label) -> (img, label)\n",
    "\n",
    "Pipeline\n",
    "\n",
    "Read Fold File -> Preprocess filename and labels (dataframe) -> Convert filename and labels to numpy array -> Convert filename and labels to tf dataset -> Parse images and labels -> Configure Dataset for performance -> Pre-Batching preprocessing -> Batch -> Post-Batching preprocessing -> Output\n",
    "\n",
    "Some preprocessing steps can only be done before and some can only be done after batching, thats why there are seperated pre and post batching list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0795464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, batchSize, configureDs=None, preBatch=[], postBatch=[]):\n",
    "    \n",
    "    def parseImage(filename):\n",
    "        img = tf.io.read_file(filename)\n",
    "        img = tf.image.decode_jpeg(img)\n",
    "        img = tf.image.resize(img, [imgHeight, imgWidth])\n",
    "         \n",
    "        return img\n",
    "    \n",
    "    # Read Fold File\n",
    "    foldData = []\n",
    "    for f in foldFiles:\n",
    "        foldData.append(pd.read_csv(f, sep=\"\\t\"))\n",
    "    foldData = pd.concat(foldData)\n",
    "    \n",
    "    # Form File Name\n",
    "    foldData['filename'] = foldData.apply(lambda r: os.path.join(imgBaseFolder, r['user_id'], f\"{imgPrefix}.{r['face_id']}.{r['original_image']}\"), axis=1)\n",
    "    \n",
    "    # Generate Label One Hot Index\n",
    "    foldData['gender_ind'] = foldData['gender'].map(genderMap)\n",
    "    foldData['age_ind'] = foldData['age'].map(ageMap)\n",
    "    \n",
    "    # Remove dirty data\n",
    "    foldData.dropna(subset=['gender_ind', 'age_ind'], inplace=True)\n",
    "    \n",
    "    # Dataframe to numpy\n",
    "    filenames = foldData['filename'].to_numpy()\n",
    "    \n",
    "    genderIndex = foldData['gender_ind'].to_numpy().astype(int)\n",
    "    ageIndex = foldData['age_ind'].to_numpy().astype(int)\n",
    "    \n",
    "    # Numpy to Dataset\n",
    "    fnDs = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    genderIndDs = tf.data.Dataset.from_tensor_slices(genderIndex)\n",
    "    ageIndDs = tf.data.Dataset.from_tensor_slices(ageIndex)\n",
    "    \n",
    "    # Parse Images\n",
    "    imageDs = fnDs.map(parseImage, num_parallel_calls=tf.data.AUTOTUNE, name=\"parse_image\")\n",
    "    \n",
    "    # Parse Labels\n",
    "    genderLabDs = genderIndDs.map(lambda x: tf.one_hot(x, genderDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"gender_one_hot\")\n",
    "    ageLabDs = ageIndDs.map(lambda x: tf.one_hot(x, ageDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"age_one_hot\")\n",
    "    \n",
    "    # Combine Labels\n",
    "    labelDs = tf.data.Dataset.zip((genderLabDs, ageLabDs), name=\"label_zip\")\n",
    "    labelDs = labelDs.map(lambda g,a: {\"gender\": g, \"age\": a}, num_parallel_calls=tf.data.AUTOTUNE, name='label_dict')\n",
    "    \n",
    "    # Combine Images and Labels into dataset\n",
    "    ds = tf.data.Dataset.zip((imageDs, labelDs))\n",
    "    \n",
    "    # Configure Performance\n",
    "    if(configureDs is not None):\n",
    "        ds = configureDs(ds)\n",
    "    \n",
    "    # Pre Batch Preprocessing\n",
    "    for n,f in preBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    # Batch\n",
    "    if(batchSize is not None):\n",
    "        ds = ds.batch(batchSize, name=\"ds_batch\")\n",
    "    \n",
    "    # Post Batch Preprocessing\n",
    "    for n,f in postBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320ed92",
   "metadata": {},
   "source": [
    "### Preprocessings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "472b7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=100)\n",
    "    ds = ds.repeat()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adf288f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc4fe2f",
   "metadata": {},
   "source": [
    "#### Preprocessing steps according to the reference paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7724a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainPreprocessA(img, lab):\n",
    "        \n",
    "        # img = tf.image.random_crop(img, [CROP_HEIGHT, CROP_WIDTH, 3])\n",
    "        \n",
    "        ud = tf.random.uniform([], dtype=tf.float32)\n",
    "        udCond = tf.less(ud, 0.5)\n",
    "        \n",
    "        img = tf.cond(udCond, lambda: tf.image.flip_up_down(img), lambda: img)\n",
    "        \n",
    "        lr = tf.random.uniform([], dtype=tf.float32)\n",
    "        lrCond = tf.less(lr, 0.5)\n",
    "        \n",
    "        img = tf.cond(lrCond, lambda: tf.image.flip_left_right(img), lambda: img)\n",
    "        \n",
    "        img = tf.image.random_brightness(img, 63/255)\n",
    "        \n",
    "        img = tf.image.random_contrast(img, 0.2, 1.8) \n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0402726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valPreprocessA(img, lab):\n",
    "        \n",
    "        img = tf.image.crop_to_bounding_box(img,\n",
    "                                            (IMG_HEIGHT-CROP_HEIGHT) // 2,\n",
    "                                            (IMG_WIDTH-CROP_WIDTH) // 2,\n",
    "                                            CROP_HEIGHT,\n",
    "                                            CROP_WIDTH)\n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f32b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageStandardize(img, lab):\n",
    "    \n",
    "    img = tf.image.per_image_standardization(img)\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f134a",
   "metadata": {},
   "source": [
    "#### Label extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "633c4277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractGenderLabel(img, lab):\n",
    "    \n",
    "    lab = lab['gender']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88b8b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAgeLabel(img, lab):\n",
    "    \n",
    "    lab = lab['age']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7778c",
   "metadata": {},
   "source": [
    "### Generate Folds for K-Folds validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4172d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFoldDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, valBatchSize, trainConfigureDs=None, trainPreBatch=[], trainPostBatch=[], valConfigureDs=None, valPreBatch=[], valPostBatch=[]):\n",
    "    '''\n",
    "        Returns list of (train, validation) datasets\n",
    "    '''\n",
    "    \n",
    "    N = len(foldFiles)\n",
    "    \n",
    "    folds = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        trainFiles = foldFiles[:i]\n",
    "        if(i < N-1):\n",
    "            trainFiles.extend(foldFiles[i+1:])\n",
    "            \n",
    "        valFiles = foldFiles[i]\n",
    "        \n",
    "        trainDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, configureDs=trainConfigureDs, preBatch=trainPreBatch, postBatch=trainPostBatch)\n",
    "        valDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, valBatchSize, configureDs=valConfigureDs, preBatch=valPreBatch, postBatch=valPostBatch)\n",
    "        \n",
    "        folds.append((trainDs, valDs))\n",
    "        \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beffce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPreBatch = [(\"train_process_a\", trainPreprocessA),\n",
    "                 (\"train_extract_gender\", extractGenderLabel)]\n",
    "\n",
    "valPreBatch = [(\"val_extract_gender\", extractGenderLabel)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10474d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 01:35:31.443390: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-10 01:35:31.444072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 01:35:31.444329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 01:35:31.444526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 01:35:31.712773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 01:35:31.712988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 01:35:31.713165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 01:35:31.713331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 738 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:2d:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "folds = generateFoldDs(foldFiles, \"adience/faces\", \"coarse_tilt_aligned_face\", genderMap, ageMap, 2, 8, \n",
    "                       IMG_WIDTH, IMG_HEIGHT, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE, \n",
    "                       trainConfigureDs=trainConfigPerformance, trainPreBatch=trainPreBatch, \n",
    "                       valConfigureDs=valConfigPerformance, valPreBatch=valPreBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57d814af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7974f8fe",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b67fe33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in folds[0][0].take(1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8aa8d0d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 256, 256, 3), dtype=float32, numpy=\n",
       "array([[[[ 5.87747192e+00,  2.41669907e+02,  2.61731628e+02],\n",
       "         [ 3.31987000e+00,  2.39112305e+02,  2.59174011e+02],\n",
       "         [ 1.61071777e-01,  2.35953506e+02,  2.56015198e+02],\n",
       "         ...,\n",
       "         [ 3.91357040e+01,  1.08798981e+02,  1.98165924e+02],\n",
       "         [-1.07546082e+01,  5.89683533e+01,  1.45663498e+02],\n",
       "         [-6.95587158e+00,  6.53587799e+01,  1.46417648e+02]],\n",
       "\n",
       "        [[ 1.43446350e+00,  2.37226913e+02,  2.57288635e+02],\n",
       "         [-2.73725891e+00,  2.33055176e+02,  2.53116882e+02],\n",
       "         [ 1.53663635e+00,  2.36556305e+02,  2.57004456e+02],\n",
       "         ...,\n",
       "         [ 8.98303986e+00,  6.69413147e+01,  1.65046021e+02],\n",
       "         [-4.78161469e+01,  9.13439941e+00,  1.03128006e+02],\n",
       "         [-2.34003448e+01,  3.64581604e+01,  1.26073257e+02]],\n",
       "\n",
       "        [[ 4.03094482e+00,  2.38249741e+02,  2.58311462e+02],\n",
       "         [-2.70399475e+00,  2.31514832e+02,  2.51576538e+02],\n",
       "         [-5.85159302e+00,  2.27466171e+02,  2.47978409e+02],\n",
       "         ...,\n",
       "         [ 1.90336609e+00,  4.91377945e+01,  1.42415405e+02],\n",
       "         [-2.28431091e+01,  2.03286972e+01,  1.15550301e+02],\n",
       "         [-3.74288483e+01,  8.61433411e+00,  1.04452446e+02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-8.32943726e+00, -2.54088440e+01,  3.37259674e+00],\n",
       "         [-2.33122253e+00, -1.94106293e+01,  9.37080383e+00],\n",
       "         [-2.83625793e+00, -2.06563568e+01,  8.49542999e+00],\n",
       "         ...,\n",
       "         [ 2.77708527e+02,  1.99488922e+02,  1.68257568e+02],\n",
       "         [ 2.60972046e+02,  1.75878830e+02,  1.45366165e+02],\n",
       "         [ 2.45606354e+02,  1.67961884e+02,  1.37774307e+02]],\n",
       "\n",
       "        [[-5.93492126e+00, -1.85011902e+01,  1.28450699e+01],\n",
       "         [-1.01734924e+00, -1.63528061e+01,  1.59165115e+01],\n",
       "         [ 3.83468628e-01, -1.49519882e+01,  1.73173294e+01],\n",
       "         ...,\n",
       "         [ 2.80465454e+02,  2.02245865e+02,  1.68299408e+02],\n",
       "         [ 2.81851807e+02,  1.98077698e+02,  1.63607849e+02],\n",
       "         [ 2.72954956e+02,  1.96581451e+02,  1.61668655e+02]],\n",
       "\n",
       "        [[-6.72856140e+00, -1.33442917e+01,  1.54371414e+01],\n",
       "         [-4.63749695e+00, -1.38208466e+01,  1.62444000e+01],\n",
       "         [-1.51475525e+00, -1.16183777e+01,  1.89069977e+01],\n",
       "         ...,\n",
       "         [ 2.91014954e+02,  2.12795349e+02,  1.78076111e+02],\n",
       "         [ 2.91736694e+02,  2.08387421e+02,  1.70864929e+02],\n",
       "         [ 2.77737854e+02,  2.01364365e+02,  1.63875946e+02]]],\n",
       "\n",
       "\n",
       "       [[[ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         ...,\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01]],\n",
       "\n",
       "        [[ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         ...,\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01]],\n",
       "\n",
       "        [[ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         ...,\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         ...,\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01]],\n",
       "\n",
       "        [[ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         ...,\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01]],\n",
       "\n",
       "        [[ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         ...,\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01],\n",
       "         [ 5.35586243e+01,  4.34544258e+01,  3.55745316e+01]]],\n",
       "\n",
       "\n",
       "       [[[-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         ...,\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01]],\n",
       "\n",
       "        [[-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         ...,\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01]],\n",
       "\n",
       "        [[-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         ...,\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         ...,\n",
       "         [-4.96267548e+01, -4.63712997e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01]],\n",
       "\n",
       "        [[-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         ...,\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01]],\n",
       "\n",
       "        [[-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         ...,\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01],\n",
       "         [-4.96267548e+01, -4.71943588e+01, -4.21380692e+01]]],\n",
       "\n",
       "\n",
       "       [[[ 1.10692307e+02,  9.69448547e+01,  9.45069351e+01],\n",
       "         [ 1.11553413e+02,  9.78189392e+01,  9.53766937e+01],\n",
       "         [ 1.11673111e+02,  9.87568359e+01,  9.59422836e+01],\n",
       "         ...,\n",
       "         [ 1.44454559e+02,  1.39400467e+02,  1.04127541e+02],\n",
       "         [ 1.42601318e+02,  1.38084274e+02,  1.02770050e+02],\n",
       "         [ 1.42212784e+02,  1.39550003e+02,  1.03647842e+02]],\n",
       "\n",
       "        [[ 1.10233681e+02,  9.73174057e+01,  9.46024246e+01],\n",
       "         [ 1.10866333e+02,  9.79500656e+01,  9.52350845e+01],\n",
       "         [ 1.13210495e+02,  1.00294228e+02,  9.74796753e+01],\n",
       "         ...,\n",
       "         [ 1.41752823e+02,  1.38362183e+02,  1.02783882e+02],\n",
       "         [ 1.40720566e+02,  1.38616241e+02,  1.02661415e+02],\n",
       "         [ 1.38470840e+02,  1.37619019e+02,  1.01400444e+02]],\n",
       "\n",
       "        [[ 1.11591042e+02,  9.87797470e+01,  9.60647659e+01],\n",
       "         [ 1.11794388e+02,  9.89831009e+01,  9.62681198e+01],\n",
       "         [ 1.12711166e+02,  9.99375992e+01,  9.70853195e+01],\n",
       "         ...,\n",
       "         [ 1.40836914e+02,  1.38015656e+02,  1.03366096e+02],\n",
       "         [ 1.37745117e+02,  1.33109406e+02,  9.99115524e+01],\n",
       "         [ 1.35865417e+02,  1.28195129e+02,  9.61818390e+01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.62120361e+02,  1.42000458e+02,  1.22107590e+02],\n",
       "         [ 1.61346878e+02,  1.41226974e+02,  1.21334099e+02],\n",
       "         [ 1.60212280e+02,  1.40092377e+02,  1.20199501e+02],\n",
       "         ...,\n",
       "         [ 1.70329102e+02,  1.52487534e+02,  1.39300598e+02],\n",
       "         [ 1.70113876e+02,  1.52210480e+02,  1.38692734e+02],\n",
       "         [ 1.70148331e+02,  1.52244919e+02,  1.38514526e+02]],\n",
       "\n",
       "        [[ 1.61060959e+02,  1.41210541e+02,  1.20509201e+02],\n",
       "         [ 1.59869171e+02,  1.40018753e+02,  1.19317413e+02],\n",
       "         [ 1.59043793e+02,  1.39193375e+02,  1.18492043e+02],\n",
       "         ...,\n",
       "         [ 1.70388214e+02,  1.52390686e+02,  1.39443314e+02],\n",
       "         [ 1.70125671e+02,  1.52487534e+02,  1.39236710e+02],\n",
       "         [ 1.70113876e+02,  1.52479965e+02,  1.39229019e+02]],\n",
       "\n",
       "        [[ 1.60916946e+02,  1.41074097e+02,  1.19795914e+02],\n",
       "         [ 1.60497849e+02,  1.40655014e+02,  1.19376823e+02],\n",
       "         [ 1.58876968e+02,  1.39034134e+02,  1.17755943e+02],\n",
       "         ...,\n",
       "         [ 1.70390945e+02,  1.52210480e+02,  1.39798294e+02],\n",
       "         [ 1.70667999e+02,  1.52487534e+02,  1.39529892e+02],\n",
       "         [ 1.70451294e+02,  1.52487534e+02,  1.39304535e+02]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d84b1683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e25507c",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ee495a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    inp = tf.keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "    conv1 = tf.keras.layers.Conv2D(96, 7, strides=(4,4), activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='conv1')\n",
    "    pool1 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, name='pool1')\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv2D(256, 5, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='conv2')\n",
    "    pool2 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, name='pool2')\n",
    "\n",
    "    conv3 = tf.keras.layers.Conv2D(384, 3, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='conv3')\n",
    "    pool3 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, name='pool3')\n",
    "\n",
    "    flat1 = tf.keras.layers.Flatten(name='flat1')\n",
    "    fc1 = tf.keras.layers.Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc1')\n",
    "    do1 = tf.keras.layers.Dropout(0.5, name='do1')\n",
    "\n",
    "    fc2 = tf.keras.layers.Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc2')\n",
    "    do2 = tf.keras.layers.Dropout(0.5, name='do2')\n",
    "\n",
    "    fc3 = tf.keras.layers.Dense(2, activation='softmax', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='fc3')\n",
    "\n",
    "    o = (inp / 127.5) - 1.0\n",
    "    o = conv1(o)\n",
    "    o = pool1(o)\n",
    "    o = tf.nn.local_response_normalization(o, depth_radius=5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    o = tf.pad(o, [[0, 0], [2, 2], [2, 2], [0, 0]])\n",
    "    o = conv2(o)\n",
    "    o = pool2(o)\n",
    "    o = tf.nn.local_response_normalization(o, depth_radius=5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    o = tf.pad(o, [[0, 0], [1, 1], [1, 1], [0, 0]])\n",
    "    o = conv3(o)\n",
    "    o = pool3(o)\n",
    "    o = tf.nn.local_response_normalization(o, depth_radius=5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    o = flat1(o)\n",
    "    o = fc1(o)\n",
    "    o = do1(o)\n",
    "\n",
    "\n",
    "    o = fc2(o)\n",
    "    o = do2(o)\n",
    "\n",
    "    o = fc3(o)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=o, name='cnn_8')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea1227d",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c5f7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = 1000\n",
    "\n",
    "EPOCH = 300\n",
    "\n",
    "START_EPOCH = 0\n",
    "END_EPOCH = START_EPOCH + EPOCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96be5cb2",
   "metadata": {},
   "source": [
    "#### Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55ee49a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(epoch, lr):\n",
    "    if(epoch == 10000*50//STEPS_PER_EPOCH):\n",
    "        return lr * 0.1\n",
    "    else:\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f41e8947",
   "metadata": {},
   "outputs": [],
   "source": [
    "logBasePath = \"log/CNN_8\"\n",
    "logPrefix = \"log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75efb222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 01:35:33.855294: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-10 01:35:33.855311: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-10 01:35:33.855330: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1665] Profiler found 1 GPUs\n",
      "2022-11-10 01:35:33.933521: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-10 01:35:33.934733: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-11-10 01:35:34.453731: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  56/3528 [..............................] - ETA: 9s - loss: 0.6638 - accuracy: 0.6205   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 01:35:35.239870: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 822.72MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-10 01:35:35.239979: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 822.72MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-10 01:35:35.248481: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 843.88MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-10 01:35:35.248497: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 843.88MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-10 01:35:35.249320: W tensorflow/core/common_runtime/bfc_allocator.cc:360] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2022-11-10 01:35:35.258592: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 11s 3ms/step - loss: 0.7368 - accuracy: 0.4768\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 01:35:44.519815: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 819.62MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-10 01:35:44.519859: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 819.62MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-10 01:35:44.527552: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 841.75MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-10 01:35:44.527576: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 841.75MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "   1/1000 [..............................] - ETA: 7:37 - loss: 0.6135 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 01:35:44.992742: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 848.12MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-10 01:35:44.992779: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 848.12MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-10 01:35:45.033384: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-10 01:35:45.033396: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  20/1000 [..............................] - ETA: 34s - loss: 0.8320 - accuracy: 0.4500 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 01:35:45.528276: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-10 01:35:45.528962: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-11-10 01:35:45.554681: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 1662 callback api events and 1637 activity events. \n",
      "2022-11-10 01:35:45.572758: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-10 01:35:45.589278: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/CNN_8/log_0/plugins/profile/2022_11_10_01_35_45\n",
      "\n",
      "2022-11-10 01:35:45.616632: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/CNN_8/log_0/plugins/profile/2022_11_10_01_35_45/rachanon-pc1.trace.json.gz\n",
      "2022-11-10 01:35:45.641610: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/CNN_8/log_0/plugins/profile/2022_11_10_01_35_45\n",
      "\n",
      "2022-11-10 01:35:45.646082: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/CNN_8/log_0/plugins/profile/2022_11_10_01_35_45/rachanon-pc1.memory_profile.json.gz\n",
      "2022-11-10 01:35:45.646536: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/CNN_8/log_0/plugins/profile/2022_11_10_01_35_45\n",
      "Dumped tool data for xplane.pb to log/CNN_8/log_0/plugins/profile/2022_11_10_01_35_45/rachanon-pc1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/CNN_8/log_0/plugins/profile/2022_11_10_01_35_45/rachanon-pc1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/CNN_8/log_0/plugins/profile/2022_11_10_01_35_45/rachanon-pc1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/CNN_8/log_0/plugins/profile/2022_11_10_01_35_45/rachanon-pc1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/CNN_8/log_0/plugins/profile/2022_11_10_01_35_45/rachanon-pc1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 997/1000 [============================>.] - ETA: 0s - loss: 0.7363 - accuracy: 0.5582"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 01:35:59.242861: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 147456000 exceeds 10% of free system memory.\n",
      "2022-11-10 01:35:59.274688: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 212336640 exceeds 10% of free system memory.\n",
      "2022-11-10 01:35:59.356360: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 16s 15ms/step - loss: 0.7362 - accuracy: 0.5577 - val_loss: 0.6921 - val_accuracy: 0.5232\n",
      "Epoch 2/300\n",
      " 997/1000 [============================>.] - ETA: 0s - loss: 0.6756 - accuracy: 0.5825"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 01:36:14.084467: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 147456000 exceeds 10% of free system memory.\n",
      "2022-11-10 01:36:14.117994: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 212336640 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6757 - accuracy: 0.5820 - val_loss: 0.6921 - val_accuracy: 0.5232\n",
      "Epoch 3/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6633 - accuracy: 0.5763 - val_loss: 0.6936 - val_accuracy: 0.4768\n",
      "Epoch 4/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6826 - accuracy: 0.5675 - val_loss: 0.7008 - val_accuracy: 0.5232\n",
      "Epoch 5/300\n",
      "1000/1000 [==============================] - 15s 14ms/step - loss: 0.6965 - accuracy: 0.4902 - val_loss: 0.6921 - val_accuracy: 0.5232\n",
      "Epoch 6/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6627 - accuracy: 0.6040 - val_loss: 0.6950 - val_accuracy: 0.4768\n",
      "Epoch 7/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6838 - accuracy: 0.5500 - val_loss: 0.6953 - val_accuracy: 0.5232\n",
      "Epoch 8/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6908 - accuracy: 0.5232 - val_loss: 0.6923 - val_accuracy: 0.5232\n",
      "Epoch 9/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6820 - accuracy: 0.5460 - val_loss: 0.6925 - val_accuracy: 0.5232\n",
      "Epoch 10/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6652 - accuracy: 0.5710 - val_loss: 0.6931 - val_accuracy: 0.5232\n",
      "Epoch 11/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6847 - accuracy: 0.5543 - val_loss: 0.6945 - val_accuracy: 0.4768\n",
      "Epoch 12/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6942 - accuracy: 0.5027 - val_loss: 0.6921 - val_accuracy: 0.5232\n",
      "Epoch 13/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6651 - accuracy: 0.5962 - val_loss: 0.6950 - val_accuracy: 0.5232\n",
      "Epoch 14/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6872 - accuracy: 0.5465 - val_loss: 0.6974 - val_accuracy: 0.5232\n",
      "Epoch 15/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6941 - accuracy: 0.4985 - val_loss: 0.6927 - val_accuracy: 0.5232\n",
      "Epoch 16/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6881 - accuracy: 0.5275 - val_loss: 0.6931 - val_accuracy: 0.5232\n",
      "Epoch 17/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6749 - accuracy: 0.5763 - val_loss: 0.7021 - val_accuracy: 0.4768\n",
      "Epoch 18/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6859 - accuracy: 0.5420 - val_loss: 0.6963 - val_accuracy: 0.4768\n",
      "Epoch 19/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6966 - accuracy: 0.4997 - val_loss: 0.6974 - val_accuracy: 0.4768\n",
      "Epoch 20/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6654 - accuracy: 0.6033 - val_loss: 0.7282 - val_accuracy: 0.5232\n",
      "Epoch 21/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6934 - accuracy: 0.5312 - val_loss: 0.7199 - val_accuracy: 0.5232\n",
      "Epoch 22/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6944 - accuracy: 0.5030 - val_loss: 0.6926 - val_accuracy: 0.5232\n",
      "Epoch 23/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6940 - accuracy: 0.5100 - val_loss: 0.6922 - val_accuracy: 0.5232\n",
      "Epoch 24/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6758 - accuracy: 0.5815 - val_loss: 0.7500 - val_accuracy: 0.4768\n",
      "Epoch 25/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6861 - accuracy: 0.5500 - val_loss: 0.6982 - val_accuracy: 0.5232\n",
      "Epoch 26/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6971 - accuracy: 0.4920 - val_loss: 0.7013 - val_accuracy: 0.4768\n",
      "Epoch 27/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6644 - accuracy: 0.6035 - val_loss: 0.7568 - val_accuracy: 0.5232\n",
      "Epoch 28/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6904 - accuracy: 0.5368 - val_loss: 0.6971 - val_accuracy: 0.5232\n",
      "Epoch 29/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6923 - accuracy: 0.5130 - val_loss: 0.6931 - val_accuracy: 0.5232\n",
      "Epoch 30/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6919 - accuracy: 0.5095 - val_loss: 0.6923 - val_accuracy: 0.5232\n",
      "Epoch 31/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6741 - accuracy: 0.5910 - val_loss: 0.6926 - val_accuracy: 0.5232\n",
      "Epoch 32/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6834 - accuracy: 0.5433 - val_loss: 0.6923 - val_accuracy: 0.5232\n",
      "Epoch 33/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6971 - accuracy: 0.4863 - val_loss: 0.6969 - val_accuracy: 0.4768\n",
      "Epoch 34/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6771 - accuracy: 0.5665 - val_loss: 0.9559 - val_accuracy: 0.5232\n",
      "Epoch 35/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6867 - accuracy: 0.5422 - val_loss: 0.6931 - val_accuracy: 0.5232\n",
      "Epoch 36/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6918 - accuracy: 0.5142 - val_loss: 0.6921 - val_accuracy: 0.5232\n",
      "Epoch 37/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6901 - accuracy: 0.5222 - val_loss: 0.7284 - val_accuracy: 0.4768\n",
      "Epoch 38/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6783 - accuracy: 0.5707 - val_loss: 0.6938 - val_accuracy: 0.5232\n",
      "Epoch 39/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6866 - accuracy: 0.5428 - val_loss: 0.6947 - val_accuracy: 0.4768\n",
      "Epoch 40/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6948 - accuracy: 0.5077 - val_loss: 0.6921 - val_accuracy: 0.5232\n",
      "Epoch 41/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6888 - accuracy: 0.5462 - val_loss: 0.6966 - val_accuracy: 0.5232\n",
      "Epoch 42/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6842 - accuracy: 0.5472 - val_loss: 0.6922 - val_accuracy: 0.5232\n",
      "Epoch 43/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6881 - accuracy: 0.5372 - val_loss: 0.6942 - val_accuracy: 0.4768\n",
      "Epoch 44/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6892 - accuracy: 0.5257 - val_loss: 0.7333 - val_accuracy: 0.4768\n",
      "Epoch 45/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6833 - accuracy: 0.5698 - val_loss: 0.6960 - val_accuracy: 0.5232\n",
      "Epoch 46/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6873 - accuracy: 0.5387 - val_loss: 0.7151 - val_accuracy: 0.4768\n",
      "Epoch 47/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6962 - accuracy: 0.4897 - val_loss: 0.6923 - val_accuracy: 0.5232\n",
      "Epoch 48/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6903 - accuracy: 0.5378 - val_loss: 0.6943 - val_accuracy: 0.5232\n",
      "Epoch 49/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6784 - accuracy: 0.5577 - val_loss: 0.6924 - val_accuracy: 0.5232\n",
      "Epoch 50/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6898 - accuracy: 0.5300 - val_loss: 0.6979 - val_accuracy: 0.4768\n",
      "Epoch 51/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6934 - accuracy: 0.5023 - val_loss: 0.7151 - val_accuracy: 0.4768\n",
      "Epoch 52/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6739 - accuracy: 0.5863 - val_loss: 0.7001 - val_accuracy: 0.5232\n",
      "Epoch 53/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6905 - accuracy: 0.5310 - val_loss: 0.6922 - val_accuracy: 0.5232\n",
      "Epoch 54/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6952 - accuracy: 0.4985 - val_loss: 0.7056 - val_accuracy: 0.4768\n",
      "Epoch 55/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6921 - accuracy: 0.5215 - val_loss: 0.6923 - val_accuracy: 0.5232\n",
      "Epoch 56/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6758 - accuracy: 0.5598 - val_loss: 0.6942 - val_accuracy: 0.4768\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6907 - accuracy: 0.5220 - val_loss: 0.6956 - val_accuracy: 0.4768\n",
      "Epoch 58/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6954 - accuracy: 0.4990 - val_loss: 0.6936 - val_accuracy: 0.4768\n",
      "Epoch 59/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6728 - accuracy: 0.5920 - val_loss: 0.6926 - val_accuracy: 0.5232\n",
      "Epoch 60/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6832 - accuracy: 0.5530 - val_loss: 0.6990 - val_accuracy: 0.5232\n",
      "Epoch 61/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6979 - accuracy: 0.4815 - val_loss: 0.6933 - val_accuracy: 0.4768\n",
      "Epoch 62/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6917 - accuracy: 0.5337 - val_loss: 0.6922 - val_accuracy: 0.5232\n",
      "Epoch 63/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6776 - accuracy: 0.5658 - val_loss: 0.6954 - val_accuracy: 0.4768\n",
      "Epoch 64/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6908 - accuracy: 0.5185 - val_loss: 0.6923 - val_accuracy: 0.5232\n",
      "Epoch 65/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6951 - accuracy: 0.4950 - val_loss: 0.6923 - val_accuracy: 0.5232\n",
      "Epoch 66/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6719 - accuracy: 0.5845 - val_loss: 0.6938 - val_accuracy: 0.5232\n",
      "Epoch 67/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6800 - accuracy: 0.5633 - val_loss: 0.7051 - val_accuracy: 0.5232\n",
      "Epoch 68/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6993 - accuracy: 0.4790 - val_loss: 0.6922 - val_accuracy: 0.5232\n",
      "Epoch 69/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6923 - accuracy: 0.5230 - val_loss: 0.6945 - val_accuracy: 0.5232\n",
      "Epoch 70/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6780 - accuracy: 0.5630 - val_loss: 0.6925 - val_accuracy: 0.5232\n",
      "Epoch 71/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6886 - accuracy: 0.5443 - val_loss: 0.6945 - val_accuracy: 0.4768\n",
      "Epoch 72/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6956 - accuracy: 0.4920 - val_loss: 0.6925 - val_accuracy: 0.5232\n",
      "Epoch 73/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6695 - accuracy: 0.5940 - val_loss: 0.7010 - val_accuracy: 0.5232\n",
      "Epoch 74/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6884 - accuracy: 0.5397 - val_loss: 0.7126 - val_accuracy: 0.5232\n",
      "Epoch 75/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6987 - accuracy: 0.4800 - val_loss: 0.6935 - val_accuracy: 0.4768\n",
      "Epoch 76/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6918 - accuracy: 0.5210 - val_loss: 0.6973 - val_accuracy: 0.5232\n",
      "Epoch 77/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6813 - accuracy: 0.5658 - val_loss: 0.6986 - val_accuracy: 0.4768\n",
      "Epoch 78/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6886 - accuracy: 0.5372 - val_loss: 0.7083 - val_accuracy: 0.4768\n",
      "Epoch 79/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6978 - accuracy: 0.4782 - val_loss: 0.6931 - val_accuracy: 0.5232\n",
      "Epoch 80/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6725 - accuracy: 0.5935 - val_loss: 0.7308 - val_accuracy: 0.5232\n",
      "Epoch 81/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6925 - accuracy: 0.5340 - val_loss: 0.6993 - val_accuracy: 0.5232\n",
      "Epoch 82/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6963 - accuracy: 0.4930 - val_loss: 0.6925 - val_accuracy: 0.5232\n",
      "Epoch 83/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6936 - accuracy: 0.5120 - val_loss: 0.6934 - val_accuracy: 0.5232\n",
      "Epoch 84/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6790 - accuracy: 0.5735 - val_loss: 0.7159 - val_accuracy: 0.4768\n",
      "Epoch 85/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6903 - accuracy: 0.5245 - val_loss: 0.6922 - val_accuracy: 0.5232\n",
      "Epoch 86/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6960 - accuracy: 0.4925 - val_loss: 0.6994 - val_accuracy: 0.4768\n",
      "Epoch 87/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6634 - accuracy: 0.5960 - val_loss: 0.7743 - val_accuracy: 0.5232\n",
      "Epoch 88/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6954 - accuracy: 0.5288 - val_loss: 0.7034 - val_accuracy: 0.5232\n",
      "Epoch 89/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6936 - accuracy: 0.5092 - val_loss: 0.6930 - val_accuracy: 0.5232\n",
      "Epoch 90/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6941 - accuracy: 0.5107 - val_loss: 0.6926 - val_accuracy: 0.5232\n",
      "Epoch 91/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6744 - accuracy: 0.5798 - val_loss: 0.6924 - val_accuracy: 0.5232\n",
      "Epoch 92/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6901 - accuracy: 0.5343 - val_loss: 0.6921 - val_accuracy: 0.5232\n",
      "Epoch 93/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6960 - accuracy: 0.4888 - val_loss: 0.7033 - val_accuracy: 0.4768\n",
      "Epoch 94/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6779 - accuracy: 0.5723 - val_loss: 0.7349 - val_accuracy: 0.5232\n",
      "Epoch 95/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6943 - accuracy: 0.5303 - val_loss: 0.6940 - val_accuracy: 0.5232\n",
      "Epoch 96/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6915 - accuracy: 0.5125 - val_loss: 0.6924 - val_accuracy: 0.5232\n",
      "Epoch 97/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6905 - accuracy: 0.5175 - val_loss: 0.7014 - val_accuracy: 0.5232\n",
      "Epoch 98/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6759 - accuracy: 0.5835 - val_loss: 0.6938 - val_accuracy: 0.5232\n",
      "Epoch 99/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6885 - accuracy: 0.5378 - val_loss: 0.6922 - val_accuracy: 0.5232\n",
      "Epoch 100/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6966 - accuracy: 0.4855 - val_loss: 0.6930 - val_accuracy: 0.5232\n",
      "Epoch 101/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6852 - accuracy: 0.5592 - val_loss: 0.7111 - val_accuracy: 0.5232\n",
      "Epoch 102/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6818 - accuracy: 0.5472 - val_loss: 0.6921 - val_accuracy: 0.5232\n",
      "Epoch 103/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6883 - accuracy: 0.5405 - val_loss: 0.6932 - val_accuracy: 0.4768\n",
      "Epoch 104/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6878 - accuracy: 0.5180 - val_loss: 0.7485 - val_accuracy: 0.4768\n",
      "Epoch 105/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6823 - accuracy: 0.5715 - val_loss: 0.6973 - val_accuracy: 0.5232\n",
      "Epoch 106/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6867 - accuracy: 0.5428 - val_loss: 0.6988 - val_accuracy: 0.4768\n",
      "Epoch 107/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6968 - accuracy: 0.4805 - val_loss: 0.6921 - val_accuracy: 0.5232\n",
      "Epoch 108/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6904 - accuracy: 0.5390 - val_loss: 0.6946 - val_accuracy: 0.5232\n",
      "Epoch 109/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6750 - accuracy: 0.5745 - val_loss: 0.6928 - val_accuracy: 0.5232\n",
      "Epoch 110/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6911 - accuracy: 0.5230 - val_loss: 0.6960 - val_accuracy: 0.4768\n",
      "Epoch 111/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6914 - accuracy: 0.5090 - val_loss: 0.7268 - val_accuracy: 0.4768\n",
      "Epoch 112/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 15ms/step - loss: 0.6769 - accuracy: 0.5755 - val_loss: 0.6942 - val_accuracy: 0.5232\n",
      "Epoch 113/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6902 - accuracy: 0.5282 - val_loss: 0.6936 - val_accuracy: 0.4768\n",
      "Epoch 114/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6965 - accuracy: 0.4935 - val_loss: 0.6964 - val_accuracy: 0.4768\n",
      "Epoch 115/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6858 - accuracy: 0.5470 - val_loss: 0.6932 - val_accuracy: 0.5232\n",
      "Epoch 116/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6823 - accuracy: 0.5567 - val_loss: 0.6923 - val_accuracy: 0.5232\n",
      "Epoch 117/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6909 - accuracy: 0.5285 - val_loss: 0.6976 - val_accuracy: 0.4768\n",
      "Epoch 118/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6948 - accuracy: 0.4955 - val_loss: 0.7023 - val_accuracy: 0.4768\n",
      "Epoch 119/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6776 - accuracy: 0.5860 - val_loss: 0.6950 - val_accuracy: 0.5232\n",
      "Epoch 120/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6888 - accuracy: 0.5408 - val_loss: 0.6946 - val_accuracy: 0.5232\n",
      "Epoch 121/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6949 - accuracy: 0.4967 - val_loss: 0.7231 - val_accuracy: 0.4768\n",
      "Epoch 122/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6934 - accuracy: 0.5222 - val_loss: 0.6936 - val_accuracy: 0.5232\n",
      "Epoch 123/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6813 - accuracy: 0.5595 - val_loss: 0.6966 - val_accuracy: 0.4768\n",
      "Epoch 124/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6910 - accuracy: 0.5182 - val_loss: 0.6942 - val_accuracy: 0.4768\n",
      "Epoch 125/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6954 - accuracy: 0.4980 - val_loss: 0.6921 - val_accuracy: 0.5232\n",
      "Epoch 126/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6767 - accuracy: 0.5880 - val_loss: 0.7027 - val_accuracy: 0.4768\n",
      "Epoch 127/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6826 - accuracy: 0.5552 - val_loss: 0.7075 - val_accuracy: 0.5232\n",
      "Epoch 128/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6964 - accuracy: 0.4940 - val_loss: 0.6921 - val_accuracy: 0.5232\n",
      "Epoch 129/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6922 - accuracy: 0.5260 - val_loss: 0.6953 - val_accuracy: 0.5232\n",
      "Epoch 130/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6815 - accuracy: 0.5610 - val_loss: 0.6948 - val_accuracy: 0.4768\n",
      "Epoch 131/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6910 - accuracy: 0.5230 - val_loss: 0.6926 - val_accuracy: 0.5232\n",
      "Epoch 132/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6950 - accuracy: 0.4963 - val_loss: 0.6921 - val_accuracy: 0.5232\n",
      "Epoch 133/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6761 - accuracy: 0.5905 - val_loss: 0.6959 - val_accuracy: 0.5232\n",
      "Epoch 134/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6831 - accuracy: 0.5560 - val_loss: 0.7021 - val_accuracy: 0.5232\n",
      "Epoch 135/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6967 - accuracy: 0.4955 - val_loss: 0.6928 - val_accuracy: 0.5232\n",
      "Epoch 136/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6887 - accuracy: 0.5282 - val_loss: 0.6978 - val_accuracy: 0.5232\n",
      "Epoch 137/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6798 - accuracy: 0.5635 - val_loss: 0.6958 - val_accuracy: 0.4768\n",
      "Epoch 138/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6892 - accuracy: 0.5378 - val_loss: 0.7054 - val_accuracy: 0.4768\n",
      "Epoch 139/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6970 - accuracy: 0.4775 - val_loss: 0.6921 - val_accuracy: 0.5232\n",
      "Epoch 140/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6743 - accuracy: 0.5922 - val_loss: 0.7187 - val_accuracy: 0.5232\n",
      "Epoch 141/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6913 - accuracy: 0.5362 - val_loss: 0.7070 - val_accuracy: 0.5232\n",
      "Epoch 142/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6981 - accuracy: 0.4807 - val_loss: 0.6925 - val_accuracy: 0.5232\n",
      "Epoch 143/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6898 - accuracy: 0.5222 - val_loss: 0.7107 - val_accuracy: 0.5232\n",
      "Epoch 144/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6764 - accuracy: 0.5735 - val_loss: 0.6984 - val_accuracy: 0.4768\n",
      "Epoch 145/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6896 - accuracy: 0.5297 - val_loss: 0.6960 - val_accuracy: 0.4768\n",
      "Epoch 146/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6969 - accuracy: 0.4835 - val_loss: 0.6956 - val_accuracy: 0.4768\n",
      "Epoch 147/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6685 - accuracy: 0.5960 - val_loss: 0.7445 - val_accuracy: 0.5232\n",
      "Epoch 148/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6909 - accuracy: 0.5362 - val_loss: 0.7368 - val_accuracy: 0.5232\n",
      "Epoch 149/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6969 - accuracy: 0.4942 - val_loss: 0.6927 - val_accuracy: 0.5232\n",
      "Epoch 150/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6943 - accuracy: 0.5125 - val_loss: 0.6925 - val_accuracy: 0.5232\n",
      "Epoch 151/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6721 - accuracy: 0.5845 - val_loss: 0.6992 - val_accuracy: 0.4768\n",
      "Epoch 152/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6897 - accuracy: 0.5330 - val_loss: 0.6925 - val_accuracy: 0.5232\n",
      "Epoch 153/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6970 - accuracy: 0.4827 - val_loss: 0.7002 - val_accuracy: 0.4768\n",
      "Epoch 154/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6644 - accuracy: 0.5830 - val_loss: 0.7181 - val_accuracy: 0.5232\n",
      "Epoch 155/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6889 - accuracy: 0.5307 - val_loss: 0.6965 - val_accuracy: 0.5232\n",
      "Epoch 156/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6926 - accuracy: 0.5135 - val_loss: 0.6936 - val_accuracy: 0.4768\n",
      "Epoch 157/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6929 - accuracy: 0.5260 - val_loss: 0.6949 - val_accuracy: 0.4768\n",
      "Epoch 158/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6644 - accuracy: 0.5855 - val_loss: 0.6918 - val_accuracy: 0.5232\n",
      "Epoch 159/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6808 - accuracy: 0.5630 - val_loss: 0.6928 - val_accuracy: 0.5232\n",
      "Epoch 160/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6960 - accuracy: 0.4997 - val_loss: 0.6989 - val_accuracy: 0.4768\n",
      "Epoch 161/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6668 - accuracy: 0.5780 - val_loss: 1.1042 - val_accuracy: 0.5232\n",
      "Epoch 162/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6838 - accuracy: 0.5465 - val_loss: 0.6961 - val_accuracy: 0.5232\n",
      "Epoch 163/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6844 - accuracy: 0.5458 - val_loss: 0.6915 - val_accuracy: 0.5232\n",
      "Epoch 164/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6853 - accuracy: 0.5383 - val_loss: 0.7143 - val_accuracy: 0.4768\n",
      "Epoch 165/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6546 - accuracy: 0.5940 - val_loss: 0.6910 - val_accuracy: 0.5232\n",
      "Epoch 166/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6798 - accuracy: 0.5660 - val_loss: 0.7065 - val_accuracy: 0.4768\n",
      "Epoch 167/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6968 - accuracy: 0.5090 - val_loss: 0.6921 - val_accuracy: 0.5406\n",
      "Epoch 168/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6576 - accuracy: 0.6127 - val_loss: 0.8246 - val_accuracy: 0.5232\n",
      "Epoch 169/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6572 - accuracy: 0.5800 - val_loss: 0.6894 - val_accuracy: 0.5297\n",
      "Epoch 170/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6529 - accuracy: 0.6292 - val_loss: 0.6701 - val_accuracy: 0.6124\n",
      "Epoch 171/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6609 - accuracy: 0.6003 - val_loss: 0.8112 - val_accuracy: 0.4768\n",
      "Epoch 172/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6364 - accuracy: 0.6360 - val_loss: 0.6647 - val_accuracy: 0.6026\n",
      "Epoch 173/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6527 - accuracy: 0.6168 - val_loss: 0.7323 - val_accuracy: 0.4772\n",
      "Epoch 174/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6591 - accuracy: 0.6205 - val_loss: 0.8256 - val_accuracy: 0.5339\n",
      "Epoch 175/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6362 - accuracy: 0.6453 - val_loss: 0.6599 - val_accuracy: 0.6377\n",
      "Epoch 176/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5978 - accuracy: 0.6687 - val_loss: 0.6561 - val_accuracy: 0.6006\n",
      "Epoch 177/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6343 - accuracy: 0.6425 - val_loss: 0.6408 - val_accuracy: 0.6275\n",
      "Epoch 178/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6028 - accuracy: 0.6775 - val_loss: 0.6402 - val_accuracy: 0.6506\n",
      "Epoch 179/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5885 - accuracy: 0.6773 - val_loss: 0.6159 - val_accuracy: 0.6593\n",
      "Epoch 180/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6086 - accuracy: 0.6560 - val_loss: 0.6385 - val_accuracy: 0.6179\n",
      "Epoch 181/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5906 - accuracy: 0.6910 - val_loss: 0.6874 - val_accuracy: 0.6706\n",
      "Epoch 182/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5706 - accuracy: 0.7053 - val_loss: 0.6308 - val_accuracy: 0.6346\n",
      "Epoch 183/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5712 - accuracy: 0.6950 - val_loss: 0.5650 - val_accuracy: 0.7012\n",
      "Epoch 184/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5682 - accuracy: 0.7090 - val_loss: 0.6424 - val_accuracy: 0.6243\n",
      "Epoch 185/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5387 - accuracy: 0.7285 - val_loss: 0.7227 - val_accuracy: 0.6065\n",
      "Epoch 186/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5215 - accuracy: 0.7312 - val_loss: 0.5790 - val_accuracy: 0.6921\n",
      "Epoch 187/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5613 - accuracy: 0.6995 - val_loss: 0.5727 - val_accuracy: 0.6846\n",
      "Epoch 188/300\n",
      "1000/1000 [==============================] - 14s 15ms/step - loss: 0.5136 - accuracy: 0.7560 - val_loss: 0.6295 - val_accuracy: 0.6540\n",
      "Epoch 189/300\n",
      "1000/1000 [==============================] - 14s 15ms/step - loss: 0.5097 - accuracy: 0.7525 - val_loss: 0.5601 - val_accuracy: 0.7093\n",
      "Epoch 190/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5401 - accuracy: 0.7182 - val_loss: 0.5831 - val_accuracy: 0.6758\n",
      "Epoch 191/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4813 - accuracy: 0.7675 - val_loss: 0.6457 - val_accuracy: 0.6474\n",
      "Epoch 192/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4873 - accuracy: 0.7688 - val_loss: 0.5020 - val_accuracy: 0.7452\n",
      "Epoch 193/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4815 - accuracy: 0.7645 - val_loss: 0.5588 - val_accuracy: 0.7210\n",
      "Epoch 194/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5210 - accuracy: 0.7437 - val_loss: 0.4953 - val_accuracy: 0.7593\n",
      "Epoch 195/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4576 - accuracy: 0.7972 - val_loss: 0.4747 - val_accuracy: 0.7690\n",
      "Epoch 196/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4597 - accuracy: 0.7880 - val_loss: 0.5302 - val_accuracy: 0.7401\n",
      "Epoch 197/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4966 - accuracy: 0.7548 - val_loss: 0.7092 - val_accuracy: 0.6139\n",
      "Epoch 198/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4449 - accuracy: 0.7933 - val_loss: 0.6450 - val_accuracy: 0.6761\n",
      "Epoch 199/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4305 - accuracy: 0.8112 - val_loss: 0.4856 - val_accuracy: 0.7630\n",
      "Epoch 200/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4547 - accuracy: 0.7872 - val_loss: 0.5737 - val_accuracy: 0.6948\n",
      "Epoch 201/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4651 - accuracy: 0.7705 - val_loss: 0.4820 - val_accuracy: 0.7802\n",
      "Epoch 202/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4094 - accuracy: 0.8195 - val_loss: 0.4682 - val_accuracy: 0.7727\n",
      "Epoch 203/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4067 - accuracy: 0.8188 - val_loss: 0.5870 - val_accuracy: 0.7041\n",
      "Epoch 204/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4635 - accuracy: 0.7700 - val_loss: 0.4415 - val_accuracy: 0.7969\n",
      "Epoch 205/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4191 - accuracy: 0.8123 - val_loss: 0.5831 - val_accuracy: 0.7013\n",
      "Epoch 206/300\n",
      "1000/1000 [==============================] - 14s 15ms/step - loss: 0.3973 - accuracy: 0.8242 - val_loss: 0.7996 - val_accuracy: 0.7139\n",
      "Epoch 207/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4237 - accuracy: 0.8043 - val_loss: 0.5012 - val_accuracy: 0.7445\n",
      "Epoch 208/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4630 - accuracy: 0.7738 - val_loss: 0.4468 - val_accuracy: 0.7927\n",
      "Epoch 209/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3731 - accuracy: 0.8397 - val_loss: 0.4678 - val_accuracy: 0.7685\n",
      "Epoch 210/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3814 - accuracy: 0.8320 - val_loss: 0.6046 - val_accuracy: 0.7706\n",
      "Epoch 211/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4464 - accuracy: 0.7937 - val_loss: 0.4225 - val_accuracy: 0.8003\n",
      "Epoch 212/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3798 - accuracy: 0.8313 - val_loss: 0.8972 - val_accuracy: 0.5217\n",
      "Epoch 213/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3648 - accuracy: 0.8405 - val_loss: 0.4059 - val_accuracy: 0.8234\n",
      "Epoch 214/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3894 - accuracy: 0.8250 - val_loss: 0.5820 - val_accuracy: 0.7715\n",
      "Epoch 215/300\n",
      "1000/1000 [==============================] - 14s 15ms/step - loss: 0.4319 - accuracy: 0.8035 - val_loss: 0.5635 - val_accuracy: 0.7948\n",
      "Epoch 216/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3424 - accuracy: 0.8572 - val_loss: 0.4572 - val_accuracy: 0.7938\n",
      "Epoch 217/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3633 - accuracy: 0.8382 - val_loss: 0.4041 - val_accuracy: 0.8037\n",
      "Epoch 218/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4109 - accuracy: 0.8125 - val_loss: 0.4851 - val_accuracy: 0.7666\n",
      "Epoch 219/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3525 - accuracy: 0.8410 - val_loss: 0.4866 - val_accuracy: 0.7869\n",
      "Epoch 220/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3416 - accuracy: 0.8528 - val_loss: 0.3982 - val_accuracy: 0.8252\n",
      "Epoch 221/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3748 - accuracy: 0.8413 - val_loss: 0.4206 - val_accuracy: 0.8111\n",
      "Epoch 222/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4107 - accuracy: 0.8100 - val_loss: 0.3670 - val_accuracy: 0.8384\n",
      "Epoch 223/300\n",
      "1000/1000 [==============================] - 14s 15ms/step - loss: 0.3182 - accuracy: 0.8685 - val_loss: 0.5334 - val_accuracy: 0.7499\n",
      "Epoch 224/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3455 - accuracy: 0.8520 - val_loss: 0.7743 - val_accuracy: 0.7188\n",
      "Epoch 225/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3915 - accuracy: 0.8220 - val_loss: 0.3514 - val_accuracy: 0.8440\n",
      "Epoch 226/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3357 - accuracy: 0.8447 - val_loss: 0.5676 - val_accuracy: 0.8033\n",
      "Epoch 227/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3265 - accuracy: 0.8637 - val_loss: 0.4422 - val_accuracy: 0.7934\n",
      "Epoch 228/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3549 - accuracy: 0.8428 - val_loss: 0.6091 - val_accuracy: 0.7532\n",
      "Epoch 229/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3730 - accuracy: 0.8328 - val_loss: 0.3590 - val_accuracy: 0.8516\n",
      "Epoch 230/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2896 - accuracy: 0.8792 - val_loss: 0.4007 - val_accuracy: 0.8368\n",
      "Epoch 231/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3295 - accuracy: 0.8572 - val_loss: 0.4238 - val_accuracy: 0.7965\n",
      "Epoch 232/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3653 - accuracy: 0.8330 - val_loss: 0.3673 - val_accuracy: 0.8386\n",
      "Epoch 233/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3324 - accuracy: 0.8568 - val_loss: 0.4790 - val_accuracy: 0.8426\n",
      "Epoch 234/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3081 - accuracy: 0.8687 - val_loss: 0.3728 - val_accuracy: 0.8270\n",
      "Epoch 235/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3400 - accuracy: 0.8533 - val_loss: 0.3942 - val_accuracy: 0.8097\n",
      "Epoch 236/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3632 - accuracy: 0.8357 - val_loss: 0.3175 - val_accuracy: 0.8624\n",
      "Epoch 237/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2715 - accuracy: 0.8888 - val_loss: 0.4103 - val_accuracy: 0.8431\n",
      "Epoch 238/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3009 - accuracy: 0.8765 - val_loss: 0.5190 - val_accuracy: 0.7646\n",
      "Epoch 239/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3190 - accuracy: 0.8600 - val_loss: 0.3303 - val_accuracy: 0.8648\n",
      "Epoch 240/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3322 - accuracy: 0.8577 - val_loss: 0.4011 - val_accuracy: 0.8547\n",
      "Epoch 241/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2822 - accuracy: 0.8878 - val_loss: 0.5213 - val_accuracy: 0.8192\n",
      "Epoch 242/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3085 - accuracy: 0.8710 - val_loss: 0.3281 - val_accuracy: 0.8553\n",
      "Epoch 243/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3526 - accuracy: 0.8418 - val_loss: 0.4143 - val_accuracy: 0.8263\n",
      "Epoch 244/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2512 - accuracy: 0.8967 - val_loss: 0.4512 - val_accuracy: 0.7992\n",
      "Epoch 245/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2721 - accuracy: 0.8850 - val_loss: 0.6476 - val_accuracy: 0.6986\n",
      "Epoch 246/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2899 - accuracy: 0.8767 - val_loss: 0.3178 - val_accuracy: 0.8688\n",
      "Epoch 247/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3314 - accuracy: 0.8572 - val_loss: 0.2806 - val_accuracy: 0.8827\n",
      "Epoch 248/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2470 - accuracy: 0.8967 - val_loss: 0.3640 - val_accuracy: 0.8440\n",
      "Epoch 249/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3030 - accuracy: 0.8733 - val_loss: 0.3326 - val_accuracy: 0.8564\n",
      "Epoch 250/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3358 - accuracy: 0.8490 - val_loss: 0.3169 - val_accuracy: 0.8579\n",
      "Epoch 251/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2410 - accuracy: 0.9025 - val_loss: 0.3415 - val_accuracy: 0.8595\n",
      "Epoch 252/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2600 - accuracy: 0.8953 - val_loss: 0.3279 - val_accuracy: 0.8557\n",
      "Epoch 253/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2910 - accuracy: 0.8765 - val_loss: 0.3308 - val_accuracy: 0.8563\n",
      "Epoch 254/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3109 - accuracy: 0.8627 - val_loss: 0.2626 - val_accuracy: 0.8924\n",
      "Epoch 255/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2448 - accuracy: 0.9045 - val_loss: 0.2943 - val_accuracy: 0.8767\n",
      "Epoch 256/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2508 - accuracy: 0.8995 - val_loss: 0.3319 - val_accuracy: 0.8457\n",
      "Epoch 257/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3232 - accuracy: 0.8600 - val_loss: 0.3907 - val_accuracy: 0.8199\n",
      "Epoch 258/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2398 - accuracy: 0.9015 - val_loss: 0.3842 - val_accuracy: 0.8624\n",
      "Epoch 259/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2412 - accuracy: 0.9053 - val_loss: 0.3311 - val_accuracy: 0.8544\n",
      "Epoch 260/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2790 - accuracy: 0.8860 - val_loss: 0.3208 - val_accuracy: 0.8561\n",
      "Epoch 261/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3077 - accuracy: 0.8695 - val_loss: 0.2867 - val_accuracy: 0.8878\n",
      "Epoch 262/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2265 - accuracy: 0.9085 - val_loss: 0.3061 - val_accuracy: 0.8693\n",
      "Epoch 263/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2369 - accuracy: 0.9087 - val_loss: 0.3332 - val_accuracy: 0.8539\n",
      "Epoch 264/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2938 - accuracy: 0.8765 - val_loss: 0.3087 - val_accuracy: 0.8656\n",
      "Epoch 265/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2331 - accuracy: 0.9035 - val_loss: 0.3132 - val_accuracy: 0.8819\n",
      "Epoch 266/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2240 - accuracy: 0.9110 - val_loss: 0.3128 - val_accuracy: 0.8808\n",
      "Epoch 267/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2619 - accuracy: 0.8928 - val_loss: 0.2926 - val_accuracy: 0.8886\n",
      "Epoch 268/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2899 - accuracy: 0.8733 - val_loss: 0.2753 - val_accuracy: 0.8831\n",
      "Epoch 269/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2105 - accuracy: 0.9172 - val_loss: 0.4058 - val_accuracy: 0.7995\n",
      "Epoch 270/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2338 - accuracy: 0.9065 - val_loss: 0.2959 - val_accuracy: 0.8694\n",
      "Epoch 271/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2870 - accuracy: 0.8792 - val_loss: 0.2601 - val_accuracy: 0.8848\n",
      "Epoch 272/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2403 - accuracy: 0.9047 - val_loss: 0.4754 - val_accuracy: 0.7843\n",
      "Epoch 273/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2168 - accuracy: 0.9165 - val_loss: 0.2684 - val_accuracy: 0.8919\n",
      "Epoch 274/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2477 - accuracy: 0.9005 - val_loss: 0.2493 - val_accuracy: 0.8967\n",
      "Epoch 275/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2656 - accuracy: 0.8913 - val_loss: 0.2946 - val_accuracy: 0.8788\n",
      "Epoch 276/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2091 - accuracy: 0.9143 - val_loss: 0.2462 - val_accuracy: 0.8965\n",
      "Epoch 277/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2244 - accuracy: 0.9090 - val_loss: 0.2653 - val_accuracy: 0.8864\n",
      "Epoch 278/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2748 - accuracy: 0.8830 - val_loss: 0.3430 - val_accuracy: 0.8481\n",
      "Epoch 279/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2073 - accuracy: 0.9158 - val_loss: 0.3684 - val_accuracy: 0.8508\n",
      "Epoch 280/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2212 - accuracy: 0.9128 - val_loss: 0.3333 - val_accuracy: 0.8644\n",
      "Epoch 281/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2357 - accuracy: 0.9050 - val_loss: 0.2658 - val_accuracy: 0.8964\n",
      "Epoch 282/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2573 - accuracy: 0.8932 - val_loss: 0.2570 - val_accuracy: 0.9040\n",
      "Epoch 283/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1822 - accuracy: 0.9280 - val_loss: 0.2999 - val_accuracy: 0.8770\n",
      "Epoch 284/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2251 - accuracy: 0.9122 - val_loss: 0.2872 - val_accuracy: 0.8775\n",
      "Epoch 285/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2456 - accuracy: 0.8990 - val_loss: 0.3901 - val_accuracy: 0.8256\n",
      "Epoch 286/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2043 - accuracy: 0.9165 - val_loss: 0.3535 - val_accuracy: 0.8668\n",
      "Epoch 287/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2069 - accuracy: 0.9227 - val_loss: 0.4127 - val_accuracy: 0.8262\n",
      "Epoch 288/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2203 - accuracy: 0.9080 - val_loss: 0.2556 - val_accuracy: 0.8947\n",
      "Epoch 289/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2333 - accuracy: 0.9060 - val_loss: 0.3130 - val_accuracy: 0.8956\n",
      "Epoch 290/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1819 - accuracy: 0.9302 - val_loss: 0.2887 - val_accuracy: 0.8795\n",
      "Epoch 291/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2093 - accuracy: 0.9165 - val_loss: 0.3728 - val_accuracy: 0.8826\n",
      "Epoch 292/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2312 - accuracy: 0.9085 - val_loss: 0.2245 - val_accuracy: 0.9068\n",
      "Epoch 293/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1933 - accuracy: 0.9252 - val_loss: 0.2629 - val_accuracy: 0.9010\n",
      "Epoch 294/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2093 - accuracy: 0.9178 - val_loss: 0.3350 - val_accuracy: 0.8628\n",
      "Epoch 295/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2096 - accuracy: 0.9178 - val_loss: 0.2382 - val_accuracy: 0.8984\n",
      "Epoch 296/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2337 - accuracy: 0.9057 - val_loss: 0.2453 - val_accuracy: 0.9118\n",
      "Epoch 297/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1843 - accuracy: 0.9255 - val_loss: 0.3176 - val_accuracy: 0.8999\n",
      "Epoch 298/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1961 - accuracy: 0.9258 - val_loss: 0.3361 - val_accuracy: 0.8625\n",
      "Epoch 299/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2162 - accuracy: 0.9153 - val_loss: 0.2162 - val_accuracy: 0.9143\n",
      "Epoch 300/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2228 - accuracy: 0.9082 - val_loss: 0.2641 - val_accuracy: 0.9011\n"
     ]
    }
   ],
   "source": [
    "for i, (train, val) in enumerate([folds[0]]):\n",
    "    \n",
    "    model = createModel()\n",
    "    \n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    metrics = ['accuracy']\n",
    "    \n",
    "    model.compile(optimizer=opt, loss=loss, metrics=metrics)\n",
    "    \n",
    "    tboardCb = tf.keras.callbacks.TensorBoard(log_dir=f\"{logBasePath}/{logPrefix}_{i}\", histogram_freq=1, profile_batch=(2,10))\n",
    "    lrSchedule = tf.keras.callbacks.LearningRateScheduler(schedule)\n",
    "    \n",
    "    cbs = [tboardCb]\n",
    "    \n",
    "    model.evaluate(val)\n",
    "    model.fit(train, initial_epoch=START_EPOCH, epochs=END_EPOCH, steps_per_epoch=STEPS_PER_EPOCH, callbacks=cbs, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae70be7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
