{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f19017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d782ddf",
   "metadata": {},
   "source": [
    "### Check Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03faa827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac4996",
   "metadata": {},
   "source": [
    "### GPU Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1e955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2835bd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f935a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be867b6",
   "metadata": {},
   "source": [
    "### Pandas Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92db292",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_column', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0907c",
   "metadata": {},
   "source": [
    "### Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0fd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VAL_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf19fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_WIDTH = 227\n",
    "CROP_HEIGHT = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d40847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldFiles = [\"adience/unprocessed/fold_0_data.txt\",\n",
    "             \"adience/unprocessed/fold_1_data.txt\",\n",
    "             \"adience/unprocessed/fold_2_data.txt\",\n",
    "             \"adience/unprocessed/fold_3_data.txt\",\n",
    "             \"adience/unprocessed/fold_4_data.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f61c7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genderMap = defaultdict(lambda : np.NaN)\n",
    "genderMap['m'] = 0\n",
    "genderMap['f'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d26242",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = ['(0, 2)', '(4, 6)', '(8, 13)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
    "ageMap = defaultdict(lambda : np.NaN)\n",
    "for i,a in enumerate(ages):\n",
    "    ageMap[a] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b1fc3",
   "metadata": {},
   "source": [
    "### Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd634a3",
   "metadata": {},
   "source": [
    "Dataset generation pipeline:\n",
    "Input: \n",
    "- foldFile - Path to fold file. Fold file Describes which images are in the fold and its corresponding labels\n",
    "- imgBaseFolder - Base folder to search image from\n",
    "- imgPrefix - Prefix of image file\n",
    "- genderMap - Map from ['m', 'f', 'u', None], to one hot index\n",
    "- ageMap - Map from age category to one hot index\n",
    "- imgWidth - Resulting image width\n",
    "- imgHeigh - Resulting image height\n",
    "- batchSize - Int or None, batch size\n",
    "- configureDs - Function accepting dataset for performance configurations\n",
    "- preBatch - List of (name, functions) pair that will be mapped before batching. name is used as name parameters for tf graph \n",
    "- postBatch - List of (name, functions) that will be mapped after batching. name is used as name parameters for tf graph\n",
    "\n",
    "The processing functions should have signature function(img, label) -> (img, label)\n",
    "\n",
    "Pipeline\n",
    "\n",
    "Read Fold File -> Preprocess filename and labels (dataframe) -> Convert filename and labels to numpy array -> Convert filename and labels to tf dataset -> Parse images and labels -> Configure Dataset for performance -> Pre-Batching preprocessing -> Batch -> Post-Batching preprocessing -> Output\n",
    "\n",
    "Some preprocessing steps can only be done before and some can only be done after batching, thats why there are seperated pre and post batching list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0795464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, batchSize, configureDs=None, preBatch=[], postBatch=[]):\n",
    "    \n",
    "    def parseImage(filename):\n",
    "        img = tf.io.read_file(filename)\n",
    "        img = tf.image.decode_jpeg(img)\n",
    "        img = tf.image.resize(img, [imgHeight, imgWidth])\n",
    "         \n",
    "        return img\n",
    "    \n",
    "    # Read Fold File\n",
    "    foldData = []\n",
    "    for f in foldFiles:\n",
    "        foldData.append(pd.read_csv(f, sep=\"\\t\"))\n",
    "    foldData = pd.concat(foldData)\n",
    "    \n",
    "    # Form File Name\n",
    "    foldData['filename'] = foldData.apply(lambda r: os.path.join(imgBaseFolder, r['user_id'], f\"{imgPrefix}.{r['face_id']}.{r['original_image']}\"), axis=1)\n",
    "    \n",
    "    # Generate Label One Hot Index\n",
    "    foldData['gender_ind'] = foldData['gender'].map(genderMap)\n",
    "    foldData['age_ind'] = foldData['age'].map(ageMap)\n",
    "    \n",
    "    # Remove dirty data\n",
    "    foldData.dropna(subset=['gender_ind', 'age_ind'], inplace=True)\n",
    "    \n",
    "    # Dataframe to numpy\n",
    "    filenames = foldData['filename'].to_numpy()\n",
    "    \n",
    "    genderIndex = foldData['gender_ind'].to_numpy().astype(int)\n",
    "    ageIndex = foldData['age_ind'].to_numpy().astype(int)\n",
    "    \n",
    "    # Numpy to Dataset\n",
    "    fnDs = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    genderIndDs = tf.data.Dataset.from_tensor_slices(genderIndex)\n",
    "    ageIndDs = tf.data.Dataset.from_tensor_slices(ageIndex)\n",
    "    \n",
    "    # Parse Images\n",
    "    imageDs = fnDs.map(parseImage, num_parallel_calls=tf.data.AUTOTUNE, name=\"parse_image\")\n",
    "    \n",
    "    # Parse Labels\n",
    "    genderLabDs = genderIndDs.map(lambda x: tf.one_hot(x, genderDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"gender_one_hot\")\n",
    "    ageLabDs = ageIndDs.map(lambda x: tf.one_hot(x, ageDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"age_one_hot\")\n",
    "    \n",
    "    # Combine Labels\n",
    "    labelDs = tf.data.Dataset.zip((genderLabDs, ageLabDs), name=\"label_zip\")\n",
    "    labelDs = labelDs.map(lambda g,a: {\"gender\": g, \"age\": a}, num_parallel_calls=tf.data.AUTOTUNE, name='label_dict')\n",
    "    \n",
    "    # Combine Images and Labels into dataset\n",
    "    ds = tf.data.Dataset.zip((imageDs, labelDs))\n",
    "    \n",
    "    # Configure Performance\n",
    "    if(configureDs is not None):\n",
    "        ds = configureDs(ds)\n",
    "    \n",
    "    # Pre Batch Preprocessing\n",
    "    for n,f in preBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    # Batch\n",
    "    if(batchSize is not None):\n",
    "        ds = ds.batch(batchSize, name=\"ds_batch\")\n",
    "    \n",
    "    # Post Batch Preprocessing\n",
    "    for n,f in postBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320ed92",
   "metadata": {},
   "source": [
    "### Preprocessings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "472b7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=100)\n",
    "    ds = ds.repeat()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adb98feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313da7f1",
   "metadata": {},
   "source": [
    "#### Preprocessing steps according to the reference paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7724a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainPreprocessA(img, lab):\n",
    "        \n",
    "        img = tf.image.random_crop(img, [CROP_HEIGHT, CROP_WIDTH, 3])\n",
    "        \n",
    "        ud = tf.random.uniform([], dtype=tf.float32)\n",
    "        udCond = tf.less(ud, 0.5)\n",
    "        \n",
    "        img = tf.cond(udCond, lambda: tf.image.flip_up_down(img), lambda: img)\n",
    "        \n",
    "        lr = tf.random.uniform([], dtype=tf.float32)\n",
    "        lrCond = tf.less(lr, 0.5)\n",
    "        \n",
    "        img = tf.cond(lrCond, lambda: tf.image.flip_left_right(img), lambda: img)\n",
    "        \n",
    "        img = tf.image.random_brightness(img, 63/255)\n",
    "        \n",
    "        img = tf.image.random_contrast(img, 0.2, 1.8) \n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14ee59ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valPreprocessA(img, lab):\n",
    "        \n",
    "        img = tf.image.crop_to_bounding_box(img,\n",
    "                                            (IMG_HEIGHT-CROP_HEIGHT) // 2,\n",
    "                                            (IMG_WIDTH-CROP_WIDTH) // 2,\n",
    "                                            CROP_HEIGHT,\n",
    "                                            CROP_WIDTH)\n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a03ab680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageStandardize(img, lab):\n",
    "    \n",
    "    img = tf.image.per_image_standardization(img)\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ec104",
   "metadata": {},
   "source": [
    "#### Label extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "294a2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractGenderLabel(img, lab):\n",
    "    \n",
    "    lab = lab['gender']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a98897ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAgeLabel(img, lab):\n",
    "    \n",
    "    lab = lab['age']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7778c",
   "metadata": {},
   "source": [
    "### Generate Folds for K-Folds validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4172d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFoldDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, valBatchSize, trainConfigureDs=None, trainPreBatch=[], trainPostBatch=[], valConfigureDs=None, valPreBatch=[], valPostBatch=[]):\n",
    "    '''\n",
    "        Returns list of (train, validation) datasets\n",
    "    '''\n",
    "    \n",
    "    N = len(foldFiles)\n",
    "    \n",
    "    folds = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        trainFiles = foldFiles[:i]\n",
    "        if(i < N-1):\n",
    "            trainFiles.extend(foldFiles[i+1:])\n",
    "            \n",
    "        valFiles = foldFiles[i]\n",
    "        \n",
    "        trainDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, configureDs=trainConfigureDs, preBatch=trainPreBatch, postBatch=trainPostBatch)\n",
    "        valDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, valBatchSize, configureDs=valConfigureDs, preBatch=valPreBatch, postBatch=valPostBatch)\n",
    "        \n",
    "        folds.append((trainDs, valDs))\n",
    "        \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4f43dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPreBatch = [(\"train_process_a\", trainPreprocessA), \n",
    "                 (\"train_standardize\", imageStandardize), \n",
    "                 (\"train_extract_gender\", extractGenderLabel)]\n",
    "\n",
    "valPreBatch = [(\"val_process_a\", valPreprocessA), \n",
    "               (\"val_standardize\", imageStandardize), \n",
    "               (\"val_extract_gender\", extractGenderLabel)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10474d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:09:28.451392: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-08 14:09:29.512619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13029 MB memory:  -> device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "folds = generateFoldDs(foldFiles, \"adience/faces\", \"coarse_tilt_aligned_face\", genderMap, ageMap, 2, 8, \n",
    "                       IMG_WIDTH, IMG_HEIGHT, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE, \n",
    "                       trainConfigureDs=trainConfigPerformance, trainPreBatch=trainPreBatch, \n",
    "                       valConfigureDs=valConfigPerformance, valPreBatch=valPreBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57d814af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b5f9bc",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d0df0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in folds[0][0].take(1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c9e2833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 227, 227, 3), dtype=float32, numpy=\n",
       "array([[[[-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         ...,\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ]],\n",
       "\n",
       "        [[-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         ...,\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ]],\n",
       "\n",
       "        [[-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         ...,\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         ...,\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ]],\n",
       "\n",
       "        [[-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         ...,\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ]],\n",
       "\n",
       "        [[-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         ...,\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ],\n",
       "         [-2.2563462 , -2.2993028 , -2.3436024 ]]],\n",
       "\n",
       "\n",
       "       [[[ 1.9296306 , -0.08312897,  0.5351382 ],\n",
       "         [ 1.8641165 , -0.09111135,  0.48033538],\n",
       "         [ 1.9205366 ,  0.11170027,  0.6337256 ],\n",
       "         ...,\n",
       "         [-0.4774052 , -0.8463681 , -0.906939  ],\n",
       "         [-0.44381618, -0.81277895, -0.87335   ],\n",
       "         [-0.4079192 , -0.7768822 , -0.8374532 ]],\n",
       "\n",
       "        [[ 1.2242539 , -0.16773793,  0.28418207],\n",
       "         [ 1.1436976 , -0.13834333,  0.25384158],\n",
       "         [ 1.1004806 , -0.03341905,  0.31004432],\n",
       "         ...,\n",
       "         [-0.48135844, -0.8230831 , -0.89727336],\n",
       "         [-0.45427158, -0.8117433 , -0.87805986],\n",
       "         [-0.4159961 , -0.8226244 , -0.87064034]],\n",
       "\n",
       "        [[ 0.57199174, -0.0921422 ,  0.08749889],\n",
       "         [ 0.56894654,  0.00304052,  0.13434781],\n",
       "         [ 0.45063022, -0.01464558,  0.08034427],\n",
       "         ...,\n",
       "         [-0.49726167, -0.83656514, -0.9416254 ],\n",
       "         [-0.43703485, -0.8059977 , -0.8665687 ],\n",
       "         [-0.4247871 , -0.84731853, -0.8900334 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.007828  , -1.3574214 , -1.3405147 ],\n",
       "         [-1.0160893 , -1.3656828 , -1.3487761 ],\n",
       "         [-0.9706023 , -1.3395653 , -1.3613974 ],\n",
       "         ...,\n",
       "         [ 2.0751238 ,  0.8926443 ,  0.40594557],\n",
       "         [ 2.1082304 ,  0.92575103,  0.43905252],\n",
       "         [ 2.1374078 ,  0.9549283 ,  0.46822956]],\n",
       "\n",
       "        [[-1.0350662 , -1.3846596 , -1.3677529 ],\n",
       "         [-1.0199386 , -1.3889015 , -1.3719947 ],\n",
       "         [-1.0206857 , -1.3896487 , -1.4114808 ],\n",
       "         ...,\n",
       "         [ 2.080084  ,  0.8976048 ,  0.4109061 ],\n",
       "         [ 2.0858295 ,  0.9033504 ,  0.4166517 ],\n",
       "         [ 2.2543998 ,  1.0719203 ,  0.5852216 ]],\n",
       "\n",
       "        [[-1.0505344 , -1.4001278 , -1.383221  ],\n",
       "         [-0.988014  , -1.3560691 , -1.3391623 ],\n",
       "         [-1.0026829 , -1.36983   , -1.3925701 ],\n",
       "         ...,\n",
       "         [ 2.083437  ,  0.90095747,  0.41607487],\n",
       "         [ 2.0503445 ,  0.86786497,  0.38298216],\n",
       "         [ 2.1382113 ,  0.9557322 ,  0.5048878 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.6078719 , -0.7780502 , -1.4321759 ],\n",
       "         [-0.34641716, -0.5356928 , -1.2360069 ],\n",
       "         [-0.20054024, -0.43222314, -1.1817812 ],\n",
       "         ...,\n",
       "         [-1.1319667 , -0.6054511 , -0.01102362],\n",
       "         [-1.222787  , -0.6703221 , -0.08596074],\n",
       "         [-1.2455711 , -0.66502327, -0.09002285]],\n",
       "\n",
       "        [[ 0.39165786, -0.01838816, -0.69336075],\n",
       "         [ 0.35012725, -0.09933115, -0.8073663 ],\n",
       "         [ 0.31618717, -0.16998325, -0.90558285],\n",
       "         ...,\n",
       "         [-1.1889348 , -0.683001  , -0.07828253],\n",
       "         [-1.0668993 , -0.5411994 ,  0.05363584],\n",
       "         [-1.1375875 , -0.5899251 , -0.00396291]],\n",
       "\n",
       "        [[ 0.42748275, -0.17463128, -0.8301578 ],\n",
       "         [ 0.47152978, -0.12116129, -0.8446652 ],\n",
       "         [ 0.46105117, -0.14633693, -0.91116846],\n",
       "         ...,\n",
       "         [-1.0818536 , -0.56245214, -0.00419729],\n",
       "         [-1.0177649 , -0.4803123 ,  0.06961727],\n",
       "         [-1.1428323 , -0.5651096 ,  0.00533133]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.0001197 ,  2.1292279 ,  2.141772  ],\n",
       "         [ 1.9991677 ,  2.1292279 ,  2.14082   ],\n",
       "         [ 2.0001197 ,  2.1292279 ,  2.141772  ],\n",
       "         ...,\n",
       "         [ 1.3622527 ,  1.4133021 ,  1.0199411 ],\n",
       "         [ 1.4135789 ,  1.4646282 ,  1.0802927 ],\n",
       "         [ 1.4643809 ,  1.5298225 ,  1.1520731 ]],\n",
       "\n",
       "        [[ 1.9773728 ,  2.1220927 ,  2.1190252 ],\n",
       "         [ 1.9773728 ,  2.1220927 ,  2.1190252 ],\n",
       "         [ 1.9845078 ,  2.1292279 ,  2.1261604 ],\n",
       "         ...,\n",
       "         [ 1.3975364 ,  1.4485857 ,  1.0552249 ],\n",
       "         [ 1.2993159 ,  1.3503654 ,  0.9660299 ],\n",
       "         [ 1.3815825 ,  1.432632  ,  1.0548825 ]],\n",
       "\n",
       "        [[ 1.9785613 ,  2.123281  ,  2.1202133 ],\n",
       "         [ 1.9688963 ,  2.0980043 ,  2.141772  ],\n",
       "         [ 1.9701159 ,  2.099224  ,  2.1429918 ],\n",
       "         ...,\n",
       "         [ 1.2589613 ,  1.3412342 ,  0.9322614 ],\n",
       "         [ 1.3544087 ,  1.4186306 ,  1.0277089 ],\n",
       "         [ 1.3892895 ,  1.4403389 ,  1.0625894 ]]],\n",
       "\n",
       "\n",
       "       [[[ 1.733346  ,  1.749203  ,  1.7729492 ],\n",
       "         [ 1.733346  ,  1.749203  ,  1.7729492 ],\n",
       "         [ 1.733346  ,  1.749203  ,  1.7729492 ],\n",
       "         ...,\n",
       "         [ 1.1681559 ,  1.2163026 ,  1.1627914 ],\n",
       "         [ 1.1780515 ,  1.2319429 ,  1.1669422 ],\n",
       "         [ 1.1941375 ,  1.2595185 ,  1.1945177 ]],\n",
       "\n",
       "        [[ 1.733346  ,  1.749203  ,  1.7729492 ],\n",
       "         [ 1.733346  ,  1.749203  ,  1.7729492 ],\n",
       "         [ 1.733346  ,  1.749203  ,  1.7729492 ],\n",
       "         ...,\n",
       "         [ 1.208193  ,  1.2620846 ,  1.1970838 ],\n",
       "         [ 1.237307  ,  1.2911985 ,  1.2261977 ],\n",
       "         [ 1.2929782 ,  1.3468696 ,  1.2818689 ]],\n",
       "\n",
       "        [[ 1.733346  ,  1.749203  ,  1.7729492 ],\n",
       "         [ 1.733346  ,  1.749203  ,  1.7729492 ],\n",
       "         [ 1.733346  ,  1.749203  ,  1.7729492 ],\n",
       "         ...,\n",
       "         [ 1.2155412 ,  1.2947891 ,  1.2297882 ],\n",
       "         [ 1.2536004 ,  1.3328482 ,  1.2678474 ],\n",
       "         [ 1.2992646 ,  1.3785125 ,  1.3135117 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.3075628 , -1.2790276 , -1.2299249 ],\n",
       "         [-1.3262643 , -1.2977291 , -1.2486265 ],\n",
       "         [-1.3082219 , -1.2796869 , -1.2305843 ],\n",
       "         ...,\n",
       "         [-1.275338  , -1.2214465 , -1.1089532 ],\n",
       "         [-1.3244659 , -1.2705745 , -1.158081  ],\n",
       "         [-1.3212963 , -1.2674049 , -1.1549116 ]],\n",
       "\n",
       "        [[-1.305198  , -1.2766628 , -1.2275603 ],\n",
       "         [-1.2848498 , -1.2563146 , -1.207212  ],\n",
       "         [-1.2901953 , -1.2616601 , -1.2125576 ],\n",
       "         ...,\n",
       "         [-1.2274824 , -1.1735909 , -1.066248  ],\n",
       "         [-1.2666249 , -1.2127334 , -1.1002401 ],\n",
       "         [-1.3087391 , -1.2548475 , -1.1423541 ]],\n",
       "\n",
       "        [[-1.2583019 , -1.2297666 , -1.1553078 ],\n",
       "         [-1.2535257 , -1.2249907 , -1.1505318 ],\n",
       "         [-1.2415162 , -1.2129811 , -1.1385221 ],\n",
       "         ...,\n",
       "         [-1.2527274 , -1.2047787 , -1.1160661 ],\n",
       "         [-1.303313  , -1.2553644 , -1.1711987 ],\n",
       "         [-1.342598  , -1.2946492 , -1.2104838 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "819ce578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78c5d50",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a70f6af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    inp = tf.keras.Input(shape=(CROP_HEIGHT, CROP_WIDTH, 3))\n",
    "\n",
    "    backbone = tf.keras.applications.MobileNetV3Large(include_top=False, input_shape=(CROP_HEIGHT, CROP_WIDTH, 3))\n",
    "    backbone.trainable = True\n",
    "    \n",
    "    finetune_layer_no = 100\n",
    "    for layer in backbone.layers[:finetune_layer_no]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    flat1 = tf.keras.layers.Flatten(name='flat1')\n",
    "    fc1 = tf.keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc1')\n",
    "    do1 = tf.keras.layers.Dropout(0.5, name='do1')\n",
    "\n",
    "    fc2 = tf.keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc2')\n",
    "    do2 = tf.keras.layers.Dropout(0.5, name='do2')\n",
    "\n",
    "    fc3 = tf.keras.layers.Dense(2, activation='softmax', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='fc3')\n",
    "\n",
    "    o = tf.keras.applications.mobilenet_v3.preprocess_input(inp)\n",
    "    o = backbone(o, training=False)\n",
    "    o = flat1(o)\n",
    "    o = fc1(o)\n",
    "    o = do1(o)\n",
    "\n",
    "    o = fc2(o)\n",
    "    o = do2(o)\n",
    "\n",
    "    o = fc3(o)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=o, name='baseline_1')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e962234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "model = createModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b73a21c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"baseline_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 227, 227, 3)]     0         \n",
      "                                                                 \n",
      " MobilenetV3large (Functiona  (None, 8, 8, 960)        2996352   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flat1 (Flatten)             (None, 61440)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 128)               7864448   \n",
      "                                                                 \n",
      " do1 (Dropout)               (None, 128)               0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 128)               16512     \n",
      "                                                                 \n",
      " do2 (Dropout)               (None, 128)               0         \n",
      "                                                                 \n",
      " fc3 (Dense)                 (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,877,570\n",
      "Trainable params: 10,743,570\n",
      "Non-trainable params: 134,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fcc28d",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ffbbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = 1000\n",
    "EPOCH = 100\n",
    "\n",
    "START_EPOCH = 0\n",
    "END_EPOCH = START_EPOCH + EPOCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cc17f1",
   "metadata": {},
   "source": [
    "#### Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1ab143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(epoch, lr):\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "222f6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logBasePath = \"log/baseline_mobilenet_2\"\n",
    "logPrefix = \"log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1b72905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:10:02.072681: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-08 14:10:02.072712: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-08 14:10:02.078374: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1665] Profiler found 1 GPUs\n",
      "2022-11-08 14:10:02.078798: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/home/ntcadmin/env/trt-11.0/TensorRT-7.1.3.4/lib:\n",
      "2022-11-08 14:10:02.078923: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so'; dlerror: libcupti.so: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/home/ntcadmin/env/trt-11.0/TensorRT-7.1.3.4/lib:\n",
      "2022-11-08 14:10:02.078937: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:135] cuptiGetTimestamp: error 999: \n",
      "2022-11-08 14:10:02.079083: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-08 14:10:02.079093: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 14:10:02.079099: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2022-11-08 14:10:02.079138: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-08 14:10:02.079168: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-08 14:10:02.079174: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 14:10:02.079178: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2022-11-08 14:10:04.471418: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 53s 14ms/step - loss: 0.7037 - accuracy: 0.4768\n",
      "Epoch 1/100\n",
      "   8/1000 [..............................] - ETA: 25s - loss: 10089468.0000 - accuracy: 0.5938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:10:59.434059: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-08 14:10:59.434079: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-08 14:10:59.434191: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 14:10:59.434202: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2022-11-08 14:10:59.434206: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 14:10:59.434211: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  10/1000 [..............................] - ETA: 45s - loss: 8969786.0000 - accuracy: 0.6250 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:10:59.662933: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-08 14:10:59.664070: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-08 14:10:59.664096: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-08 14:10:59.664106: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2022-11-08 14:10:59.725794: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 14:10:59.725828: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-08 14:10:59.725834: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-11-08 14:10:59.741489: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-08 14:10:59.757624: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_2/log_0/plugins/profile/2022_11_08_14_10_59\n",
      "\n",
      "2022-11-08 14:10:59.763796: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_mobilenet_2/log_0/plugins/profile/2022_11_08_14_10_59/ntcadmin-scse.trace.json.gz\n",
      "2022-11-08 14:10:59.825037: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_mobilenet_2/log_0/plugins/profile/2022_11_08_14_10_59\n",
      "\n",
      "2022-11-08 14:10:59.832665: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_mobilenet_2/log_0/plugins/profile/2022_11_08_14_10_59/ntcadmin-scse.memory_profile.json.gz\n",
      "2022-11-08 14:10:59.833946: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_mobilenet_2/log_0/plugins/profile/2022_11_08_14_10_59\n",
      "Dumped tool data for xplane.pb to log/baseline_mobilenet_2/log_0/plugins/profile/2022_11_08_14_10_59/ntcadmin-scse.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_mobilenet_2/log_0/plugins/profile/2022_11_08_14_10_59/ntcadmin-scse.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_mobilenet_2/log_0/plugins/profile/2022_11_08_14_10_59/ntcadmin-scse.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_mobilenet_2/log_0/plugins/profile/2022_11_08_14_10_59/ntcadmin-scse.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_mobilenet_2/log_0/plugins/profile/2022_11_08_14_10_59/ntcadmin-scse.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 436775321600.0000 - accuracy: 0.5468"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:12:08.577001: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1887436800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 74s 70ms/step - loss: 436775321600.0000 - accuracy: 0.5468 - val_loss: 0.6949 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 2/100\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.6677 - accuracy: 0.6216"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:13:18.147309: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1887436800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.6677 - accuracy: 0.6217 - val_loss: 0.6968 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 3/100\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.6681 - accuracy: 0.5711"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:14:27.720714: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1887436800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.6682 - accuracy: 0.5710 - val_loss: 0.6966 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 4/100\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.6781 - accuracy: 0.5923"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:15:37.181305: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1887436800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.6784 - accuracy: 0.5920 - val_loss: 0.7573 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 5/100\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 0.6957 - accuracy: 0.5413"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:16:48.318834: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1887436800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6957 - accuracy: 0.5412 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6517 - accuracy: 0.6205 - val_loss: 0.7128 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6843 - accuracy: 0.5515 - val_loss: 0.7017 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6928 - accuracy: 0.5278 - val_loss: 0.6928 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6754 - accuracy: 0.5907 - val_loss: 0.7083 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6694 - accuracy: 0.5825 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6827 - accuracy: 0.5730 - val_loss: 0.7246 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6951 - accuracy: 0.5290 - val_loss: 0.7075 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 71s 72ms/step - loss: 0.6534 - accuracy: 0.6225 - val_loss: 0.6933 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 71s 72ms/step - loss: 0.6833 - accuracy: 0.5623 - val_loss: 0.7130 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6923 - accuracy: 0.5368 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6758 - accuracy: 0.5817 - val_loss: 0.7440 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6690 - accuracy: 0.5838 - val_loss: 0.7269 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6799 - accuracy: 0.5702 - val_loss: 0.7448 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 71s 72ms/step - loss: 0.6993 - accuracy: 0.5200 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6510 - accuracy: 0.6315 - val_loss: 0.7833 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6875 - accuracy: 0.5458 - val_loss: 0.7500 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6919 - accuracy: 0.5418 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6835 - accuracy: 0.5642 - val_loss: 0.7083 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6645 - accuracy: 0.5945 - val_loss: 0.7733 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6826 - accuracy: 0.5675 - val_loss: 0.7095 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6996 - accuracy: 0.5148 - val_loss: 0.7072 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6505 - accuracy: 0.6227 - val_loss: 0.8603 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6910 - accuracy: 0.5462 - val_loss: 0.7153 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6877 - accuracy: 0.5543 - val_loss: 0.6955 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6827 - accuracy: 0.5590 - val_loss: 0.7290 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6675 - accuracy: 0.5882 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6789 - accuracy: 0.5725 - val_loss: 0.6982 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6975 - accuracy: 0.5257 - val_loss: 0.7266 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6629 - accuracy: 0.6058 - val_loss: 0.8419 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6842 - accuracy: 0.5527 - val_loss: 0.7008 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6837 - accuracy: 0.5715 - val_loss: 0.6952 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6848 - accuracy: 0.5460 - val_loss: 0.7259 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6665 - accuracy: 0.5950 - val_loss: 0.6945 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6788 - accuracy: 0.5738 - val_loss: 0.7319 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6993 - accuracy: 0.5173 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6724 - accuracy: 0.5945 - val_loss: 0.7064 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6714 - accuracy: 0.5717 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6830 - accuracy: 0.5707 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6820 - accuracy: 0.5555 - val_loss: 0.8161 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6702 - accuracy: 0.5885 - val_loss: 0.6938 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6802 - accuracy: 0.5723 - val_loss: 0.7337 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6958 - accuracy: 0.5242 - val_loss: 0.7123 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6772 - accuracy: 0.5798 - val_loss: 0.7026 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6705 - accuracy: 0.5780 - val_loss: 0.7042 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6847 - accuracy: 0.5633 - val_loss: 0.7039 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6869 - accuracy: 0.5405 - val_loss: 0.8195 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6632 - accuracy: 0.6025 - val_loss: 0.6979 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6812 - accuracy: 0.5658 - val_loss: 0.7190 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6931 - accuracy: 0.5312 - val_loss: 0.7604 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6800 - accuracy: 0.5740 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6701 - accuracy: 0.5790 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6827 - accuracy: 0.5725 - val_loss: 0.7025 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6944 - accuracy: 0.5260 - val_loss: 0.7277 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6575 - accuracy: 0.6108 - val_loss: 0.6932 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6829 - accuracy: 0.5663 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6932 - accuracy: 0.5312 - val_loss: 0.7049 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6770 - accuracy: 0.5835 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6681 - accuracy: 0.5838 - val_loss: 0.7012 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6833 - accuracy: 0.5700 - val_loss: 0.6944 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6943 - accuracy: 0.5288 - val_loss: 0.6938 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6550 - accuracy: 0.6173 - val_loss: 0.7012 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6816 - accuracy: 0.5617 - val_loss: 0.7064 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6940 - accuracy: 0.5275 - val_loss: 0.6928 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6784 - accuracy: 0.5825 - val_loss: 0.6989 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6690 - accuracy: 0.5825 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6832 - accuracy: 0.5670 - val_loss: 0.6929 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6954 - accuracy: 0.5257 - val_loss: 0.7027 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6571 - accuracy: 0.6173 - val_loss: 0.6941 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6826 - accuracy: 0.5533 - val_loss: 0.7115 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6932 - accuracy: 0.5307 - val_loss: 0.6941 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6769 - accuracy: 0.5860 - val_loss: 0.7287 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6709 - accuracy: 0.5800 - val_loss: 0.6992 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6751 - accuracy: 0.5788 - val_loss: 0.8374 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.7035 - accuracy: 0.5107 - val_loss: 0.6948 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6545 - accuracy: 0.6242 - val_loss: 0.7151 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6827 - accuracy: 0.5590 - val_loss: 0.7432 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6933 - accuracy: 0.5365 - val_loss: 0.6926 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 71s 72ms/step - loss: 0.6780 - accuracy: 0.5753 - val_loss: 0.7507 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6687 - accuracy: 0.5880 - val_loss: 0.7639 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6839 - accuracy: 0.5595 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6967 - accuracy: 0.5305 - val_loss: 0.6996 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6488 - accuracy: 0.6275 - val_loss: 0.8246 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6899 - accuracy: 0.5493 - val_loss: 0.7369 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6902 - accuracy: 0.5443 - val_loss: 0.6933 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6818 - accuracy: 0.5633 - val_loss: 0.7259 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6674 - accuracy: 0.5855 - val_loss: 0.7137 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6795 - accuracy: 0.5723 - val_loss: 0.7033 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6969 - accuracy: 0.5238 - val_loss: 0.7427 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6572 - accuracy: 0.6122 - val_loss: 0.8743 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6884 - accuracy: 0.5497 - val_loss: 0.7183 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6870 - accuracy: 0.5585 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6840 - accuracy: 0.5515 - val_loss: 0.6957 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6644 - accuracy: 0.5960 - val_loss: 0.6942 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 71s 72ms/step - loss: 0.6816 - accuracy: 0.5680 - val_loss: 0.6930 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6972 - accuracy: 0.5167 - val_loss: 0.6948 - val_accuracy: 0.4768 - lr: 0.0100\n"
     ]
    }
   ],
   "source": [
    "for i, (train, val) in enumerate([folds[0]]):\n",
    "    \n",
    "    model = createModel()\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    metrics = ['accuracy']\n",
    "    \n",
    "    model.compile(optimizer=opt, loss=loss, metrics=metrics)\n",
    "    \n",
    "    tboardCb = tf.keras.callbacks.TensorBoard(log_dir=f\"{logBasePath}/{logPrefix}_{i}\", histogram_freq=1, profile_batch=(2,10))\n",
    "    lrSchedule = tf.keras.callbacks.LearningRateScheduler(schedule)\n",
    "    \n",
    "    cbs = [tboardCb, lrSchedule]\n",
    "    \n",
    "    model.evaluate(val)\n",
    "    model.fit(train, initial_epoch=START_EPOCH, epochs=END_EPOCH, steps_per_epoch=STEPS_PER_EPOCH, callbacks=cbs, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e841a27f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
