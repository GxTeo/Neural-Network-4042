{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f19017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d782ddf",
   "metadata": {},
   "source": [
    "### Check Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03faa827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac4996",
   "metadata": {},
   "source": [
    "### GPU Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1e955b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 15:23:13.262041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-11 15:23:13.270888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-11 15:23:13.271155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2835bd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f935a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be867b6",
   "metadata": {},
   "source": [
    "### Pandas Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92db292",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_column', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0907c",
   "metadata": {},
   "source": [
    "### Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0fd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VAL_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc35c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_WIDTH = 227\n",
    "CROP_HEIGHT = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d40847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldFiles = [\"adience/unprocessed/fold_0_data.txt\",\n",
    "             \"adience/unprocessed/fold_1_data.txt\",\n",
    "             \"adience/unprocessed/fold_2_data.txt\",\n",
    "             \"adience/unprocessed/fold_3_data.txt\",\n",
    "             \"adience/unprocessed/fold_4_data.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f61c7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genderMap = defaultdict(lambda : np.NaN)\n",
    "genderMap['m'] = 0\n",
    "genderMap['f'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d26242",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = ['(0, 2)', '(4, 6)', '(8, 13)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
    "ageMap = defaultdict(lambda : np.NaN)\n",
    "for i,a in enumerate(ages):\n",
    "    ageMap[a] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b1fc3",
   "metadata": {},
   "source": [
    "### Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd634a3",
   "metadata": {},
   "source": [
    "Dataset generation pipeline:\n",
    "Input: \n",
    "- foldFile - Path to fold file. Fold file Describes which images are in the fold and its corresponding labels\n",
    "- imgBaseFolder - Base folder to search image from\n",
    "- imgPrefix - Prefix of image file\n",
    "- genderMap - Map from ['m', 'f', 'u', None], to one hot index\n",
    "- ageMap - Map from age category to one hot index\n",
    "- imgWidth - Resulting image width\n",
    "- imgHeigh - Resulting image height\n",
    "- batchSize - Int or None, batch size\n",
    "- configureDs - Function accepting dataset for performance configurations\n",
    "- preBatch - List of (name, functions) pair that will be mapped before batching. name is used as name parameters for tf graph \n",
    "- postBatch - List of (name, functions) that will be mapped after batching. name is used as name parameters for tf graph\n",
    "\n",
    "The processing functions should have signature function(img, label) -> (img, label)\n",
    "\n",
    "Pipeline\n",
    "\n",
    "Read Fold File -> Preprocess filename and labels (dataframe) -> Convert filename and labels to numpy array -> Convert filename and labels to tf dataset -> Parse images and labels -> Configure Dataset for performance -> Pre-Batching preprocessing -> Batch -> Post-Batching preprocessing -> Output\n",
    "\n",
    "Some preprocessing steps can only be done before and some can only be done after batching, thats why there are seperated pre and post batching list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0795464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, batchSize, configureDs=None, preBatch=[], postBatch=[]):\n",
    "    \n",
    "    def parseImage(filename):\n",
    "        img = tf.io.read_file(filename)\n",
    "        img = tf.image.decode_jpeg(img)\n",
    "        img = tf.image.resize(img, [imgHeight, imgWidth])\n",
    "         \n",
    "        return img\n",
    "    \n",
    "    # Read Fold File\n",
    "    foldData = []\n",
    "    for f in foldFiles:\n",
    "        foldData.append(pd.read_csv(f, sep=\"\\t\"))\n",
    "    foldData = pd.concat(foldData)\n",
    "    \n",
    "    # Form File Name\n",
    "    foldData['filename'] = foldData.apply(lambda r: os.path.join(imgBaseFolder, r['user_id'], f\"{imgPrefix}.{r['face_id']}.{r['original_image']}\"), axis=1)\n",
    "    \n",
    "    # Generate Label One Hot Index\n",
    "    foldData['gender_ind'] = foldData['gender'].map(genderMap)\n",
    "    foldData['age_ind'] = foldData['age'].map(ageMap)\n",
    "    \n",
    "    # Remove dirty data\n",
    "    foldData.dropna(subset=['gender_ind', 'age_ind'], inplace=True)\n",
    "    \n",
    "    # Dataframe to numpy\n",
    "    filenames = foldData['filename'].to_numpy()\n",
    "    \n",
    "    genderIndex = foldData['gender_ind'].to_numpy().astype(int)\n",
    "    ageIndex = foldData['age_ind'].to_numpy().astype(int)\n",
    "    \n",
    "    # Numpy to Dataset\n",
    "    fnDs = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    genderIndDs = tf.data.Dataset.from_tensor_slices(genderIndex)\n",
    "    ageIndDs = tf.data.Dataset.from_tensor_slices(ageIndex)\n",
    "    \n",
    "    # Parse Images\n",
    "    imageDs = fnDs.map(parseImage, num_parallel_calls=tf.data.AUTOTUNE, name=\"parse_image\")\n",
    "    \n",
    "    # Parse Labels\n",
    "    genderLabDs = genderIndDs.map(lambda x: tf.one_hot(x, genderDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"gender_one_hot\")\n",
    "    ageLabDs = ageIndDs.map(lambda x: tf.one_hot(x, ageDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"age_one_hot\")\n",
    "    \n",
    "    # Combine Labels\n",
    "    labelDs = tf.data.Dataset.zip((genderLabDs, ageLabDs), name=\"label_zip\")\n",
    "    labelDs = labelDs.map(lambda g,a: {\"gender\": g, \"age\": a}, num_parallel_calls=tf.data.AUTOTUNE, name='label_dict')\n",
    "    \n",
    "    # Combine Images and Labels into dataset\n",
    "    ds = tf.data.Dataset.zip((imageDs, labelDs))\n",
    "    \n",
    "    # Configure Performance\n",
    "    if(configureDs is not None):\n",
    "        ds = configureDs(ds)\n",
    "    \n",
    "    # Pre Batch Preprocessing\n",
    "    for n,f in preBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    # Batch\n",
    "    if(batchSize is not None):\n",
    "        ds = ds.batch(batchSize, name=\"ds_batch\")\n",
    "    \n",
    "    # Post Batch Preprocessing\n",
    "    for n,f in postBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320ed92",
   "metadata": {},
   "source": [
    "### Preprocessings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "472b7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=100)\n",
    "    ds = ds.repeat()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adf288f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc4fe2f",
   "metadata": {},
   "source": [
    "#### Preprocessing steps according to the reference paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7724a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainPreprocessA(img, lab):\n",
    "        \n",
    "        # img = tf.image.random_crop(img, [CROP_HEIGHT, CROP_WIDTH, 3])\n",
    "        \n",
    "        ud = tf.random.uniform([], dtype=tf.float32)\n",
    "        udCond = tf.less(ud, 0.5)\n",
    "        \n",
    "        img = tf.cond(udCond, lambda: tf.image.flip_up_down(img), lambda: img)\n",
    "        \n",
    "        lr = tf.random.uniform([], dtype=tf.float32)\n",
    "        lrCond = tf.less(lr, 0.5)\n",
    "        \n",
    "        img = tf.cond(lrCond, lambda: tf.image.flip_left_right(img), lambda: img)\n",
    "        \n",
    "        img = tf.image.random_brightness(img, 63/255)\n",
    "        \n",
    "        img = tf.image.random_contrast(img, 0.2, 1.8) \n",
    "        img.set_shape([IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0402726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valPreprocessA(img, lab):\n",
    "        \n",
    "        img = tf.image.crop_to_bounding_box(img,\n",
    "                                            (IMG_HEIGHT-CROP_HEIGHT) // 2,\n",
    "                                            (IMG_WIDTH-CROP_WIDTH) // 2,\n",
    "                                            CROP_HEIGHT,\n",
    "                                            CROP_WIDTH)\n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f32b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageStandardize(img, lab):\n",
    "    \n",
    "    img = tf.image.per_image_standardization(img)\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f134a",
   "metadata": {},
   "source": [
    "#### Label extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "633c4277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractGenderLabel(img, lab):\n",
    "    \n",
    "    lab = lab['gender']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88b8b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAgeLabel(img, lab):\n",
    "    \n",
    "    lab = lab['age']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7778c",
   "metadata": {},
   "source": [
    "### Generate Folds for K-Folds validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4172d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFoldDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, valBatchSize, trainConfigureDs=None, trainPreBatch=[], trainPostBatch=[], valConfigureDs=None, valPreBatch=[], valPostBatch=[]):\n",
    "    '''\n",
    "        Returns list of (train, validation) datasets\n",
    "    '''\n",
    "    \n",
    "    N = len(foldFiles)\n",
    "    \n",
    "    folds = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        trainFiles = foldFiles[:i]\n",
    "        if(i < N-1):\n",
    "            trainFiles.extend(foldFiles[i+1:])\n",
    "            \n",
    "        valFiles = foldFiles[i]\n",
    "        \n",
    "        trainDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, configureDs=trainConfigureDs, preBatch=trainPreBatch, postBatch=trainPostBatch)\n",
    "        valDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, valBatchSize, configureDs=valConfigureDs, preBatch=valPreBatch, postBatch=valPostBatch)\n",
    "        \n",
    "        folds.append((trainDs, valDs))\n",
    "        \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beffce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPreBatch = [(\"train_process_a\", trainPreprocessA),\n",
    "                 (\"train_extract_gender\", extractGenderLabel)]\n",
    "\n",
    "valPreBatch = [(\"val_extract_gender\", extractGenderLabel)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10474d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 15:23:13.528019: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-11 15:23:13.528811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-11 15:23:13.529119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-11 15:23:13.529437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-11 15:23:13.808758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-11 15:23:13.809022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-11 15:23:13.809247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-11 15:23:13.809458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3887 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:2d:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "folds = generateFoldDs(foldFiles, \"adience/faces\", \"coarse_tilt_aligned_face\", genderMap, ageMap, 2, 8, \n",
    "                       IMG_WIDTH, IMG_HEIGHT, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE, \n",
    "                       trainConfigureDs=trainConfigPerformance, trainPreBatch=trainPreBatch, \n",
    "                       valConfigureDs=valConfigPerformance, valPreBatch=valPreBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57d814af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7974f8fe",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b67fe33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in folds[0][0].take(1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8aa8d0d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 256, 256, 3), dtype=float32, numpy=\n",
       "array([[[[-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         ...,\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ]],\n",
       "\n",
       "        [[-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         ...,\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ]],\n",
       "\n",
       "        [[-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         ...,\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         ...,\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ]],\n",
       "\n",
       "        [[-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         ...,\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ]],\n",
       "\n",
       "        [[-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         ...,\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ],\n",
       "         [-18.021072 , -13.178383 , -10.055122 ]]],\n",
       "\n",
       "\n",
       "       [[[ 22.912598 ,  40.568226 , 122.62686  ],\n",
       "         [ 21.310143 ,  37.396057 , 119.144424 ],\n",
       "         [ 20.94616  ,  36.305042 , 117.42368  ],\n",
       "         ...,\n",
       "         [216.55173  , 221.34851  , 228.52701  ],\n",
       "         [222.43317  , 225.04886  , 234.20279  ],\n",
       "         [227.83704  , 231.39273  , 234.99316  ]],\n",
       "\n",
       "        [[ 20.150253 ,  37.805885 , 119.031006 ],\n",
       "         [ 21.365753 ,  36.831123 , 117.7368   ],\n",
       "         [ 21.036896 ,  35.553085 , 115.208496 ],\n",
       "         ...,\n",
       "         [223.3476   , 228.57239  , 236.08813  ],\n",
       "         [222.84724  , 225.46295  , 234.61688  ],\n",
       "         [227.1237   , 230.67941  , 235.48862  ]],\n",
       "\n",
       "        [[ 19.568954 ,  37.224586 , 118.44971  ],\n",
       "         [ 23.990128 ,  39.765766 , 120.050896 ],\n",
       "         [ 22.376617 ,  36.84168  , 114.478584 ],\n",
       "         ...,\n",
       "         [218.97112  , 224.4068   , 232.82635  ],\n",
       "         [231.8452   , 234.4609   , 242.63708  ],\n",
       "         [230.26292  , 233.81863  , 238.90414  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[162.92892  , 121.77243  ,  88.92952  ],\n",
       "         [176.79968  , 135.64319  , 102.80028  ],\n",
       "         [186.5506   , 145.07889  , 112.23597  ],\n",
       "         ...,\n",
       "         [ 87.634674 ,  28.210705 ,  15.436325 ],\n",
       "         [ 86.51159  ,  27.08762  ,  14.313236 ],\n",
       "         [ 90.73529  ,  29.431324 ,  17.59694  ]],\n",
       "\n",
       "        [[124.55977  ,  86.71256  ,  63.13144  ],\n",
       "         [135.08788  ,  97.172806 ,  73.00507  ],\n",
       "         [142.76259  , 102.94502  ,  79.60854  ],\n",
       "         ...,\n",
       "         [ 85.44361  ,  26.019642 ,  13.245258 ],\n",
       "         [ 86.23093  ,  26.806953 ,  14.03257  ],\n",
       "         [ 90.37497  ,  29.07101  ,  17.236622 ]],\n",
       "\n",
       "        [[ 91.52752  ,  56.486195 ,  39.612343 ],\n",
       "         [ 98.37684  ,  63.221054 ,  46.40443  ],\n",
       "         [ 99.52022  ,  63.191433 ,  45.193836 ],\n",
       "         ...,\n",
       "         [ 84.03232  ,  27.42833  ,  13.713951 ],\n",
       "         [ 86.581055 ,  27.157085 ,  14.382702 ],\n",
       "         [ 89.28291  ,  27.978947 ,  16.144562 ]]],\n",
       "\n",
       "\n",
       "       [[[ 24.11976  ,   5.2657533,  29.796602 ],\n",
       "         [ 24.58553  ,   5.7315226,  30.093002 ],\n",
       "         [ 24.431293 ,   5.5772862,  29.981108 ],\n",
       "         ...,\n",
       "         [ 25.669321 ,   5.4603477,  34.521866 ],\n",
       "         [ 25.203552 ,   4.994578 ,  34.056095 ],\n",
       "         [ 24.838924 ,   4.762686 ,  33.691467 ]],\n",
       "\n",
       "        [[ 24.433279 ,   5.579271 ,  29.92363  ],\n",
       "         [ 24.289131 ,   5.435124 ,  29.796602 ],\n",
       "         [ 24.289131 ,   5.435124 ,  30.431744 ],\n",
       "         ...,\n",
       "         [ 25.730768 ,   5.8605356,  33.905827 ],\n",
       "         [ 25.300312 ,   5.0913377,  34.152855 ],\n",
       "         [ 24.787155 ,   4.603404 ,  33.639698 ]],\n",
       "\n",
       "        [[ 23.809551 ,   4.9555435,  29.842253 ],\n",
       "         [ 23.659698 ,   4.80569  ,  29.802309 ],\n",
       "         [ 23.944683 ,   5.0906763,  30.093002 ],\n",
       "         ...,\n",
       "         [ 26.451916 ,   6.5816846,  34.62127  ],\n",
       "         [ 25.647406 ,   5.7771735,  33.822464 ],\n",
       "         [ 24.377125 ,   4.506893 ,  32.552185 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 71.822845 ,  24.302843 , 107.22426  ],\n",
       "         [ 73.889206 ,  24.596512 , 109.53326  ],\n",
       "         [ 69.998474 ,  20.827103 , 105.65394  ],\n",
       "         ...,\n",
       "         [ 23.699642 ,   5.184376 ,  39.665756 ],\n",
       "         [ 23.611649 ,   5.096382 ,  39.577763 ],\n",
       "         [ 22.84948  ,   4.461242 ,  38.815594 ]],\n",
       "\n",
       "        [[ 61.399845 ,  14.121824 ,  97.4818   ],\n",
       "         [ 64.07901  ,  15.309983 , 100.18619  ],\n",
       "         [ 70.2632   ,  22.532555 , 106.93794  ],\n",
       "         ...,\n",
       "         [ 23.31525  ,   4.7999835,  39.281364 ],\n",
       "         [ 23.613632 ,   5.098367 ,  39.579746 ],\n",
       "         [ 23.653992 ,   5.1387253,  39.620106 ]],\n",
       "\n",
       "        [[ 63.334793 ,  16.185783 ,  99.70504  ],\n",
       "         [ 67.01688  ,  19.031096 , 103.64622  ],\n",
       "         [ 68.865234 ,  21.76865  , 105.875656 ],\n",
       "         ...,\n",
       "         [ 22.987259 ,   4.6299515,  38.763824 ],\n",
       "         [ 23.102875 ,   4.5876083,  39.06899  ],\n",
       "         [ 23.103537 ,   4.58827  ,  39.322384 ]]],\n",
       "\n",
       "\n",
       "       [[[ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         ...,\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ]],\n",
       "\n",
       "        [[ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         ...,\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ]],\n",
       "\n",
       "        [[ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         ...,\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         ...,\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ]],\n",
       "\n",
       "        [[ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         ...,\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ]],\n",
       "\n",
       "        [[ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         ...,\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ],\n",
       "         [ 30.289162 ,  25.34829  ,  21.563553 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d84b1683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e25507c",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ee495a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(trainSet, steps=700):\n",
    "    inp = tf.keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "    scale1 = tf.keras.layers.Rescaling(1.0/255.0, name='pre_rescale')\n",
    "    tempNorm = tf.keras.layers.Normalization(axis=3, name='temp_norm')\n",
    "    tempNorm.adapt(trainSet.map(lambda x,y: x), steps=steps)\n",
    "    \n",
    "    norm1 = tf.keras.layers.Normalization(axis=3, mean=tempNorm.variables[0]/(255.0), variance=tempNorm.variables[1]/(255.0**2), name='pre_norm')\n",
    "    \n",
    "    conv1 = tf.keras.layers.Conv2D(96, 7, strides=(4,4), activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='conv1')\n",
    "    pool1 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, name='pool1')\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv2D(256, 5, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='conv2')\n",
    "    pool2 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, name='pool2')\n",
    "\n",
    "    conv3 = tf.keras.layers.Conv2D(384, 3, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='conv3')\n",
    "    pool3 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, name='pool3')\n",
    "\n",
    "    flat1 = tf.keras.layers.Flatten(name='flat1')\n",
    "    fc1 = tf.keras.layers.Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc1')\n",
    "    do1 = tf.keras.layers.Dropout(0.5, name='do1')\n",
    "\n",
    "    fc2 = tf.keras.layers.Dense(256, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc2')\n",
    "    do2 = tf.keras.layers.Dropout(0.5, name='do2')\n",
    "\n",
    "    fc3 = tf.keras.layers.Dense(2, activation='softmax', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='fc3')\n",
    "\n",
    "    o = scale1(inp)\n",
    "    o = norm1(o)\n",
    "    o = conv1(o)\n",
    "    o = pool1(o)\n",
    "    o = tf.nn.local_response_normalization(o, depth_radius=5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    o = tf.pad(o, [[0, 0], [2, 2], [2, 2], [0, 0]])\n",
    "    o = conv2(o)\n",
    "    o = pool2(o)\n",
    "    o = tf.nn.local_response_normalization(o, depth_radius=5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    o = tf.pad(o, [[0, 0], [1, 1], [1, 1], [0, 0]])\n",
    "    o = conv3(o)\n",
    "    o = pool3(o)\n",
    "    o = tf.nn.local_response_normalization(o, depth_radius=5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    o = flat1(o)\n",
    "    o = fc1(o)\n",
    "    o = do1(o)\n",
    "\n",
    "\n",
    "    o = fc2(o)\n",
    "    o = do2(o)\n",
    "\n",
    "    o = fc3(o)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=o, name='cnn_12')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e962234",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel(folds[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b73a21c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " pre_rescale (Rescaling)     (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " pre_norm (Normalization)    (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 63, 63, 96)        14208     \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 31, 31, 96)        0         \n",
      "                                                                 \n",
      " tf.nn.local_response_normal  (None, 31, 31, 96)       0         \n",
      " ization (TFOpLambda)                                            \n",
      "                                                                 \n",
      " tf.compat.v1.pad (TFOpLambd  (None, 35, 35, 96)       0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 31, 31, 256)       614656    \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 15, 15, 256)       0         \n",
      "                                                                 \n",
      " tf.nn.local_response_normal  (None, 15, 15, 256)      0         \n",
      " ization_1 (TFOpLambda)                                          \n",
      "                                                                 \n",
      " tf.compat.v1.pad_1 (TFOpLam  (None, 17, 17, 256)      0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 15, 15, 384)       885120    \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 7, 7, 384)         0         \n",
      "                                                                 \n",
      " tf.nn.local_response_normal  (None, 7, 7, 384)        0         \n",
      " ization_2 (TFOpLambda)                                          \n",
      "                                                                 \n",
      " flat1 (Flatten)             (None, 18816)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 512)               9634304   \n",
      "                                                                 \n",
      " do1 (Dropout)               (None, 512)               0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 256)               131328    \n",
      "                                                                 \n",
      " do2 (Dropout)               (None, 256)               0         \n",
      "                                                                 \n",
      " fc3 (Dense)                 (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,280,130\n",
      "Trainable params: 11,280,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea1227d",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c5f7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = 1000\n",
    "\n",
    "EPOCH = 300\n",
    "\n",
    "START_EPOCH = 0\n",
    "END_EPOCH = START_EPOCH + EPOCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96be5cb2",
   "metadata": {},
   "source": [
    "#### Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55ee49a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(epoch, lr):\n",
    "    if(epoch == 10000*50//STEPS_PER_EPOCH):\n",
    "        return lr * 0.1\n",
    "    else:\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f41e8947",
   "metadata": {},
   "outputs": [],
   "source": [
    "logBasePath = \"log/CNN_12\"\n",
    "logPrefix = \"log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75efb222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 15:23:24.887017: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-11 15:23:24.887037: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-11 15:23:24.887055: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1665] Profiler found 1 GPUs\n",
      "2022-11-11 15:23:25.001520: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-11 15:23:25.002818: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-11-11 15:23:25.538253: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  54/3528 [..............................] - ETA: 10s - loss: 0.6784 - accuracy: 0.6111  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 15:23:26.275300: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 11s 3ms/step - loss: 0.7002 - accuracy: 0.4768\n",
      "Epoch 1/300\n",
      "   1/1000 [..............................] - ETA: 7:51 - loss: 0.5915 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 15:23:36.269470: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-11 15:23:36.269488: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  20/1000 [..............................] - ETA: 30s - loss: 0.6851 - accuracy: 0.6750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 15:23:36.694097: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-11 15:23:36.694729: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-11-11 15:23:36.720327: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 1671 callback api events and 1646 activity events. \n",
      "2022-11-11 15:23:36.737058: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-11 15:23:36.753370: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/CNN_12/log_0/plugins/profile/2022_11_11_15_23_36\n",
      "\n",
      "2022-11-11 15:23:36.781056: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/CNN_12/log_0/plugins/profile/2022_11_11_15_23_36/rachanon-pc1.trace.json.gz\n",
      "2022-11-11 15:23:36.806548: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/CNN_12/log_0/plugins/profile/2022_11_11_15_23_36\n",
      "\n",
      "2022-11-11 15:23:36.811053: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/CNN_12/log_0/plugins/profile/2022_11_11_15_23_36/rachanon-pc1.memory_profile.json.gz\n",
      "2022-11-11 15:23:36.811508: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/CNN_12/log_0/plugins/profile/2022_11_11_15_23_36\n",
      "Dumped tool data for xplane.pb to log/CNN_12/log_0/plugins/profile/2022_11_11_15_23_36/rachanon-pc1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/CNN_12/log_0/plugins/profile/2022_11_11_15_23_36/rachanon-pc1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/CNN_12/log_0/plugins/profile/2022_11_11_15_23_36/rachanon-pc1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/CNN_12/log_0/plugins/profile/2022_11_11_15_23_36/rachanon-pc1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/CNN_12/log_0/plugins/profile/2022_11_11_15_23_36/rachanon-pc1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 996/1000 [============================>.] - ETA: 0s - loss: 0.6896 - accuracy: 0.5733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 15:23:50.986598: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 16s 15ms/step - loss: 0.6897 - accuracy: 0.5725 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 2/300\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 0.6680 - accuracy: 0.5906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 15:24:05.477084: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6681 - accuracy: 0.5905 - val_loss: 0.6929 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 3/300\n",
      " 996/1000 [============================>.] - ETA: 0s - loss: 0.6692 - accuracy: 0.5695"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 15:24:20.108536: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6693 - accuracy: 0.5688 - val_loss: 0.6936 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 4/300\n",
      " 995/1000 [============================>.] - ETA: 0s - loss: 0.6849 - accuracy: 0.5472"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 15:24:34.850064: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6849 - accuracy: 0.5470 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 5/300\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.6944 - accuracy: 0.4977"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 15:24:49.580404: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6944 - accuracy: 0.4980 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6689 - accuracy: 0.5910 - val_loss: 0.6938 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6873 - accuracy: 0.5465 - val_loss: 0.7016 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6940 - accuracy: 0.5095 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6788 - accuracy: 0.5495 - val_loss: 0.6980 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6732 - accuracy: 0.5785 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6875 - accuracy: 0.5472 - val_loss: 0.7000 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6961 - accuracy: 0.4897 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6703 - accuracy: 0.5920 - val_loss: 0.7111 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6903 - accuracy: 0.5380 - val_loss: 0.7051 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6942 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6888 - accuracy: 0.5340 - val_loss: 0.6968 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6763 - accuracy: 0.5735 - val_loss: 0.6953 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6837 - accuracy: 0.5385 - val_loss: 0.6980 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6967 - accuracy: 0.4893 - val_loss: 0.6964 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6644 - accuracy: 0.5940 - val_loss: 0.7520 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6931 - accuracy: 0.5293 - val_loss: 0.7073 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6963 - accuracy: 0.4983 - val_loss: 0.6927 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6887 - accuracy: 0.5170 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6719 - accuracy: 0.5882 - val_loss: 0.7407 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6840 - accuracy: 0.5560 - val_loss: 0.6955 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6981 - accuracy: 0.4832 - val_loss: 0.6991 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6648 - accuracy: 0.5962 - val_loss: 0.7426 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6971 - accuracy: 0.5272 - val_loss: 0.6949 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6932 - accuracy: 0.5048 - val_loss: 0.6935 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6941 - accuracy: 0.5080 - val_loss: 0.6954 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6785 - accuracy: 0.5835 - val_loss: 0.6928 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6900 - accuracy: 0.5250 - val_loss: 0.6933 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6962 - accuracy: 0.4875 - val_loss: 0.6993 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6806 - accuracy: 0.5663 - val_loss: 0.7240 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6918 - accuracy: 0.5328 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6897 - accuracy: 0.5268 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 37/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6879 - accuracy: 0.5295 - val_loss: 0.7264 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 38/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6740 - accuracy: 0.5773 - val_loss: 0.6963 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 39/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6906 - accuracy: 0.5272 - val_loss: 0.6974 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 40/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6969 - accuracy: 0.4827 - val_loss: 0.6925 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 41/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6847 - accuracy: 0.5608 - val_loss: 0.6928 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 42/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6757 - accuracy: 0.5585 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 43/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6908 - accuracy: 0.5220 - val_loss: 0.6935 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 44/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6888 - accuracy: 0.5173 - val_loss: 0.7550 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 45/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6806 - accuracy: 0.5753 - val_loss: 0.6934 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 46/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6888 - accuracy: 0.5360 - val_loss: 0.6979 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 47/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6971 - accuracy: 0.4840 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 48/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6908 - accuracy: 0.5400 - val_loss: 0.6938 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 49/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6819 - accuracy: 0.5558 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 50/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6901 - accuracy: 0.5322 - val_loss: 0.6984 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 51/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6925 - accuracy: 0.5033 - val_loss: 0.7392 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 52/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6764 - accuracy: 0.5790 - val_loss: 0.7023 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 53/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6889 - accuracy: 0.5353 - val_loss: 0.7180 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 54/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6948 - accuracy: 0.5040 - val_loss: 0.7072 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 55/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6915 - accuracy: 0.5240 - val_loss: 0.6931 - val_accuracy: 0.5232 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6695 - accuracy: 0.5788 - val_loss: 0.6919 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 57/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6879 - accuracy: 0.5403 - val_loss: 0.6937 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 58/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6929 - accuracy: 0.5138 - val_loss: 0.6933 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 59/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6601 - accuracy: 0.6162 - val_loss: 0.7004 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 60/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6801 - accuracy: 0.5790 - val_loss: 0.6870 - val_accuracy: 0.5587 - lr: 0.0010\n",
      "Epoch 61/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6763 - accuracy: 0.5725 - val_loss: 0.7578 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 62/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6697 - accuracy: 0.5853 - val_loss: 0.6909 - val_accuracy: 0.5222 - lr: 0.0010\n",
      "Epoch 63/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6576 - accuracy: 0.5997 - val_loss: 0.7029 - val_accuracy: 0.4737 - lr: 0.0010\n",
      "Epoch 64/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6680 - accuracy: 0.6043 - val_loss: 0.7205 - val_accuracy: 0.5037 - lr: 0.0010\n",
      "Epoch 65/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6759 - accuracy: 0.5740 - val_loss: 0.6905 - val_accuracy: 0.5226 - lr: 0.0010\n",
      "Epoch 66/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6406 - accuracy: 0.6340 - val_loss: 0.6761 - val_accuracy: 0.5727 - lr: 0.0010\n",
      "Epoch 67/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6693 - accuracy: 0.5953 - val_loss: 0.6845 - val_accuracy: 0.5562 - lr: 0.0010\n",
      "Epoch 68/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6845 - accuracy: 0.5595 - val_loss: 0.6762 - val_accuracy: 0.5774 - lr: 0.0010\n",
      "Epoch 69/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6403 - accuracy: 0.6472 - val_loss: 0.6834 - val_accuracy: 0.5251 - lr: 0.0010\n",
      "Epoch 70/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6373 - accuracy: 0.6280 - val_loss: 0.7010 - val_accuracy: 0.4593 - lr: 0.0010\n",
      "Epoch 71/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6585 - accuracy: 0.6137 - val_loss: 0.6956 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 72/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6616 - accuracy: 0.5965 - val_loss: 0.6909 - val_accuracy: 0.5341 - lr: 0.0010\n",
      "Epoch 73/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6144 - accuracy: 0.6620 - val_loss: 0.6547 - val_accuracy: 0.6074 - lr: 0.0010\n",
      "Epoch 74/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6305 - accuracy: 0.6370 - val_loss: 0.6353 - val_accuracy: 0.6345 - lr: 0.0010\n",
      "Epoch 75/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6382 - accuracy: 0.6302 - val_loss: 0.6204 - val_accuracy: 0.6406 - lr: 0.0010\n",
      "Epoch 76/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5956 - accuracy: 0.6895 - val_loss: 0.6431 - val_accuracy: 0.5740 - lr: 0.0010\n",
      "Epoch 77/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5871 - accuracy: 0.6785 - val_loss: 0.6255 - val_accuracy: 0.6321 - lr: 0.0010\n",
      "Epoch 78/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6030 - accuracy: 0.6770 - val_loss: 0.6638 - val_accuracy: 0.6277 - lr: 0.0010\n",
      "Epoch 79/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5712 - accuracy: 0.7078 - val_loss: 0.7177 - val_accuracy: 0.5486 - lr: 0.0010\n",
      "Epoch 80/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5596 - accuracy: 0.7155 - val_loss: 0.5902 - val_accuracy: 0.6860 - lr: 0.0010\n",
      "Epoch 81/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5713 - accuracy: 0.6950 - val_loss: 0.6809 - val_accuracy: 0.6501 - lr: 0.0010\n",
      "Epoch 82/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5481 - accuracy: 0.7197 - val_loss: 0.5460 - val_accuracy: 0.7214 - lr: 0.0010\n",
      "Epoch 83/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5100 - accuracy: 0.7485 - val_loss: 0.9680 - val_accuracy: 0.6096 - lr: 0.0010\n",
      "Epoch 84/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5384 - accuracy: 0.7232 - val_loss: 0.5753 - val_accuracy: 0.7226 - lr: 0.0010\n",
      "Epoch 85/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5094 - accuracy: 0.7452 - val_loss: 0.6257 - val_accuracy: 0.6513 - lr: 0.0010\n",
      "Epoch 86/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4684 - accuracy: 0.7810 - val_loss: 0.4964 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 87/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5006 - accuracy: 0.7460 - val_loss: 0.5451 - val_accuracy: 0.7251 - lr: 0.0010\n",
      "Epoch 88/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5088 - accuracy: 0.7517 - val_loss: 0.5403 - val_accuracy: 0.7224 - lr: 0.0010\n",
      "Epoch 89/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4586 - accuracy: 0.7900 - val_loss: 0.5151 - val_accuracy: 0.7485 - lr: 0.0010\n",
      "Epoch 90/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4452 - accuracy: 0.7977 - val_loss: 0.4865 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 91/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4812 - accuracy: 0.7602 - val_loss: 0.5731 - val_accuracy: 0.7182 - lr: 0.0010\n",
      "Epoch 92/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4240 - accuracy: 0.8015 - val_loss: 0.4719 - val_accuracy: 0.7628 - lr: 0.0010\n",
      "Epoch 93/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4125 - accuracy: 0.8127 - val_loss: 0.4922 - val_accuracy: 0.7674 - lr: 0.0010\n",
      "Epoch 94/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4429 - accuracy: 0.7878 - val_loss: 0.4954 - val_accuracy: 0.7683 - lr: 0.0010\n",
      "Epoch 95/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4621 - accuracy: 0.7820 - val_loss: 0.5508 - val_accuracy: 0.7499 - lr: 0.0010\n",
      "Epoch 96/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3823 - accuracy: 0.8270 - val_loss: 0.4456 - val_accuracy: 0.7870 - lr: 0.0010\n",
      "Epoch 97/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3976 - accuracy: 0.8175 - val_loss: 0.7137 - val_accuracy: 0.7120 - lr: 0.0010\n",
      "Epoch 98/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4327 - accuracy: 0.7987 - val_loss: 0.4722 - val_accuracy: 0.7535 - lr: 0.0010\n",
      "Epoch 99/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3821 - accuracy: 0.8285 - val_loss: 0.5304 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 100/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3821 - accuracy: 0.8328 - val_loss: 0.4320 - val_accuracy: 0.7947 - lr: 0.0010\n",
      "Epoch 101/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4063 - accuracy: 0.8115 - val_loss: 0.5637 - val_accuracy: 0.6974 - lr: 0.0010\n",
      "Epoch 102/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4209 - accuracy: 0.8083 - val_loss: 0.4327 - val_accuracy: 0.8124 - lr: 0.0010\n",
      "Epoch 103/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3290 - accuracy: 0.8630 - val_loss: 0.4268 - val_accuracy: 0.8233 - lr: 0.0010\n",
      "Epoch 104/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3563 - accuracy: 0.8468 - val_loss: 0.3982 - val_accuracy: 0.8140 - lr: 0.0010\n",
      "Epoch 105/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3799 - accuracy: 0.8278 - val_loss: 0.4028 - val_accuracy: 0.8265 - lr: 0.0010\n",
      "Epoch 106/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3530 - accuracy: 0.8317 - val_loss: 0.4754 - val_accuracy: 0.8135 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3235 - accuracy: 0.8580 - val_loss: 0.3873 - val_accuracy: 0.8208 - lr: 0.0010\n",
      "Epoch 108/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3567 - accuracy: 0.8415 - val_loss: 0.3991 - val_accuracy: 0.8224 - lr: 0.0010\n",
      "Epoch 109/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3757 - accuracy: 0.8267 - val_loss: 0.3767 - val_accuracy: 0.8343 - lr: 0.0010\n",
      "Epoch 110/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3041 - accuracy: 0.8705 - val_loss: 0.3910 - val_accuracy: 0.8140 - lr: 0.0010\n",
      "Epoch 111/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3217 - accuracy: 0.8658 - val_loss: 0.5231 - val_accuracy: 0.7331 - lr: 0.0010\n",
      "Epoch 112/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3469 - accuracy: 0.8490 - val_loss: 0.3573 - val_accuracy: 0.8430 - lr: 0.0010\n",
      "Epoch 113/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3402 - accuracy: 0.8395 - val_loss: 0.4217 - val_accuracy: 0.8343 - lr: 0.0010\n",
      "Epoch 114/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2931 - accuracy: 0.8805 - val_loss: 0.6322 - val_accuracy: 0.7345 - lr: 0.0010\n",
      "Epoch 115/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3237 - accuracy: 0.8547 - val_loss: 0.4331 - val_accuracy: 0.7992 - lr: 0.0010\n",
      "Epoch 116/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3533 - accuracy: 0.8393 - val_loss: 0.3517 - val_accuracy: 0.8462 - lr: 0.0010\n",
      "Epoch 117/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2661 - accuracy: 0.8932 - val_loss: 0.5376 - val_accuracy: 0.7661 - lr: 0.0010\n",
      "Epoch 118/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2746 - accuracy: 0.8878 - val_loss: 0.7164 - val_accuracy: 0.7030 - lr: 0.0010\n",
      "Epoch 119/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3026 - accuracy: 0.8765 - val_loss: 0.3110 - val_accuracy: 0.8641 - lr: 0.0010\n",
      "Epoch 120/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3189 - accuracy: 0.8577 - val_loss: 0.3648 - val_accuracy: 0.8597 - lr: 0.0010\n",
      "Epoch 121/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2500 - accuracy: 0.8995 - val_loss: 0.3617 - val_accuracy: 0.8625 - lr: 0.0010\n",
      "Epoch 122/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2778 - accuracy: 0.8860 - val_loss: 0.3565 - val_accuracy: 0.8370 - lr: 0.0010\n",
      "Epoch 123/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3404 - accuracy: 0.8547 - val_loss: 0.3450 - val_accuracy: 0.8457 - lr: 0.0010\n",
      "Epoch 124/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2470 - accuracy: 0.8940 - val_loss: 0.3438 - val_accuracy: 0.8510 - lr: 0.0010\n",
      "Epoch 125/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2625 - accuracy: 0.8988 - val_loss: 0.3464 - val_accuracy: 0.8506 - lr: 0.0010\n",
      "Epoch 126/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2810 - accuracy: 0.8830 - val_loss: 0.3181 - val_accuracy: 0.8600 - lr: 0.0010\n",
      "Epoch 127/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3068 - accuracy: 0.8637 - val_loss: 0.2947 - val_accuracy: 0.8701 - lr: 0.0010\n",
      "Epoch 128/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2327 - accuracy: 0.9030 - val_loss: 0.3509 - val_accuracy: 0.8624 - lr: 0.0010\n",
      "Epoch 129/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2516 - accuracy: 0.8945 - val_loss: 0.3390 - val_accuracy: 0.8442 - lr: 0.0010\n",
      "Epoch 130/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3074 - accuracy: 0.8700 - val_loss: 0.3326 - val_accuracy: 0.8499 - lr: 0.0010\n",
      "Epoch 131/300\n",
      "1000/1000 [==============================] - 14s 15ms/step - loss: 0.2384 - accuracy: 0.9003 - val_loss: 0.3766 - val_accuracy: 0.8373 - lr: 0.0010\n",
      "Epoch 132/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2411 - accuracy: 0.9070 - val_loss: 0.3860 - val_accuracy: 0.8164 - lr: 0.0010\n",
      "Epoch 133/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2679 - accuracy: 0.8848 - val_loss: 0.2868 - val_accuracy: 0.8792 - lr: 0.0010\n",
      "Epoch 134/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2960 - accuracy: 0.8760 - val_loss: 0.2684 - val_accuracy: 0.8872 - lr: 0.0010\n",
      "Epoch 135/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2168 - accuracy: 0.9118 - val_loss: 0.2859 - val_accuracy: 0.8774 - lr: 0.0010\n",
      "Epoch 136/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2280 - accuracy: 0.9103 - val_loss: 0.2677 - val_accuracy: 0.8831 - lr: 0.0010\n",
      "Epoch 137/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2803 - accuracy: 0.8835 - val_loss: 0.3549 - val_accuracy: 0.8412 - lr: 0.0010\n",
      "Epoch 138/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2272 - accuracy: 0.9055 - val_loss: 0.2745 - val_accuracy: 0.8817 - lr: 0.0010\n",
      "Epoch 139/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2156 - accuracy: 0.9183 - val_loss: 0.3576 - val_accuracy: 0.8608 - lr: 0.0010\n",
      "Epoch 140/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2517 - accuracy: 0.8982 - val_loss: 0.2763 - val_accuracy: 0.8872 - lr: 0.0010\n",
      "Epoch 141/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2671 - accuracy: 0.8878 - val_loss: 0.2764 - val_accuracy: 0.8770 - lr: 0.0010\n",
      "Epoch 142/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1927 - accuracy: 0.9230 - val_loss: 0.3195 - val_accuracy: 0.8787 - lr: 0.0010\n",
      "Epoch 143/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2066 - accuracy: 0.9140 - val_loss: 0.3410 - val_accuracy: 0.8588 - lr: 0.0010\n",
      "Epoch 144/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2668 - accuracy: 0.8845 - val_loss: 0.2848 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 145/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2073 - accuracy: 0.9120 - val_loss: 0.7001 - val_accuracy: 0.7883 - lr: 0.0010\n",
      "Epoch 146/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2132 - accuracy: 0.9110 - val_loss: 0.2392 - val_accuracy: 0.8986 - lr: 0.0010\n",
      "Epoch 147/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2224 - accuracy: 0.9082 - val_loss: 0.2470 - val_accuracy: 0.8997 - lr: 0.0010\n",
      "Epoch 148/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2516 - accuracy: 0.8942 - val_loss: 0.2953 - val_accuracy: 0.8699 - lr: 0.0010\n",
      "Epoch 149/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1847 - accuracy: 0.9287 - val_loss: 0.2298 - val_accuracy: 0.9043 - lr: 0.0010\n",
      "Epoch 150/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1902 - accuracy: 0.9208 - val_loss: 0.2630 - val_accuracy: 0.8888 - lr: 0.0010\n",
      "Epoch 151/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2521 - accuracy: 0.8945 - val_loss: 0.3015 - val_accuracy: 0.8817 - lr: 0.0010\n",
      "Epoch 152/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1920 - accuracy: 0.9187 - val_loss: 0.3419 - val_accuracy: 0.8751 - lr: 0.0010\n",
      "Epoch 153/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2013 - accuracy: 0.9243 - val_loss: 0.2796 - val_accuracy: 0.8934 - lr: 0.0010\n",
      "Epoch 154/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2201 - accuracy: 0.9150 - val_loss: 0.2315 - val_accuracy: 0.9004 - lr: 0.0010\n",
      "Epoch 155/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2378 - accuracy: 0.9028 - val_loss: 0.6047 - val_accuracy: 0.8291 - lr: 0.0010\n",
      "Epoch 156/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1808 - accuracy: 0.9252 - val_loss: 0.3472 - val_accuracy: 0.8648 - lr: 0.0010\n",
      "Epoch 157/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1968 - accuracy: 0.9247 - val_loss: 0.2173 - val_accuracy: 0.9094 - lr: 0.0010\n",
      "Epoch 158/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2296 - accuracy: 0.9082 - val_loss: 0.2712 - val_accuracy: 0.8831 - lr: 0.0010\n",
      "Epoch 159/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1967 - accuracy: 0.9233 - val_loss: 0.2799 - val_accuracy: 0.8714 - lr: 0.0010\n",
      "Epoch 160/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1970 - accuracy: 0.9240 - val_loss: 0.2415 - val_accuracy: 0.8994 - lr: 0.0010\n",
      "Epoch 161/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1882 - accuracy: 0.9273 - val_loss: 0.2329 - val_accuracy: 0.9022 - lr: 0.0010\n",
      "Epoch 162/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2171 - accuracy: 0.9105 - val_loss: 0.3028 - val_accuracy: 0.8930 - lr: 0.0010\n",
      "Epoch 163/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1755 - accuracy: 0.9402 - val_loss: 0.2170 - val_accuracy: 0.9121 - lr: 0.0010\n",
      "Epoch 164/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1761 - accuracy: 0.9337 - val_loss: 0.3955 - val_accuracy: 0.8532 - lr: 0.0010\n",
      "Epoch 165/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2130 - accuracy: 0.9158 - val_loss: 0.2294 - val_accuracy: 0.9051 - lr: 0.0010\n",
      "Epoch 166/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1875 - accuracy: 0.9230 - val_loss: 0.2737 - val_accuracy: 0.8993 - lr: 0.0010\n",
      "Epoch 167/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1844 - accuracy: 0.9300 - val_loss: 0.2060 - val_accuracy: 0.9178 - lr: 0.0010\n",
      "Epoch 168/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1791 - accuracy: 0.9305 - val_loss: 0.2846 - val_accuracy: 0.8632 - lr: 0.0010\n",
      "Epoch 169/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2026 - accuracy: 0.9172 - val_loss: 0.2224 - val_accuracy: 0.9147 - lr: 0.0010\n",
      "Epoch 170/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1606 - accuracy: 0.9373 - val_loss: 0.2321 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 171/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1556 - accuracy: 0.9410 - val_loss: 0.2440 - val_accuracy: 0.8979 - lr: 0.0010\n",
      "Epoch 172/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1905 - accuracy: 0.9268 - val_loss: 0.2399 - val_accuracy: 0.8997 - lr: 0.0010\n",
      "Epoch 173/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1808 - accuracy: 0.9255 - val_loss: 0.2189 - val_accuracy: 0.9197 - lr: 0.0010\n",
      "Epoch 174/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1787 - accuracy: 0.9300 - val_loss: 0.1971 - val_accuracy: 0.9210 - lr: 0.0010\n",
      "Epoch 175/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1791 - accuracy: 0.9310 - val_loss: 0.2741 - val_accuracy: 0.8890 - lr: 0.0010\n",
      "Epoch 176/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1940 - accuracy: 0.9247 - val_loss: 0.2235 - val_accuracy: 0.9128 - lr: 0.0010\n",
      "Epoch 177/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1484 - accuracy: 0.9415 - val_loss: 0.2126 - val_accuracy: 0.9129 - lr: 0.0010\n",
      "Epoch 178/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1660 - accuracy: 0.9355 - val_loss: 0.3333 - val_accuracy: 0.8759 - lr: 0.0010\n",
      "Epoch 179/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1738 - accuracy: 0.9345 - val_loss: 0.1772 - val_accuracy: 0.9274 - lr: 0.0010\n",
      "Epoch 180/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1977 - accuracy: 0.9233 - val_loss: 0.1983 - val_accuracy: 0.9243 - lr: 0.0010\n",
      "Epoch 181/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1421 - accuracy: 0.9433 - val_loss: 0.2169 - val_accuracy: 0.9177 - lr: 0.0010\n",
      "Epoch 182/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1591 - accuracy: 0.9405 - val_loss: 0.2304 - val_accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 183/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2056 - accuracy: 0.9158 - val_loss: 0.2762 - val_accuracy: 0.8804 - lr: 0.0010\n",
      "Epoch 184/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1371 - accuracy: 0.9505 - val_loss: 0.2328 - val_accuracy: 0.9113 - lr: 0.0010\n",
      "Epoch 185/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1641 - accuracy: 0.9423 - val_loss: 0.3024 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 186/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1627 - accuracy: 0.9398 - val_loss: 0.2297 - val_accuracy: 0.9101 - lr: 0.0010\n",
      "Epoch 187/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1776 - accuracy: 0.9258 - val_loss: 0.1889 - val_accuracy: 0.9218 - lr: 0.0010\n",
      "Epoch 188/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1327 - accuracy: 0.9503 - val_loss: 0.1894 - val_accuracy: 0.9300 - lr: 0.0010\n",
      "Epoch 189/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1480 - accuracy: 0.9433 - val_loss: 0.1937 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 190/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1895 - accuracy: 0.9205 - val_loss: 0.2832 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Epoch 191/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1337 - accuracy: 0.9490 - val_loss: 0.1723 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 192/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1409 - accuracy: 0.9470 - val_loss: 0.2234 - val_accuracy: 0.9040 - lr: 0.0010\n",
      "Epoch 193/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1444 - accuracy: 0.9373 - val_loss: 0.2113 - val_accuracy: 0.9196 - lr: 0.0010\n",
      "Epoch 194/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1705 - accuracy: 0.9312 - val_loss: 0.2311 - val_accuracy: 0.8882 - lr: 0.0010\n",
      "Epoch 195/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1413 - accuracy: 0.9452 - val_loss: 0.1666 - val_accuracy: 0.9400 - lr: 0.0010\n",
      "Epoch 196/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1316 - accuracy: 0.9507 - val_loss: 0.1771 - val_accuracy: 0.9228 - lr: 0.0010\n",
      "Epoch 197/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1719 - accuracy: 0.9335 - val_loss: 0.1894 - val_accuracy: 0.9247 - lr: 0.0010\n",
      "Epoch 198/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1298 - accuracy: 0.9510 - val_loss: 0.2094 - val_accuracy: 0.9194 - lr: 0.0010\n",
      "Epoch 199/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1204 - accuracy: 0.9515 - val_loss: 0.2170 - val_accuracy: 0.9150 - lr: 0.0010\n",
      "Epoch 200/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1434 - accuracy: 0.9442 - val_loss: 0.1579 - val_accuracy: 0.9386 - lr: 0.0010\n",
      "Epoch 201/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1579 - accuracy: 0.9323 - val_loss: 0.1633 - val_accuracy: 0.9355 - lr: 0.0010\n",
      "Epoch 202/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1167 - accuracy: 0.9590 - val_loss: 0.1436 - val_accuracy: 0.9417 - lr: 0.0010\n",
      "Epoch 203/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1271 - accuracy: 0.9535 - val_loss: 0.2415 - val_accuracy: 0.8986 - lr: 0.0010\n",
      "Epoch 204/300\n",
      "1000/1000 [==============================] - 14s 15ms/step - loss: 0.1680 - accuracy: 0.9377 - val_loss: 0.1569 - val_accuracy: 0.9354 - lr: 0.0010\n",
      "Epoch 205/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1239 - accuracy: 0.9542 - val_loss: 0.2330 - val_accuracy: 0.9145 - lr: 0.0010\n",
      "Epoch 206/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1299 - accuracy: 0.9532 - val_loss: 0.2101 - val_accuracy: 0.9096 - lr: 0.0010\n",
      "Epoch 207/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1453 - accuracy: 0.9448 - val_loss: 0.1598 - val_accuracy: 0.9352 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1521 - accuracy: 0.9433 - val_loss: 0.1731 - val_accuracy: 0.9361 - lr: 0.0010\n",
      "Epoch 209/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1209 - accuracy: 0.9557 - val_loss: 0.1639 - val_accuracy: 0.9349 - lr: 0.0010\n",
      "Epoch 210/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1268 - accuracy: 0.9532 - val_loss: 0.1751 - val_accuracy: 0.9273 - lr: 0.0010\n",
      "Epoch 211/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1560 - accuracy: 0.9345 - val_loss: 0.1594 - val_accuracy: 0.9342 - lr: 0.0010\n",
      "Epoch 212/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1175 - accuracy: 0.9503 - val_loss: 0.4284 - val_accuracy: 0.8528 - lr: 0.0010\n",
      "Epoch 213/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1365 - accuracy: 0.9457 - val_loss: 0.1835 - val_accuracy: 0.9351 - lr: 0.0010\n",
      "Epoch 214/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1275 - accuracy: 0.9507 - val_loss: 0.1651 - val_accuracy: 0.9280 - lr: 0.0010\n",
      "Epoch 215/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1566 - accuracy: 0.9360 - val_loss: 0.1520 - val_accuracy: 0.9391 - lr: 0.0010\n",
      "Epoch 216/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1023 - accuracy: 0.9605 - val_loss: 0.1628 - val_accuracy: 0.9396 - lr: 0.0010\n",
      "Epoch 217/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1364 - accuracy: 0.9510 - val_loss: 0.1357 - val_accuracy: 0.9470 - lr: 0.0010\n",
      "Epoch 218/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1534 - accuracy: 0.9392 - val_loss: 0.1534 - val_accuracy: 0.9427 - lr: 0.0010\n",
      "Epoch 219/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1154 - accuracy: 0.9563 - val_loss: 0.1901 - val_accuracy: 0.9298 - lr: 0.0010\n",
      "Epoch 220/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1211 - accuracy: 0.9572 - val_loss: 0.1650 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 221/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1404 - accuracy: 0.9482 - val_loss: 0.2055 - val_accuracy: 0.9165 - lr: 0.0010\n",
      "Epoch 222/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1482 - accuracy: 0.9423 - val_loss: 0.3294 - val_accuracy: 0.8820 - lr: 0.0010\n",
      "Epoch 223/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1115 - accuracy: 0.9557 - val_loss: 0.1751 - val_accuracy: 0.9351 - lr: 0.0010\n",
      "Epoch 224/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1206 - accuracy: 0.9520 - val_loss: 0.2998 - val_accuracy: 0.8824 - lr: 0.0010\n",
      "Epoch 225/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1331 - accuracy: 0.9450 - val_loss: 0.1174 - val_accuracy: 0.9522 - lr: 0.0010\n",
      "Epoch 226/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1207 - accuracy: 0.9528 - val_loss: 0.1797 - val_accuracy: 0.9283 - lr: 0.0010\n",
      "Epoch 227/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1056 - accuracy: 0.9590 - val_loss: 0.1250 - val_accuracy: 0.9539 - lr: 0.0010\n",
      "Epoch 228/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1165 - accuracy: 0.9550 - val_loss: 0.1783 - val_accuracy: 0.9333 - lr: 0.0010\n",
      "Epoch 229/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1400 - accuracy: 0.9415 - val_loss: 0.1635 - val_accuracy: 0.9299 - lr: 0.0010\n",
      "Epoch 230/300\n",
      "1000/1000 [==============================] - 14s 15ms/step - loss: 0.1032 - accuracy: 0.9643 - val_loss: 0.1213 - val_accuracy: 0.9522 - lr: 0.0010\n",
      "Epoch 231/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0989 - accuracy: 0.9650 - val_loss: 0.1326 - val_accuracy: 0.9476 - lr: 0.0010\n",
      "Epoch 232/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1241 - accuracy: 0.9528 - val_loss: 0.1307 - val_accuracy: 0.9541 - lr: 0.0010\n",
      "Epoch 233/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1135 - accuracy: 0.9575 - val_loss: 0.1513 - val_accuracy: 0.9377 - lr: 0.0010\n",
      "Epoch 234/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1139 - accuracy: 0.9572 - val_loss: 0.1272 - val_accuracy: 0.9508 - lr: 0.0010\n",
      "Epoch 235/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1239 - accuracy: 0.9503 - val_loss: 0.1546 - val_accuracy: 0.9411 - lr: 0.0010\n",
      "Epoch 236/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1235 - accuracy: 0.9517 - val_loss: 0.1396 - val_accuracy: 0.9486 - lr: 0.0010\n",
      "Epoch 237/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1076 - accuracy: 0.9588 - val_loss: 0.1211 - val_accuracy: 0.9515 - lr: 0.0010\n",
      "Epoch 238/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1150 - accuracy: 0.9535 - val_loss: 0.2469 - val_accuracy: 0.9183 - lr: 0.0010\n",
      "Epoch 239/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1320 - accuracy: 0.9505 - val_loss: 0.1312 - val_accuracy: 0.9417 - lr: 0.0010\n",
      "Epoch 240/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1315 - accuracy: 0.9463 - val_loss: 0.1616 - val_accuracy: 0.9410 - lr: 0.0010\n",
      "Epoch 241/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1158 - accuracy: 0.9567 - val_loss: 0.3213 - val_accuracy: 0.8735 - lr: 0.0010\n",
      "Epoch 242/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1520 - accuracy: 0.9413 - val_loss: 0.1748 - val_accuracy: 0.9240 - lr: 0.0010\n",
      "Epoch 243/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1298 - accuracy: 0.9482 - val_loss: 0.1800 - val_accuracy: 0.9349 - lr: 0.0010\n",
      "Epoch 244/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1129 - accuracy: 0.9532 - val_loss: 0.2019 - val_accuracy: 0.9210 - lr: 0.0010\n",
      "Epoch 245/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0971 - accuracy: 0.9643 - val_loss: 0.2134 - val_accuracy: 0.9310 - lr: 0.0010\n",
      "Epoch 246/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1147 - accuracy: 0.9572 - val_loss: 0.1188 - val_accuracy: 0.9559 - lr: 0.0010\n",
      "Epoch 247/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1225 - accuracy: 0.9532 - val_loss: 0.1540 - val_accuracy: 0.9404 - lr: 0.0010\n",
      "Epoch 248/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0978 - accuracy: 0.9638 - val_loss: 0.1324 - val_accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 249/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1118 - accuracy: 0.9610 - val_loss: 0.1358 - val_accuracy: 0.9505 - lr: 0.0010\n",
      "Epoch 250/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1239 - accuracy: 0.9505 - val_loss: 0.1770 - val_accuracy: 0.9369 - lr: 0.0010\n",
      "Epoch 251/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0936 - accuracy: 0.9640 - val_loss: 0.1313 - val_accuracy: 0.9521 - lr: 0.0010\n",
      "Epoch 252/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1008 - accuracy: 0.9615 - val_loss: 0.1346 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 253/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1145 - accuracy: 0.9580 - val_loss: 0.1593 - val_accuracy: 0.9352 - lr: 0.0010\n",
      "Epoch 254/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1206 - accuracy: 0.9517 - val_loss: 0.1294 - val_accuracy: 0.9417 - lr: 0.0010\n",
      "Epoch 255/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1008 - accuracy: 0.9638 - val_loss: 0.1161 - val_accuracy: 0.9558 - lr: 0.0010\n",
      "Epoch 256/300\n",
      "1000/1000 [==============================] - 14s 15ms/step - loss: 0.1016 - accuracy: 0.9615 - val_loss: 0.1240 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 257/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1263 - accuracy: 0.9523 - val_loss: 0.1238 - val_accuracy: 0.9535 - lr: 0.0010\n",
      "Epoch 258/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0928 - accuracy: 0.9640 - val_loss: 0.1851 - val_accuracy: 0.9308 - lr: 0.0010\n",
      "Epoch 259/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0949 - accuracy: 0.9665 - val_loss: 0.1615 - val_accuracy: 0.9370 - lr: 0.0010\n",
      "Epoch 260/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1167 - accuracy: 0.9575 - val_loss: 0.1264 - val_accuracy: 0.9490 - lr: 0.0010\n",
      "Epoch 261/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1084 - accuracy: 0.9588 - val_loss: 0.1290 - val_accuracy: 0.9506 - lr: 0.0010\n",
      "Epoch 262/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0889 - accuracy: 0.9700 - val_loss: 0.1104 - val_accuracy: 0.9551 - lr: 0.0010\n",
      "Epoch 263/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1077 - accuracy: 0.9653 - val_loss: 0.1166 - val_accuracy: 0.9510 - lr: 0.0010\n",
      "Epoch 264/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1071 - accuracy: 0.9570 - val_loss: 0.0985 - val_accuracy: 0.9619 - lr: 0.0010\n",
      "Epoch 265/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0952 - accuracy: 0.9625 - val_loss: 0.1580 - val_accuracy: 0.9318 - lr: 0.0010\n",
      "Epoch 266/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0921 - accuracy: 0.9672 - val_loss: 0.1396 - val_accuracy: 0.9471 - lr: 0.0010\n",
      "Epoch 267/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1114 - accuracy: 0.9588 - val_loss: 0.1793 - val_accuracy: 0.9366 - lr: 0.0010\n",
      "Epoch 268/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1150 - accuracy: 0.9553 - val_loss: 0.2290 - val_accuracy: 0.9150 - lr: 0.0010\n",
      "Epoch 269/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0904 - accuracy: 0.9655 - val_loss: 0.1441 - val_accuracy: 0.9470 - lr: 0.0010\n",
      "Epoch 270/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0895 - accuracy: 0.9675 - val_loss: 0.1261 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 271/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1124 - accuracy: 0.9588 - val_loss: 0.0879 - val_accuracy: 0.9656 - lr: 0.0010\n",
      "Epoch 272/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0807 - accuracy: 0.9695 - val_loss: 0.3205 - val_accuracy: 0.9018 - lr: 0.0010\n",
      "Epoch 273/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1134 - accuracy: 0.9617 - val_loss: 0.1187 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 274/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1104 - accuracy: 0.9567 - val_loss: 0.1084 - val_accuracy: 0.9598 - lr: 0.0010\n",
      "Epoch 275/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1087 - accuracy: 0.9610 - val_loss: 0.1803 - val_accuracy: 0.9260 - lr: 0.0010\n",
      "Epoch 276/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0904 - accuracy: 0.9655 - val_loss: 0.1243 - val_accuracy: 0.9522 - lr: 0.0010\n",
      "Epoch 277/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0806 - accuracy: 0.9718 - val_loss: 0.0948 - val_accuracy: 0.9631 - lr: 0.0010\n",
      "Epoch 278/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1106 - accuracy: 0.9628 - val_loss: 0.1448 - val_accuracy: 0.9452 - lr: 0.0010\n",
      "Epoch 279/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0954 - accuracy: 0.9605 - val_loss: 0.1332 - val_accuracy: 0.9496 - lr: 0.0010\n",
      "Epoch 280/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0791 - accuracy: 0.9718 - val_loss: 0.0999 - val_accuracy: 0.9590 - lr: 0.0010\n",
      "Epoch 281/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0880 - accuracy: 0.9657 - val_loss: 0.0993 - val_accuracy: 0.9604 - lr: 0.0010\n",
      "Epoch 282/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1108 - accuracy: 0.9578 - val_loss: 0.1552 - val_accuracy: 0.9384 - lr: 0.0010\n",
      "Epoch 283/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0735 - accuracy: 0.9720 - val_loss: 0.1140 - val_accuracy: 0.9586 - lr: 0.0010\n",
      "Epoch 284/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0854 - accuracy: 0.9690 - val_loss: 0.1273 - val_accuracy: 0.9439 - lr: 0.0010\n",
      "Epoch 285/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1059 - accuracy: 0.9567 - val_loss: 0.0846 - val_accuracy: 0.9652 - lr: 0.0010\n",
      "Epoch 286/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1029 - accuracy: 0.9620 - val_loss: 0.0882 - val_accuracy: 0.9659 - lr: 0.0010\n",
      "Epoch 287/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0929 - accuracy: 0.9635 - val_loss: 0.1429 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 288/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1128 - accuracy: 0.9595 - val_loss: 0.0990 - val_accuracy: 0.9597 - lr: 0.0010\n",
      "Epoch 289/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0994 - accuracy: 0.9643 - val_loss: 0.1099 - val_accuracy: 0.9552 - lr: 0.0010\n",
      "Epoch 290/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0719 - accuracy: 0.9728 - val_loss: 0.1140 - val_accuracy: 0.9586 - lr: 0.0010\n",
      "Epoch 291/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0856 - accuracy: 0.9665 - val_loss: 0.1933 - val_accuracy: 0.9298 - lr: 0.0010\n",
      "Epoch 292/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1030 - accuracy: 0.9607 - val_loss: 0.0726 - val_accuracy: 0.9724 - lr: 0.0010\n",
      "Epoch 293/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0832 - accuracy: 0.9630 - val_loss: 0.0922 - val_accuracy: 0.9683 - lr: 0.0010\n",
      "Epoch 294/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0860 - accuracy: 0.9712 - val_loss: 0.1018 - val_accuracy: 0.9614 - lr: 0.0010\n",
      "Epoch 295/300\n",
      "1000/1000 [==============================] - 14s 15ms/step - loss: 0.1019 - accuracy: 0.9632 - val_loss: 0.1832 - val_accuracy: 0.9330 - lr: 0.0010\n",
      "Epoch 296/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0950 - accuracy: 0.9640 - val_loss: 0.0938 - val_accuracy: 0.9648 - lr: 0.0010\n",
      "Epoch 297/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0781 - accuracy: 0.9710 - val_loss: 0.1274 - val_accuracy: 0.9568 - lr: 0.0010\n",
      "Epoch 298/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1090 - accuracy: 0.9592 - val_loss: 0.0849 - val_accuracy: 0.9704 - lr: 0.0010\n",
      "Epoch 299/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0923 - accuracy: 0.9628 - val_loss: 0.1615 - val_accuracy: 0.9334 - lr: 0.0010\n",
      "Epoch 300/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0978 - accuracy: 0.9640 - val_loss: 0.0999 - val_accuracy: 0.9610 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "for i, (train, val) in enumerate([folds[0]]):\n",
    "    \n",
    "    model = createModel(train)\n",
    "    \n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    metrics = ['accuracy']\n",
    "    \n",
    "    model.compile(optimizer=opt, loss=loss, metrics=metrics)\n",
    "    \n",
    "    tboardCb = tf.keras.callbacks.TensorBoard(log_dir=f\"{logBasePath}/{logPrefix}_{i}\", histogram_freq=1, profile_batch=(2,10))\n",
    "    lrSchedule = tf.keras.callbacks.LearningRateScheduler(schedule)\n",
    "    \n",
    "    cbs = [tboardCb, lrSchedule]\n",
    "    \n",
    "    model.evaluate(val)\n",
    "    model.fit(train, initial_epoch=START_EPOCH, epochs=END_EPOCH, steps_per_epoch=STEPS_PER_EPOCH, callbacks=cbs, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae70be7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
