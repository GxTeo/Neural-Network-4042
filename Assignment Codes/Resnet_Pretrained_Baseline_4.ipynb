{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f19017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d782ddf",
   "metadata": {},
   "source": [
    "### Check Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03faa827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac4996",
   "metadata": {},
   "source": [
    "### GPU Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1e955b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 00:40:24.721595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-30 00:40:24.728370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-30 00:40:24.728873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2835bd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f935a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be867b6",
   "metadata": {},
   "source": [
    "### Pandas Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92db292",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_column', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0907c",
   "metadata": {},
   "source": [
    "### Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0fd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VAL_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf19fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_WIDTH = 227\n",
    "CROP_HEIGHT = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d40847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldFiles = [\"adience/unprocessed/fold_0_data.txt\",\n",
    "             \"adience/unprocessed/fold_1_data.txt\",\n",
    "             \"adience/unprocessed/fold_2_data.txt\",\n",
    "             \"adience/unprocessed/fold_3_data.txt\",\n",
    "             \"adience/unprocessed/fold_4_data.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f61c7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genderMap = defaultdict(lambda : np.NaN)\n",
    "genderMap['m'] = 0\n",
    "genderMap['f'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d26242",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = ['(0, 2)', '(4, 6)', '(8, 13)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
    "ageMap = defaultdict(lambda : np.NaN)\n",
    "for i,a in enumerate(ages):\n",
    "    ageMap[a] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b1fc3",
   "metadata": {},
   "source": [
    "### Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd634a3",
   "metadata": {},
   "source": [
    "Dataset generation pipeline:\n",
    "Input: \n",
    "- foldFile - Path to fold file. Fold file Describes which images are in the fold and its corresponding labels\n",
    "- imgBaseFolder - Base folder to search image from\n",
    "- imgPrefix - Prefix of image file\n",
    "- genderMap - Map from ['m', 'f', 'u', None], to one hot index\n",
    "- ageMap - Map from age category to one hot index\n",
    "- imgWidth - Resulting image width\n",
    "- imgHeigh - Resulting image height\n",
    "- batchSize - Int or None, batch size\n",
    "- configureDs - Function accepting dataset for performance configurations\n",
    "- preBatch - List of (name, functions) pair that will be mapped before batching. name is used as name parameters for tf graph \n",
    "- postBatch - List of (name, functions) that will be mapped after batching. name is used as name parameters for tf graph\n",
    "\n",
    "The processing functions should have signature function(img, label) -> (img, label)\n",
    "\n",
    "Pipeline\n",
    "\n",
    "Read Fold File -> Preprocess filename and labels (dataframe) -> Convert filename and labels to numpy array -> Convert filename and labels to tf dataset -> Parse images and labels -> Configure Dataset for performance -> Pre-Batching preprocessing -> Batch -> Post-Batching preprocessing -> Output\n",
    "\n",
    "Some preprocessing steps can only be done before and some can only be done after batching, thats why there are seperated pre and post batching list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0795464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, batchSize, configureDs=None, preBatch=[], postBatch=[]):\n",
    "    \n",
    "    def parseImage(filename):\n",
    "        img = tf.io.read_file(filename)\n",
    "        img = tf.image.decode_jpeg(img)\n",
    "        img = tf.image.resize(img, [imgHeight, imgWidth])\n",
    "         \n",
    "        return img\n",
    "    \n",
    "    # Read Fold File\n",
    "    foldData = []\n",
    "    for f in foldFiles:\n",
    "        foldData.append(pd.read_csv(f, sep=\"\\t\"))\n",
    "    foldData = pd.concat(foldData)\n",
    "    \n",
    "    # Form File Name\n",
    "    foldData['filename'] = foldData.apply(lambda r: os.path.join(imgBaseFolder, r['user_id'], f\"{imgPrefix}.{r['face_id']}.{r['original_image']}\"), axis=1)\n",
    "    \n",
    "    # Generate Label One Hot Index\n",
    "    foldData['gender_ind'] = foldData['gender'].map(genderMap)\n",
    "    foldData['age_ind'] = foldData['age'].map(ageMap)\n",
    "    \n",
    "    # Remove dirty data\n",
    "    foldData.dropna(subset=['gender_ind', 'age_ind'], inplace=True)\n",
    "    \n",
    "    # Dataframe to numpy\n",
    "    filenames = foldData['filename'].to_numpy()\n",
    "    \n",
    "    genderIndex = foldData['gender_ind'].to_numpy().astype(int)\n",
    "    ageIndex = foldData['age_ind'].to_numpy().astype(int)\n",
    "    \n",
    "    # Numpy to Dataset\n",
    "    fnDs = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    genderIndDs = tf.data.Dataset.from_tensor_slices(genderIndex)\n",
    "    ageIndDs = tf.data.Dataset.from_tensor_slices(ageIndex)\n",
    "    \n",
    "    # Parse Images\n",
    "    imageDs = fnDs.map(parseImage, num_parallel_calls=tf.data.AUTOTUNE, name=\"parse_image\")\n",
    "    \n",
    "    # Parse Labels\n",
    "    genderLabDs = genderIndDs.map(lambda x: tf.one_hot(x, genderDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"gender_one_hot\")\n",
    "    ageLabDs = ageIndDs.map(lambda x: tf.one_hot(x, ageDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"age_one_hot\")\n",
    "    \n",
    "    # Combine Labels\n",
    "    labelDs = tf.data.Dataset.zip((genderLabDs, ageLabDs), name=\"label_zip\")\n",
    "    labelDs = labelDs.map(lambda g,a: {\"gender\": g, \"age\": a}, num_parallel_calls=tf.data.AUTOTUNE, name='label_dict')\n",
    "    \n",
    "    # Combine Images and Labels into dataset\n",
    "    ds = tf.data.Dataset.zip((imageDs, labelDs))\n",
    "    \n",
    "    # Configure Performance\n",
    "    if(configureDs is not None):\n",
    "        ds = configureDs(ds)\n",
    "    \n",
    "    # Pre Batch Preprocessing\n",
    "    for n,f in preBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    # Batch\n",
    "    if(batchSize is not None):\n",
    "        ds = ds.batch(batchSize, name=\"ds_batch\")\n",
    "    \n",
    "    # Post Batch Preprocessing\n",
    "    for n,f in postBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320ed92",
   "metadata": {},
   "source": [
    "### Preprocessings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "472b7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=100)\n",
    "    ds = ds.repeat()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adb98feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313da7f1",
   "metadata": {},
   "source": [
    "#### Preprocessing steps according to the reference paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7724a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainPreprocessA(img, lab):\n",
    "        \n",
    "        img = tf.image.random_crop(img, [CROP_HEIGHT, CROP_WIDTH, 3])\n",
    "        \n",
    "        ud = tf.random.uniform([], dtype=tf.float32)\n",
    "        udCond = tf.less(ud, 0.5)\n",
    "        \n",
    "        img = tf.cond(udCond, lambda: tf.image.flip_up_down(img), lambda: img)\n",
    "        \n",
    "        lr = tf.random.uniform([], dtype=tf.float32)\n",
    "        lrCond = tf.less(lr, 0.5)\n",
    "        \n",
    "        img = tf.cond(lrCond, lambda: tf.image.flip_left_right(img), lambda: img)\n",
    "        \n",
    "        img = tf.image.random_brightness(img, 63/255)\n",
    "        \n",
    "        img = tf.image.random_contrast(img, 0.2, 1.8)\n",
    "        \n",
    "        img = tf.clip_by_value(img, 0.0, 255.0)\n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14ee59ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valPreprocessA(img, lab):\n",
    "        \n",
    "        img = tf.image.crop_to_bounding_box(img,\n",
    "                                            (IMG_HEIGHT-CROP_HEIGHT) // 2,\n",
    "                                            (IMG_WIDTH-CROP_WIDTH) // 2,\n",
    "                                            CROP_HEIGHT,\n",
    "                                            CROP_WIDTH)\n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ec104",
   "metadata": {},
   "source": [
    "#### Label extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "294a2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractGenderLabel(img, lab):\n",
    "    \n",
    "    lab = lab['gender']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a98897ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAgeLabel(img, lab):\n",
    "    \n",
    "    lab = lab['age']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7778c",
   "metadata": {},
   "source": [
    "### Generate Folds for K-Folds validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4172d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFoldDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, valBatchSize, trainConfigureDs=None, trainPreBatch=[], trainPostBatch=[], valConfigureDs=None, valPreBatch=[], valPostBatch=[]):\n",
    "    '''\n",
    "        Returns list of (train, validation) datasets\n",
    "    '''\n",
    "    \n",
    "    N = len(foldFiles)\n",
    "    \n",
    "    folds = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        trainFiles = foldFiles[:i]\n",
    "        if(i < N-1):\n",
    "            trainFiles.extend(foldFiles[i+1:])\n",
    "            \n",
    "        valFiles = foldFiles[i]\n",
    "        \n",
    "        trainDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, configureDs=trainConfigureDs, preBatch=trainPreBatch, postBatch=trainPostBatch)\n",
    "        valDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, valBatchSize, configureDs=valConfigureDs, preBatch=valPreBatch, postBatch=valPostBatch)\n",
    "        \n",
    "        folds.append((trainDs, valDs))\n",
    "        \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4f43dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPreBatch = [(\"train_process_a\", trainPreprocessA), \n",
    "                 (\"train_extract_gender\", extractGenderLabel)]\n",
    "\n",
    "valPreBatch = [(\"val_process_a\", valPreprocessA), \n",
    "               (\"val_extract_gender\", extractGenderLabel)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10474d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 00:40:24.987728: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-30 00:40:24.988492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-30 00:40:24.988850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-30 00:40:24.989150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-30 00:40:25.297770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-30 00:40:25.298103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-30 00:40:25.298393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-30 00:40:25.298675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9060 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:2d:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "folds = generateFoldDs(foldFiles, \"adience/faces\", \"coarse_tilt_aligned_face\", genderMap, ageMap, 2, 8, \n",
    "                       IMG_WIDTH, IMG_HEIGHT, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE, \n",
    "                       trainConfigureDs=trainConfigPerformance, trainPreBatch=trainPreBatch, \n",
    "                       valConfigureDs=valConfigPerformance, valPreBatch=valPreBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57d814af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b5f9bc",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d0df0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in folds[0][0].take(1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c9e2833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 227, 227, 3), dtype=float32, numpy=\n",
       "array([[[[1.62701584e+02, 1.32776443e+02, 1.18964485e+02],\n",
       "         [1.59919342e+02, 1.30864212e+02, 1.17052261e+02],\n",
       "         [1.59201355e+02, 1.30072067e+02, 1.15999641e+02],\n",
       "         ...,\n",
       "         [2.06219742e+02, 2.09546844e+02, 1.85461136e+02],\n",
       "         [2.19730362e+02, 2.25456940e+02, 2.01690857e+02],\n",
       "         [2.16103790e+02, 2.20443802e+02, 1.97371002e+02]],\n",
       "\n",
       "        [[1.61539062e+02, 1.31613922e+02, 1.17801964e+02],\n",
       "         [1.58071503e+02, 1.28146347e+02, 1.14334396e+02],\n",
       "         [1.59458588e+02, 1.30004440e+02, 1.15932014e+02],\n",
       "         ...,\n",
       "         [2.16449753e+02, 2.19570114e+02, 1.96104614e+02],\n",
       "         [2.15672638e+02, 2.20012634e+02, 1.96939835e+02],\n",
       "         [2.15195145e+02, 2.19535156e+02, 1.96462341e+02]],\n",
       "\n",
       "        [[1.62811127e+02, 1.32885986e+02, 1.19074028e+02],\n",
       "         [1.59609436e+02, 1.29684280e+02, 1.14472343e+02],\n",
       "         [1.60491318e+02, 1.31966141e+02, 1.15602028e+02],\n",
       "         ...,\n",
       "         [2.14293365e+02, 2.17114014e+02, 1.94547668e+02],\n",
       "         [2.17215225e+02, 2.21555237e+02, 1.98482422e+02],\n",
       "         [2.18047668e+02, 2.22387680e+02, 1.99314880e+02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.25057465e+02, 1.96058411e+02, 1.82246460e+02],\n",
       "         [2.22502258e+02, 1.93503189e+02, 1.81543411e+02],\n",
       "         [2.19273819e+02, 1.90274750e+02, 1.79110825e+02],\n",
       "         ...,\n",
       "         [2.12752472e+02, 1.78703354e+02, 1.65224213e+02],\n",
       "         [2.10008209e+02, 1.75452637e+02, 1.63492859e+02],\n",
       "         [2.09762558e+02, 1.77059158e+02, 1.66025467e+02]],\n",
       "\n",
       "        [[2.21812576e+02, 1.92813522e+02, 1.80853729e+02],\n",
       "         [2.26833817e+02, 1.97834747e+02, 1.85874969e+02],\n",
       "         [2.21499161e+02, 1.92500092e+02, 1.80577194e+02],\n",
       "         ...,\n",
       "         [2.09890503e+02, 1.75841385e+02, 1.62362244e+02],\n",
       "         [2.10903580e+02, 1.76348007e+02, 1.64388229e+02],\n",
       "         [2.11282883e+02, 1.78579483e+02, 1.67545776e+02]],\n",
       "\n",
       "        [[2.32510040e+02, 2.03510986e+02, 1.91551208e+02],\n",
       "         [2.31195526e+02, 2.02196472e+02, 1.90236679e+02],\n",
       "         [2.31589020e+02, 2.02589951e+02, 1.90760406e+02],\n",
       "         ...,\n",
       "         [2.10196533e+02, 1.76412140e+02, 1.62138809e+02],\n",
       "         [2.10054337e+02, 1.75617432e+02, 1.63301636e+02],\n",
       "         [2.11638397e+02, 1.78934982e+02, 1.66732834e+02]]],\n",
       "\n",
       "\n",
       "       [[[1.68179276e+02, 1.50272385e+02, 1.58183228e+02],\n",
       "         [1.64817291e+02, 1.46910400e+02, 1.54821228e+02],\n",
       "         [1.51529266e+02, 1.37022491e+02, 1.43233276e+02],\n",
       "         ...,\n",
       "         [1.51558838e+02, 9.54782104e+00, 9.76353455e+00],\n",
       "         [1.48164597e+02, 1.27479324e+01, 1.20829010e+01],\n",
       "         [1.38688889e+02, 1.20779877e+01, 1.22887650e+01]],\n",
       "\n",
       "        [[1.65583923e+02, 1.47677032e+02, 1.55587860e+02],\n",
       "         [1.45964600e+02, 1.31457825e+02, 1.37668610e+02],\n",
       "         [1.51876678e+02, 1.37369873e+02, 1.43580658e+02],\n",
       "         ...,\n",
       "         [1.47906219e+02, 8.33238983e+00, 4.82430267e+00],\n",
       "         [1.35155960e+02, 2.72235870e+00, 4.79347229e-01],\n",
       "         [1.27303154e+02, 5.73929596e+00, 4.13061523e+00]],\n",
       "\n",
       "        [[1.66813049e+02, 1.54019608e+02, 1.59659271e+02],\n",
       "         [1.52402237e+02, 1.39608780e+02, 1.45248444e+02],\n",
       "         [1.61814362e+02, 1.49020920e+02, 1.53518356e+02],\n",
       "         ...,\n",
       "         [1.50619171e+02, 1.51825790e+01, 6.57431793e+00],\n",
       "         [1.19597824e+02, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.04138512e+02, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.42020859e+02, 2.55000000e+02, 2.26300400e+02],\n",
       "         [1.42123810e+02, 1.64908707e+02, 1.37666214e+02],\n",
       "         [4.40514526e+01, 7.19812622e+01, 5.50738373e+01],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.05044556e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.36386871e+00]],\n",
       "\n",
       "        [[2.31928894e+02, 2.52585388e+02, 2.15756866e+02],\n",
       "         [1.96232513e+02, 2.19055923e+02, 1.89724228e+02],\n",
       "         [1.17357941e+02, 1.42585464e+02, 1.20180847e+02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 8.92478943e-01]],\n",
       "\n",
       "        [[2.33801666e+02, 2.54458160e+02, 2.17629639e+02],\n",
       "         [2.06850052e+02, 2.29744507e+02, 1.96963593e+02],\n",
       "         [1.62827011e+02, 1.88633484e+02, 1.58183487e+02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         ...,\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00]],\n",
       "\n",
       "        [[6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         ...,\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00]],\n",
       "\n",
       "        [[6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         ...,\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         ...,\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00]],\n",
       "\n",
       "        [[6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         ...,\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00]],\n",
       "\n",
       "        [[6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         ...,\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00],\n",
       "         [6.52240753e+00, 4.34444809e+00, 3.20224762e+00]]],\n",
       "\n",
       "\n",
       "       [[[5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         ...,\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01]],\n",
       "\n",
       "        [[5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         ...,\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01]],\n",
       "\n",
       "        [[5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         ...,\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         ...,\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01]],\n",
       "\n",
       "        [[5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         ...,\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01]],\n",
       "\n",
       "        [[5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         ...,\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01],\n",
       "         [5.62486191e+01, 4.65398941e+01, 3.83791771e+01]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "819ce578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec440c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.rubberband_canvas.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1, ax1 = plt.subplots(nrows=TRAIN_BATCH_SIZE, ncols=1)\n",
    "\n",
    "if(TRAIN_BATCH_SIZE is None or TRAIN_BATCH_SIZE == 1):\n",
    "    ax1.imshow(x/255)\n",
    "    ax1.set_title(y)\n",
    "else:\n",
    "    for i in range(TRAIN_BATCH_SIZE):\n",
    "        ax1[i].imshow(x[i]/255)\n",
    "        ax1[i].set_title(f\"Gender:{y[i]}\")\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78c5d50",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a70f6af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    inp = tf.keras.Input(shape=(CROP_HEIGHT, CROP_WIDTH, 3))\n",
    "\n",
    "    backbone = tf.keras.applications.resnet_v2.ResNet50V2(include_top=False, input_shape=(CROP_HEIGHT, CROP_WIDTH, 3))\n",
    "    backbone.trainable = False    \n",
    "    \n",
    "    flat1 = tf.keras.layers.Flatten(name='flat1')\n",
    "    fc1 = tf.keras.layers.Dense(128, activation='relu', name='fc1')\n",
    "    do1 = tf.keras.layers.Dropout(0.5, name='do1')\n",
    "\n",
    "    fc2 = tf.keras.layers.Dense(2, activation='softmax', name='fc2')\n",
    "\n",
    "    o = tf.keras.applications.resnet_v2.preprocess_input(inp)\n",
    "    o = backbone(o, training=False)\n",
    "    o = flat1(o)\n",
    "    o = fc1(o)\n",
    "    o = do1(o)\n",
    "\n",
    "    o = fc2(o)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=o, name='baseline_1')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e962234",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b73a21c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"baseline_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 227, 227, 3)]     0         \n",
      "                                                                 \n",
      " tf.math.truediv (TFOpLambda  (None, 227, 227, 3)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " tf.math.subtract (TFOpLambd  (None, 227, 227, 3)      0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 8, 8, 2048)        23564800  \n",
      "                                                                 \n",
      " flat1 (Flatten)             (None, 131072)            0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 128)               16777344  \n",
      "                                                                 \n",
      " do1 (Dropout)               (None, 128)               0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,342,402\n",
      "Trainable params: 16,777,602\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fcc28d",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ffbbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = 1000\n",
    "EPOCH = 300\n",
    "\n",
    "START_EPOCH = 0\n",
    "END_EPOCH = START_EPOCH + EPOCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cc17f1",
   "metadata": {},
   "source": [
    "#### Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1ab143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(epoch, lr):\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "222f6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logBasePath = \"log/baseline_resnet_4\"\n",
    "logPrefix = \"log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1b72905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 00:40:40.570707: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-30 00:40:40.570730: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-10-30 00:40:40.570752: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1665] Profiler found 1 GPUs\n",
      "2022-10-30 00:40:40.667378: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-10-30 00:40:40.668765: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-10-30 00:40:41.740192: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  20/3528 [..............................] - ETA: 30s - loss: 1.8072 - accuracy: 0.4500  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 00:40:42.750156: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 29s 8ms/step - loss: 1.5193 - accuracy: 0.5540\n",
      "Epoch 1/300\n",
      "   1/1000 [..............................] - ETA: 22:47 - loss: 3.2219 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 00:41:11.596307: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-30 00:41:11.596325: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10/1000 [..............................] - ETA: 1:08 - loss: 6.5037 - accuracy: 0.5750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 00:41:12.042080: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-10-30 00:41:12.042892: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-10-30 00:41:12.082569: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 3066 callback api events and 3041 activity events. \n",
      "2022-10-30 00:41:12.107530: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-10-30 00:41:12.133806: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_resnet_4/log_0/plugins/profile/2022_10_30_00_41_12\n",
      "\n",
      "2022-10-30 00:41:12.167128: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_resnet_4/log_0/plugins/profile/2022_10_30_00_41_12/rachanon-pc1.trace.json.gz\n",
      "2022-10-30 00:41:12.206693: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_resnet_4/log_0/plugins/profile/2022_10_30_00_41_12\n",
      "\n",
      "2022-10-30 00:41:12.211018: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_resnet_4/log_0/plugins/profile/2022_10_30_00_41_12/rachanon-pc1.memory_profile.json.gz\n",
      "2022-10-30 00:41:12.212085: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_resnet_4/log_0/plugins/profile/2022_10_30_00_41_12\n",
      "Dumped tool data for xplane.pb to log/baseline_resnet_4/log_0/plugins/profile/2022_10_30_00_41_12/rachanon-pc1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_resnet_4/log_0/plugins/profile/2022_10_30_00_41_12/rachanon-pc1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_resnet_4/log_0/plugins/profile/2022_10_30_00_41_12/rachanon-pc1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_resnet_4/log_0/plugins/profile/2022_10_30_00_41_12/rachanon-pc1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_resnet_4/log_0/plugins/profile/2022_10_30_00_41_12/rachanon-pc1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 995/1000 [============================>.] - ETA: 0s - loss: 0.9564 - accuracy: 0.7286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 00:41:46.785018: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4026531840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 37s 36ms/step - loss: 0.9533 - accuracy: 0.7290 - val_loss: 0.4434 - val_accuracy: 0.8021\n",
      "Epoch 2/300\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 0.5370 - accuracy: 0.7505"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 00:42:22.139433: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4026531840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.5369 - accuracy: 0.7508 - val_loss: 0.4553 - val_accuracy: 0.8061\n",
      "Epoch 3/300\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 0.5105 - accuracy: 0.7638"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 00:42:57.613976: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4026531840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.5104 - accuracy: 0.7642 - val_loss: 0.4310 - val_accuracy: 0.7878\n",
      "Epoch 4/300\n",
      " 997/1000 [============================>.] - ETA: 0s - loss: 0.4993 - accuracy: 0.7600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 00:43:33.230626: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4026531840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4992 - accuracy: 0.7600 - val_loss: 0.4840 - val_accuracy: 0.7934\n",
      "Epoch 5/300\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.4782 - accuracy: 0.7805"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 00:44:09.088899: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4026531840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4782 - accuracy: 0.7805 - val_loss: 0.4388 - val_accuracy: 0.8395\n",
      "Epoch 6/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4411 - accuracy: 0.7887 - val_loss: 0.3525 - val_accuracy: 0.8272\n",
      "Epoch 7/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4854 - accuracy: 0.7617 - val_loss: 0.3843 - val_accuracy: 0.8498\n",
      "Epoch 8/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4205 - accuracy: 0.8027 - val_loss: 0.3513 - val_accuracy: 0.8452\n",
      "Epoch 9/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4593 - accuracy: 0.7968 - val_loss: 0.3362 - val_accuracy: 0.8465\n",
      "Epoch 10/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4431 - accuracy: 0.7832 - val_loss: 0.3061 - val_accuracy: 0.8614\n",
      "Epoch 11/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4461 - accuracy: 0.7755 - val_loss: 0.3259 - val_accuracy: 0.8517\n",
      "Epoch 12/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4336 - accuracy: 0.8010 - val_loss: 0.3239 - val_accuracy: 0.8626\n",
      "Epoch 13/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4099 - accuracy: 0.8158 - val_loss: 0.3005 - val_accuracy: 0.8612\n",
      "Epoch 14/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4323 - accuracy: 0.7763 - val_loss: 0.3304 - val_accuracy: 0.8456\n",
      "Epoch 15/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4087 - accuracy: 0.8095 - val_loss: 0.3009 - val_accuracy: 0.8697\n",
      "Epoch 16/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4031 - accuracy: 0.8177 - val_loss: 0.3354 - val_accuracy: 0.8596\n",
      "Epoch 17/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4117 - accuracy: 0.8018 - val_loss: 0.3155 - val_accuracy: 0.8521\n",
      "Epoch 18/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4457 - accuracy: 0.7883 - val_loss: 0.4030 - val_accuracy: 0.8313\n",
      "Epoch 19/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4140 - accuracy: 0.7955 - val_loss: 0.3160 - val_accuracy: 0.8635\n",
      "Epoch 20/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3711 - accuracy: 0.8192 - val_loss: 0.3016 - val_accuracy: 0.8688\n",
      "Epoch 21/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4457 - accuracy: 0.7785 - val_loss: 0.3177 - val_accuracy: 0.8749\n",
      "Epoch 22/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4067 - accuracy: 0.8087 - val_loss: 0.3474 - val_accuracy: 0.8702\n",
      "Epoch 23/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3834 - accuracy: 0.8223 - val_loss: 0.2970 - val_accuracy: 0.8818\n",
      "Epoch 24/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4160 - accuracy: 0.8108 - val_loss: 0.3341 - val_accuracy: 0.8495\n",
      "Epoch 25/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4218 - accuracy: 0.8067 - val_loss: 0.3285 - val_accuracy: 0.8548\n",
      "Epoch 26/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4003 - accuracy: 0.8138 - val_loss: 0.3071 - val_accuracy: 0.8628\n",
      "Epoch 27/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3924 - accuracy: 0.8227 - val_loss: 0.3596 - val_accuracy: 0.8590\n",
      "Epoch 28/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4041 - accuracy: 0.8050 - val_loss: 0.3063 - val_accuracy: 0.8751\n",
      "Epoch 29/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3955 - accuracy: 0.8048 - val_loss: 0.2756 - val_accuracy: 0.8705\n",
      "Epoch 30/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4091 - accuracy: 0.8245 - val_loss: 0.4242 - val_accuracy: 0.8593\n",
      "Epoch 31/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3829 - accuracy: 0.8163 - val_loss: 0.2622 - val_accuracy: 0.8865\n",
      "Epoch 32/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3787 - accuracy: 0.8087 - val_loss: 0.3003 - val_accuracy: 0.8798\n",
      "Epoch 33/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4129 - accuracy: 0.8027 - val_loss: 0.3129 - val_accuracy: 0.8499\n",
      "Epoch 34/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3785 - accuracy: 0.8207 - val_loss: 0.2808 - val_accuracy: 0.8887\n",
      "Epoch 35/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4199 - accuracy: 0.8070 - val_loss: 0.3566 - val_accuracy: 0.8741\n",
      "Epoch 36/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3598 - accuracy: 0.8305 - val_loss: 0.2747 - val_accuracy: 0.8932\n",
      "Epoch 37/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3989 - accuracy: 0.8382 - val_loss: 0.3161 - val_accuracy: 0.8829\n",
      "Epoch 38/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3829 - accuracy: 0.8265 - val_loss: 0.3222 - val_accuracy: 0.8623\n",
      "Epoch 39/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3790 - accuracy: 0.8158 - val_loss: 0.2492 - val_accuracy: 0.9023\n",
      "Epoch 40/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3933 - accuracy: 0.8167 - val_loss: 0.2668 - val_accuracy: 0.8884\n",
      "Epoch 41/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3854 - accuracy: 0.8340 - val_loss: 0.2380 - val_accuracy: 0.8936\n",
      "Epoch 42/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3845 - accuracy: 0.8192 - val_loss: 0.2618 - val_accuracy: 0.8638\n",
      "Epoch 43/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3925 - accuracy: 0.8037 - val_loss: 0.2370 - val_accuracy: 0.8949\n",
      "Epoch 44/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3830 - accuracy: 0.8330 - val_loss: 0.2521 - val_accuracy: 0.8831\n",
      "Epoch 45/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3522 - accuracy: 0.8303 - val_loss: 0.2368 - val_accuracy: 0.9041\n",
      "Epoch 46/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3773 - accuracy: 0.8167 - val_loss: 0.2459 - val_accuracy: 0.9029\n",
      "Epoch 47/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3874 - accuracy: 0.8192 - val_loss: 0.2737 - val_accuracy: 0.8941\n",
      "Epoch 48/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3611 - accuracy: 0.8313 - val_loss: 0.2408 - val_accuracy: 0.8894\n",
      "Epoch 49/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3778 - accuracy: 0.8167 - val_loss: 0.3489 - val_accuracy: 0.8821\n",
      "Epoch 50/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3788 - accuracy: 0.8095 - val_loss: 0.2740 - val_accuracy: 0.8797\n",
      "Epoch 51/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3721 - accuracy: 0.8342 - val_loss: 0.7347 - val_accuracy: 0.8404\n",
      "Epoch 52/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3593 - accuracy: 0.8330 - val_loss: 0.2492 - val_accuracy: 0.8900\n",
      "Epoch 53/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3848 - accuracy: 0.8012 - val_loss: 0.2504 - val_accuracy: 0.8965\n",
      "Epoch 54/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3624 - accuracy: 0.8328 - val_loss: 0.2515 - val_accuracy: 0.8922\n",
      "Epoch 55/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3935 - accuracy: 0.8155 - val_loss: 0.2875 - val_accuracy: 0.8850\n",
      "Epoch 56/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3867 - accuracy: 0.8183 - val_loss: 0.3099 - val_accuracy: 0.8818\n",
      "Epoch 57/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3674 - accuracy: 0.8253 - val_loss: 0.2505 - val_accuracy: 0.8919\n",
      "Epoch 58/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3628 - accuracy: 0.8365 - val_loss: 0.2552 - val_accuracy: 0.8881\n",
      "Epoch 59/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3456 - accuracy: 0.8292 - val_loss: 0.2505 - val_accuracy: 0.8855\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3956 - accuracy: 0.8050 - val_loss: 0.2629 - val_accuracy: 0.8972\n",
      "Epoch 61/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3329 - accuracy: 0.8465 - val_loss: 0.3465 - val_accuracy: 0.8779\n",
      "Epoch 62/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3896 - accuracy: 0.8135 - val_loss: 0.2423 - val_accuracy: 0.9054\n",
      "Epoch 63/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3842 - accuracy: 0.8192 - val_loss: 0.2601 - val_accuracy: 0.8833\n",
      "Epoch 64/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3834 - accuracy: 0.8125 - val_loss: 0.2457 - val_accuracy: 0.9004\n",
      "Epoch 65/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3682 - accuracy: 0.8363 - val_loss: 0.2623 - val_accuracy: 0.8931\n",
      "Epoch 66/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3596 - accuracy: 0.8405 - val_loss: 0.2295 - val_accuracy: 0.9017\n",
      "Epoch 67/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3684 - accuracy: 0.8220 - val_loss: 0.2421 - val_accuracy: 0.9040\n",
      "Epoch 68/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3775 - accuracy: 0.8393 - val_loss: 0.3112 - val_accuracy: 0.8962\n",
      "Epoch 69/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3740 - accuracy: 0.8365 - val_loss: 0.2363 - val_accuracy: 0.8967\n",
      "Epoch 70/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3739 - accuracy: 0.8267 - val_loss: 0.2311 - val_accuracy: 0.8971\n",
      "Epoch 71/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3773 - accuracy: 0.8148 - val_loss: 0.2658 - val_accuracy: 0.8982\n",
      "Epoch 72/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3759 - accuracy: 0.8288 - val_loss: 0.2524 - val_accuracy: 0.8992\n",
      "Epoch 73/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3582 - accuracy: 0.8275 - val_loss: 0.2317 - val_accuracy: 0.9000\n",
      "Epoch 74/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4017 - accuracy: 0.8125 - val_loss: 0.2879 - val_accuracy: 0.8918\n",
      "Epoch 75/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3680 - accuracy: 0.8303 - val_loss: 0.2236 - val_accuracy: 0.9059\n",
      "Epoch 76/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3333 - accuracy: 0.8443 - val_loss: 0.2289 - val_accuracy: 0.9084\n",
      "Epoch 77/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3688 - accuracy: 0.8330 - val_loss: 0.2693 - val_accuracy: 0.8664\n",
      "Epoch 78/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3896 - accuracy: 0.8087 - val_loss: 0.2374 - val_accuracy: 0.8967\n",
      "Epoch 79/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3638 - accuracy: 0.8320 - val_loss: 0.2587 - val_accuracy: 0.8934\n",
      "Epoch 80/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3531 - accuracy: 0.8307 - val_loss: 0.2898 - val_accuracy: 0.8807\n",
      "Epoch 81/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4396 - accuracy: 0.7800 - val_loss: 0.2329 - val_accuracy: 0.9115\n",
      "Epoch 82/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3440 - accuracy: 0.8410 - val_loss: 0.3296 - val_accuracy: 0.8463\n",
      "Epoch 83/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3467 - accuracy: 0.8468 - val_loss: 0.2370 - val_accuracy: 0.9056\n",
      "Epoch 84/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3622 - accuracy: 0.8270 - val_loss: 0.2248 - val_accuracy: 0.8933\n",
      "Epoch 85/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3869 - accuracy: 0.8250 - val_loss: 0.2304 - val_accuracy: 0.9045\n",
      "Epoch 86/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3834 - accuracy: 0.8285 - val_loss: 0.2402 - val_accuracy: 0.8936\n",
      "Epoch 87/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3513 - accuracy: 0.8345 - val_loss: 0.2200 - val_accuracy: 0.9119\n",
      "Epoch 88/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3930 - accuracy: 0.8035 - val_loss: 0.8596 - val_accuracy: 0.6768\n",
      "Epoch 89/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3865 - accuracy: 0.8340 - val_loss: 0.2442 - val_accuracy: 0.8877\n",
      "Epoch 90/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3429 - accuracy: 0.8403 - val_loss: 0.2529 - val_accuracy: 0.9048\n",
      "Epoch 91/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3666 - accuracy: 0.8385 - val_loss: 0.2543 - val_accuracy: 0.8770\n",
      "Epoch 92/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3752 - accuracy: 0.8180 - val_loss: 0.2185 - val_accuracy: 0.9107\n",
      "Epoch 93/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3645 - accuracy: 0.8395 - val_loss: 0.2477 - val_accuracy: 0.8881\n",
      "Epoch 94/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3380 - accuracy: 0.8267 - val_loss: 0.2066 - val_accuracy: 0.9162\n",
      "Epoch 95/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3797 - accuracy: 0.8198 - val_loss: 0.2360 - val_accuracy: 0.9108\n",
      "Epoch 96/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3965 - accuracy: 0.8170 - val_loss: 0.2116 - val_accuracy: 0.9100\n",
      "Epoch 97/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3555 - accuracy: 0.8453 - val_loss: 0.4890 - val_accuracy: 0.8743\n",
      "Epoch 98/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3391 - accuracy: 0.8453 - val_loss: 0.2557 - val_accuracy: 0.8798\n",
      "Epoch 99/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3713 - accuracy: 0.8240 - val_loss: 0.2274 - val_accuracy: 0.9097\n",
      "Epoch 100/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3830 - accuracy: 0.8370 - val_loss: 0.2240 - val_accuracy: 0.9059\n",
      "Epoch 101/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3516 - accuracy: 0.8375 - val_loss: 0.2234 - val_accuracy: 0.9059\n",
      "Epoch 102/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3545 - accuracy: 0.8353 - val_loss: 0.2287 - val_accuracy: 0.9112\n",
      "Epoch 103/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3633 - accuracy: 0.8275 - val_loss: 0.2046 - val_accuracy: 0.9145\n",
      "Epoch 104/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3604 - accuracy: 0.8407 - val_loss: 0.2158 - val_accuracy: 0.9074\n",
      "Epoch 105/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3248 - accuracy: 0.8393 - val_loss: 0.2103 - val_accuracy: 0.9098\n",
      "Epoch 106/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3741 - accuracy: 0.8165 - val_loss: 0.2125 - val_accuracy: 0.9191\n",
      "Epoch 107/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3789 - accuracy: 0.8322 - val_loss: 0.2478 - val_accuracy: 0.8936\n",
      "Epoch 108/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3573 - accuracy: 0.8505 - val_loss: 0.2151 - val_accuracy: 0.9065\n",
      "Epoch 109/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3713 - accuracy: 0.8422 - val_loss: 0.2400 - val_accuracy: 0.8937\n",
      "Epoch 110/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3756 - accuracy: 0.8265 - val_loss: 0.2436 - val_accuracy: 0.9067\n",
      "Epoch 111/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3369 - accuracy: 0.8482 - val_loss: 0.2218 - val_accuracy: 0.8903\n",
      "Epoch 112/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3411 - accuracy: 0.8332 - val_loss: 0.2391 - val_accuracy: 0.8901\n",
      "Epoch 113/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3666 - accuracy: 0.8173 - val_loss: 0.2165 - val_accuracy: 0.9136\n",
      "Epoch 114/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3458 - accuracy: 0.8500 - val_loss: 0.3174 - val_accuracy: 0.8965\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3867 - accuracy: 0.8255 - val_loss: 0.2495 - val_accuracy: 0.8890\n",
      "Epoch 116/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3673 - accuracy: 0.8260 - val_loss: 0.2632 - val_accuracy: 0.8786\n",
      "Epoch 117/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3388 - accuracy: 0.8280 - val_loss: 0.2239 - val_accuracy: 0.9021\n",
      "Epoch 118/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3588 - accuracy: 0.8340 - val_loss: 0.3635 - val_accuracy: 0.7918\n",
      "Epoch 119/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3650 - accuracy: 0.8347 - val_loss: 0.2609 - val_accuracy: 0.8904\n",
      "Epoch 120/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3935 - accuracy: 0.8073 - val_loss: 0.2168 - val_accuracy: 0.9164\n",
      "Epoch 121/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3672 - accuracy: 0.8420 - val_loss: 0.3501 - val_accuracy: 0.8744\n",
      "Epoch 122/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3434 - accuracy: 0.8292 - val_loss: 0.2228 - val_accuracy: 0.9073\n",
      "Epoch 123/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3405 - accuracy: 0.8367 - val_loss: 0.2136 - val_accuracy: 0.9029\n",
      "Epoch 124/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3464 - accuracy: 0.8403 - val_loss: 0.2168 - val_accuracy: 0.9164\n",
      "Epoch 125/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3698 - accuracy: 0.8370 - val_loss: 0.2244 - val_accuracy: 0.9147\n",
      "Epoch 126/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3280 - accuracy: 0.8543 - val_loss: 0.2398 - val_accuracy: 0.8864\n",
      "Epoch 127/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3959 - accuracy: 0.8073 - val_loss: 0.2480 - val_accuracy: 0.9101\n",
      "Epoch 128/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3459 - accuracy: 0.8443 - val_loss: 0.2083 - val_accuracy: 0.9135\n",
      "Epoch 129/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3687 - accuracy: 0.8280 - val_loss: 0.2295 - val_accuracy: 0.9113\n",
      "Epoch 130/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3622 - accuracy: 0.8382 - val_loss: 0.2122 - val_accuracy: 0.9036\n",
      "Epoch 131/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3584 - accuracy: 0.8158 - val_loss: 0.2225 - val_accuracy: 0.9147\n",
      "Epoch 132/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3377 - accuracy: 0.8435 - val_loss: 0.2257 - val_accuracy: 0.9157\n",
      "Epoch 133/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.2980 - accuracy: 0.8580 - val_loss: 0.2186 - val_accuracy: 0.9122\n",
      "Epoch 134/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3859 - accuracy: 0.8065 - val_loss: 0.2220 - val_accuracy: 0.9196\n",
      "Epoch 135/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3477 - accuracy: 0.8465 - val_loss: 0.2422 - val_accuracy: 0.8998\n",
      "Epoch 136/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3377 - accuracy: 0.8495 - val_loss: 0.2245 - val_accuracy: 0.9004\n",
      "Epoch 137/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3630 - accuracy: 0.8285 - val_loss: 0.2294 - val_accuracy: 0.8890\n",
      "Epoch 138/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3368 - accuracy: 0.8250 - val_loss: 0.2175 - val_accuracy: 0.9145\n",
      "Epoch 139/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3324 - accuracy: 0.8450 - val_loss: 0.2337 - val_accuracy: 0.9099\n",
      "Epoch 140/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3307 - accuracy: 0.8487 - val_loss: 0.2511 - val_accuracy: 0.8838\n",
      "Epoch 141/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4079 - accuracy: 0.8123 - val_loss: 0.2928 - val_accuracy: 0.9058\n",
      "Epoch 142/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3540 - accuracy: 0.8345 - val_loss: 0.1981 - val_accuracy: 0.9185\n",
      "Epoch 143/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3869 - accuracy: 0.8370 - val_loss: 0.2567 - val_accuracy: 0.9163\n",
      "Epoch 144/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3618 - accuracy: 0.8253 - val_loss: 0.2112 - val_accuracy: 0.9013\n",
      "Epoch 145/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3568 - accuracy: 0.8220 - val_loss: 0.2752 - val_accuracy: 0.9077\n",
      "Epoch 146/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3676 - accuracy: 0.8413 - val_loss: 0.2174 - val_accuracy: 0.9143\n",
      "Epoch 147/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3432 - accuracy: 0.8432 - val_loss: 0.2113 - val_accuracy: 0.9095\n",
      "Epoch 148/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3813 - accuracy: 0.8240 - val_loss: 0.3371 - val_accuracy: 0.8980\n",
      "Epoch 149/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3497 - accuracy: 0.8505 - val_loss: 0.2626 - val_accuracy: 0.8921\n",
      "Epoch 150/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3416 - accuracy: 0.8540 - val_loss: 0.3259 - val_accuracy: 0.9167\n",
      "Epoch 151/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3616 - accuracy: 0.8390 - val_loss: 0.2078 - val_accuracy: 0.9039\n",
      "Epoch 152/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3582 - accuracy: 0.8223 - val_loss: 0.2302 - val_accuracy: 0.9094\n",
      "Epoch 153/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3652 - accuracy: 0.8435 - val_loss: 0.2067 - val_accuracy: 0.9100\n",
      "Epoch 154/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3437 - accuracy: 0.8422 - val_loss: 0.2367 - val_accuracy: 0.9150\n",
      "Epoch 155/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3665 - accuracy: 0.8200 - val_loss: 0.3920 - val_accuracy: 0.8571\n",
      "Epoch 156/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3442 - accuracy: 0.8360 - val_loss: 0.2082 - val_accuracy: 0.9078\n",
      "Epoch 157/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3803 - accuracy: 0.8378 - val_loss: 0.3193 - val_accuracy: 0.9033\n",
      "Epoch 158/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3525 - accuracy: 0.8482 - val_loss: 0.2215 - val_accuracy: 0.9101\n",
      "Epoch 159/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3742 - accuracy: 0.8167 - val_loss: 0.2140 - val_accuracy: 0.9147\n",
      "Epoch 160/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3676 - accuracy: 0.8335 - val_loss: 0.2138 - val_accuracy: 0.9143\n",
      "Epoch 161/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3566 - accuracy: 0.8350 - val_loss: 0.2732 - val_accuracy: 0.9019\n",
      "Epoch 162/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3725 - accuracy: 0.8138 - val_loss: 0.2958 - val_accuracy: 0.8848\n",
      "Epoch 163/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3530 - accuracy: 0.8317 - val_loss: 0.2161 - val_accuracy: 0.9124\n",
      "Epoch 164/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3463 - accuracy: 0.8430 - val_loss: 0.1955 - val_accuracy: 0.9171\n",
      "Epoch 165/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3461 - accuracy: 0.8378 - val_loss: 0.2288 - val_accuracy: 0.9068\n",
      "Epoch 166/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3442 - accuracy: 0.8267 - val_loss: 0.2143 - val_accuracy: 0.9198\n",
      "Epoch 167/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3654 - accuracy: 0.8330 - val_loss: 0.2382 - val_accuracy: 0.9119\n",
      "Epoch 168/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3913 - accuracy: 0.8240 - val_loss: 0.2129 - val_accuracy: 0.9080\n",
      "Epoch 169/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3729 - accuracy: 0.8230 - val_loss: 0.2060 - val_accuracy: 0.9057\n",
      "Epoch 170/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3738 - accuracy: 0.8173 - val_loss: 0.2313 - val_accuracy: 0.9133\n",
      "Epoch 171/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3888 - accuracy: 0.8495 - val_loss: 0.2164 - val_accuracy: 0.9017\n",
      "Epoch 172/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3570 - accuracy: 0.8382 - val_loss: 0.1992 - val_accuracy: 0.9213\n",
      "Epoch 173/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3875 - accuracy: 0.8173 - val_loss: 0.2181 - val_accuracy: 0.9237\n",
      "Epoch 174/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3714 - accuracy: 0.8278 - val_loss: 0.2231 - val_accuracy: 0.9108\n",
      "Epoch 175/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3619 - accuracy: 0.8328 - val_loss: 0.2141 - val_accuracy: 0.9140\n",
      "Epoch 176/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3617 - accuracy: 0.8342 - val_loss: 0.2057 - val_accuracy: 0.9092\n",
      "Epoch 177/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3470 - accuracy: 0.8465 - val_loss: 0.2152 - val_accuracy: 0.9068\n",
      "Epoch 178/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3398 - accuracy: 0.8485 - val_loss: 0.2511 - val_accuracy: 0.8748\n",
      "Epoch 179/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3186 - accuracy: 0.8478 - val_loss: 0.2104 - val_accuracy: 0.9065\n",
      "Epoch 180/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3828 - accuracy: 0.8095 - val_loss: 0.2279 - val_accuracy: 0.9203\n",
      "Epoch 181/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3622 - accuracy: 0.8485 - val_loss: 0.2036 - val_accuracy: 0.9057\n",
      "Epoch 182/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3475 - accuracy: 0.8347 - val_loss: 0.1831 - val_accuracy: 0.9241\n",
      "Epoch 183/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3685 - accuracy: 0.8242 - val_loss: 0.2371 - val_accuracy: 0.8865\n",
      "Epoch 184/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3487 - accuracy: 0.8257 - val_loss: 0.1963 - val_accuracy: 0.9176\n",
      "Epoch 185/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3289 - accuracy: 0.8558 - val_loss: 0.2031 - val_accuracy: 0.9157\n",
      "Epoch 186/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3487 - accuracy: 0.8307 - val_loss: 0.2202 - val_accuracy: 0.9004\n",
      "Epoch 187/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3872 - accuracy: 0.7918 - val_loss: 0.2308 - val_accuracy: 0.9155\n",
      "Epoch 188/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3557 - accuracy: 0.8512 - val_loss: 0.1957 - val_accuracy: 0.9203\n",
      "Epoch 189/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3510 - accuracy: 0.8328 - val_loss: 0.1951 - val_accuracy: 0.9206\n",
      "Epoch 190/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3592 - accuracy: 0.8395 - val_loss: 0.2561 - val_accuracy: 0.8722\n",
      "Epoch 191/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3725 - accuracy: 0.8265 - val_loss: 0.1969 - val_accuracy: 0.9198\n",
      "Epoch 192/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3668 - accuracy: 0.8432 - val_loss: 0.2400 - val_accuracy: 0.9138\n",
      "Epoch 193/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3393 - accuracy: 0.8245 - val_loss: 0.1990 - val_accuracy: 0.9154\n",
      "Epoch 194/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3954 - accuracy: 0.7910 - val_loss: 0.2025 - val_accuracy: 0.9186\n",
      "Epoch 195/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3711 - accuracy: 0.8328 - val_loss: 0.2057 - val_accuracy: 0.9150\n",
      "Epoch 196/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3843 - accuracy: 0.8125 - val_loss: 0.2220 - val_accuracy: 0.9143\n",
      "Epoch 197/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3817 - accuracy: 0.8242 - val_loss: 0.2329 - val_accuracy: 0.8873\n",
      "Epoch 198/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4240 - accuracy: 0.7903 - val_loss: 0.2144 - val_accuracy: 0.9149\n",
      "Epoch 199/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3638 - accuracy: 0.8307 - val_loss: 0.2033 - val_accuracy: 0.9182\n",
      "Epoch 200/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3696 - accuracy: 0.8400 - val_loss: 0.2340 - val_accuracy: 0.9116\n",
      "Epoch 201/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3754 - accuracy: 0.8170 - val_loss: 0.2394 - val_accuracy: 0.9208\n",
      "Epoch 202/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3766 - accuracy: 0.8395 - val_loss: 0.5886 - val_accuracy: 0.6496\n",
      "Epoch 203/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3696 - accuracy: 0.8407 - val_loss: 0.2355 - val_accuracy: 0.9153\n",
      "Epoch 204/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4045 - accuracy: 0.8133 - val_loss: 0.2618 - val_accuracy: 0.8574\n",
      "Epoch 205/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3743 - accuracy: 0.8080 - val_loss: 0.2429 - val_accuracy: 0.9053\n",
      "Epoch 206/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4112 - accuracy: 0.8235 - val_loss: 0.2186 - val_accuracy: 0.9050\n",
      "Epoch 207/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3570 - accuracy: 0.8370 - val_loss: 0.2151 - val_accuracy: 0.9060\n",
      "Epoch 208/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4132 - accuracy: 0.8087 - val_loss: 0.2594 - val_accuracy: 0.9126\n",
      "Epoch 209/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3819 - accuracy: 0.8265 - val_loss: 0.2067 - val_accuracy: 0.9109\n",
      "Epoch 210/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3771 - accuracy: 0.8275 - val_loss: 0.2002 - val_accuracy: 0.9133\n",
      "Epoch 211/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3276 - accuracy: 0.8420 - val_loss: 0.2004 - val_accuracy: 0.9061\n",
      "Epoch 212/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3960 - accuracy: 0.8127 - val_loss: 0.2178 - val_accuracy: 0.9132\n",
      "Epoch 213/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3820 - accuracy: 0.8345 - val_loss: 0.2291 - val_accuracy: 0.8984\n",
      "Epoch 214/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3404 - accuracy: 0.8430 - val_loss: 0.2143 - val_accuracy: 0.9099\n",
      "Epoch 215/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3996 - accuracy: 0.8135 - val_loss: 0.3240 - val_accuracy: 0.8968\n",
      "Epoch 216/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3533 - accuracy: 0.8322 - val_loss: 0.2037 - val_accuracy: 0.9040\n",
      "Epoch 217/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3613 - accuracy: 0.8367 - val_loss: 0.2118 - val_accuracy: 0.9174\n",
      "Epoch 218/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3298 - accuracy: 0.8380 - val_loss: 0.2216 - val_accuracy: 0.8870\n",
      "Epoch 219/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3571 - accuracy: 0.8292 - val_loss: 0.2098 - val_accuracy: 0.9166\n",
      "Epoch 220/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3433 - accuracy: 0.8435 - val_loss: 0.2224 - val_accuracy: 0.9043\n",
      "Epoch 221/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3548 - accuracy: 0.8285 - val_loss: 0.1944 - val_accuracy: 0.9158\n",
      "Epoch 222/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3968 - accuracy: 0.8180 - val_loss: 0.2125 - val_accuracy: 0.9150\n",
      "Epoch 223/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3634 - accuracy: 0.8298 - val_loss: 0.2111 - val_accuracy: 0.9121\n",
      "Epoch 224/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3731 - accuracy: 0.8345 - val_loss: 0.2080 - val_accuracy: 0.9136\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3510 - accuracy: 0.8282 - val_loss: 0.2061 - val_accuracy: 0.9070\n",
      "Epoch 226/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3542 - accuracy: 0.8280 - val_loss: 0.1930 - val_accuracy: 0.9226\n",
      "Epoch 227/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3983 - accuracy: 0.8280 - val_loss: 0.2476 - val_accuracy: 0.8880\n",
      "Epoch 228/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3796 - accuracy: 0.8188 - val_loss: 0.2045 - val_accuracy: 0.9092\n",
      "Epoch 229/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3745 - accuracy: 0.8332 - val_loss: 0.2154 - val_accuracy: 0.9123\n",
      "Epoch 230/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3633 - accuracy: 0.8220 - val_loss: 0.2613 - val_accuracy: 0.9121\n",
      "Epoch 231/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3704 - accuracy: 0.8465 - val_loss: 0.2133 - val_accuracy: 0.9128\n",
      "Epoch 232/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3462 - accuracy: 0.8447 - val_loss: 0.2003 - val_accuracy: 0.9172\n",
      "Epoch 233/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3631 - accuracy: 0.8207 - val_loss: 0.1956 - val_accuracy: 0.9213\n",
      "Epoch 234/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3597 - accuracy: 0.8300 - val_loss: 0.2297 - val_accuracy: 0.9047\n",
      "Epoch 235/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3910 - accuracy: 0.8170 - val_loss: 0.2316 - val_accuracy: 0.8778\n",
      "Epoch 236/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3617 - accuracy: 0.8280 - val_loss: 0.2205 - val_accuracy: 0.9118\n",
      "Epoch 237/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3761 - accuracy: 0.8110 - val_loss: 0.2122 - val_accuracy: 0.9137\n",
      "Epoch 238/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3634 - accuracy: 0.8418 - val_loss: 0.2134 - val_accuracy: 0.9090\n",
      "Epoch 239/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3633 - accuracy: 0.8288 - val_loss: 0.2153 - val_accuracy: 0.9110\n",
      "Epoch 240/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3930 - accuracy: 0.8062 - val_loss: 0.2001 - val_accuracy: 0.9201\n",
      "Epoch 241/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3707 - accuracy: 0.8350 - val_loss: 0.2888 - val_accuracy: 0.9118\n",
      "Epoch 242/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3904 - accuracy: 0.8310 - val_loss: 0.1919 - val_accuracy: 0.9198\n",
      "Epoch 243/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3854 - accuracy: 0.8393 - val_loss: 0.2177 - val_accuracy: 0.9037\n",
      "Epoch 244/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3730 - accuracy: 0.8282 - val_loss: 0.1974 - val_accuracy: 0.9211\n",
      "Epoch 245/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3632 - accuracy: 0.8453 - val_loss: 0.3833 - val_accuracy: 0.8543\n",
      "Epoch 246/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3340 - accuracy: 0.8317 - val_loss: 0.2250 - val_accuracy: 0.9124\n",
      "Epoch 247/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4256 - accuracy: 0.8033 - val_loss: 0.2115 - val_accuracy: 0.9235\n",
      "Epoch 248/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3521 - accuracy: 0.8533 - val_loss: 0.2265 - val_accuracy: 0.9069\n",
      "Epoch 249/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3883 - accuracy: 0.8188 - val_loss: 0.2224 - val_accuracy: 0.9225\n",
      "Epoch 250/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3928 - accuracy: 0.8295 - val_loss: 0.2000 - val_accuracy: 0.9109\n",
      "Epoch 251/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3575 - accuracy: 0.8290 - val_loss: 0.2057 - val_accuracy: 0.9212\n",
      "Epoch 252/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3340 - accuracy: 0.8400 - val_loss: 0.2017 - val_accuracy: 0.9220\n",
      "Epoch 253/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3785 - accuracy: 0.8372 - val_loss: 0.2102 - val_accuracy: 0.9101\n",
      "Epoch 254/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3891 - accuracy: 0.8035 - val_loss: 0.2527 - val_accuracy: 0.9163\n",
      "Epoch 255/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3632 - accuracy: 0.8410 - val_loss: 0.2181 - val_accuracy: 0.9044\n",
      "Epoch 256/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3784 - accuracy: 0.8220 - val_loss: 0.2005 - val_accuracy: 0.9237\n",
      "Epoch 257/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3653 - accuracy: 0.8295 - val_loss: 0.1886 - val_accuracy: 0.9116\n",
      "Epoch 258/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3760 - accuracy: 0.8110 - val_loss: 0.1987 - val_accuracy: 0.9206\n",
      "Epoch 259/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3229 - accuracy: 0.8505 - val_loss: 0.2052 - val_accuracy: 0.9230\n",
      "Epoch 260/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3694 - accuracy: 0.8372 - val_loss: 0.1879 - val_accuracy: 0.9088\n",
      "Epoch 261/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3950 - accuracy: 0.8055 - val_loss: 0.2136 - val_accuracy: 0.9206\n",
      "Epoch 262/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3710 - accuracy: 0.8382 - val_loss: 0.1920 - val_accuracy: 0.9081\n",
      "Epoch 263/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3661 - accuracy: 0.8380 - val_loss: 0.1985 - val_accuracy: 0.9219\n",
      "Epoch 264/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3927 - accuracy: 0.8325 - val_loss: 0.1872 - val_accuracy: 0.9130\n",
      "Epoch 265/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3615 - accuracy: 0.8255 - val_loss: 0.1916 - val_accuracy: 0.9091\n",
      "Epoch 266/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3631 - accuracy: 0.8355 - val_loss: 0.1859 - val_accuracy: 0.9267\n",
      "Epoch 267/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3648 - accuracy: 0.8395 - val_loss: 0.2014 - val_accuracy: 0.9128\n",
      "Epoch 268/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3928 - accuracy: 0.8090 - val_loss: 0.2160 - val_accuracy: 0.9264\n",
      "Epoch 269/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3859 - accuracy: 0.8385 - val_loss: 0.2316 - val_accuracy: 0.8947\n",
      "Epoch 270/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3704 - accuracy: 0.8300 - val_loss: 0.2070 - val_accuracy: 0.9184\n",
      "Epoch 271/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3946 - accuracy: 0.8325 - val_loss: 0.2196 - val_accuracy: 0.8932\n",
      "Epoch 272/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3718 - accuracy: 0.8292 - val_loss: 0.2409 - val_accuracy: 0.8836\n",
      "Epoch 273/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4133 - accuracy: 0.8192 - val_loss: 0.2173 - val_accuracy: 0.9181\n",
      "Epoch 274/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3356 - accuracy: 0.8403 - val_loss: 0.1921 - val_accuracy: 0.9118\n",
      "Epoch 275/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3947 - accuracy: 0.8062 - val_loss: 0.2991 - val_accuracy: 0.9147\n",
      "Epoch 276/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3656 - accuracy: 0.8355 - val_loss: 0.1787 - val_accuracy: 0.9225\n",
      "Epoch 277/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3633 - accuracy: 0.8355 - val_loss: 0.1937 - val_accuracy: 0.9265\n",
      "Epoch 278/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3859 - accuracy: 0.8260 - val_loss: 0.2385 - val_accuracy: 0.8802\n",
      "Epoch 279/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3686 - accuracy: 0.8167 - val_loss: 0.1998 - val_accuracy: 0.9206\n",
      "Epoch 280/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3739 - accuracy: 0.8395 - val_loss: 0.2017 - val_accuracy: 0.9141\n",
      "Epoch 281/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3436 - accuracy: 0.8480 - val_loss: 0.2100 - val_accuracy: 0.9230\n",
      "Epoch 282/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3798 - accuracy: 0.8245 - val_loss: 0.2027 - val_accuracy: 0.9250\n",
      "Epoch 283/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3741 - accuracy: 0.8345 - val_loss: 0.2042 - val_accuracy: 0.9075\n",
      "Epoch 284/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3657 - accuracy: 0.8322 - val_loss: 0.2489 - val_accuracy: 0.9154\n",
      "Epoch 285/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3864 - accuracy: 0.8267 - val_loss: 0.2292 - val_accuracy: 0.8868\n",
      "Epoch 286/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3861 - accuracy: 0.8080 - val_loss: 0.2331 - val_accuracy: 0.9213\n",
      "Epoch 287/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3816 - accuracy: 0.8415 - val_loss: 0.1890 - val_accuracy: 0.9148\n",
      "Epoch 288/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3361 - accuracy: 0.8370 - val_loss: 0.1881 - val_accuracy: 0.9275\n",
      "Epoch 289/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3674 - accuracy: 0.8210 - val_loss: 0.2119 - val_accuracy: 0.9109\n",
      "Epoch 290/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3836 - accuracy: 0.8192 - val_loss: 0.2195 - val_accuracy: 0.8975\n",
      "Epoch 291/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3671 - accuracy: 0.8320 - val_loss: 0.1896 - val_accuracy: 0.9255\n",
      "Epoch 292/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3515 - accuracy: 0.8435 - val_loss: 0.2065 - val_accuracy: 0.9148\n",
      "Epoch 293/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3549 - accuracy: 0.8355 - val_loss: 0.1896 - val_accuracy: 0.9254\n",
      "Epoch 294/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3925 - accuracy: 0.8230 - val_loss: 0.2142 - val_accuracy: 0.9080\n",
      "Epoch 295/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3242 - accuracy: 0.8472 - val_loss: 0.1974 - val_accuracy: 0.9168\n",
      "Epoch 296/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3678 - accuracy: 0.8342 - val_loss: 0.2220 - val_accuracy: 0.9097\n",
      "Epoch 297/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3907 - accuracy: 0.8165 - val_loss: 0.2402 - val_accuracy: 0.9229\n",
      "Epoch 298/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3612 - accuracy: 0.8480 - val_loss: 0.1900 - val_accuracy: 0.9162\n",
      "Epoch 299/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3867 - accuracy: 0.8217 - val_loss: 0.1982 - val_accuracy: 0.9047\n",
      "Epoch 300/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3968 - accuracy: 0.8215 - val_loss: 0.2575 - val_accuracy: 0.9213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 03:39:08.418340: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-30 03:39:08.418364: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-10-30 03:39:08.693591: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-10-30 03:39:08.695989: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 28s 8ms/step - loss: 1.3420 - accuracy: 0.4674\n",
      "Epoch 1/300\n",
      "   1/1000 [..............................] - ETA: 26:02 - loss: 0.0060 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 03:39:38.426786: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-30 03:39:38.426905: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   7/1000 [..............................] - ETA: 50s - loss: 9.2987 - accuracy: 0.7143 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 03:39:38.965104: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-10-30 03:39:38.987998: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-10-30 03:39:39.052880: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 3066 callback api events and 3041 activity events. \n",
      "2022-10-30 03:39:39.109616: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-10-30 03:39:39.164217: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_resnet_4/log_1/plugins/profile/2022_10_30_03_39_39\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  15/1000 [..............................] - ETA: 1:06 - loss: 9.8222 - accuracy: 0.6333 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 03:39:39.197441: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_resnet_4/log_1/plugins/profile/2022_10_30_03_39_39/rachanon-pc1.trace.json.gz\n",
      "2022-10-30 03:39:39.285028: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_resnet_4/log_1/plugins/profile/2022_10_30_03_39_39\n",
      "\n",
      "2022-10-30 03:39:39.290838: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_resnet_4/log_1/plugins/profile/2022_10_30_03_39_39/rachanon-pc1.memory_profile.json.gz\n",
      "2022-10-30 03:39:39.292404: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_resnet_4/log_1/plugins/profile/2022_10_30_03_39_39\n",
      "Dumped tool data for xplane.pb to log/baseline_resnet_4/log_1/plugins/profile/2022_10_30_03_39_39/rachanon-pc1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_resnet_4/log_1/plugins/profile/2022_10_30_03_39_39/rachanon-pc1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_resnet_4/log_1/plugins/profile/2022_10_30_03_39_39/rachanon-pc1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_resnet_4/log_1/plugins/profile/2022_10_30_03_39_39/rachanon-pc1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_resnet_4/log_1/plugins/profile/2022_10_30_03_39_39/rachanon-pc1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 38s 36ms/step - loss: 1.0763 - accuracy: 0.7297 - val_loss: 0.4318 - val_accuracy: 0.8072\n",
      "Epoch 2/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5373 - accuracy: 0.7287 - val_loss: 0.4885 - val_accuracy: 0.7561\n",
      "Epoch 3/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5140 - accuracy: 0.7465 - val_loss: 0.4091 - val_accuracy: 0.8183\n",
      "Epoch 4/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5218 - accuracy: 0.7592 - val_loss: 0.4065 - val_accuracy: 0.7869\n",
      "Epoch 5/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4640 - accuracy: 0.7675 - val_loss: 0.3578 - val_accuracy: 0.8325\n",
      "Epoch 6/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4341 - accuracy: 0.7895 - val_loss: 0.3865 - val_accuracy: 0.8339\n",
      "Epoch 7/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4823 - accuracy: 0.7657 - val_loss: 0.3671 - val_accuracy: 0.8174\n",
      "Epoch 8/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4694 - accuracy: 0.7945 - val_loss: 0.3347 - val_accuracy: 0.8543\n",
      "Epoch 9/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4348 - accuracy: 0.7910 - val_loss: 0.3531 - val_accuracy: 0.8563\n",
      "Epoch 10/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4511 - accuracy: 0.7757 - val_loss: 0.3555 - val_accuracy: 0.8428\n",
      "Epoch 11/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4748 - accuracy: 0.7837 - val_loss: 0.3755 - val_accuracy: 0.8237\n",
      "Epoch 12/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4170 - accuracy: 0.8058 - val_loss: 0.4250 - val_accuracy: 0.8326\n",
      "Epoch 13/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4106 - accuracy: 0.8095 - val_loss: 0.3623 - val_accuracy: 0.8445\n",
      "Epoch 14/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4434 - accuracy: 0.7922 - val_loss: 0.3173 - val_accuracy: 0.8611\n",
      "Epoch 15/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.4230 - accuracy: 0.8140 - val_loss: 0.3422 - val_accuracy: 0.8593\n",
      "Epoch 16/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4296 - accuracy: 0.8027 - val_loss: 0.3160 - val_accuracy: 0.8595\n",
      "Epoch 17/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4260 - accuracy: 0.8067 - val_loss: 0.3481 - val_accuracy: 0.8537\n",
      "Epoch 18/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4204 - accuracy: 0.8012 - val_loss: 0.5460 - val_accuracy: 0.7871\n",
      "Epoch 19/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4312 - accuracy: 0.8070 - val_loss: 0.3027 - val_accuracy: 0.8632\n",
      "Epoch 20/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3800 - accuracy: 0.8207 - val_loss: 0.3420 - val_accuracy: 0.8565\n",
      "Epoch 21/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4553 - accuracy: 0.7857 - val_loss: 0.3552 - val_accuracy: 0.8250\n",
      "Epoch 22/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3860 - accuracy: 0.8225 - val_loss: 0.2924 - val_accuracy: 0.8712\n",
      "Epoch 23/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4113 - accuracy: 0.8055 - val_loss: 0.2864 - val_accuracy: 0.8809\n",
      "Epoch 24/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4099 - accuracy: 0.8073 - val_loss: 0.3155 - val_accuracy: 0.8764\n",
      "Epoch 25/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4030 - accuracy: 0.8217 - val_loss: 0.2889 - val_accuracy: 0.8770\n",
      "Epoch 26/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3925 - accuracy: 0.8087 - val_loss: 0.3451 - val_accuracy: 0.8620\n",
      "Epoch 27/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3753 - accuracy: 0.8378 - val_loss: 0.2982 - val_accuracy: 0.8792\n",
      "Epoch 28/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4130 - accuracy: 0.7878 - val_loss: 0.3950 - val_accuracy: 0.8483\n",
      "Epoch 29/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4038 - accuracy: 0.8173 - val_loss: 0.2713 - val_accuracy: 0.8872\n",
      "Epoch 30/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4089 - accuracy: 0.8090 - val_loss: 0.4408 - val_accuracy: 0.8547\n",
      "Epoch 31/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3923 - accuracy: 0.8227 - val_loss: 0.3082 - val_accuracy: 0.8818\n",
      "Epoch 32/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3856 - accuracy: 0.8315 - val_loss: 0.2574 - val_accuracy: 0.8914\n",
      "Epoch 33/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.4045 - accuracy: 0.8160 - val_loss: 0.2777 - val_accuracy: 0.8809\n",
      "Epoch 34/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3927 - accuracy: 0.8213 - val_loss: 0.2766 - val_accuracy: 0.8870\n",
      "Epoch 35/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4233 - accuracy: 0.8045 - val_loss: 0.2811 - val_accuracy: 0.8827\n",
      "Epoch 36/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3873 - accuracy: 0.8400 - val_loss: 0.2972 - val_accuracy: 0.8767\n",
      "Epoch 37/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3739 - accuracy: 0.8278 - val_loss: 0.2716 - val_accuracy: 0.8912\n",
      "Epoch 38/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4000 - accuracy: 0.8238 - val_loss: 0.2931 - val_accuracy: 0.8777\n",
      "Epoch 39/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3938 - accuracy: 0.8270 - val_loss: 0.2632 - val_accuracy: 0.8900\n",
      "Epoch 40/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4273 - accuracy: 0.7883 - val_loss: 0.3767 - val_accuracy: 0.8228\n",
      "Epoch 41/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3771 - accuracy: 0.8240 - val_loss: 0.2622 - val_accuracy: 0.8907\n",
      "Epoch 42/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3990 - accuracy: 0.8027 - val_loss: 0.3851 - val_accuracy: 0.8842\n",
      "Epoch 43/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3980 - accuracy: 0.8253 - val_loss: 0.2627 - val_accuracy: 0.8910\n",
      "Epoch 44/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3659 - accuracy: 0.8188 - val_loss: 0.2550 - val_accuracy: 0.9016\n",
      "Epoch 45/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3783 - accuracy: 0.8213 - val_loss: 0.2632 - val_accuracy: 0.8829\n",
      "Epoch 46/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4026 - accuracy: 0.8152 - val_loss: 0.2689 - val_accuracy: 0.9000\n",
      "Epoch 47/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4071 - accuracy: 0.8270 - val_loss: 0.3313 - val_accuracy: 0.8279\n",
      "Epoch 48/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3957 - accuracy: 0.8033 - val_loss: 0.2532 - val_accuracy: 0.8935\n",
      "Epoch 49/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3902 - accuracy: 0.8027 - val_loss: 0.2583 - val_accuracy: 0.8914\n",
      "Epoch 50/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3391 - accuracy: 0.8390 - val_loss: 0.2387 - val_accuracy: 0.9023\n",
      "Epoch 51/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3739 - accuracy: 0.8267 - val_loss: 0.3161 - val_accuracy: 0.8887\n",
      "Epoch 52/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3537 - accuracy: 0.8447 - val_loss: 0.2857 - val_accuracy: 0.8759\n",
      "Epoch 53/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3826 - accuracy: 0.8120 - val_loss: 0.2635 - val_accuracy: 0.8970\n",
      "Epoch 54/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3740 - accuracy: 0.8248 - val_loss: 0.2415 - val_accuracy: 0.9035\n",
      "Epoch 55/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3618 - accuracy: 0.8340 - val_loss: 0.2595 - val_accuracy: 0.8967\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3751 - accuracy: 0.8220 - val_loss: 0.2640 - val_accuracy: 0.8965\n",
      "Epoch 57/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3852 - accuracy: 0.8340 - val_loss: 0.4568 - val_accuracy: 0.8791\n",
      "Epoch 58/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3727 - accuracy: 0.8220 - val_loss: 0.2705 - val_accuracy: 0.8994\n",
      "Epoch 59/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3610 - accuracy: 0.8430 - val_loss: 0.2697 - val_accuracy: 0.8999\n",
      "Epoch 60/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3930 - accuracy: 0.8253 - val_loss: 0.2443 - val_accuracy: 0.8953\n",
      "Epoch 61/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3653 - accuracy: 0.8313 - val_loss: 0.8697 - val_accuracy: 0.8775\n",
      "Epoch 62/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3601 - accuracy: 0.8370 - val_loss: 0.2343 - val_accuracy: 0.9028\n",
      "Epoch 63/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4022 - accuracy: 0.8080 - val_loss: 0.2753 - val_accuracy: 0.8979\n",
      "Epoch 64/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3879 - accuracy: 0.8405 - val_loss: 0.2508 - val_accuracy: 0.8900\n",
      "Epoch 65/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3695 - accuracy: 0.8267 - val_loss: 0.2743 - val_accuracy: 0.8796\n",
      "Epoch 66/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3518 - accuracy: 0.8298 - val_loss: 0.3159 - val_accuracy: 0.8910\n",
      "Epoch 67/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4234 - accuracy: 0.8110 - val_loss: 0.2818 - val_accuracy: 0.8784\n",
      "Epoch 68/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3771 - accuracy: 0.8313 - val_loss: 0.2500 - val_accuracy: 0.9037\n",
      "Epoch 69/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3592 - accuracy: 0.8470 - val_loss: 0.2735 - val_accuracy: 0.8723\n",
      "Epoch 70/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3620 - accuracy: 0.8290 - val_loss: 0.2561 - val_accuracy: 0.9060\n",
      "Epoch 71/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3734 - accuracy: 0.8292 - val_loss: 0.2397 - val_accuracy: 0.8954\n",
      "Epoch 72/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3623 - accuracy: 0.8248 - val_loss: 0.2495 - val_accuracy: 0.8931\n",
      "Epoch 73/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3574 - accuracy: 0.8120 - val_loss: 0.2755 - val_accuracy: 0.8848\n",
      "Epoch 74/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4133 - accuracy: 0.8138 - val_loss: 0.2569 - val_accuracy: 0.8868\n",
      "Epoch 75/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3594 - accuracy: 0.8400 - val_loss: 0.2435 - val_accuracy: 0.8970\n",
      "Epoch 76/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3549 - accuracy: 0.8460 - val_loss: 0.2654 - val_accuracy: 0.9018\n",
      "Epoch 77/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3729 - accuracy: 0.8245 - val_loss: 0.2361 - val_accuracy: 0.9055\n",
      "Epoch 78/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3805 - accuracy: 0.8360 - val_loss: 0.3304 - val_accuracy: 0.8869\n",
      "Epoch 79/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3466 - accuracy: 0.8365 - val_loss: 0.2554 - val_accuracy: 0.8838\n",
      "Epoch 80/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3530 - accuracy: 0.8382 - val_loss: 0.2530 - val_accuracy: 0.9041\n",
      "Epoch 81/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3851 - accuracy: 0.8185 - val_loss: 0.2827 - val_accuracy: 0.8797\n",
      "Epoch 82/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3646 - accuracy: 0.8357 - val_loss: 0.3150 - val_accuracy: 0.8539\n",
      "Epoch 83/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3831 - accuracy: 0.8335 - val_loss: 0.3030 - val_accuracy: 0.8945\n",
      "Epoch 84/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3645 - accuracy: 0.8307 - val_loss: 0.2526 - val_accuracy: 0.9055\n",
      "Epoch 85/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3748 - accuracy: 0.8375 - val_loss: 0.2832 - val_accuracy: 0.9033\n",
      "Epoch 86/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3794 - accuracy: 0.8275 - val_loss: 0.2508 - val_accuracy: 0.9091\n",
      "Epoch 87/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3525 - accuracy: 0.8495 - val_loss: 0.2420 - val_accuracy: 0.9068\n",
      "Epoch 88/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3855 - accuracy: 0.8207 - val_loss: 0.3430 - val_accuracy: 0.8795\n",
      "Epoch 89/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3950 - accuracy: 0.8248 - val_loss: 0.2296 - val_accuracy: 0.9111\n",
      "Epoch 90/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3671 - accuracy: 0.8275 - val_loss: 0.4194 - val_accuracy: 0.8780\n",
      "Epoch 91/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3895 - accuracy: 0.8213 - val_loss: 0.2650 - val_accuracy: 0.9018\n",
      "Epoch 92/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3630 - accuracy: 0.8422 - val_loss: 0.2902 - val_accuracy: 0.9026\n",
      "Epoch 93/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3800 - accuracy: 0.8185 - val_loss: 0.2825 - val_accuracy: 0.8979\n",
      "Epoch 94/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3613 - accuracy: 0.8353 - val_loss: 0.2458 - val_accuracy: 0.9006\n",
      "Epoch 95/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3981 - accuracy: 0.8227 - val_loss: 0.2637 - val_accuracy: 0.8739\n",
      "Epoch 96/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3954 - accuracy: 0.8255 - val_loss: 0.3025 - val_accuracy: 0.8777\n",
      "Epoch 97/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3580 - accuracy: 0.8170 - val_loss: 0.2355 - val_accuracy: 0.9023\n",
      "Epoch 98/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3907 - accuracy: 0.8305 - val_loss: 0.2425 - val_accuracy: 0.9044\n",
      "Epoch 99/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3921 - accuracy: 0.8275 - val_loss: 0.2457 - val_accuracy: 0.8906\n",
      "Epoch 100/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3913 - accuracy: 0.8330 - val_loss: 0.2791 - val_accuracy: 0.8676\n",
      "Epoch 101/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3383 - accuracy: 0.8223 - val_loss: 0.2159 - val_accuracy: 0.9085\n",
      "Epoch 102/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3574 - accuracy: 0.8180 - val_loss: 0.2555 - val_accuracy: 0.8943\n",
      "Epoch 103/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3765 - accuracy: 0.8465 - val_loss: 0.2265 - val_accuracy: 0.9065\n",
      "Epoch 104/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3552 - accuracy: 0.8213 - val_loss: 0.2539 - val_accuracy: 0.9109\n",
      "Epoch 105/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3751 - accuracy: 0.8413 - val_loss: 0.2470 - val_accuracy: 0.8986\n",
      "Epoch 106/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3867 - accuracy: 0.8295 - val_loss: 0.2340 - val_accuracy: 0.9081\n",
      "Epoch 107/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3694 - accuracy: 0.8242 - val_loss: 0.2490 - val_accuracy: 0.8892\n",
      "Epoch 108/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3640 - accuracy: 0.8303 - val_loss: 0.2278 - val_accuracy: 0.9094\n",
      "Epoch 109/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3978 - accuracy: 0.8090 - val_loss: 0.2205 - val_accuracy: 0.9061\n",
      "Epoch 110/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3627 - accuracy: 0.8530 - val_loss: 0.2197 - val_accuracy: 0.9050\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3621 - accuracy: 0.8447 - val_loss: 0.2329 - val_accuracy: 0.9082\n",
      "Epoch 112/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3574 - accuracy: 0.8292 - val_loss: 0.2483 - val_accuracy: 0.8958\n",
      "Epoch 113/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4135 - accuracy: 0.8158 - val_loss: 0.2344 - val_accuracy: 0.9093\n",
      "Epoch 114/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3699 - accuracy: 0.8273 - val_loss: 0.3263 - val_accuracy: 0.8586\n",
      "Epoch 115/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3685 - accuracy: 0.8303 - val_loss: 0.2282 - val_accuracy: 0.9028\n",
      "Epoch 116/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3872 - accuracy: 0.8205 - val_loss: 0.2224 - val_accuracy: 0.9084\n",
      "Epoch 117/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3576 - accuracy: 0.8443 - val_loss: 0.2181 - val_accuracy: 0.9019\n",
      "Epoch 118/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3549 - accuracy: 0.8478 - val_loss: 0.2289 - val_accuracy: 0.9152\n",
      "Epoch 119/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3478 - accuracy: 0.8430 - val_loss: 0.3139 - val_accuracy: 0.9040\n",
      "Epoch 120/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3622 - accuracy: 0.8380 - val_loss: 0.2466 - val_accuracy: 0.9011\n",
      "Epoch 121/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3784 - accuracy: 0.8288 - val_loss: 0.3139 - val_accuracy: 0.9062\n",
      "Epoch 122/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4111 - accuracy: 0.8313 - val_loss: 0.2375 - val_accuracy: 0.9031\n",
      "Epoch 123/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3635 - accuracy: 0.8152 - val_loss: 0.2573 - val_accuracy: 0.9089\n",
      "Epoch 124/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3779 - accuracy: 0.8335 - val_loss: 0.2390 - val_accuracy: 0.8998\n",
      "Epoch 125/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3688 - accuracy: 0.8378 - val_loss: 0.2724 - val_accuracy: 0.8999\n",
      "Epoch 126/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3478 - accuracy: 0.8462 - val_loss: 0.2184 - val_accuracy: 0.9202\n",
      "Epoch 127/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4135 - accuracy: 0.8190 - val_loss: 0.2719 - val_accuracy: 0.8580\n",
      "Epoch 128/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3756 - accuracy: 0.8403 - val_loss: 0.2120 - val_accuracy: 0.9171\n",
      "Epoch 129/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3407 - accuracy: 0.8340 - val_loss: 0.2074 - val_accuracy: 0.9122\n",
      "Epoch 130/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3703 - accuracy: 0.8280 - val_loss: 0.2297 - val_accuracy: 0.9135\n",
      "Epoch 131/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3912 - accuracy: 0.8267 - val_loss: 0.2341 - val_accuracy: 0.8870\n",
      "Epoch 132/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3450 - accuracy: 0.8428 - val_loss: 0.2345 - val_accuracy: 0.9058\n",
      "Epoch 133/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3510 - accuracy: 0.8512 - val_loss: 0.2449 - val_accuracy: 0.9110\n",
      "Epoch 134/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3777 - accuracy: 0.8257 - val_loss: 0.2330 - val_accuracy: 0.8927\n",
      "Epoch 135/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3595 - accuracy: 0.8378 - val_loss: 0.2192 - val_accuracy: 0.9172\n",
      "Epoch 136/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3482 - accuracy: 0.8263 - val_loss: 0.2149 - val_accuracy: 0.9062\n",
      "Epoch 137/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3543 - accuracy: 0.8202 - val_loss: 0.2368 - val_accuracy: 0.9131\n",
      "Epoch 138/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4310 - accuracy: 0.8375 - val_loss: 0.2332 - val_accuracy: 0.9043\n",
      "Epoch 139/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3549 - accuracy: 0.8443 - val_loss: 0.2318 - val_accuracy: 0.8934\n",
      "Epoch 140/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4078 - accuracy: 0.8273 - val_loss: 0.2363 - val_accuracy: 0.8989\n",
      "Epoch 141/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4185 - accuracy: 0.8170 - val_loss: 0.4900 - val_accuracy: 0.8584\n",
      "Epoch 142/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3919 - accuracy: 0.8345 - val_loss: 0.2132 - val_accuracy: 0.9072\n",
      "Epoch 143/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3313 - accuracy: 0.8447 - val_loss: 0.2154 - val_accuracy: 0.9116\n",
      "Epoch 144/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3805 - accuracy: 0.8288 - val_loss: 0.2411 - val_accuracy: 0.9144\n",
      "Epoch 145/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3525 - accuracy: 0.8397 - val_loss: 0.3414 - val_accuracy: 0.9080\n",
      "Epoch 146/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3793 - accuracy: 0.8332 - val_loss: 0.2282 - val_accuracy: 0.9036\n",
      "Epoch 147/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3459 - accuracy: 0.8493 - val_loss: 0.2337 - val_accuracy: 0.9089\n",
      "Epoch 148/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3849 - accuracy: 0.8213 - val_loss: 0.3030 - val_accuracy: 0.8488\n",
      "Epoch 149/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3570 - accuracy: 0.8357 - val_loss: 0.2025 - val_accuracy: 0.9189\n",
      "Epoch 150/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3584 - accuracy: 0.8317 - val_loss: 0.2413 - val_accuracy: 0.9128\n",
      "Epoch 151/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4071 - accuracy: 0.8370 - val_loss: 0.2377 - val_accuracy: 0.9106\n",
      "Epoch 152/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3716 - accuracy: 0.8388 - val_loss: 0.2139 - val_accuracy: 0.9144\n",
      "Epoch 153/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3624 - accuracy: 0.8322 - val_loss: 0.2232 - val_accuracy: 0.9126\n",
      "Epoch 154/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3388 - accuracy: 0.8525 - val_loss: 0.2196 - val_accuracy: 0.9179\n",
      "Epoch 155/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3850 - accuracy: 0.8207 - val_loss: 0.2187 - val_accuracy: 0.9128\n",
      "Epoch 156/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3821 - accuracy: 0.8267 - val_loss: 0.2146 - val_accuracy: 0.9155\n",
      "Epoch 157/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3701 - accuracy: 0.8405 - val_loss: 0.2369 - val_accuracy: 0.9046\n",
      "Epoch 158/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3451 - accuracy: 0.8405 - val_loss: 0.2324 - val_accuracy: 0.8967\n",
      "Epoch 159/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3624 - accuracy: 0.8307 - val_loss: 0.2083 - val_accuracy: 0.9087\n",
      "Epoch 160/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3732 - accuracy: 0.8215 - val_loss: 0.2869 - val_accuracy: 0.8990\n",
      "Epoch 161/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3862 - accuracy: 0.8313 - val_loss: 0.2274 - val_accuracy: 0.8987\n",
      "Epoch 162/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3812 - accuracy: 0.8165 - val_loss: 0.2303 - val_accuracy: 0.9092\n",
      "Epoch 163/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4008 - accuracy: 0.8515 - val_loss: 0.2113 - val_accuracy: 0.9209\n",
      "Epoch 164/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3385 - accuracy: 0.8292 - val_loss: 0.2431 - val_accuracy: 0.9108\n",
      "Epoch 165/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3617 - accuracy: 0.8365 - val_loss: 0.2255 - val_accuracy: 0.9004\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3826 - accuracy: 0.8158 - val_loss: 0.1946 - val_accuracy: 0.9147\n",
      "Epoch 167/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3864 - accuracy: 0.8260 - val_loss: 0.2331 - val_accuracy: 0.8987\n",
      "Epoch 168/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3852 - accuracy: 0.8375 - val_loss: 0.2223 - val_accuracy: 0.9152\n",
      "Epoch 169/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3617 - accuracy: 0.8223 - val_loss: 0.2358 - val_accuracy: 0.9194\n",
      "Epoch 170/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3710 - accuracy: 0.8395 - val_loss: 0.2195 - val_accuracy: 0.8999\n",
      "Epoch 171/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3527 - accuracy: 0.8230 - val_loss: 0.2192 - val_accuracy: 0.9127\n",
      "Epoch 172/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3404 - accuracy: 0.8533 - val_loss: 0.2090 - val_accuracy: 0.9160\n",
      "Epoch 173/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3588 - accuracy: 0.8335 - val_loss: 0.2129 - val_accuracy: 0.9126\n",
      "Epoch 174/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4076 - accuracy: 0.8315 - val_loss: 0.2866 - val_accuracy: 0.8634\n",
      "Epoch 175/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3604 - accuracy: 0.8288 - val_loss: 0.2174 - val_accuracy: 0.9118\n",
      "Epoch 176/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3548 - accuracy: 0.8345 - val_loss: 0.2098 - val_accuracy: 0.9143\n",
      "Epoch 177/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3811 - accuracy: 0.8290 - val_loss: 0.2191 - val_accuracy: 0.9116\n",
      "Epoch 178/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3776 - accuracy: 0.8317 - val_loss: 0.2057 - val_accuracy: 0.9173\n",
      "Epoch 179/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3597 - accuracy: 0.8355 - val_loss: 0.2681 - val_accuracy: 0.8925\n",
      "Epoch 180/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3996 - accuracy: 0.8213 - val_loss: 0.2191 - val_accuracy: 0.8995\n",
      "Epoch 181/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3832 - accuracy: 0.8317 - val_loss: 0.2205 - val_accuracy: 0.9112\n",
      "Epoch 182/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3925 - accuracy: 0.8367 - val_loss: 0.2186 - val_accuracy: 0.9179\n",
      "Epoch 183/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3725 - accuracy: 0.8322 - val_loss: 0.2120 - val_accuracy: 0.9161\n",
      "Epoch 184/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3642 - accuracy: 0.8475 - val_loss: 0.2163 - val_accuracy: 0.8975\n",
      "Epoch 185/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3743 - accuracy: 0.8278 - val_loss: 0.2182 - val_accuracy: 0.9092\n",
      "Epoch 186/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3408 - accuracy: 0.8482 - val_loss: 0.2516 - val_accuracy: 0.9130\n",
      "Epoch 187/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3961 - accuracy: 0.8278 - val_loss: 0.2218 - val_accuracy: 0.8914\n",
      "Epoch 188/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3351 - accuracy: 0.8420 - val_loss: 0.2879 - val_accuracy: 0.9109\n",
      "Epoch 189/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4005 - accuracy: 0.8310 - val_loss: 0.2355 - val_accuracy: 0.9097\n",
      "Epoch 190/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3626 - accuracy: 0.8167 - val_loss: 0.2104 - val_accuracy: 0.9223\n",
      "Epoch 191/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4056 - accuracy: 0.8438 - val_loss: 0.2187 - val_accuracy: 0.9142\n",
      "Epoch 192/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3464 - accuracy: 0.8307 - val_loss: 0.2134 - val_accuracy: 0.9138\n",
      "Epoch 193/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3333 - accuracy: 0.8508 - val_loss: 0.2016 - val_accuracy: 0.9223\n",
      "Epoch 194/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3990 - accuracy: 0.8175 - val_loss: 0.2329 - val_accuracy: 0.9033\n",
      "Epoch 195/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3523 - accuracy: 0.8367 - val_loss: 0.2253 - val_accuracy: 0.9210\n",
      "Epoch 196/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3733 - accuracy: 0.8335 - val_loss: 0.1970 - val_accuracy: 0.9194\n",
      "Epoch 197/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3653 - accuracy: 0.8245 - val_loss: 0.2031 - val_accuracy: 0.9172\n",
      "Epoch 198/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3859 - accuracy: 0.8363 - val_loss: 0.1971 - val_accuracy: 0.9207\n",
      "Epoch 199/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3979 - accuracy: 0.8375 - val_loss: 0.2357 - val_accuracy: 0.9050\n",
      "Epoch 200/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3711 - accuracy: 0.8410 - val_loss: 0.2383 - val_accuracy: 0.9229\n",
      "Epoch 201/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3964 - accuracy: 0.8447 - val_loss: 0.2068 - val_accuracy: 0.9047\n",
      "Epoch 202/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3313 - accuracy: 0.8543 - val_loss: 0.2006 - val_accuracy: 0.9218\n",
      "Epoch 203/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3678 - accuracy: 0.8455 - val_loss: 0.2218 - val_accuracy: 0.9176\n",
      "Epoch 204/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3619 - accuracy: 0.8267 - val_loss: 0.2098 - val_accuracy: 0.9148\n",
      "Epoch 205/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3754 - accuracy: 0.8435 - val_loss: 0.2057 - val_accuracy: 0.9184\n",
      "Epoch 206/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3622 - accuracy: 0.8405 - val_loss: 0.2169 - val_accuracy: 0.9108\n",
      "Epoch 207/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3585 - accuracy: 0.8418 - val_loss: 0.2769 - val_accuracy: 0.9100\n",
      "Epoch 208/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4235 - accuracy: 0.8033 - val_loss: 0.2672 - val_accuracy: 0.8698\n",
      "Epoch 209/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3441 - accuracy: 0.8470 - val_loss: 0.2190 - val_accuracy: 0.9188\n",
      "Epoch 210/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3789 - accuracy: 0.8285 - val_loss: 0.2660 - val_accuracy: 0.9101\n",
      "Epoch 211/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3805 - accuracy: 0.8240 - val_loss: 0.2315 - val_accuracy: 0.9084\n",
      "Epoch 212/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3777 - accuracy: 0.8332 - val_loss: 0.3274 - val_accuracy: 0.8984\n",
      "Epoch 213/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3744 - accuracy: 0.8215 - val_loss: 0.2191 - val_accuracy: 0.9150\n",
      "Epoch 214/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3684 - accuracy: 0.8520 - val_loss: 0.2217 - val_accuracy: 0.9128\n",
      "Epoch 215/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4194 - accuracy: 0.8008 - val_loss: 0.2392 - val_accuracy: 0.8897\n",
      "Epoch 216/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3251 - accuracy: 0.8465 - val_loss: 0.2150 - val_accuracy: 0.9209\n",
      "Epoch 217/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3942 - accuracy: 0.8207 - val_loss: 0.2229 - val_accuracy: 0.8972\n",
      "Epoch 218/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3722 - accuracy: 0.8227 - val_loss: 0.2149 - val_accuracy: 0.9094\n",
      "Epoch 219/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3725 - accuracy: 0.8325 - val_loss: 0.2206 - val_accuracy: 0.8985\n",
      "Epoch 220/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3547 - accuracy: 0.8335 - val_loss: 0.2068 - val_accuracy: 0.9246\n",
      "Epoch 221/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3486 - accuracy: 0.8475 - val_loss: 0.2119 - val_accuracy: 0.9016\n",
      "Epoch 222/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3555 - accuracy: 0.8313 - val_loss: 0.2114 - val_accuracy: 0.9074\n",
      "Epoch 223/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3775 - accuracy: 0.8295 - val_loss: 0.2469 - val_accuracy: 0.9139\n",
      "Epoch 224/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4029 - accuracy: 0.8355 - val_loss: 0.2422 - val_accuracy: 0.8946\n",
      "Epoch 225/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4048 - accuracy: 0.8342 - val_loss: 0.2447 - val_accuracy: 0.8785\n",
      "Epoch 226/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3560 - accuracy: 0.8335 - val_loss: 0.2965 - val_accuracy: 0.8519\n",
      "Epoch 227/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4067 - accuracy: 0.8217 - val_loss: 0.2187 - val_accuracy: 0.9077\n",
      "Epoch 228/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3872 - accuracy: 0.8367 - val_loss: 0.2105 - val_accuracy: 0.9074\n",
      "Epoch 229/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3816 - accuracy: 0.8112 - val_loss: 0.2074 - val_accuracy: 0.9148\n",
      "Epoch 230/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3709 - accuracy: 0.8495 - val_loss: 0.2076 - val_accuracy: 0.9097\n",
      "Epoch 231/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3553 - accuracy: 0.8305 - val_loss: 0.2030 - val_accuracy: 0.9260\n",
      "Epoch 232/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4146 - accuracy: 0.8273 - val_loss: 0.2393 - val_accuracy: 0.8911\n",
      "Epoch 233/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3554 - accuracy: 0.8357 - val_loss: 0.2396 - val_accuracy: 0.9111\n",
      "Epoch 234/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4188 - accuracy: 0.8303 - val_loss: 0.2510 - val_accuracy: 0.8661\n",
      "Epoch 235/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3879 - accuracy: 0.8155 - val_loss: 0.2127 - val_accuracy: 0.9045\n",
      "Epoch 236/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3594 - accuracy: 0.8267 - val_loss: 0.2673 - val_accuracy: 0.8797\n",
      "Epoch 237/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3813 - accuracy: 0.8315 - val_loss: 0.2189 - val_accuracy: 0.9027\n",
      "Epoch 238/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3608 - accuracy: 0.8263 - val_loss: 0.2202 - val_accuracy: 0.9258\n",
      "Epoch 239/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3500 - accuracy: 0.8462 - val_loss: 0.2208 - val_accuracy: 0.9225\n",
      "Epoch 240/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4110 - accuracy: 0.8215 - val_loss: 0.2062 - val_accuracy: 0.9125\n",
      "Epoch 241/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3667 - accuracy: 0.8265 - val_loss: 0.4014 - val_accuracy: 0.8302\n",
      "Epoch 242/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4272 - accuracy: 0.8175 - val_loss: 0.2066 - val_accuracy: 0.9123\n",
      "Epoch 243/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3360 - accuracy: 0.8357 - val_loss: 0.2032 - val_accuracy: 0.9152\n",
      "Epoch 244/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3383 - accuracy: 0.8378 - val_loss: 0.2192 - val_accuracy: 0.8956\n",
      "Epoch 245/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3790 - accuracy: 0.8170 - val_loss: 0.2723 - val_accuracy: 0.9113\n",
      "Epoch 246/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3305 - accuracy: 0.8530 - val_loss: 0.2724 - val_accuracy: 0.9135\n",
      "Epoch 247/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3921 - accuracy: 0.8177 - val_loss: 0.2111 - val_accuracy: 0.8977\n",
      "Epoch 248/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3564 - accuracy: 0.8363 - val_loss: 0.2828 - val_accuracy: 0.8607\n",
      "Epoch 249/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3711 - accuracy: 0.8342 - val_loss: 0.2162 - val_accuracy: 0.9089\n",
      "Epoch 250/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3507 - accuracy: 0.8232 - val_loss: 0.2210 - val_accuracy: 0.9108\n",
      "Epoch 251/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3567 - accuracy: 0.8540 - val_loss: 0.2149 - val_accuracy: 0.9025\n",
      "Epoch 252/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3500 - accuracy: 0.8340 - val_loss: 0.2217 - val_accuracy: 0.9150\n",
      "Epoch 253/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3900 - accuracy: 0.8360 - val_loss: 0.2002 - val_accuracy: 0.9194\n",
      "Epoch 254/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3800 - accuracy: 0.8263 - val_loss: 0.2510 - val_accuracy: 0.8789\n",
      "Epoch 255/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3638 - accuracy: 0.8357 - val_loss: 0.1895 - val_accuracy: 0.9265\n",
      "Epoch 256/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3676 - accuracy: 0.8450 - val_loss: 0.2751 - val_accuracy: 0.8835\n",
      "Epoch 257/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4015 - accuracy: 0.8238 - val_loss: 0.2364 - val_accuracy: 0.9180\n",
      "Epoch 258/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3717 - accuracy: 0.8413 - val_loss: 0.2038 - val_accuracy: 0.9074\n",
      "Epoch 259/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3666 - accuracy: 0.8382 - val_loss: 0.2486 - val_accuracy: 0.9073\n",
      "Epoch 260/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3815 - accuracy: 0.8482 - val_loss: 0.2100 - val_accuracy: 0.9140\n",
      "Epoch 261/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4063 - accuracy: 0.8240 - val_loss: 0.2270 - val_accuracy: 0.8934\n",
      "Epoch 262/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3602 - accuracy: 0.8388 - val_loss: 0.2106 - val_accuracy: 0.9137\n",
      "Epoch 263/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3598 - accuracy: 0.8382 - val_loss: 0.2052 - val_accuracy: 0.9186\n",
      "Epoch 264/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3786 - accuracy: 0.8232 - val_loss: 0.3106 - val_accuracy: 0.9076\n",
      "Epoch 265/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4249 - accuracy: 0.8133 - val_loss: 0.2669 - val_accuracy: 0.8813\n",
      "Epoch 266/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3759 - accuracy: 0.8213 - val_loss: 0.2627 - val_accuracy: 0.8870\n",
      "Epoch 267/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3764 - accuracy: 0.8295 - val_loss: 0.2027 - val_accuracy: 0.9037\n",
      "Epoch 268/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3942 - accuracy: 0.8095 - val_loss: 0.2145 - val_accuracy: 0.9001\n",
      "Epoch 269/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3856 - accuracy: 0.8285 - val_loss: 0.2200 - val_accuracy: 0.9106\n",
      "Epoch 270/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3540 - accuracy: 0.8305 - val_loss: 0.2147 - val_accuracy: 0.9067\n",
      "Epoch 271/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3871 - accuracy: 0.8227 - val_loss: 0.2544 - val_accuracy: 0.9090\n",
      "Epoch 272/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3799 - accuracy: 0.8332 - val_loss: 0.2688 - val_accuracy: 0.9164\n",
      "Epoch 273/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3513 - accuracy: 0.8345 - val_loss: 0.2357 - val_accuracy: 0.9148\n",
      "Epoch 274/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3902 - accuracy: 0.8432 - val_loss: 0.2072 - val_accuracy: 0.9132\n",
      "Epoch 275/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4046 - accuracy: 0.8130 - val_loss: 0.2669 - val_accuracy: 0.8776\n",
      "Epoch 276/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3612 - accuracy: 0.8440 - val_loss: 0.2228 - val_accuracy: 0.9132\n",
      "Epoch 277/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3838 - accuracy: 0.8217 - val_loss: 0.3295 - val_accuracy: 0.8982\n",
      "Epoch 278/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3907 - accuracy: 0.8140 - val_loss: 0.2289 - val_accuracy: 0.9141\n",
      "Epoch 279/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3529 - accuracy: 0.8370 - val_loss: 0.2608 - val_accuracy: 0.9040\n",
      "Epoch 280/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3794 - accuracy: 0.8250 - val_loss: 0.2061 - val_accuracy: 0.9221\n",
      "Epoch 281/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3664 - accuracy: 0.8430 - val_loss: 0.2054 - val_accuracy: 0.9070\n",
      "Epoch 282/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4439 - accuracy: 0.7933 - val_loss: 0.2619 - val_accuracy: 0.8826\n",
      "Epoch 283/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3955 - accuracy: 0.8238 - val_loss: 0.2273 - val_accuracy: 0.9149\n",
      "Epoch 284/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4007 - accuracy: 0.8198 - val_loss: 0.2506 - val_accuracy: 0.8890\n",
      "Epoch 285/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3452 - accuracy: 0.8390 - val_loss: 0.2132 - val_accuracy: 0.9247\n",
      "Epoch 286/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3645 - accuracy: 0.8410 - val_loss: 0.2753 - val_accuracy: 0.9190\n",
      "Epoch 287/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4169 - accuracy: 0.8138 - val_loss: 0.2369 - val_accuracy: 0.9138\n",
      "Epoch 288/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3564 - accuracy: 0.8418 - val_loss: 0.2236 - val_accuracy: 0.8941\n",
      "Epoch 289/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3946 - accuracy: 0.8052 - val_loss: 0.2159 - val_accuracy: 0.9069\n",
      "Epoch 290/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4138 - accuracy: 0.8227 - val_loss: 0.2308 - val_accuracy: 0.9023\n",
      "Epoch 291/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3444 - accuracy: 0.8298 - val_loss: 0.2371 - val_accuracy: 0.9231\n",
      "Epoch 292/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3689 - accuracy: 0.8493 - val_loss: 0.2299 - val_accuracy: 0.9048\n",
      "Epoch 293/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3730 - accuracy: 0.8328 - val_loss: 0.2169 - val_accuracy: 0.9075\n",
      "Epoch 294/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3983 - accuracy: 0.8202 - val_loss: 0.2115 - val_accuracy: 0.9174\n",
      "Epoch 295/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3538 - accuracy: 0.8353 - val_loss: 0.2230 - val_accuracy: 0.9185\n",
      "Epoch 296/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4043 - accuracy: 0.8155 - val_loss: 0.2272 - val_accuracy: 0.9106\n",
      "Epoch 297/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3606 - accuracy: 0.8425 - val_loss: 0.2513 - val_accuracy: 0.9065\n",
      "Epoch 298/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3819 - accuracy: 0.8090 - val_loss: 0.2473 - val_accuracy: 0.9173\n",
      "Epoch 299/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3836 - accuracy: 0.8470 - val_loss: 0.2222 - val_accuracy: 0.9116\n",
      "Epoch 300/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3793 - accuracy: 0.8285 - val_loss: 0.2163 - val_accuracy: 0.9024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 06:38:36.706178: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-30 06:38:36.706204: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-10-30 06:38:36.986765: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-10-30 06:38:36.990044: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 28s 8ms/step - loss: 1.1853 - accuracy: 0.4874\n",
      "Epoch 1/300\n",
      "   1/1000 [..............................] - ETA: 26:36 - loss: 2.9475 - accuracy: 0.2500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 06:39:06.949692: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-30 06:39:06.949714: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6/1000 [..............................] - ETA: 1:12 - loss: 9.6074 - accuracy: 0.4167"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 06:39:07.596184: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-10-30 06:39:07.624006: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-10-30 06:39:07.712297: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 3066 callback api events and 3041 activity events. \n",
      "2022-10-30 06:39:07.774311: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  10/1000 [..............................] - ETA: 1:57 - loss: 10.3380 - accuracy: 0.4500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 06:39:07.839080: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_resnet_4/log_2/plugins/profile/2022_10_30_06_39_07\n",
      "\n",
      "2022-10-30 06:39:07.871909: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_resnet_4/log_2/plugins/profile/2022_10_30_06_39_07/rachanon-pc1.trace.json.gz\n",
      "2022-10-30 06:39:07.980855: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_resnet_4/log_2/plugins/profile/2022_10_30_06_39_07\n",
      "\n",
      "2022-10-30 06:39:07.987470: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_resnet_4/log_2/plugins/profile/2022_10_30_06_39_07/rachanon-pc1.memory_profile.json.gz\n",
      "2022-10-30 06:39:07.989223: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_resnet_4/log_2/plugins/profile/2022_10_30_06_39_07\n",
      "Dumped tool data for xplane.pb to log/baseline_resnet_4/log_2/plugins/profile/2022_10_30_06_39_07/rachanon-pc1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_resnet_4/log_2/plugins/profile/2022_10_30_06_39_07/rachanon-pc1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_resnet_4/log_2/plugins/profile/2022_10_30_06_39_07/rachanon-pc1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_resnet_4/log_2/plugins/profile/2022_10_30_06_39_07/rachanon-pc1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_resnet_4/log_2/plugins/profile/2022_10_30_06_39_07/rachanon-pc1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 39s 37ms/step - loss: 0.8957 - accuracy: 0.7132 - val_loss: 0.5873 - val_accuracy: 0.7583\n",
      "Epoch 2/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5415 - accuracy: 0.7222 - val_loss: 0.5165 - val_accuracy: 0.7810\n",
      "Epoch 3/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.5333 - accuracy: 0.7425 - val_loss: 0.4746 - val_accuracy: 0.7914\n",
      "Epoch 4/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5223 - accuracy: 0.7635 - val_loss: 0.4716 - val_accuracy: 0.7797\n",
      "Epoch 5/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4610 - accuracy: 0.7805 - val_loss: 0.5141 - val_accuracy: 0.8129\n",
      "Epoch 6/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4484 - accuracy: 0.8002 - val_loss: 0.3522 - val_accuracy: 0.8447\n",
      "Epoch 7/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4861 - accuracy: 0.7595 - val_loss: 0.4388 - val_accuracy: 0.7976\n",
      "Epoch 8/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4563 - accuracy: 0.7868 - val_loss: 0.3429 - val_accuracy: 0.8443\n",
      "Epoch 9/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4211 - accuracy: 0.8027 - val_loss: 0.3681 - val_accuracy: 0.8352\n",
      "Epoch 10/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4512 - accuracy: 0.7940 - val_loss: 0.3295 - val_accuracy: 0.8553\n",
      "Epoch 11/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4551 - accuracy: 0.7855 - val_loss: 0.3554 - val_accuracy: 0.8553\n",
      "Epoch 12/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4301 - accuracy: 0.8023 - val_loss: 0.3470 - val_accuracy: 0.8368\n",
      "Epoch 13/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.4066 - accuracy: 0.8160 - val_loss: 0.4076 - val_accuracy: 0.8039\n",
      "Epoch 14/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4700 - accuracy: 0.7753 - val_loss: 0.3086 - val_accuracy: 0.8565\n",
      "Epoch 15/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.4206 - accuracy: 0.8138 - val_loss: 0.3105 - val_accuracy: 0.8666\n",
      "Epoch 16/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4273 - accuracy: 0.8025 - val_loss: 0.3042 - val_accuracy: 0.8676\n",
      "Epoch 17/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4223 - accuracy: 0.7995 - val_loss: 0.3230 - val_accuracy: 0.8684\n",
      "Epoch 18/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4310 - accuracy: 0.8045 - val_loss: 0.4608 - val_accuracy: 0.8226\n",
      "Epoch 19/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4135 - accuracy: 0.8190 - val_loss: 0.3337 - val_accuracy: 0.8305\n",
      "Epoch 20/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3913 - accuracy: 0.8260 - val_loss: 0.2941 - val_accuracy: 0.8738\n",
      "Epoch 21/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4404 - accuracy: 0.7925 - val_loss: 0.3474 - val_accuracy: 0.8337\n",
      "Epoch 22/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4245 - accuracy: 0.8023 - val_loss: 0.3439 - val_accuracy: 0.8415\n",
      "Epoch 23/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3825 - accuracy: 0.8127 - val_loss: 0.2913 - val_accuracy: 0.8799\n",
      "Epoch 24/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4033 - accuracy: 0.8058 - val_loss: 0.4173 - val_accuracy: 0.8382\n",
      "Epoch 25/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4037 - accuracy: 0.8127 - val_loss: 0.3123 - val_accuracy: 0.8722\n",
      "Epoch 26/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3864 - accuracy: 0.8135 - val_loss: 0.3005 - val_accuracy: 0.8811\n",
      "Epoch 27/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3792 - accuracy: 0.8407 - val_loss: 0.2920 - val_accuracy: 0.8850\n",
      "Epoch 28/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4001 - accuracy: 0.8120 - val_loss: 0.3933 - val_accuracy: 0.8483\n",
      "Epoch 29/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3958 - accuracy: 0.8173 - val_loss: 0.2766 - val_accuracy: 0.8916\n",
      "Epoch 30/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3746 - accuracy: 0.8292 - val_loss: 0.3662 - val_accuracy: 0.8683\n",
      "Epoch 31/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4047 - accuracy: 0.8235 - val_loss: 0.2794 - val_accuracy: 0.8860\n",
      "Epoch 32/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3782 - accuracy: 0.8238 - val_loss: 0.2616 - val_accuracy: 0.8911\n",
      "Epoch 33/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4257 - accuracy: 0.8062 - val_loss: 0.3019 - val_accuracy: 0.8717\n",
      "Epoch 34/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3805 - accuracy: 0.8175 - val_loss: 0.3430 - val_accuracy: 0.8710\n",
      "Epoch 35/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4088 - accuracy: 0.8095 - val_loss: 0.2935 - val_accuracy: 0.8714\n",
      "Epoch 36/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3851 - accuracy: 0.8260 - val_loss: 0.2782 - val_accuracy: 0.8762\n",
      "Epoch 37/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3623 - accuracy: 0.8295 - val_loss: 0.3056 - val_accuracy: 0.8744\n",
      "Epoch 38/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3859 - accuracy: 0.8313 - val_loss: 0.3070 - val_accuracy: 0.8559\n",
      "Epoch 39/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4068 - accuracy: 0.8083 - val_loss: 0.2788 - val_accuracy: 0.8943\n",
      "Epoch 40/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4039 - accuracy: 0.8120 - val_loss: 0.3112 - val_accuracy: 0.8729\n",
      "Epoch 41/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3982 - accuracy: 0.8108 - val_loss: 0.2722 - val_accuracy: 0.8946\n",
      "Epoch 42/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4239 - accuracy: 0.8230 - val_loss: 0.2566 - val_accuracy: 0.8970\n",
      "Epoch 43/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3685 - accuracy: 0.8353 - val_loss: 0.2698 - val_accuracy: 0.8906\n",
      "Epoch 44/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3835 - accuracy: 0.8273 - val_loss: 0.2642 - val_accuracy: 0.8997\n",
      "Epoch 45/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3698 - accuracy: 0.8380 - val_loss: 0.2706 - val_accuracy: 0.8839\n",
      "Epoch 46/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4134 - accuracy: 0.8198 - val_loss: 0.2667 - val_accuracy: 0.8987\n",
      "Epoch 47/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4013 - accuracy: 0.8217 - val_loss: 0.4063 - val_accuracy: 0.8057\n",
      "Epoch 48/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3932 - accuracy: 0.8048 - val_loss: 0.2687 - val_accuracy: 0.8980\n",
      "Epoch 49/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3662 - accuracy: 0.8198 - val_loss: 0.2599 - val_accuracy: 0.9014\n",
      "Epoch 50/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3558 - accuracy: 0.8493 - val_loss: 0.3307 - val_accuracy: 0.8969\n",
      "Epoch 51/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3802 - accuracy: 0.8217 - val_loss: 0.2719 - val_accuracy: 0.8995\n",
      "Epoch 52/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3718 - accuracy: 0.8367 - val_loss: 0.2904 - val_accuracy: 0.8964\n",
      "Epoch 53/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3999 - accuracy: 0.8165 - val_loss: 0.2437 - val_accuracy: 0.9021\n",
      "Epoch 54/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3566 - accuracy: 0.8145 - val_loss: 0.2954 - val_accuracy: 0.8775\n",
      "Epoch 55/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4065 - accuracy: 0.7918 - val_loss: 0.2543 - val_accuracy: 0.9004\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3880 - accuracy: 0.7947 - val_loss: 0.2955 - val_accuracy: 0.8763\n",
      "Epoch 57/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3848 - accuracy: 0.8235 - val_loss: 0.2819 - val_accuracy: 0.8944\n",
      "Epoch 58/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3700 - accuracy: 0.8273 - val_loss: 0.2547 - val_accuracy: 0.8890\n",
      "Epoch 59/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3616 - accuracy: 0.8210 - val_loss: 0.3351 - val_accuracy: 0.8925\n",
      "Epoch 60/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4189 - accuracy: 0.8192 - val_loss: 0.3431 - val_accuracy: 0.8930\n",
      "Epoch 61/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3578 - accuracy: 0.8360 - val_loss: 0.2504 - val_accuracy: 0.9062\n",
      "Epoch 62/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3368 - accuracy: 0.8390 - val_loss: 0.2657 - val_accuracy: 0.9038\n",
      "Epoch 63/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3943 - accuracy: 0.8170 - val_loss: 0.2632 - val_accuracy: 0.9015\n",
      "Epoch 64/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3693 - accuracy: 0.8290 - val_loss: 0.2430 - val_accuracy: 0.9004\n",
      "Epoch 65/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3540 - accuracy: 0.8390 - val_loss: 0.2457 - val_accuracy: 0.9054\n",
      "Epoch 66/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3596 - accuracy: 0.8465 - val_loss: 0.2627 - val_accuracy: 0.8980\n",
      "Epoch 67/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3996 - accuracy: 0.8245 - val_loss: 0.3744 - val_accuracy: 0.8424\n",
      "Epoch 68/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3581 - accuracy: 0.8278 - val_loss: 0.2684 - val_accuracy: 0.9013\n",
      "Epoch 69/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3462 - accuracy: 0.8360 - val_loss: 0.2380 - val_accuracy: 0.8976\n",
      "Epoch 70/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3745 - accuracy: 0.8080 - val_loss: 0.2369 - val_accuracy: 0.9098\n",
      "Epoch 71/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3739 - accuracy: 0.8275 - val_loss: 0.2794 - val_accuracy: 0.8792\n",
      "Epoch 72/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3649 - accuracy: 0.8370 - val_loss: 0.2431 - val_accuracy: 0.9082\n",
      "Epoch 73/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3363 - accuracy: 0.8372 - val_loss: 0.2447 - val_accuracy: 0.9077\n",
      "Epoch 74/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3656 - accuracy: 0.8282 - val_loss: 0.3205 - val_accuracy: 0.8631\n",
      "Epoch 75/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3570 - accuracy: 0.8223 - val_loss: 0.2333 - val_accuracy: 0.9100\n",
      "Epoch 76/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3470 - accuracy: 0.8345 - val_loss: 0.2340 - val_accuracy: 0.9041\n",
      "Epoch 77/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3767 - accuracy: 0.8275 - val_loss: 0.2615 - val_accuracy: 0.9055\n",
      "Epoch 78/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4184 - accuracy: 0.8213 - val_loss: 0.2484 - val_accuracy: 0.9063\n",
      "Epoch 79/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3534 - accuracy: 0.8347 - val_loss: 0.2769 - val_accuracy: 0.8846\n",
      "Epoch 80/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3430 - accuracy: 0.8240 - val_loss: 0.2493 - val_accuracy: 0.9075\n",
      "Epoch 81/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4114 - accuracy: 0.8180 - val_loss: 0.3213 - val_accuracy: 0.8464\n",
      "Epoch 82/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3687 - accuracy: 0.8393 - val_loss: 0.2358 - val_accuracy: 0.9048\n",
      "Epoch 83/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3673 - accuracy: 0.8378 - val_loss: 0.2321 - val_accuracy: 0.9098\n",
      "Epoch 84/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3817 - accuracy: 0.8158 - val_loss: 0.2587 - val_accuracy: 0.9062\n",
      "Epoch 85/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3574 - accuracy: 0.8342 - val_loss: 0.3236 - val_accuracy: 0.8811\n",
      "Epoch 86/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3684 - accuracy: 0.8298 - val_loss: 0.2499 - val_accuracy: 0.9054\n",
      "Epoch 87/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3355 - accuracy: 0.8355 - val_loss: 0.2440 - val_accuracy: 0.9065\n",
      "Epoch 88/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3965 - accuracy: 0.8043 - val_loss: 0.3097 - val_accuracy: 0.8843\n",
      "Epoch 89/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3423 - accuracy: 0.8413 - val_loss: 0.2308 - val_accuracy: 0.9123\n",
      "Epoch 90/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3964 - accuracy: 0.8303 - val_loss: 0.3031 - val_accuracy: 0.9050\n",
      "Epoch 91/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3736 - accuracy: 0.8175 - val_loss: 0.2559 - val_accuracy: 0.9009\n",
      "Epoch 92/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3568 - accuracy: 0.8350 - val_loss: 0.2519 - val_accuracy: 0.9040\n",
      "Epoch 93/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3827 - accuracy: 0.8220 - val_loss: 0.3218 - val_accuracy: 0.8964\n",
      "Epoch 94/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3441 - accuracy: 0.8460 - val_loss: 0.2616 - val_accuracy: 0.8894\n",
      "Epoch 95/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3695 - accuracy: 0.8130 - val_loss: 0.3292 - val_accuracy: 0.8955\n",
      "Epoch 96/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3750 - accuracy: 0.8400 - val_loss: 0.2222 - val_accuracy: 0.9076\n",
      "Epoch 97/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3655 - accuracy: 0.8360 - val_loss: 0.2833 - val_accuracy: 0.9031\n",
      "Epoch 98/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3513 - accuracy: 0.8350 - val_loss: 0.2404 - val_accuracy: 0.9033\n",
      "Epoch 99/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3518 - accuracy: 0.8397 - val_loss: 0.2529 - val_accuracy: 0.8874\n",
      "Epoch 100/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3655 - accuracy: 0.8150 - val_loss: 0.2688 - val_accuracy: 0.8973\n",
      "Epoch 101/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3686 - accuracy: 0.8175 - val_loss: 0.2317 - val_accuracy: 0.9012\n",
      "Epoch 102/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3828 - accuracy: 0.8087 - val_loss: 0.2119 - val_accuracy: 0.9172\n",
      "Epoch 103/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3661 - accuracy: 0.8390 - val_loss: 0.2407 - val_accuracy: 0.8942\n",
      "Epoch 104/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3466 - accuracy: 0.8288 - val_loss: 0.2407 - val_accuracy: 0.9162\n",
      "Epoch 105/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3466 - accuracy: 0.8335 - val_loss: 0.2131 - val_accuracy: 0.9159\n",
      "Epoch 106/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3702 - accuracy: 0.8353 - val_loss: 0.2436 - val_accuracy: 0.9120\n",
      "Epoch 107/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4088 - accuracy: 0.8210 - val_loss: 0.2737 - val_accuracy: 0.8835\n",
      "Epoch 108/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3653 - accuracy: 0.8340 - val_loss: 0.2223 - val_accuracy: 0.9120\n",
      "Epoch 109/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3458 - accuracy: 0.8275 - val_loss: 0.2087 - val_accuracy: 0.9198\n",
      "Epoch 110/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3652 - accuracy: 0.8425 - val_loss: 0.2325 - val_accuracy: 0.9128\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3507 - accuracy: 0.8120 - val_loss: 0.2230 - val_accuracy: 0.9195\n",
      "Epoch 112/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3420 - accuracy: 0.8468 - val_loss: 0.2363 - val_accuracy: 0.9136\n",
      "Epoch 113/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3759 - accuracy: 0.8155 - val_loss: 0.2365 - val_accuracy: 0.9029\n",
      "Epoch 114/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3507 - accuracy: 0.8325 - val_loss: 0.3537 - val_accuracy: 0.8555\n",
      "Epoch 115/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3687 - accuracy: 0.8235 - val_loss: 0.2286 - val_accuracy: 0.9023\n",
      "Epoch 116/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3713 - accuracy: 0.8253 - val_loss: 0.2778 - val_accuracy: 0.8869\n",
      "Epoch 117/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3432 - accuracy: 0.8405 - val_loss: 0.2227 - val_accuracy: 0.9076\n",
      "Epoch 118/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3864 - accuracy: 0.8120 - val_loss: 0.3854 - val_accuracy: 0.8243\n",
      "Epoch 119/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3401 - accuracy: 0.8395 - val_loss: 0.4408 - val_accuracy: 0.8908\n",
      "Epoch 120/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3792 - accuracy: 0.8192 - val_loss: 0.2573 - val_accuracy: 0.8918\n",
      "Epoch 121/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3309 - accuracy: 0.8192 - val_loss: 0.2687 - val_accuracy: 0.8942\n",
      "Epoch 122/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4032 - accuracy: 0.8165 - val_loss: 0.2335 - val_accuracy: 0.9091\n",
      "Epoch 123/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3891 - accuracy: 0.8108 - val_loss: 0.2177 - val_accuracy: 0.9181\n",
      "Epoch 124/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3666 - accuracy: 0.8340 - val_loss: 0.2109 - val_accuracy: 0.9158\n",
      "Epoch 125/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3700 - accuracy: 0.8217 - val_loss: 0.2146 - val_accuracy: 0.9153\n",
      "Epoch 126/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3515 - accuracy: 0.8265 - val_loss: 0.2116 - val_accuracy: 0.9152\n",
      "Epoch 127/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3927 - accuracy: 0.8175 - val_loss: 0.3268 - val_accuracy: 0.8703\n",
      "Epoch 128/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3484 - accuracy: 0.8313 - val_loss: 0.2120 - val_accuracy: 0.9186\n",
      "Epoch 129/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3592 - accuracy: 0.8270 - val_loss: 0.2639 - val_accuracy: 0.8891\n",
      "Epoch 130/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3500 - accuracy: 0.8177 - val_loss: 0.2465 - val_accuracy: 0.9133\n",
      "Epoch 131/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3614 - accuracy: 0.8410 - val_loss: 0.2383 - val_accuracy: 0.9093\n",
      "Epoch 132/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3424 - accuracy: 0.8393 - val_loss: 0.2363 - val_accuracy: 0.9043\n",
      "Epoch 133/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3462 - accuracy: 0.8447 - val_loss: 0.2156 - val_accuracy: 0.9154\n",
      "Epoch 134/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3776 - accuracy: 0.8205 - val_loss: 0.2437 - val_accuracy: 0.8936\n",
      "Epoch 135/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3764 - accuracy: 0.8313 - val_loss: 0.2071 - val_accuracy: 0.9164\n",
      "Epoch 136/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3751 - accuracy: 0.8253 - val_loss: 0.2067 - val_accuracy: 0.9162\n",
      "Epoch 137/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3708 - accuracy: 0.8217 - val_loss: 0.2219 - val_accuracy: 0.9188\n",
      "Epoch 138/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3750 - accuracy: 0.8255 - val_loss: 0.2129 - val_accuracy: 0.9157\n",
      "Epoch 139/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3606 - accuracy: 0.8380 - val_loss: 0.2274 - val_accuracy: 0.9121\n",
      "Epoch 140/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3459 - accuracy: 0.8390 - val_loss: 0.2246 - val_accuracy: 0.9181\n",
      "Epoch 141/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3973 - accuracy: 0.8220 - val_loss: 0.2115 - val_accuracy: 0.9014\n",
      "Epoch 142/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3446 - accuracy: 0.8388 - val_loss: 0.2124 - val_accuracy: 0.9213\n",
      "Epoch 143/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3524 - accuracy: 0.8332 - val_loss: 0.2422 - val_accuracy: 0.8953\n",
      "Epoch 144/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3749 - accuracy: 0.8220 - val_loss: 0.2212 - val_accuracy: 0.9194\n",
      "Epoch 145/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3581 - accuracy: 0.8380 - val_loss: 0.2260 - val_accuracy: 0.9167\n",
      "Epoch 146/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3503 - accuracy: 0.8378 - val_loss: 0.2147 - val_accuracy: 0.9185\n",
      "Epoch 147/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3369 - accuracy: 0.8490 - val_loss: 0.2159 - val_accuracy: 0.9199\n",
      "Epoch 148/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4229 - accuracy: 0.8090 - val_loss: 0.2909 - val_accuracy: 0.8879\n",
      "Epoch 149/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3439 - accuracy: 0.8238 - val_loss: 0.2028 - val_accuracy: 0.9113\n",
      "Epoch 150/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3435 - accuracy: 0.8200 - val_loss: 0.2139 - val_accuracy: 0.9206\n",
      "Epoch 151/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3656 - accuracy: 0.8332 - val_loss: 0.2382 - val_accuracy: 0.9172\n",
      "Epoch 152/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3551 - accuracy: 0.8328 - val_loss: 0.2219 - val_accuracy: 0.9070\n",
      "Epoch 153/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3647 - accuracy: 0.8295 - val_loss: 0.2077 - val_accuracy: 0.9106\n",
      "Epoch 154/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3348 - accuracy: 0.8530 - val_loss: 0.2091 - val_accuracy: 0.9179\n",
      "Epoch 155/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3574 - accuracy: 0.8207 - val_loss: 0.2358 - val_accuracy: 0.8992\n",
      "Epoch 156/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3545 - accuracy: 0.8363 - val_loss: 0.2432 - val_accuracy: 0.9197\n",
      "Epoch 157/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3438 - accuracy: 0.8292 - val_loss: 0.2740 - val_accuracy: 0.9000\n",
      "Epoch 158/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3662 - accuracy: 0.8273 - val_loss: 0.2113 - val_accuracy: 0.9139\n",
      "Epoch 159/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3347 - accuracy: 0.8422 - val_loss: 0.2025 - val_accuracy: 0.9126\n",
      "Epoch 160/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3614 - accuracy: 0.8220 - val_loss: 0.2138 - val_accuracy: 0.9094\n",
      "Epoch 161/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3789 - accuracy: 0.8430 - val_loss: 0.2007 - val_accuracy: 0.9134\n",
      "Epoch 162/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3591 - accuracy: 0.8190 - val_loss: 0.2139 - val_accuracy: 0.8994\n",
      "Epoch 163/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3606 - accuracy: 0.8455 - val_loss: 0.2010 - val_accuracy: 0.9174\n",
      "Epoch 164/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3779 - accuracy: 0.8102 - val_loss: 0.2403 - val_accuracy: 0.9100\n",
      "Epoch 165/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3804 - accuracy: 0.8332 - val_loss: 0.2218 - val_accuracy: 0.9125\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3849 - accuracy: 0.8152 - val_loss: 0.2545 - val_accuracy: 0.8893\n",
      "Epoch 167/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3733 - accuracy: 0.8165 - val_loss: 0.2433 - val_accuracy: 0.9196\n",
      "Epoch 168/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3345 - accuracy: 0.8418 - val_loss: 0.2898 - val_accuracy: 0.8980\n",
      "Epoch 169/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3508 - accuracy: 0.8282 - val_loss: 0.2369 - val_accuracy: 0.9142\n",
      "Epoch 170/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3747 - accuracy: 0.8328 - val_loss: 0.2031 - val_accuracy: 0.9128\n",
      "Epoch 171/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3419 - accuracy: 0.8345 - val_loss: 0.2219 - val_accuracy: 0.9209\n",
      "Epoch 172/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3526 - accuracy: 0.8393 - val_loss: 0.3143 - val_accuracy: 0.8542\n",
      "Epoch 173/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3625 - accuracy: 0.8083 - val_loss: 0.2318 - val_accuracy: 0.9190\n",
      "Epoch 174/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3494 - accuracy: 0.8347 - val_loss: 0.2812 - val_accuracy: 0.8492\n",
      "Epoch 175/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3565 - accuracy: 0.8285 - val_loss: 0.1974 - val_accuracy: 0.9193\n",
      "Epoch 176/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3595 - accuracy: 0.8332 - val_loss: 0.2194 - val_accuracy: 0.9225\n",
      "Epoch 177/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3747 - accuracy: 0.8330 - val_loss: 0.2489 - val_accuracy: 0.8875\n",
      "Epoch 178/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4168 - accuracy: 0.8200 - val_loss: 0.2257 - val_accuracy: 0.9147\n",
      "Epoch 179/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3438 - accuracy: 0.8405 - val_loss: 0.2304 - val_accuracy: 0.9064\n",
      "Epoch 180/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4087 - accuracy: 0.8372 - val_loss: 0.2142 - val_accuracy: 0.9122\n",
      "Epoch 181/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3231 - accuracy: 0.8400 - val_loss: 0.2020 - val_accuracy: 0.9198\n",
      "Epoch 182/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4150 - accuracy: 0.8265 - val_loss: 0.2446 - val_accuracy: 0.9071\n",
      "Epoch 183/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3890 - accuracy: 0.8110 - val_loss: 0.2297 - val_accuracy: 0.9070\n",
      "Epoch 184/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3734 - accuracy: 0.8462 - val_loss: 0.2169 - val_accuracy: 0.8987\n",
      "Epoch 185/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3474 - accuracy: 0.8242 - val_loss: 0.2065 - val_accuracy: 0.9115\n",
      "Epoch 186/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3511 - accuracy: 0.8305 - val_loss: 0.2485 - val_accuracy: 0.9164\n",
      "Epoch 187/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3709 - accuracy: 0.8310 - val_loss: 0.2063 - val_accuracy: 0.9076\n",
      "Epoch 188/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3494 - accuracy: 0.8202 - val_loss: 0.2099 - val_accuracy: 0.9229\n",
      "Epoch 189/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3646 - accuracy: 0.8263 - val_loss: 0.2225 - val_accuracy: 0.9126\n",
      "Epoch 190/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3640 - accuracy: 0.8363 - val_loss: 0.2102 - val_accuracy: 0.9201\n",
      "Epoch 191/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3501 - accuracy: 0.8457 - val_loss: 0.2264 - val_accuracy: 0.9173\n",
      "Epoch 192/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3861 - accuracy: 0.8245 - val_loss: 0.2564 - val_accuracy: 0.8908\n",
      "Epoch 193/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3775 - accuracy: 0.8360 - val_loss: 0.2102 - val_accuracy: 0.9184\n",
      "Epoch 194/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3849 - accuracy: 0.8273 - val_loss: 0.2221 - val_accuracy: 0.8902\n",
      "Epoch 195/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3645 - accuracy: 0.8372 - val_loss: 0.2279 - val_accuracy: 0.9185\n",
      "Epoch 196/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3753 - accuracy: 0.8422 - val_loss: 0.2256 - val_accuracy: 0.9174\n",
      "Epoch 197/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4224 - accuracy: 0.8030 - val_loss: 0.2041 - val_accuracy: 0.9172\n",
      "Epoch 198/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3452 - accuracy: 0.8440 - val_loss: 0.2477 - val_accuracy: 0.8856\n",
      "Epoch 199/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3720 - accuracy: 0.8242 - val_loss: 0.2380 - val_accuracy: 0.8805\n",
      "Epoch 200/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3588 - accuracy: 0.8295 - val_loss: 0.2186 - val_accuracy: 0.9084\n",
      "Epoch 201/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3956 - accuracy: 0.8195 - val_loss: 0.1940 - val_accuracy: 0.9164\n",
      "Epoch 202/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3845 - accuracy: 0.8127 - val_loss: 0.1955 - val_accuracy: 0.9170\n",
      "Epoch 203/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3317 - accuracy: 0.8320 - val_loss: 0.2487 - val_accuracy: 0.9218\n",
      "Epoch 204/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3879 - accuracy: 0.8242 - val_loss: 0.2470 - val_accuracy: 0.8984\n",
      "Epoch 205/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3708 - accuracy: 0.8213 - val_loss: 0.2284 - val_accuracy: 0.9154\n",
      "Epoch 206/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3674 - accuracy: 0.8285 - val_loss: 0.2485 - val_accuracy: 0.9048\n",
      "Epoch 207/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3411 - accuracy: 0.8378 - val_loss: 0.2128 - val_accuracy: 0.9171\n",
      "Epoch 208/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4164 - accuracy: 0.8138 - val_loss: 0.2509 - val_accuracy: 0.8898\n",
      "Epoch 209/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3727 - accuracy: 0.8322 - val_loss: 0.2152 - val_accuracy: 0.9180\n",
      "Epoch 210/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3339 - accuracy: 0.8472 - val_loss: 0.2320 - val_accuracy: 0.9091\n",
      "Epoch 211/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3877 - accuracy: 0.8070 - val_loss: 0.2553 - val_accuracy: 0.9102\n",
      "Epoch 212/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3473 - accuracy: 0.8422 - val_loss: 0.2111 - val_accuracy: 0.9177\n",
      "Epoch 213/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3503 - accuracy: 0.8382 - val_loss: 0.2385 - val_accuracy: 0.9157\n",
      "Epoch 214/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3939 - accuracy: 0.8335 - val_loss: 0.2236 - val_accuracy: 0.9152\n",
      "Epoch 215/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3921 - accuracy: 0.8215 - val_loss: 0.4059 - val_accuracy: 0.8262\n",
      "Epoch 216/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4046 - accuracy: 0.8148 - val_loss: 0.2101 - val_accuracy: 0.9209\n",
      "Epoch 217/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3532 - accuracy: 0.8322 - val_loss: 0.2777 - val_accuracy: 0.8870\n",
      "Epoch 218/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3432 - accuracy: 0.8395 - val_loss: 0.2433 - val_accuracy: 0.9079\n",
      "Epoch 219/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3555 - accuracy: 0.8482 - val_loss: 0.2083 - val_accuracy: 0.9129\n",
      "Epoch 220/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3984 - accuracy: 0.8163 - val_loss: 0.2640 - val_accuracy: 0.9208\n",
      "Epoch 221/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3516 - accuracy: 0.8420 - val_loss: 0.1976 - val_accuracy: 0.9135\n",
      "Epoch 222/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3622 - accuracy: 0.8163 - val_loss: 0.2345 - val_accuracy: 0.9062\n",
      "Epoch 223/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3719 - accuracy: 0.8393 - val_loss: 0.2229 - val_accuracy: 0.9046\n",
      "Epoch 224/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3448 - accuracy: 0.8245 - val_loss: 0.2950 - val_accuracy: 0.8995\n",
      "Epoch 225/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3767 - accuracy: 0.8245 - val_loss: 0.2289 - val_accuracy: 0.9070\n",
      "Epoch 226/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3724 - accuracy: 0.8313 - val_loss: 0.2525 - val_accuracy: 0.8924\n",
      "Epoch 227/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3790 - accuracy: 0.8267 - val_loss: 0.2117 - val_accuracy: 0.8975\n",
      "Epoch 228/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3428 - accuracy: 0.8322 - val_loss: 0.2240 - val_accuracy: 0.9167\n",
      "Epoch 229/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3647 - accuracy: 0.8165 - val_loss: 0.1937 - val_accuracy: 0.9228\n",
      "Epoch 230/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3592 - accuracy: 0.8385 - val_loss: 0.2214 - val_accuracy: 0.9154\n",
      "Epoch 231/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3840 - accuracy: 0.8140 - val_loss: 0.2207 - val_accuracy: 0.9197\n",
      "Epoch 232/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4069 - accuracy: 0.8098 - val_loss: 0.3124 - val_accuracy: 0.8284\n",
      "Epoch 233/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3969 - accuracy: 0.8120 - val_loss: 0.2015 - val_accuracy: 0.9053\n",
      "Epoch 234/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4047 - accuracy: 0.7935 - val_loss: 0.2146 - val_accuracy: 0.9067\n",
      "Epoch 235/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3517 - accuracy: 0.8167 - val_loss: 0.2080 - val_accuracy: 0.9152\n",
      "Epoch 236/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3453 - accuracy: 0.8207 - val_loss: 0.2068 - val_accuracy: 0.8968\n",
      "Epoch 237/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3651 - accuracy: 0.8353 - val_loss: 0.2212 - val_accuracy: 0.9013\n",
      "Epoch 238/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3463 - accuracy: 0.8170 - val_loss: 0.2582 - val_accuracy: 0.9232\n",
      "Epoch 239/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3486 - accuracy: 0.8472 - val_loss: 0.2371 - val_accuracy: 0.9197\n",
      "Epoch 240/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3777 - accuracy: 0.8188 - val_loss: 0.2018 - val_accuracy: 0.9083\n",
      "Epoch 241/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3506 - accuracy: 0.8353 - val_loss: 0.3077 - val_accuracy: 0.8469\n",
      "Epoch 242/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3904 - accuracy: 0.8045 - val_loss: 0.2029 - val_accuracy: 0.9207\n",
      "Epoch 243/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4084 - accuracy: 0.8152 - val_loss: 0.2226 - val_accuracy: 0.9031\n",
      "Epoch 244/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3704 - accuracy: 0.8298 - val_loss: 0.2376 - val_accuracy: 0.9226\n",
      "Epoch 245/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4046 - accuracy: 0.8158 - val_loss: 0.2397 - val_accuracy: 0.9184\n",
      "Epoch 246/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3695 - accuracy: 0.8355 - val_loss: 0.2804 - val_accuracy: 0.9130\n",
      "Epoch 247/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3535 - accuracy: 0.8295 - val_loss: 0.4348 - val_accuracy: 0.8948\n",
      "Epoch 248/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3795 - accuracy: 0.8195 - val_loss: 0.1988 - val_accuracy: 0.9259\n",
      "Epoch 249/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3916 - accuracy: 0.7980 - val_loss: 0.2161 - val_accuracy: 0.9177\n",
      "Epoch 250/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3616 - accuracy: 0.8345 - val_loss: 0.2532 - val_accuracy: 0.9191\n",
      "Epoch 251/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3780 - accuracy: 0.8245 - val_loss: 0.2038 - val_accuracy: 0.9137\n",
      "Epoch 252/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3568 - accuracy: 0.8353 - val_loss: 0.2494 - val_accuracy: 0.9163\n",
      "Epoch 253/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3539 - accuracy: 0.8322 - val_loss: 0.2156 - val_accuracy: 0.9208\n",
      "Epoch 254/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4015 - accuracy: 0.8195 - val_loss: 0.2760 - val_accuracy: 0.8773\n",
      "Epoch 255/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3451 - accuracy: 0.8315 - val_loss: 0.1999 - val_accuracy: 0.9195\n",
      "Epoch 256/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3934 - accuracy: 0.8110 - val_loss: 0.2049 - val_accuracy: 0.9130\n",
      "Epoch 257/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3898 - accuracy: 0.8108 - val_loss: 0.2155 - val_accuracy: 0.9179\n",
      "Epoch 258/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3610 - accuracy: 0.8403 - val_loss: 0.2507 - val_accuracy: 0.8948\n",
      "Epoch 259/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3411 - accuracy: 0.8360 - val_loss: 0.3236 - val_accuracy: 0.8892\n",
      "Epoch 260/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3532 - accuracy: 0.8215 - val_loss: 0.2014 - val_accuracy: 0.9177\n",
      "Epoch 261/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3986 - accuracy: 0.8167 - val_loss: 0.1962 - val_accuracy: 0.9076\n",
      "Epoch 262/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3717 - accuracy: 0.8278 - val_loss: 0.2038 - val_accuracy: 0.9125\n",
      "Epoch 263/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3217 - accuracy: 0.8250 - val_loss: 0.1925 - val_accuracy: 0.9196\n",
      "Epoch 264/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4292 - accuracy: 0.8035 - val_loss: 0.2122 - val_accuracy: 0.9200\n",
      "Epoch 265/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3664 - accuracy: 0.8223 - val_loss: 0.1987 - val_accuracy: 0.9180\n",
      "Epoch 266/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3869 - accuracy: 0.8202 - val_loss: 0.3493 - val_accuracy: 0.8998\n",
      "Epoch 267/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3423 - accuracy: 0.8363 - val_loss: 0.2497 - val_accuracy: 0.9135\n",
      "Epoch 268/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4236 - accuracy: 0.8167 - val_loss: 0.2159 - val_accuracy: 0.8926\n",
      "Epoch 269/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3720 - accuracy: 0.8213 - val_loss: 0.2252 - val_accuracy: 0.9223\n",
      "Epoch 270/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4090 - accuracy: 0.8105 - val_loss: 0.2161 - val_accuracy: 0.9026\n",
      "Epoch 271/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3955 - accuracy: 0.8200 - val_loss: 0.2096 - val_accuracy: 0.9233\n",
      "Epoch 272/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3498 - accuracy: 0.8388 - val_loss: 0.2168 - val_accuracy: 0.9181\n",
      "Epoch 273/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3556 - accuracy: 0.8135 - val_loss: 0.2315 - val_accuracy: 0.9193\n",
      "Epoch 274/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4142 - accuracy: 0.8087 - val_loss: 0.2096 - val_accuracy: 0.9084\n",
      "Epoch 275/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3820 - accuracy: 0.8037 - val_loss: 0.2131 - val_accuracy: 0.9056\n",
      "Epoch 276/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3640 - accuracy: 0.8167 - val_loss: 0.2138 - val_accuracy: 0.9222\n",
      "Epoch 277/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3594 - accuracy: 0.8340 - val_loss: 0.2103 - val_accuracy: 0.9213\n",
      "Epoch 278/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4113 - accuracy: 0.8195 - val_loss: 0.2219 - val_accuracy: 0.9179\n",
      "Epoch 279/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3603 - accuracy: 0.8305 - val_loss: 0.2386 - val_accuracy: 0.9114\n",
      "Epoch 280/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3544 - accuracy: 0.8210 - val_loss: 0.2125 - val_accuracy: 0.9256\n",
      "Epoch 281/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3988 - accuracy: 0.8438 - val_loss: 0.2178 - val_accuracy: 0.9123\n",
      "Epoch 282/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3839 - accuracy: 0.8192 - val_loss: 0.2839 - val_accuracy: 0.8933\n",
      "Epoch 283/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3936 - accuracy: 0.8313 - val_loss: 0.2261 - val_accuracy: 0.9195\n",
      "Epoch 284/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3649 - accuracy: 0.8330 - val_loss: 0.2574 - val_accuracy: 0.8674\n",
      "Epoch 285/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3729 - accuracy: 0.8335 - val_loss: 0.1963 - val_accuracy: 0.9216\n",
      "Epoch 286/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3839 - accuracy: 0.8255 - val_loss: 0.2196 - val_accuracy: 0.8924\n",
      "Epoch 287/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4176 - accuracy: 0.8080 - val_loss: 0.2970 - val_accuracy: 0.8936\n",
      "Epoch 288/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3803 - accuracy: 0.8250 - val_loss: 0.2184 - val_accuracy: 0.9084\n",
      "Epoch 289/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3944 - accuracy: 0.7965 - val_loss: 0.2157 - val_accuracy: 0.9127\n",
      "Epoch 290/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3792 - accuracy: 0.8385 - val_loss: 0.2218 - val_accuracy: 0.9152\n",
      "Epoch 291/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3579 - accuracy: 0.8232 - val_loss: 0.2055 - val_accuracy: 0.9222\n",
      "Epoch 292/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3678 - accuracy: 0.8253 - val_loss: 0.2275 - val_accuracy: 0.9021\n",
      "Epoch 293/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3869 - accuracy: 0.8188 - val_loss: 0.2151 - val_accuracy: 0.8938\n",
      "Epoch 294/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3807 - accuracy: 0.7975 - val_loss: 0.2576 - val_accuracy: 0.9063\n",
      "Epoch 295/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4005 - accuracy: 0.8205 - val_loss: 0.2301 - val_accuracy: 0.8852\n",
      "Epoch 296/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3459 - accuracy: 0.8133 - val_loss: 0.2207 - val_accuracy: 0.9097\n",
      "Epoch 297/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3828 - accuracy: 0.8255 - val_loss: 0.2210 - val_accuracy: 0.8975\n",
      "Epoch 298/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3670 - accuracy: 0.8165 - val_loss: 0.2355 - val_accuracy: 0.9145\n",
      "Epoch 299/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3908 - accuracy: 0.8220 - val_loss: 0.2313 - val_accuracy: 0.8983\n",
      "Epoch 300/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3981 - accuracy: 0.8133 - val_loss: 0.2140 - val_accuracy: 0.9052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 09:38:09.634328: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-30 09:38:09.634354: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-10-30 09:38:09.911206: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-10-30 09:38:09.914026: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 28s 8ms/step - loss: 1.5464 - accuracy: 0.4730\n",
      "Epoch 1/300\n",
      "   1/1000 [..............................] - ETA: 35:11 - loss: 0.9347 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 09:38:40.633874: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-30 09:38:40.633897: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   7/1000 [..............................] - ETA: 1:00 - loss: 9.4980 - accuracy: 0.6071"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 09:38:41.304844: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-10-30 09:38:41.337840: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-10-30 09:38:41.434170: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 3066 callback api events and 3041 activity events. \n",
      "2022-10-30 09:38:41.501104: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  10/1000 [..............................] - ETA: 2:04 - loss: 9.2192 - accuracy: 0.6000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 09:38:41.575696: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_resnet_4/log_3/plugins/profile/2022_10_30_09_38_41\n",
      "\n",
      "2022-10-30 09:38:41.609696: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_resnet_4/log_3/plugins/profile/2022_10_30_09_38_41/rachanon-pc1.trace.json.gz\n",
      "2022-10-30 09:38:41.726347: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_resnet_4/log_3/plugins/profile/2022_10_30_09_38_41\n",
      "\n",
      "2022-10-30 09:38:41.733798: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_resnet_4/log_3/plugins/profile/2022_10_30_09_38_41/rachanon-pc1.memory_profile.json.gz\n",
      "2022-10-30 09:38:41.736499: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_resnet_4/log_3/plugins/profile/2022_10_30_09_38_41\n",
      "Dumped tool data for xplane.pb to log/baseline_resnet_4/log_3/plugins/profile/2022_10_30_09_38_41/rachanon-pc1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_resnet_4/log_3/plugins/profile/2022_10_30_09_38_41/rachanon-pc1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_resnet_4/log_3/plugins/profile/2022_10_30_09_38_41/rachanon-pc1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_resnet_4/log_3/plugins/profile/2022_10_30_09_38_41/rachanon-pc1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_resnet_4/log_3/plugins/profile/2022_10_30_09_38_41/rachanon-pc1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 39s 37ms/step - loss: 1.3797 - accuracy: 0.7048 - val_loss: 0.5865 - val_accuracy: 0.7871\n",
      "Epoch 2/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.5476 - accuracy: 0.7207 - val_loss: 0.4595 - val_accuracy: 0.7985\n",
      "Epoch 3/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.5353 - accuracy: 0.7175 - val_loss: 0.4387 - val_accuracy: 0.8041\n",
      "Epoch 4/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.5498 - accuracy: 0.7445 - val_loss: 0.4125 - val_accuracy: 0.8211\n",
      "Epoch 5/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4686 - accuracy: 0.7347 - val_loss: 0.4272 - val_accuracy: 0.8179\n",
      "Epoch 6/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4618 - accuracy: 0.7625 - val_loss: 0.4559 - val_accuracy: 0.8044\n",
      "Epoch 7/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4992 - accuracy: 0.7435 - val_loss: 0.4009 - val_accuracy: 0.8356\n",
      "Epoch 8/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4704 - accuracy: 0.7903 - val_loss: 0.3845 - val_accuracy: 0.8348\n",
      "Epoch 9/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4966 - accuracy: 0.7820 - val_loss: 0.3520 - val_accuracy: 0.8444\n",
      "Epoch 10/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4271 - accuracy: 0.7857 - val_loss: 0.3162 - val_accuracy: 0.8561\n",
      "Epoch 11/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4458 - accuracy: 0.7815 - val_loss: 0.4543 - val_accuracy: 0.8312\n",
      "Epoch 12/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4469 - accuracy: 0.7890 - val_loss: 0.4206 - val_accuracy: 0.8265\n",
      "Epoch 13/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4153 - accuracy: 0.8070 - val_loss: 0.3367 - val_accuracy: 0.8379\n",
      "Epoch 14/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4709 - accuracy: 0.7598 - val_loss: 0.3823 - val_accuracy: 0.8432\n",
      "Epoch 15/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4511 - accuracy: 0.8110 - val_loss: 0.3186 - val_accuracy: 0.8527\n",
      "Epoch 16/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4299 - accuracy: 0.7990 - val_loss: 0.2979 - val_accuracy: 0.8723\n",
      "Epoch 17/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4250 - accuracy: 0.8020 - val_loss: 0.3390 - val_accuracy: 0.8547\n",
      "Epoch 18/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4308 - accuracy: 0.8010 - val_loss: 0.4473 - val_accuracy: 0.7825\n",
      "Epoch 19/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4663 - accuracy: 0.8002 - val_loss: 0.3585 - val_accuracy: 0.8423\n",
      "Epoch 20/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4164 - accuracy: 0.7940 - val_loss: 0.2978 - val_accuracy: 0.8703\n",
      "Epoch 21/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4592 - accuracy: 0.7598 - val_loss: 0.3488 - val_accuracy: 0.8495\n",
      "Epoch 22/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4293 - accuracy: 0.8223 - val_loss: 0.3386 - val_accuracy: 0.8649\n",
      "Epoch 23/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4212 - accuracy: 0.8015 - val_loss: 0.2878 - val_accuracy: 0.8815\n",
      "Epoch 24/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3786 - accuracy: 0.8210 - val_loss: 0.3362 - val_accuracy: 0.8273\n",
      "Epoch 25/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4329 - accuracy: 0.7857 - val_loss: 0.2831 - val_accuracy: 0.8753\n",
      "Epoch 26/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4232 - accuracy: 0.8195 - val_loss: 0.3494 - val_accuracy: 0.8461\n",
      "Epoch 27/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4405 - accuracy: 0.8070 - val_loss: 0.2759 - val_accuracy: 0.8814\n",
      "Epoch 28/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4266 - accuracy: 0.7872 - val_loss: 0.3378 - val_accuracy: 0.8663\n",
      "Epoch 29/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3969 - accuracy: 0.8328 - val_loss: 0.2841 - val_accuracy: 0.8720\n",
      "Epoch 30/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3969 - accuracy: 0.8273 - val_loss: 0.3988 - val_accuracy: 0.8634\n",
      "Epoch 31/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3827 - accuracy: 0.8275 - val_loss: 0.3010 - val_accuracy: 0.8665\n",
      "Epoch 32/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4527 - accuracy: 0.8073 - val_loss: 0.3450 - val_accuracy: 0.8666\n",
      "Epoch 33/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4378 - accuracy: 0.8112 - val_loss: 0.3591 - val_accuracy: 0.8235\n",
      "Epoch 34/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3839 - accuracy: 0.8260 - val_loss: 0.3351 - val_accuracy: 0.8626\n",
      "Epoch 35/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4348 - accuracy: 0.8008 - val_loss: 0.3415 - val_accuracy: 0.8756\n",
      "Epoch 36/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4094 - accuracy: 0.8123 - val_loss: 0.3318 - val_accuracy: 0.8610\n",
      "Epoch 37/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3878 - accuracy: 0.8167 - val_loss: 0.2891 - val_accuracy: 0.8805\n",
      "Epoch 38/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3927 - accuracy: 0.8148 - val_loss: 0.2954 - val_accuracy: 0.8760\n",
      "Epoch 39/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4117 - accuracy: 0.8135 - val_loss: 0.2606 - val_accuracy: 0.8921\n",
      "Epoch 40/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3933 - accuracy: 0.8108 - val_loss: 0.2742 - val_accuracy: 0.8836\n",
      "Epoch 41/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4186 - accuracy: 0.8130 - val_loss: 0.2830 - val_accuracy: 0.8772\n",
      "Epoch 42/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3963 - accuracy: 0.8185 - val_loss: 0.2471 - val_accuracy: 0.8887\n",
      "Epoch 43/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3766 - accuracy: 0.8255 - val_loss: 0.2807 - val_accuracy: 0.8900\n",
      "Epoch 44/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3969 - accuracy: 0.8305 - val_loss: 0.2642 - val_accuracy: 0.8794\n",
      "Epoch 45/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3489 - accuracy: 0.8338 - val_loss: 0.2441 - val_accuracy: 0.8892\n",
      "Epoch 46/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3995 - accuracy: 0.8185 - val_loss: 0.2616 - val_accuracy: 0.8970\n",
      "Epoch 47/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3853 - accuracy: 0.8345 - val_loss: 0.3234 - val_accuracy: 0.8870\n",
      "Epoch 48/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4111 - accuracy: 0.8223 - val_loss: 0.2739 - val_accuracy: 0.8778\n",
      "Epoch 49/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4014 - accuracy: 0.8102 - val_loss: 0.2669 - val_accuracy: 0.8843\n",
      "Epoch 50/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3930 - accuracy: 0.8317 - val_loss: 0.2929 - val_accuracy: 0.8599\n",
      "Epoch 51/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3767 - accuracy: 0.8307 - val_loss: 0.2541 - val_accuracy: 0.8846\n",
      "Epoch 52/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3507 - accuracy: 0.8372 - val_loss: 0.2515 - val_accuracy: 0.8885\n",
      "Epoch 53/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4099 - accuracy: 0.7928 - val_loss: 0.2437 - val_accuracy: 0.9048\n",
      "Epoch 54/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3904 - accuracy: 0.8447 - val_loss: 0.2520 - val_accuracy: 0.8941\n",
      "Epoch 55/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3911 - accuracy: 0.8298 - val_loss: 0.2886 - val_accuracy: 0.8925\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3971 - accuracy: 0.8130 - val_loss: 0.2631 - val_accuracy: 0.8829\n",
      "Epoch 57/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3890 - accuracy: 0.8173 - val_loss: 0.3721 - val_accuracy: 0.8821\n",
      "Epoch 58/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4278 - accuracy: 0.8105 - val_loss: 0.3450 - val_accuracy: 0.8264\n",
      "Epoch 59/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3486 - accuracy: 0.8292 - val_loss: 0.2831 - val_accuracy: 0.8843\n",
      "Epoch 60/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4101 - accuracy: 0.8140 - val_loss: 0.2688 - val_accuracy: 0.9009\n",
      "Epoch 61/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3766 - accuracy: 0.8355 - val_loss: 0.2687 - val_accuracy: 0.8940\n",
      "Epoch 62/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4007 - accuracy: 0.8242 - val_loss: 0.2604 - val_accuracy: 0.8967\n",
      "Epoch 63/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3749 - accuracy: 0.8365 - val_loss: 0.3123 - val_accuracy: 0.8307\n",
      "Epoch 64/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3853 - accuracy: 0.8148 - val_loss: 0.2450 - val_accuracy: 0.8969\n",
      "Epoch 65/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3599 - accuracy: 0.8432 - val_loss: 0.2655 - val_accuracy: 0.8940\n",
      "Epoch 66/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3665 - accuracy: 0.8320 - val_loss: 0.2413 - val_accuracy: 0.8958\n",
      "Epoch 67/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4039 - accuracy: 0.8005 - val_loss: 0.2518 - val_accuracy: 0.9009\n",
      "Epoch 68/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3863 - accuracy: 0.8468 - val_loss: 0.2371 - val_accuracy: 0.9001\n",
      "Epoch 69/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3545 - accuracy: 0.8410 - val_loss: 0.2234 - val_accuracy: 0.9052\n",
      "Epoch 70/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3861 - accuracy: 0.8300 - val_loss: 0.2336 - val_accuracy: 0.8888\n",
      "Epoch 71/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3916 - accuracy: 0.8110 - val_loss: 0.3036 - val_accuracy: 0.8946\n",
      "Epoch 72/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4064 - accuracy: 0.8263 - val_loss: 0.2400 - val_accuracy: 0.9044\n",
      "Epoch 73/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3317 - accuracy: 0.8493 - val_loss: 0.2372 - val_accuracy: 0.9066\n",
      "Epoch 74/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4092 - accuracy: 0.8062 - val_loss: 0.2871 - val_accuracy: 0.9025\n",
      "Epoch 75/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3583 - accuracy: 0.8460 - val_loss: 0.2425 - val_accuracy: 0.8950\n",
      "Epoch 76/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3659 - accuracy: 0.8455 - val_loss: 0.2322 - val_accuracy: 0.9103\n",
      "Epoch 77/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3774 - accuracy: 0.8292 - val_loss: 0.2305 - val_accuracy: 0.8963\n",
      "Epoch 78/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3730 - accuracy: 0.8250 - val_loss: 0.2254 - val_accuracy: 0.9036\n",
      "Epoch 79/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4195 - accuracy: 0.8410 - val_loss: 0.2441 - val_accuracy: 0.9043\n",
      "Epoch 80/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3728 - accuracy: 0.8365 - val_loss: 0.2754 - val_accuracy: 0.8856\n",
      "Epoch 81/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4264 - accuracy: 0.8033 - val_loss: 0.2530 - val_accuracy: 0.8987\n",
      "Epoch 82/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3705 - accuracy: 0.8410 - val_loss: 0.2322 - val_accuracy: 0.8946\n",
      "Epoch 83/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3557 - accuracy: 0.8390 - val_loss: 0.3780 - val_accuracy: 0.8842\n",
      "Epoch 84/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3783 - accuracy: 0.8280 - val_loss: 0.2423 - val_accuracy: 0.8956\n",
      "Epoch 85/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3581 - accuracy: 0.8403 - val_loss: 0.3206 - val_accuracy: 0.8692\n",
      "Epoch 86/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3774 - accuracy: 0.8332 - val_loss: 0.2694 - val_accuracy: 0.8897\n",
      "Epoch 87/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3376 - accuracy: 0.8445 - val_loss: 0.2390 - val_accuracy: 0.9128\n",
      "Epoch 88/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3953 - accuracy: 0.8145 - val_loss: 0.4852 - val_accuracy: 0.8574\n",
      "Epoch 89/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3884 - accuracy: 0.8390 - val_loss: 0.2176 - val_accuracy: 0.8997\n",
      "Epoch 90/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3693 - accuracy: 0.8347 - val_loss: 0.2715 - val_accuracy: 0.9018\n",
      "Epoch 91/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3744 - accuracy: 0.8280 - val_loss: 0.2438 - val_accuracy: 0.8808\n",
      "Epoch 92/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3695 - accuracy: 0.8248 - val_loss: 0.2250 - val_accuracy: 0.9080\n",
      "Epoch 93/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3770 - accuracy: 0.8332 - val_loss: 0.2280 - val_accuracy: 0.8984\n",
      "Epoch 94/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3445 - accuracy: 0.8500 - val_loss: 0.2225 - val_accuracy: 0.9109\n",
      "Epoch 95/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3762 - accuracy: 0.8265 - val_loss: 0.2761 - val_accuracy: 0.9048\n",
      "Epoch 96/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3871 - accuracy: 0.8353 - val_loss: 0.3748 - val_accuracy: 0.7996\n",
      "Epoch 97/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3531 - accuracy: 0.8438 - val_loss: 0.2938 - val_accuracy: 0.9049\n",
      "Epoch 98/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3502 - accuracy: 0.8325 - val_loss: 0.2431 - val_accuracy: 0.8926\n",
      "Epoch 99/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3846 - accuracy: 0.8338 - val_loss: 0.2239 - val_accuracy: 0.9133\n",
      "Epoch 100/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3809 - accuracy: 0.8338 - val_loss: 0.2475 - val_accuracy: 0.9031\n",
      "Epoch 101/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3667 - accuracy: 0.8482 - val_loss: 0.2134 - val_accuracy: 0.9096\n",
      "Epoch 102/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3423 - accuracy: 0.8425 - val_loss: 0.2197 - val_accuracy: 0.9126\n",
      "Epoch 103/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3720 - accuracy: 0.8328 - val_loss: 0.2029 - val_accuracy: 0.9123\n",
      "Epoch 104/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3631 - accuracy: 0.8470 - val_loss: 0.2147 - val_accuracy: 0.9089\n",
      "Epoch 105/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3669 - accuracy: 0.8338 - val_loss: 0.2588 - val_accuracy: 0.9126\n",
      "Epoch 106/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3466 - accuracy: 0.8370 - val_loss: 0.2326 - val_accuracy: 0.9163\n",
      "Epoch 107/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3505 - accuracy: 0.8425 - val_loss: 0.2448 - val_accuracy: 0.9062\n",
      "Epoch 108/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3911 - accuracy: 0.8400 - val_loss: 0.2077 - val_accuracy: 0.9172\n",
      "Epoch 109/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3573 - accuracy: 0.8405 - val_loss: 0.2112 - val_accuracy: 0.9111\n",
      "Epoch 110/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3591 - accuracy: 0.8223 - val_loss: 0.2490 - val_accuracy: 0.9066\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3723 - accuracy: 0.8450 - val_loss: 0.2375 - val_accuracy: 0.8928\n",
      "Epoch 112/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3688 - accuracy: 0.8340 - val_loss: 0.2400 - val_accuracy: 0.9067\n",
      "Epoch 113/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3559 - accuracy: 0.8315 - val_loss: 0.2782 - val_accuracy: 0.9125\n",
      "Epoch 114/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3641 - accuracy: 0.8407 - val_loss: 0.2642 - val_accuracy: 0.9102\n",
      "Epoch 115/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3989 - accuracy: 0.8200 - val_loss: 0.2190 - val_accuracy: 0.9046\n",
      "Epoch 116/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4032 - accuracy: 0.8235 - val_loss: 0.2320 - val_accuracy: 0.9104\n",
      "Epoch 117/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3539 - accuracy: 0.8380 - val_loss: 0.2077 - val_accuracy: 0.9128\n",
      "Epoch 118/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3618 - accuracy: 0.8405 - val_loss: 0.2783 - val_accuracy: 0.8806\n",
      "Epoch 119/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3431 - accuracy: 0.8347 - val_loss: 0.2874 - val_accuracy: 0.8576\n",
      "Epoch 120/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3942 - accuracy: 0.8138 - val_loss: 0.2284 - val_accuracy: 0.9152\n",
      "Epoch 121/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3601 - accuracy: 0.8500 - val_loss: 0.2215 - val_accuracy: 0.9060\n",
      "Epoch 122/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3810 - accuracy: 0.8435 - val_loss: 0.2083 - val_accuracy: 0.9201\n",
      "Epoch 123/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3684 - accuracy: 0.8397 - val_loss: 0.2014 - val_accuracy: 0.9093\n",
      "Epoch 124/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3776 - accuracy: 0.8207 - val_loss: 0.2554 - val_accuracy: 0.9169\n",
      "Epoch 125/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3448 - accuracy: 0.8443 - val_loss: 0.2935 - val_accuracy: 0.9043\n",
      "Epoch 126/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3792 - accuracy: 0.8322 - val_loss: 0.2101 - val_accuracy: 0.9072\n",
      "Epoch 127/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4105 - accuracy: 0.8265 - val_loss: 0.4406 - val_accuracy: 0.8858\n",
      "Epoch 128/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3601 - accuracy: 0.8438 - val_loss: 0.1952 - val_accuracy: 0.9191\n",
      "Epoch 129/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3453 - accuracy: 0.8515 - val_loss: 0.2420 - val_accuracy: 0.9157\n",
      "Epoch 130/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3641 - accuracy: 0.8400 - val_loss: 0.2170 - val_accuracy: 0.9072\n",
      "Epoch 131/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3548 - accuracy: 0.8335 - val_loss: 0.2041 - val_accuracy: 0.9165\n",
      "Epoch 132/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3621 - accuracy: 0.8472 - val_loss: 0.2675 - val_accuracy: 0.9102\n",
      "Epoch 133/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3483 - accuracy: 0.8410 - val_loss: 0.2167 - val_accuracy: 0.9011\n",
      "Epoch 134/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3819 - accuracy: 0.8223 - val_loss: 0.2074 - val_accuracy: 0.9177\n",
      "Epoch 135/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3316 - accuracy: 0.8575 - val_loss: 0.2079 - val_accuracy: 0.9082\n",
      "Epoch 136/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3349 - accuracy: 0.8478 - val_loss: 0.1879 - val_accuracy: 0.9252\n",
      "Epoch 137/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3614 - accuracy: 0.8332 - val_loss: 0.1984 - val_accuracy: 0.9120\n",
      "Epoch 138/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3518 - accuracy: 0.8332 - val_loss: 0.2031 - val_accuracy: 0.9160\n",
      "Epoch 139/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3459 - accuracy: 0.8572 - val_loss: 0.2307 - val_accuracy: 0.9065\n",
      "Epoch 140/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3475 - accuracy: 0.8558 - val_loss: 0.2135 - val_accuracy: 0.9090\n",
      "Epoch 141/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3978 - accuracy: 0.8267 - val_loss: 0.2114 - val_accuracy: 0.9203\n",
      "Epoch 142/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3230 - accuracy: 0.8562 - val_loss: 0.2138 - val_accuracy: 0.9065\n",
      "Epoch 143/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3582 - accuracy: 0.8428 - val_loss: 0.2064 - val_accuracy: 0.9226\n",
      "Epoch 144/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3423 - accuracy: 0.8485 - val_loss: 0.2028 - val_accuracy: 0.9138\n",
      "Epoch 145/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3611 - accuracy: 0.8375 - val_loss: 0.2677 - val_accuracy: 0.8964\n",
      "Epoch 146/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3704 - accuracy: 0.8313 - val_loss: 0.2226 - val_accuracy: 0.9079\n",
      "Epoch 147/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3602 - accuracy: 0.8317 - val_loss: 0.1956 - val_accuracy: 0.9202\n",
      "Epoch 148/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3934 - accuracy: 0.8155 - val_loss: 0.2853 - val_accuracy: 0.9053\n",
      "Epoch 149/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3584 - accuracy: 0.8482 - val_loss: 0.2126 - val_accuracy: 0.9177\n",
      "Epoch 150/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4009 - accuracy: 0.8295 - val_loss: 0.2383 - val_accuracy: 0.9192\n",
      "Epoch 151/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3735 - accuracy: 0.8325 - val_loss: 0.3133 - val_accuracy: 0.8473\n",
      "Epoch 152/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3518 - accuracy: 0.8320 - val_loss: 0.2015 - val_accuracy: 0.9242\n",
      "Epoch 153/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3448 - accuracy: 0.8478 - val_loss: 0.2169 - val_accuracy: 0.9132\n",
      "Epoch 154/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3523 - accuracy: 0.8455 - val_loss: 0.1947 - val_accuracy: 0.9183\n",
      "Epoch 155/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3838 - accuracy: 0.8313 - val_loss: 0.2230 - val_accuracy: 0.9217\n",
      "Epoch 156/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3762 - accuracy: 0.8388 - val_loss: 0.2010 - val_accuracy: 0.9171\n",
      "Epoch 157/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3548 - accuracy: 0.8508 - val_loss: 0.3571 - val_accuracy: 0.9033\n",
      "Epoch 158/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3578 - accuracy: 0.8397 - val_loss: 0.2218 - val_accuracy: 0.9011\n",
      "Epoch 159/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3765 - accuracy: 0.8288 - val_loss: 0.1924 - val_accuracy: 0.9259\n",
      "Epoch 160/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3625 - accuracy: 0.8485 - val_loss: 0.2269 - val_accuracy: 0.9094\n",
      "Epoch 161/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3369 - accuracy: 0.8493 - val_loss: 0.2022 - val_accuracy: 0.9278\n",
      "Epoch 162/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4059 - accuracy: 0.8205 - val_loss: 0.2256 - val_accuracy: 0.9190\n",
      "Epoch 163/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3661 - accuracy: 0.8375 - val_loss: 0.1973 - val_accuracy: 0.9215\n",
      "Epoch 164/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3448 - accuracy: 0.8562 - val_loss: 0.2040 - val_accuracy: 0.9228\n",
      "Epoch 165/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3697 - accuracy: 0.8365 - val_loss: 0.2261 - val_accuracy: 0.9149\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3626 - accuracy: 0.8305 - val_loss: 0.1965 - val_accuracy: 0.9184\n",
      "Epoch 167/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3435 - accuracy: 0.8403 - val_loss: 0.2449 - val_accuracy: 0.9138\n",
      "Epoch 168/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3584 - accuracy: 0.8365 - val_loss: 0.2299 - val_accuracy: 0.9208\n",
      "Epoch 169/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3583 - accuracy: 0.8345 - val_loss: 0.2090 - val_accuracy: 0.9138\n",
      "Epoch 170/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3700 - accuracy: 0.8360 - val_loss: 0.2378 - val_accuracy: 0.9221\n",
      "Epoch 171/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3951 - accuracy: 0.8428 - val_loss: 0.2155 - val_accuracy: 0.9031\n",
      "Epoch 172/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3516 - accuracy: 0.8365 - val_loss: 0.2517 - val_accuracy: 0.8804\n",
      "Epoch 173/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3566 - accuracy: 0.8342 - val_loss: 0.2004 - val_accuracy: 0.9267\n",
      "Epoch 174/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3668 - accuracy: 0.8405 - val_loss: 0.3473 - val_accuracy: 0.8845\n",
      "Epoch 175/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3893 - accuracy: 0.8388 - val_loss: 0.2018 - val_accuracy: 0.9159\n",
      "Epoch 176/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3600 - accuracy: 0.8385 - val_loss: 0.2003 - val_accuracy: 0.9247\n",
      "Epoch 177/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3622 - accuracy: 0.8425 - val_loss: 0.2066 - val_accuracy: 0.9218\n",
      "Epoch 178/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3655 - accuracy: 0.8602 - val_loss: 0.2042 - val_accuracy: 0.9165\n",
      "Epoch 179/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3891 - accuracy: 0.8310 - val_loss: 0.2247 - val_accuracy: 0.8978\n",
      "Epoch 180/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3772 - accuracy: 0.8317 - val_loss: 0.2111 - val_accuracy: 0.9235\n",
      "Epoch 181/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3259 - accuracy: 0.8620 - val_loss: 0.2184 - val_accuracy: 0.9213\n",
      "Epoch 182/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3494 - accuracy: 0.8472 - val_loss: 0.2313 - val_accuracy: 0.8909\n",
      "Epoch 183/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3595 - accuracy: 0.8395 - val_loss: 0.2116 - val_accuracy: 0.9125\n",
      "Epoch 184/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3566 - accuracy: 0.8347 - val_loss: 0.1961 - val_accuracy: 0.9177\n",
      "Epoch 185/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3423 - accuracy: 0.8585 - val_loss: 0.1944 - val_accuracy: 0.9206\n",
      "Epoch 186/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3734 - accuracy: 0.8418 - val_loss: 0.1949 - val_accuracy: 0.9172\n",
      "Epoch 187/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3653 - accuracy: 0.8242 - val_loss: 0.1998 - val_accuracy: 0.9228\n",
      "Epoch 188/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3708 - accuracy: 0.8475 - val_loss: 0.2861 - val_accuracy: 0.9101\n",
      "Epoch 189/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3650 - accuracy: 0.8405 - val_loss: 0.1877 - val_accuracy: 0.9279\n",
      "Epoch 190/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3646 - accuracy: 0.8375 - val_loss: 0.1996 - val_accuracy: 0.9105\n",
      "Epoch 191/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3629 - accuracy: 0.8325 - val_loss: 0.2120 - val_accuracy: 0.9204\n",
      "Epoch 192/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3310 - accuracy: 0.8600 - val_loss: 0.8107 - val_accuracy: 0.6829\n",
      "Epoch 193/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3459 - accuracy: 0.8485 - val_loss: 0.1981 - val_accuracy: 0.9241\n",
      "Epoch 194/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3730 - accuracy: 0.8285 - val_loss: 0.2259 - val_accuracy: 0.9188\n",
      "Epoch 195/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3385 - accuracy: 0.8595 - val_loss: 0.2232 - val_accuracy: 0.9135\n",
      "Epoch 196/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3535 - accuracy: 0.8420 - val_loss: 0.1938 - val_accuracy: 0.9216\n",
      "Epoch 197/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4054 - accuracy: 0.8282 - val_loss: 0.2313 - val_accuracy: 0.9010\n",
      "Epoch 198/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3773 - accuracy: 0.8133 - val_loss: 0.2030 - val_accuracy: 0.9197\n",
      "Epoch 199/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4048 - accuracy: 0.8342 - val_loss: 0.2034 - val_accuracy: 0.9233\n",
      "Epoch 200/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3371 - accuracy: 0.8535 - val_loss: 0.2145 - val_accuracy: 0.9130\n",
      "Epoch 201/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3794 - accuracy: 0.8112 - val_loss: 0.2351 - val_accuracy: 0.9261\n",
      "Epoch 202/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3433 - accuracy: 0.8522 - val_loss: 0.1893 - val_accuracy: 0.9211\n",
      "Epoch 203/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3660 - accuracy: 0.8482 - val_loss: 0.2308 - val_accuracy: 0.9210\n",
      "Epoch 204/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3849 - accuracy: 0.8270 - val_loss: 0.2331 - val_accuracy: 0.8843\n",
      "Epoch 205/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3651 - accuracy: 0.8350 - val_loss: 0.2440 - val_accuracy: 0.9104\n",
      "Epoch 206/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3610 - accuracy: 0.8430 - val_loss: 0.2182 - val_accuracy: 0.9167\n",
      "Epoch 207/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3534 - accuracy: 0.8418 - val_loss: 0.2000 - val_accuracy: 0.9206\n",
      "Epoch 208/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3859 - accuracy: 0.8290 - val_loss: 0.2041 - val_accuracy: 0.9304\n",
      "Epoch 209/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3454 - accuracy: 0.8620 - val_loss: 0.2450 - val_accuracy: 0.9230\n",
      "Epoch 210/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3384 - accuracy: 0.8525 - val_loss: 0.2958 - val_accuracy: 0.9138\n",
      "Epoch 211/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3628 - accuracy: 0.8425 - val_loss: 0.2861 - val_accuracy: 0.8530\n",
      "Epoch 212/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3761 - accuracy: 0.8245 - val_loss: 0.1968 - val_accuracy: 0.9155\n",
      "Epoch 213/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3777 - accuracy: 0.8315 - val_loss: 0.2074 - val_accuracy: 0.9130\n",
      "Epoch 214/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3612 - accuracy: 0.8355 - val_loss: 0.1901 - val_accuracy: 0.9269\n",
      "Epoch 215/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3786 - accuracy: 0.8152 - val_loss: 0.2071 - val_accuracy: 0.9265\n",
      "Epoch 216/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3775 - accuracy: 0.8470 - val_loss: 0.2017 - val_accuracy: 0.9133\n",
      "Epoch 217/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3417 - accuracy: 0.8555 - val_loss: 0.2083 - val_accuracy: 0.9251\n",
      "Epoch 218/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3583 - accuracy: 0.8450 - val_loss: 0.2092 - val_accuracy: 0.9029\n",
      "Epoch 219/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3443 - accuracy: 0.8393 - val_loss: 0.1970 - val_accuracy: 0.9273\n",
      "Epoch 220/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4131 - accuracy: 0.8365 - val_loss: 0.2062 - val_accuracy: 0.9129\n",
      "Epoch 221/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3669 - accuracy: 0.8438 - val_loss: 0.2024 - val_accuracy: 0.9191\n",
      "Epoch 222/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4155 - accuracy: 0.8188 - val_loss: 0.2080 - val_accuracy: 0.9248\n",
      "Epoch 223/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3401 - accuracy: 0.8347 - val_loss: 0.1916 - val_accuracy: 0.9172\n",
      "Epoch 224/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4009 - accuracy: 0.8385 - val_loss: 0.1939 - val_accuracy: 0.9189\n",
      "Epoch 225/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3569 - accuracy: 0.8413 - val_loss: 0.2073 - val_accuracy: 0.9090\n",
      "Epoch 226/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3566 - accuracy: 0.8445 - val_loss: 0.2826 - val_accuracy: 0.9177\n",
      "Epoch 227/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3803 - accuracy: 0.8347 - val_loss: 0.2389 - val_accuracy: 0.9191\n",
      "Epoch 228/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3875 - accuracy: 0.8338 - val_loss: 0.2211 - val_accuracy: 0.8890\n",
      "Epoch 229/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3735 - accuracy: 0.8238 - val_loss: 0.1872 - val_accuracy: 0.9231\n",
      "Epoch 230/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3915 - accuracy: 0.8298 - val_loss: 0.2222 - val_accuracy: 0.9239\n",
      "Epoch 231/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3482 - accuracy: 0.8595 - val_loss: 0.1956 - val_accuracy: 0.9150\n",
      "Epoch 232/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3883 - accuracy: 0.8285 - val_loss: 0.2243 - val_accuracy: 0.8949\n",
      "Epoch 233/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3677 - accuracy: 0.8288 - val_loss: 0.2002 - val_accuracy: 0.9310\n",
      "Epoch 234/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4116 - accuracy: 0.8370 - val_loss: 0.2138 - val_accuracy: 0.9088\n",
      "Epoch 235/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3566 - accuracy: 0.8457 - val_loss: 0.2324 - val_accuracy: 0.9276\n",
      "Epoch 236/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3998 - accuracy: 0.8403 - val_loss: 0.2063 - val_accuracy: 0.9270\n",
      "Epoch 237/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3917 - accuracy: 0.8365 - val_loss: 0.2127 - val_accuracy: 0.9073\n",
      "Epoch 238/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3788 - accuracy: 0.8420 - val_loss: 0.2063 - val_accuracy: 0.9022\n",
      "Epoch 239/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3575 - accuracy: 0.8307 - val_loss: 0.1902 - val_accuracy: 0.9229\n",
      "Epoch 240/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3783 - accuracy: 0.8227 - val_loss: 0.2090 - val_accuracy: 0.9293\n",
      "Epoch 241/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3510 - accuracy: 0.8528 - val_loss: 0.2174 - val_accuracy: 0.9292\n",
      "Epoch 242/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4011 - accuracy: 0.8460 - val_loss: 0.2081 - val_accuracy: 0.9248\n",
      "Epoch 243/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4014 - accuracy: 0.8393 - val_loss: 0.1980 - val_accuracy: 0.9251\n",
      "Epoch 244/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3486 - accuracy: 0.8487 - val_loss: 0.1903 - val_accuracy: 0.9298\n",
      "Epoch 245/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3867 - accuracy: 0.8528 - val_loss: 0.2690 - val_accuracy: 0.8914\n",
      "Epoch 246/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3697 - accuracy: 0.8363 - val_loss: 0.2450 - val_accuracy: 0.9018\n",
      "Epoch 247/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4068 - accuracy: 0.8023 - val_loss: 0.1988 - val_accuracy: 0.9333\n",
      "Epoch 248/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3544 - accuracy: 0.8537 - val_loss: 0.1822 - val_accuracy: 0.9241\n",
      "Epoch 249/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4036 - accuracy: 0.8117 - val_loss: 0.1786 - val_accuracy: 0.9288\n",
      "Epoch 250/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3702 - accuracy: 0.8397 - val_loss: 0.1962 - val_accuracy: 0.9141\n",
      "Epoch 251/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3323 - accuracy: 0.8475 - val_loss: 0.1981 - val_accuracy: 0.9317\n",
      "Epoch 252/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4182 - accuracy: 0.8403 - val_loss: 0.2215 - val_accuracy: 0.9268\n",
      "Epoch 253/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3486 - accuracy: 0.8407 - val_loss: 0.1880 - val_accuracy: 0.9295\n",
      "Epoch 254/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3984 - accuracy: 0.8185 - val_loss: 0.2058 - val_accuracy: 0.9252\n",
      "Epoch 255/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3535 - accuracy: 0.8518 - val_loss: 0.2192 - val_accuracy: 0.9051\n",
      "Epoch 256/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4047 - accuracy: 0.8395 - val_loss: 0.2033 - val_accuracy: 0.9181\n",
      "Epoch 257/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3562 - accuracy: 0.8380 - val_loss: 0.2833 - val_accuracy: 0.8588\n",
      "Epoch 258/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3659 - accuracy: 0.8232 - val_loss: 0.1861 - val_accuracy: 0.9289\n",
      "Epoch 259/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3791 - accuracy: 0.8497 - val_loss: 0.2611 - val_accuracy: 0.9235\n",
      "Epoch 260/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3286 - accuracy: 0.8478 - val_loss: 0.2009 - val_accuracy: 0.9174\n",
      "Epoch 261/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3640 - accuracy: 0.8325 - val_loss: 0.2101 - val_accuracy: 0.9256\n",
      "Epoch 262/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3167 - accuracy: 0.8570 - val_loss: 0.2026 - val_accuracy: 0.9247\n",
      "Epoch 263/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4120 - accuracy: 0.8340 - val_loss: 0.2588 - val_accuracy: 0.9193\n",
      "Epoch 264/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3870 - accuracy: 0.8278 - val_loss: 0.2322 - val_accuracy: 0.8813\n",
      "Epoch 265/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3936 - accuracy: 0.8240 - val_loss: 0.2032 - val_accuracy: 0.9276\n",
      "Epoch 266/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3951 - accuracy: 0.8298 - val_loss: 0.2229 - val_accuracy: 0.9095\n",
      "Epoch 267/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3587 - accuracy: 0.8355 - val_loss: 0.2077 - val_accuracy: 0.9099\n",
      "Epoch 268/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3673 - accuracy: 0.8307 - val_loss: 0.2039 - val_accuracy: 0.9303\n",
      "Epoch 269/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3935 - accuracy: 0.8465 - val_loss: 0.2087 - val_accuracy: 0.9218\n",
      "Epoch 270/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3882 - accuracy: 0.8462 - val_loss: 0.1879 - val_accuracy: 0.9292\n",
      "Epoch 271/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3812 - accuracy: 0.8280 - val_loss: 0.2144 - val_accuracy: 0.8982\n",
      "Epoch 272/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3606 - accuracy: 0.8393 - val_loss: 0.2454 - val_accuracy: 0.8901\n",
      "Epoch 273/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3645 - accuracy: 0.8388 - val_loss: 0.1970 - val_accuracy: 0.9128\n",
      "Epoch 274/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3334 - accuracy: 0.8558 - val_loss: 0.2389 - val_accuracy: 0.9156\n",
      "Epoch 275/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3969 - accuracy: 0.8238 - val_loss: 0.6884 - val_accuracy: 0.8761\n",
      "Epoch 276/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3599 - accuracy: 0.8422 - val_loss: 0.1916 - val_accuracy: 0.9289\n",
      "Epoch 277/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3721 - accuracy: 0.8407 - val_loss: 0.6110 - val_accuracy: 0.8964\n",
      "Epoch 278/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4465 - accuracy: 0.8292 - val_loss: 0.2502 - val_accuracy: 0.8773\n",
      "Epoch 279/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3655 - accuracy: 0.8227 - val_loss: 0.2022 - val_accuracy: 0.9203\n",
      "Epoch 280/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3739 - accuracy: 0.8510 - val_loss: 0.1961 - val_accuracy: 0.9145\n",
      "Epoch 281/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3867 - accuracy: 0.8295 - val_loss: 0.1963 - val_accuracy: 0.9217\n",
      "Epoch 282/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3943 - accuracy: 0.8220 - val_loss: 0.2163 - val_accuracy: 0.9253\n",
      "Epoch 283/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3555 - accuracy: 0.8407 - val_loss: 0.1975 - val_accuracy: 0.9178\n",
      "Epoch 284/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3739 - accuracy: 0.8335 - val_loss: 0.3396 - val_accuracy: 0.9071\n",
      "Epoch 285/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3955 - accuracy: 0.8263 - val_loss: 0.2348 - val_accuracy: 0.9055\n",
      "Epoch 286/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3836 - accuracy: 0.8180 - val_loss: 0.2189 - val_accuracy: 0.9317\n",
      "Epoch 287/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4107 - accuracy: 0.8335 - val_loss: 0.1979 - val_accuracy: 0.9172\n",
      "Epoch 288/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3892 - accuracy: 0.8150 - val_loss: 0.1951 - val_accuracy: 0.9135\n",
      "Epoch 289/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3966 - accuracy: 0.8145 - val_loss: 0.2010 - val_accuracy: 0.9199\n",
      "Epoch 290/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3744 - accuracy: 0.8375 - val_loss: 0.2104 - val_accuracy: 0.9278\n",
      "Epoch 291/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3567 - accuracy: 0.8508 - val_loss: 0.1900 - val_accuracy: 0.9261\n",
      "Epoch 292/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3643 - accuracy: 0.8330 - val_loss: 0.2089 - val_accuracy: 0.9142\n",
      "Epoch 293/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3708 - accuracy: 0.8353 - val_loss: 0.2095 - val_accuracy: 0.9308\n",
      "Epoch 294/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3781 - accuracy: 0.8425 - val_loss: 0.2212 - val_accuracy: 0.9254\n",
      "Epoch 295/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3751 - accuracy: 0.8350 - val_loss: 0.1908 - val_accuracy: 0.9218\n",
      "Epoch 296/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3823 - accuracy: 0.8315 - val_loss: 0.2131 - val_accuracy: 0.9084\n",
      "Epoch 297/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3546 - accuracy: 0.8425 - val_loss: 0.2291 - val_accuracy: 0.9183\n",
      "Epoch 298/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3678 - accuracy: 0.8510 - val_loss: 0.2144 - val_accuracy: 0.8982\n",
      "Epoch 299/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3894 - accuracy: 0.8322 - val_loss: 0.1968 - val_accuracy: 0.9203\n",
      "Epoch 300/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3711 - accuracy: 0.8372 - val_loss: 0.2381 - val_accuracy: 0.9292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 12:37:39.876481: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-30 12:37:39.876507: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-10-30 12:37:40.142317: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-10-30 12:37:40.144653: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 28s 8ms/step - loss: 1.3052 - accuracy: 0.4687\n",
      "Epoch 1/300\n",
      "   1/1000 [..............................] - ETA: 34:33 - loss: 0.7784 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 12:38:10.573544: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-30 12:38:10.573570: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   8/1000 [..............................] - ETA: 42s - loss: 5.4362 - accuracy: 0.4688 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 12:38:11.206531: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-10-30 12:38:11.247081: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-10-30 12:38:11.352004: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 3066 callback api events and 3041 activity events. \n",
      "2022-10-30 12:38:11.422335: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-10-30 12:38:11.497200: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_resnet_4/log_4/plugins/profile/2022_10_30_12_38_11\n",
      "\n",
      "2022-10-30 12:38:11.530983: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_resnet_4/log_4/plugins/profile/2022_10_30_12_38_11/rachanon-pc1.trace.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  20/1000 [..............................] - ETA: 1:03 - loss: 6.3703 - accuracy: 0.5750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 12:38:11.656513: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_resnet_4/log_4/plugins/profile/2022_10_30_12_38_11\n",
      "\n",
      "2022-10-30 12:38:11.664002: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_resnet_4/log_4/plugins/profile/2022_10_30_12_38_11/rachanon-pc1.memory_profile.json.gz\n",
      "2022-10-30 12:38:11.666745: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_resnet_4/log_4/plugins/profile/2022_10_30_12_38_11\n",
      "Dumped tool data for xplane.pb to log/baseline_resnet_4/log_4/plugins/profile/2022_10_30_12_38_11/rachanon-pc1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_resnet_4/log_4/plugins/profile/2022_10_30_12_38_11/rachanon-pc1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_resnet_4/log_4/plugins/profile/2022_10_30_12_38_11/rachanon-pc1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_resnet_4/log_4/plugins/profile/2022_10_30_12_38_11/rachanon-pc1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_resnet_4/log_4/plugins/profile/2022_10_30_12_38_11/rachanon-pc1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 39s 37ms/step - loss: 1.0674 - accuracy: 0.7243 - val_loss: 0.4347 - val_accuracy: 0.8025\n",
      "Epoch 2/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.5404 - accuracy: 0.7253 - val_loss: 0.4226 - val_accuracy: 0.8020\n",
      "Epoch 3/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5056 - accuracy: 0.7542 - val_loss: 0.4140 - val_accuracy: 0.8043\n",
      "Epoch 4/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4952 - accuracy: 0.7433 - val_loss: 0.4207 - val_accuracy: 0.8092\n",
      "Epoch 5/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.4743 - accuracy: 0.7812 - val_loss: 0.3546 - val_accuracy: 0.8459\n",
      "Epoch 6/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4646 - accuracy: 0.7582 - val_loss: 0.4541 - val_accuracy: 0.8183\n",
      "Epoch 7/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4974 - accuracy: 0.7580 - val_loss: 0.3577 - val_accuracy: 0.8503\n",
      "Epoch 8/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4429 - accuracy: 0.7900 - val_loss: 0.3095 - val_accuracy: 0.8645\n",
      "Epoch 9/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.4289 - accuracy: 0.7818 - val_loss: 0.3564 - val_accuracy: 0.8435\n",
      "Epoch 10/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4533 - accuracy: 0.7740 - val_loss: 0.3259 - val_accuracy: 0.8514\n",
      "Epoch 11/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4448 - accuracy: 0.7747 - val_loss: 0.3492 - val_accuracy: 0.8554\n",
      "Epoch 12/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4327 - accuracy: 0.7905 - val_loss: 0.5004 - val_accuracy: 0.8234\n",
      "Epoch 13/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3983 - accuracy: 0.7860 - val_loss: 0.3445 - val_accuracy: 0.8278\n",
      "Epoch 14/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4424 - accuracy: 0.7540 - val_loss: 0.3380 - val_accuracy: 0.8540\n",
      "Epoch 15/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4148 - accuracy: 0.7862 - val_loss: 0.2916 - val_accuracy: 0.8709\n",
      "Epoch 16/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4005 - accuracy: 0.8043 - val_loss: 0.2926 - val_accuracy: 0.8761\n",
      "Epoch 17/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4213 - accuracy: 0.7910 - val_loss: 0.3009 - val_accuracy: 0.8653\n",
      "Epoch 18/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4348 - accuracy: 0.7853 - val_loss: 0.4183 - val_accuracy: 0.7919\n",
      "Epoch 19/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4401 - accuracy: 0.7807 - val_loss: 0.3130 - val_accuracy: 0.8629\n",
      "Epoch 20/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3885 - accuracy: 0.8140 - val_loss: 0.2875 - val_accuracy: 0.8805\n",
      "Epoch 21/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4207 - accuracy: 0.7897 - val_loss: 0.4495 - val_accuracy: 0.8284\n",
      "Epoch 22/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4270 - accuracy: 0.7965 - val_loss: 0.2824 - val_accuracy: 0.8680\n",
      "Epoch 23/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4260 - accuracy: 0.8085 - val_loss: 0.2738 - val_accuracy: 0.8792\n",
      "Epoch 24/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4281 - accuracy: 0.8025 - val_loss: 0.3454 - val_accuracy: 0.8346\n",
      "Epoch 25/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.4064 - accuracy: 0.8002 - val_loss: 0.3100 - val_accuracy: 0.8666\n",
      "Epoch 26/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4319 - accuracy: 0.7905 - val_loss: 0.2813 - val_accuracy: 0.8676\n",
      "Epoch 27/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3803 - accuracy: 0.8075 - val_loss: 0.2721 - val_accuracy: 0.8869\n",
      "Epoch 28/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4228 - accuracy: 0.7830 - val_loss: 0.3168 - val_accuracy: 0.8727\n",
      "Epoch 29/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3985 - accuracy: 0.8060 - val_loss: 0.2902 - val_accuracy: 0.8753\n",
      "Epoch 30/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4005 - accuracy: 0.8195 - val_loss: 0.4181 - val_accuracy: 0.8194\n",
      "Epoch 31/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3807 - accuracy: 0.8192 - val_loss: 0.2710 - val_accuracy: 0.8744\n",
      "Epoch 32/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4009 - accuracy: 0.8083 - val_loss: 0.2767 - val_accuracy: 0.8856\n",
      "Epoch 33/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4175 - accuracy: 0.8008 - val_loss: 0.2978 - val_accuracy: 0.8754\n",
      "Epoch 34/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3946 - accuracy: 0.8223 - val_loss: 0.4589 - val_accuracy: 0.8092\n",
      "Epoch 35/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3924 - accuracy: 0.8117 - val_loss: 0.2952 - val_accuracy: 0.8831\n",
      "Epoch 36/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3824 - accuracy: 0.8100 - val_loss: 0.2697 - val_accuracy: 0.8774\n",
      "Epoch 37/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3738 - accuracy: 0.8273 - val_loss: 0.2661 - val_accuracy: 0.8897\n",
      "Epoch 38/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3827 - accuracy: 0.8115 - val_loss: 0.2865 - val_accuracy: 0.8480\n",
      "Epoch 39/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4068 - accuracy: 0.8050 - val_loss: 0.2800 - val_accuracy: 0.8755\n",
      "Epoch 40/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3977 - accuracy: 0.8043 - val_loss: 0.2814 - val_accuracy: 0.8729\n",
      "Epoch 41/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3957 - accuracy: 0.8110 - val_loss: 0.2604 - val_accuracy: 0.8674\n",
      "Epoch 42/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3968 - accuracy: 0.8135 - val_loss: 0.2646 - val_accuracy: 0.8671\n",
      "Epoch 43/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3801 - accuracy: 0.8112 - val_loss: 0.2484 - val_accuracy: 0.8977\n",
      "Epoch 44/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3788 - accuracy: 0.8313 - val_loss: 0.2718 - val_accuracy: 0.8704\n",
      "Epoch 45/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3579 - accuracy: 0.8213 - val_loss: 0.2696 - val_accuracy: 0.8835\n",
      "Epoch 46/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3935 - accuracy: 0.8142 - val_loss: 0.2623 - val_accuracy: 0.9035\n",
      "Epoch 47/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3784 - accuracy: 0.8215 - val_loss: 0.2989 - val_accuracy: 0.8798\n",
      "Epoch 48/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3961 - accuracy: 0.8058 - val_loss: 0.2836 - val_accuracy: 0.8460\n",
      "Epoch 49/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3783 - accuracy: 0.8012 - val_loss: 0.2446 - val_accuracy: 0.8841\n",
      "Epoch 50/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3760 - accuracy: 0.8095 - val_loss: 0.2717 - val_accuracy: 0.8817\n",
      "Epoch 51/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3889 - accuracy: 0.8273 - val_loss: 0.3838 - val_accuracy: 0.8717\n",
      "Epoch 52/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3594 - accuracy: 0.8170 - val_loss: 0.2986 - val_accuracy: 0.8773\n",
      "Epoch 53/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4034 - accuracy: 0.8027 - val_loss: 0.3357 - val_accuracy: 0.8916\n",
      "Epoch 54/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3690 - accuracy: 0.8273 - val_loss: 0.3012 - val_accuracy: 0.8795\n",
      "Epoch 55/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4011 - accuracy: 0.8090 - val_loss: 0.2425 - val_accuracy: 0.8897\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3838 - accuracy: 0.8140 - val_loss: 0.2650 - val_accuracy: 0.8778\n",
      "Epoch 57/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3854 - accuracy: 0.8100 - val_loss: 0.2555 - val_accuracy: 0.8865\n",
      "Epoch 58/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3941 - accuracy: 0.8133 - val_loss: 0.2442 - val_accuracy: 0.8921\n",
      "Epoch 59/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3933 - accuracy: 0.8265 - val_loss: 0.2837 - val_accuracy: 0.8649\n",
      "Epoch 60/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4038 - accuracy: 0.7912 - val_loss: 0.2648 - val_accuracy: 0.8971\n",
      "Epoch 61/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3996 - accuracy: 0.8260 - val_loss: 0.2520 - val_accuracy: 0.8881\n",
      "Epoch 62/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3838 - accuracy: 0.8115 - val_loss: 0.2611 - val_accuracy: 0.8856\n",
      "Epoch 63/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3677 - accuracy: 0.8245 - val_loss: 0.2495 - val_accuracy: 0.8860\n",
      "Epoch 64/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4252 - accuracy: 0.8037 - val_loss: 0.2938 - val_accuracy: 0.8842\n",
      "Epoch 65/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3845 - accuracy: 0.8138 - val_loss: 0.2508 - val_accuracy: 0.8884\n",
      "Epoch 66/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3557 - accuracy: 0.8340 - val_loss: 0.2348 - val_accuracy: 0.8989\n",
      "Epoch 67/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4067 - accuracy: 0.7980 - val_loss: 0.2475 - val_accuracy: 0.9041\n",
      "Epoch 68/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3970 - accuracy: 0.8145 - val_loss: 0.2729 - val_accuracy: 0.8920\n",
      "Epoch 69/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3985 - accuracy: 0.8192 - val_loss: 0.2474 - val_accuracy: 0.8841\n",
      "Epoch 70/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3830 - accuracy: 0.8095 - val_loss: 0.2344 - val_accuracy: 0.8960\n",
      "Epoch 71/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3688 - accuracy: 0.8098 - val_loss: 0.5863 - val_accuracy: 0.6549\n",
      "Epoch 72/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3516 - accuracy: 0.8385 - val_loss: 0.2471 - val_accuracy: 0.8989\n",
      "Epoch 73/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3522 - accuracy: 0.8353 - val_loss: 0.2443 - val_accuracy: 0.8966\n",
      "Epoch 74/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4108 - accuracy: 0.7965 - val_loss: 0.2759 - val_accuracy: 0.8965\n",
      "Epoch 75/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3751 - accuracy: 0.8310 - val_loss: 0.2403 - val_accuracy: 0.8986\n",
      "Epoch 76/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3589 - accuracy: 0.8188 - val_loss: 0.2237 - val_accuracy: 0.9079\n",
      "Epoch 77/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4115 - accuracy: 0.8018 - val_loss: 0.2607 - val_accuracy: 0.8822\n",
      "Epoch 78/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3584 - accuracy: 0.8158 - val_loss: 0.2430 - val_accuracy: 0.8878\n",
      "Epoch 79/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3755 - accuracy: 0.8175 - val_loss: 0.2552 - val_accuracy: 0.9007\n",
      "Epoch 80/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3677 - accuracy: 0.8180 - val_loss: 0.2617 - val_accuracy: 0.8841\n",
      "Epoch 81/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3853 - accuracy: 0.7933 - val_loss: 0.2418 - val_accuracy: 0.9048\n",
      "Epoch 82/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3922 - accuracy: 0.8175 - val_loss: 0.2866 - val_accuracy: 0.8629\n",
      "Epoch 83/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3809 - accuracy: 0.8332 - val_loss: 0.2596 - val_accuracy: 0.9075\n",
      "Epoch 84/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3741 - accuracy: 0.8133 - val_loss: 0.2605 - val_accuracy: 0.8678\n",
      "Epoch 85/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3725 - accuracy: 0.8145 - val_loss: 0.2162 - val_accuracy: 0.9061\n",
      "Epoch 86/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3797 - accuracy: 0.8142 - val_loss: 0.2559 - val_accuracy: 0.8971\n",
      "Epoch 87/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3652 - accuracy: 0.8125 - val_loss: 0.2445 - val_accuracy: 0.9072\n",
      "Epoch 88/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3795 - accuracy: 0.8090 - val_loss: 0.3654 - val_accuracy: 0.8730\n",
      "Epoch 89/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3970 - accuracy: 0.8370 - val_loss: 0.2061 - val_accuracy: 0.9087\n",
      "Epoch 90/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3478 - accuracy: 0.8253 - val_loss: 0.2491 - val_accuracy: 0.9082\n",
      "Epoch 91/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3549 - accuracy: 0.8238 - val_loss: 0.2370 - val_accuracy: 0.8896\n",
      "Epoch 92/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3724 - accuracy: 0.8058 - val_loss: 0.2108 - val_accuracy: 0.9080\n",
      "Epoch 93/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3764 - accuracy: 0.8300 - val_loss: 0.2620 - val_accuracy: 0.8972\n",
      "Epoch 94/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3292 - accuracy: 0.8290 - val_loss: 0.2299 - val_accuracy: 0.9060\n",
      "Epoch 95/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4008 - accuracy: 0.8173 - val_loss: 0.2369 - val_accuracy: 0.9099\n",
      "Epoch 96/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3530 - accuracy: 0.8200 - val_loss: 0.2199 - val_accuracy: 0.9016\n",
      "Epoch 97/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3368 - accuracy: 0.8372 - val_loss: 0.2655 - val_accuracy: 0.9026\n",
      "Epoch 98/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3500 - accuracy: 0.8148 - val_loss: 0.2458 - val_accuracy: 0.8967\n",
      "Epoch 99/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3570 - accuracy: 0.8240 - val_loss: 0.2161 - val_accuracy: 0.9108\n",
      "Epoch 100/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3605 - accuracy: 0.8223 - val_loss: 0.2094 - val_accuracy: 0.9116\n",
      "Epoch 101/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4083 - accuracy: 0.8075 - val_loss: 0.2443 - val_accuracy: 0.8941\n",
      "Epoch 102/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3533 - accuracy: 0.8183 - val_loss: 0.3096 - val_accuracy: 0.8998\n",
      "Epoch 103/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3757 - accuracy: 0.8232 - val_loss: 0.2067 - val_accuracy: 0.9138\n",
      "Epoch 104/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3389 - accuracy: 0.8520 - val_loss: 0.2932 - val_accuracy: 0.8980\n",
      "Epoch 105/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3602 - accuracy: 0.8225 - val_loss: 0.2196 - val_accuracy: 0.9059\n",
      "Epoch 106/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3584 - accuracy: 0.8163 - val_loss: 0.2247 - val_accuracy: 0.9170\n",
      "Epoch 107/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3978 - accuracy: 0.8073 - val_loss: 0.2197 - val_accuracy: 0.8953\n",
      "Epoch 108/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3902 - accuracy: 0.8275 - val_loss: 0.2043 - val_accuracy: 0.9109\n",
      "Epoch 109/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3520 - accuracy: 0.8290 - val_loss: 0.2127 - val_accuracy: 0.9111\n",
      "Epoch 110/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3555 - accuracy: 0.8163 - val_loss: 0.2315 - val_accuracy: 0.9070\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3350 - accuracy: 0.8375 - val_loss: 0.2977 - val_accuracy: 0.8899\n",
      "Epoch 112/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3871 - accuracy: 0.8142 - val_loss: 0.2257 - val_accuracy: 0.9069\n",
      "Epoch 113/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3865 - accuracy: 0.8135 - val_loss: 0.2130 - val_accuracy: 0.9142\n",
      "Epoch 114/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3721 - accuracy: 0.8298 - val_loss: 0.2211 - val_accuracy: 0.9040\n",
      "Epoch 115/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3864 - accuracy: 0.8180 - val_loss: 0.2257 - val_accuracy: 0.9062\n",
      "Epoch 116/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3584 - accuracy: 0.8108 - val_loss: 0.2187 - val_accuracy: 0.8998\n",
      "Epoch 117/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3674 - accuracy: 0.8065 - val_loss: 0.2173 - val_accuracy: 0.9084\n",
      "Epoch 118/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4093 - accuracy: 0.8235 - val_loss: 0.2215 - val_accuracy: 0.9158\n",
      "Epoch 119/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3319 - accuracy: 0.8438 - val_loss: 0.2452 - val_accuracy: 0.8862\n",
      "Epoch 120/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3707 - accuracy: 0.7993 - val_loss: 0.2477 - val_accuracy: 0.9099\n",
      "Epoch 121/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3489 - accuracy: 0.8482 - val_loss: 0.2538 - val_accuracy: 0.8893\n",
      "Epoch 122/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3960 - accuracy: 0.8150 - val_loss: 0.2505 - val_accuracy: 0.8955\n",
      "Epoch 123/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3630 - accuracy: 0.8288 - val_loss: 0.2272 - val_accuracy: 0.8816\n",
      "Epoch 124/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3615 - accuracy: 0.8077 - val_loss: 0.2060 - val_accuracy: 0.9155\n",
      "Epoch 125/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3437 - accuracy: 0.8405 - val_loss: 0.2362 - val_accuracy: 0.9156\n",
      "Epoch 126/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3552 - accuracy: 0.8232 - val_loss: 0.2403 - val_accuracy: 0.8887\n",
      "Epoch 127/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3846 - accuracy: 0.8115 - val_loss: 0.2513 - val_accuracy: 0.9127\n",
      "Epoch 128/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3386 - accuracy: 0.8388 - val_loss: 0.2270 - val_accuracy: 0.9077\n",
      "Epoch 129/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3590 - accuracy: 0.8332 - val_loss: 0.4781 - val_accuracy: 0.7036\n",
      "Epoch 130/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3514 - accuracy: 0.8253 - val_loss: 0.2348 - val_accuracy: 0.9053\n",
      "Epoch 131/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3441 - accuracy: 0.8265 - val_loss: 0.2439 - val_accuracy: 0.9127\n",
      "Epoch 132/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3576 - accuracy: 0.8403 - val_loss: 0.4666 - val_accuracy: 0.7578\n",
      "Epoch 133/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3609 - accuracy: 0.8223 - val_loss: 0.2464 - val_accuracy: 0.8986\n",
      "Epoch 134/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3798 - accuracy: 0.8062 - val_loss: 0.2163 - val_accuracy: 0.9141\n",
      "Epoch 135/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3814 - accuracy: 0.8410 - val_loss: 0.2254 - val_accuracy: 0.9104\n",
      "Epoch 136/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3492 - accuracy: 0.8275 - val_loss: 0.2416 - val_accuracy: 0.9070\n",
      "Epoch 137/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3470 - accuracy: 0.8300 - val_loss: 0.2074 - val_accuracy: 0.9060\n",
      "Epoch 138/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3804 - accuracy: 0.8150 - val_loss: 0.2198 - val_accuracy: 0.9074\n",
      "Epoch 139/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3608 - accuracy: 0.8367 - val_loss: 0.2461 - val_accuracy: 0.8895\n",
      "Epoch 140/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3705 - accuracy: 0.8127 - val_loss: 0.2273 - val_accuracy: 0.8932\n",
      "Epoch 141/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3794 - accuracy: 0.8123 - val_loss: 0.2183 - val_accuracy: 0.9184\n",
      "Epoch 142/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3465 - accuracy: 0.8310 - val_loss: 0.2149 - val_accuracy: 0.9113\n",
      "Epoch 143/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3313 - accuracy: 0.8367 - val_loss: 0.2178 - val_accuracy: 0.9120\n",
      "Epoch 144/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3617 - accuracy: 0.8260 - val_loss: 0.2158 - val_accuracy: 0.9010\n",
      "Epoch 145/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3664 - accuracy: 0.8058 - val_loss: 0.7545 - val_accuracy: 0.6058\n",
      "Epoch 146/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3581 - accuracy: 0.8335 - val_loss: 0.2218 - val_accuracy: 0.9087\n",
      "Epoch 147/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3252 - accuracy: 0.8347 - val_loss: 0.2325 - val_accuracy: 0.9082\n",
      "Epoch 148/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3934 - accuracy: 0.7975 - val_loss: 0.2109 - val_accuracy: 0.9184\n",
      "Epoch 149/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3646 - accuracy: 0.8303 - val_loss: 0.2197 - val_accuracy: 0.9106\n",
      "Epoch 150/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3658 - accuracy: 0.8273 - val_loss: 0.1990 - val_accuracy: 0.9184\n",
      "Epoch 151/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3716 - accuracy: 0.8275 - val_loss: 0.2310 - val_accuracy: 0.8879\n",
      "Epoch 152/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3877 - accuracy: 0.8040 - val_loss: 0.2313 - val_accuracy: 0.9116\n",
      "Epoch 153/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3397 - accuracy: 0.8322 - val_loss: 0.2291 - val_accuracy: 0.9029\n",
      "Epoch 154/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3422 - accuracy: 0.8282 - val_loss: 0.2286 - val_accuracy: 0.9087\n",
      "Epoch 155/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4127 - accuracy: 0.8123 - val_loss: 0.3116 - val_accuracy: 0.8909\n",
      "Epoch 156/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3489 - accuracy: 0.8288 - val_loss: 0.2027 - val_accuracy: 0.9167\n",
      "Epoch 157/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3395 - accuracy: 0.8415 - val_loss: 0.2548 - val_accuracy: 0.9138\n",
      "Epoch 158/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3666 - accuracy: 0.8298 - val_loss: 0.2143 - val_accuracy: 0.8931\n",
      "Epoch 159/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3668 - accuracy: 0.8165 - val_loss: 0.2441 - val_accuracy: 0.9010\n",
      "Epoch 160/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3826 - accuracy: 0.8232 - val_loss: 0.2444 - val_accuracy: 0.8924\n",
      "Epoch 161/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3688 - accuracy: 0.8317 - val_loss: 0.2317 - val_accuracy: 0.9104\n",
      "Epoch 162/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3941 - accuracy: 0.8192 - val_loss: 0.2227 - val_accuracy: 0.9077\n",
      "Epoch 163/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3401 - accuracy: 0.8220 - val_loss: 0.2169 - val_accuracy: 0.9013\n",
      "Epoch 164/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3508 - accuracy: 0.8430 - val_loss: 0.2196 - val_accuracy: 0.9162\n",
      "Epoch 165/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3319 - accuracy: 0.8320 - val_loss: 0.2385 - val_accuracy: 0.8955\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3596 - accuracy: 0.8225 - val_loss: 0.2253 - val_accuracy: 0.9107\n",
      "Epoch 167/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3551 - accuracy: 0.8365 - val_loss: 0.2288 - val_accuracy: 0.9161\n",
      "Epoch 168/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3843 - accuracy: 0.8173 - val_loss: 0.2358 - val_accuracy: 0.9048\n",
      "Epoch 169/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3406 - accuracy: 0.8300 - val_loss: 0.2361 - val_accuracy: 0.9110\n",
      "Epoch 170/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3633 - accuracy: 0.8232 - val_loss: 0.2348 - val_accuracy: 0.8919\n",
      "Epoch 171/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3808 - accuracy: 0.8430 - val_loss: 0.2253 - val_accuracy: 0.9028\n",
      "Epoch 172/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3488 - accuracy: 0.8248 - val_loss: 0.2128 - val_accuracy: 0.9093\n",
      "Epoch 173/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3877 - accuracy: 0.8043 - val_loss: 0.2206 - val_accuracy: 0.9169\n",
      "Epoch 174/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3750 - accuracy: 0.8242 - val_loss: 0.2239 - val_accuracy: 0.9130\n",
      "Epoch 175/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3674 - accuracy: 0.8273 - val_loss: 0.2306 - val_accuracy: 0.9071\n",
      "Epoch 176/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3791 - accuracy: 0.8198 - val_loss: 0.2029 - val_accuracy: 0.9150\n",
      "Epoch 177/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3924 - accuracy: 0.8115 - val_loss: 0.2342 - val_accuracy: 0.9012\n",
      "Epoch 178/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3605 - accuracy: 0.8360 - val_loss: 0.2020 - val_accuracy: 0.9110\n",
      "Epoch 179/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3872 - accuracy: 0.8170 - val_loss: 0.2333 - val_accuracy: 0.9011\n",
      "Epoch 180/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3973 - accuracy: 0.7895 - val_loss: 0.2033 - val_accuracy: 0.9182\n",
      "Epoch 181/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3402 - accuracy: 0.8397 - val_loss: 0.2210 - val_accuracy: 0.9125\n",
      "Epoch 182/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3873 - accuracy: 0.8183 - val_loss: 0.2267 - val_accuracy: 0.9155\n",
      "Epoch 183/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3790 - accuracy: 0.8220 - val_loss: 0.2150 - val_accuracy: 0.9039\n",
      "Epoch 184/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3653 - accuracy: 0.8183 - val_loss: 0.2144 - val_accuracy: 0.9136\n",
      "Epoch 185/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3551 - accuracy: 0.8340 - val_loss: 0.2053 - val_accuracy: 0.9012\n",
      "Epoch 186/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3311 - accuracy: 0.8347 - val_loss: 0.2024 - val_accuracy: 0.9151\n",
      "Epoch 187/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3896 - accuracy: 0.8145 - val_loss: 0.2388 - val_accuracy: 0.9189\n",
      "Epoch 188/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3375 - accuracy: 0.8367 - val_loss: 0.2055 - val_accuracy: 0.9184\n",
      "Epoch 189/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3604 - accuracy: 0.8225 - val_loss: 0.2066 - val_accuracy: 0.9136\n",
      "Epoch 190/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3677 - accuracy: 0.8355 - val_loss: 0.3351 - val_accuracy: 0.8355\n",
      "Epoch 191/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3705 - accuracy: 0.8117 - val_loss: 0.1961 - val_accuracy: 0.9140\n",
      "Epoch 192/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3289 - accuracy: 0.8460 - val_loss: 0.2104 - val_accuracy: 0.9176\n",
      "Epoch 193/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3440 - accuracy: 0.8328 - val_loss: 0.2516 - val_accuracy: 0.8980\n",
      "Epoch 194/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4112 - accuracy: 0.8075 - val_loss: 0.2183 - val_accuracy: 0.9194\n",
      "Epoch 195/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3357 - accuracy: 0.8460 - val_loss: 0.2107 - val_accuracy: 0.9037\n",
      "Epoch 196/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3441 - accuracy: 0.8313 - val_loss: 0.2196 - val_accuracy: 0.9179\n",
      "Epoch 197/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3600 - accuracy: 0.8185 - val_loss: 0.2204 - val_accuracy: 0.8984\n",
      "Epoch 198/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3784 - accuracy: 0.8152 - val_loss: 0.3132 - val_accuracy: 0.8556\n",
      "Epoch 199/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3659 - accuracy: 0.8273 - val_loss: 0.2310 - val_accuracy: 0.9111\n",
      "Epoch 200/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3654 - accuracy: 0.8242 - val_loss: 0.2052 - val_accuracy: 0.9082\n",
      "Epoch 201/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3965 - accuracy: 0.7955 - val_loss: 0.1909 - val_accuracy: 0.9224\n",
      "Epoch 202/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3582 - accuracy: 0.8375 - val_loss: 0.1964 - val_accuracy: 0.9199\n",
      "Epoch 203/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3161 - accuracy: 0.8460 - val_loss: 0.2150 - val_accuracy: 0.9150\n",
      "Epoch 204/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3275 - accuracy: 0.8385 - val_loss: 0.2321 - val_accuracy: 0.9043\n",
      "Epoch 205/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3949 - accuracy: 0.8115 - val_loss: 0.2191 - val_accuracy: 0.9048\n",
      "Epoch 206/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3767 - accuracy: 0.8170 - val_loss: 0.2112 - val_accuracy: 0.9200\n",
      "Epoch 207/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3501 - accuracy: 0.8447 - val_loss: 0.2488 - val_accuracy: 0.9067\n",
      "Epoch 208/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3881 - accuracy: 0.8127 - val_loss: 0.3110 - val_accuracy: 0.8670\n",
      "Epoch 209/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3638 - accuracy: 0.8400 - val_loss: 0.1999 - val_accuracy: 0.9088\n",
      "Epoch 210/300\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.3939 - accuracy: 0.8230 - val_loss: 0.2511 - val_accuracy: 0.9146\n",
      "Epoch 211/300\n",
      "1000/1000 [==============================] - 35s 36ms/step - loss: 0.3576 - accuracy: 0.8270 - val_loss: 0.2037 - val_accuracy: 0.8938\n",
      "Epoch 212/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3776 - accuracy: 0.8200 - val_loss: 0.3513 - val_accuracy: 0.9027\n",
      "Epoch 213/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4223 - accuracy: 0.8298 - val_loss: 0.1979 - val_accuracy: 0.9100\n",
      "Epoch 214/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3268 - accuracy: 0.8382 - val_loss: 0.2235 - val_accuracy: 0.9218\n",
      "Epoch 215/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3854 - accuracy: 0.8202 - val_loss: 0.2276 - val_accuracy: 0.9235\n",
      "Epoch 216/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3788 - accuracy: 0.8280 - val_loss: 0.1973 - val_accuracy: 0.9196\n",
      "Epoch 217/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3567 - accuracy: 0.8360 - val_loss: 0.2322 - val_accuracy: 0.9139\n",
      "Epoch 218/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3696 - accuracy: 0.8300 - val_loss: 0.2444 - val_accuracy: 0.8918\n",
      "Epoch 219/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3745 - accuracy: 0.8065 - val_loss: 0.1996 - val_accuracy: 0.9247\n",
      "Epoch 220/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4203 - accuracy: 0.8420 - val_loss: 0.2351 - val_accuracy: 0.9099\n",
      "Epoch 221/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4008 - accuracy: 0.8185 - val_loss: 0.2060 - val_accuracy: 0.9124\n",
      "Epoch 222/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3888 - accuracy: 0.8148 - val_loss: 0.2122 - val_accuracy: 0.9148\n",
      "Epoch 223/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3679 - accuracy: 0.8102 - val_loss: 0.2241 - val_accuracy: 0.8811\n",
      "Epoch 224/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3605 - accuracy: 0.8270 - val_loss: 0.2266 - val_accuracy: 0.9067\n",
      "Epoch 225/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4021 - accuracy: 0.8105 - val_loss: 0.2526 - val_accuracy: 0.8877\n",
      "Epoch 226/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3707 - accuracy: 0.8292 - val_loss: 0.2249 - val_accuracy: 0.9191\n",
      "Epoch 227/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3663 - accuracy: 0.8248 - val_loss: 0.1987 - val_accuracy: 0.9197\n",
      "Epoch 228/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3559 - accuracy: 0.8395 - val_loss: 0.2426 - val_accuracy: 0.9184\n",
      "Epoch 229/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3637 - accuracy: 0.8365 - val_loss: 0.2118 - val_accuracy: 0.9169\n",
      "Epoch 230/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3803 - accuracy: 0.8338 - val_loss: 0.2095 - val_accuracy: 0.9163\n",
      "Epoch 231/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3883 - accuracy: 0.8400 - val_loss: 0.2258 - val_accuracy: 0.9121\n",
      "Epoch 232/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3411 - accuracy: 0.8250 - val_loss: 0.2101 - val_accuracy: 0.9019\n",
      "Epoch 233/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3981 - accuracy: 0.8130 - val_loss: 0.2411 - val_accuracy: 0.9211\n",
      "Epoch 234/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3983 - accuracy: 0.8160 - val_loss: 0.2244 - val_accuracy: 0.9106\n",
      "Epoch 235/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3829 - accuracy: 0.8235 - val_loss: 0.2293 - val_accuracy: 0.9031\n",
      "Epoch 236/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4068 - accuracy: 0.8230 - val_loss: 0.1989 - val_accuracy: 0.9149\n",
      "Epoch 237/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3529 - accuracy: 0.8267 - val_loss: 0.2041 - val_accuracy: 0.9198\n",
      "Epoch 238/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3535 - accuracy: 0.8405 - val_loss: 0.2063 - val_accuracy: 0.9045\n",
      "Epoch 239/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3707 - accuracy: 0.8230 - val_loss: 0.2029 - val_accuracy: 0.9164\n",
      "Epoch 240/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3833 - accuracy: 0.8150 - val_loss: 0.1955 - val_accuracy: 0.9193\n",
      "Epoch 241/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4226 - accuracy: 0.8230 - val_loss: 0.2828 - val_accuracy: 0.8714\n",
      "Epoch 242/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3718 - accuracy: 0.8332 - val_loss: 0.1898 - val_accuracy: 0.9198\n",
      "Epoch 243/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3885 - accuracy: 0.8257 - val_loss: 0.2227 - val_accuracy: 0.8972\n",
      "Epoch 244/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3532 - accuracy: 0.8205 - val_loss: 0.2073 - val_accuracy: 0.9083\n",
      "Epoch 245/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3462 - accuracy: 0.8403 - val_loss: 0.2023 - val_accuracy: 0.9092\n",
      "Epoch 246/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3880 - accuracy: 0.8232 - val_loss: 0.2003 - val_accuracy: 0.9053\n",
      "Epoch 247/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3745 - accuracy: 0.8098 - val_loss: 0.2210 - val_accuracy: 0.9230\n",
      "Epoch 248/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3842 - accuracy: 0.8345 - val_loss: 0.2198 - val_accuracy: 0.8931\n",
      "Epoch 249/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3929 - accuracy: 0.8142 - val_loss: 0.2259 - val_accuracy: 0.9101\n",
      "Epoch 250/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3848 - accuracy: 0.8207 - val_loss: 0.2338 - val_accuracy: 0.8939\n",
      "Epoch 251/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3951 - accuracy: 0.7977 - val_loss: 0.1974 - val_accuracy: 0.9181\n",
      "Epoch 252/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3711 - accuracy: 0.8313 - val_loss: 0.2009 - val_accuracy: 0.9164\n",
      "Epoch 253/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3418 - accuracy: 0.8307 - val_loss: 0.2254 - val_accuracy: 0.9079\n",
      "Epoch 254/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4163 - accuracy: 0.7828 - val_loss: 0.2916 - val_accuracy: 0.9160\n",
      "Epoch 255/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3755 - accuracy: 0.8410 - val_loss: 0.2014 - val_accuracy: 0.9203\n",
      "Epoch 256/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4282 - accuracy: 0.8250 - val_loss: 0.2331 - val_accuracy: 0.8856\n",
      "Epoch 257/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3793 - accuracy: 0.8248 - val_loss: 0.2123 - val_accuracy: 0.9000\n",
      "Epoch 258/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3536 - accuracy: 0.8205 - val_loss: 0.2116 - val_accuracy: 0.9234\n",
      "Epoch 259/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3587 - accuracy: 0.8393 - val_loss: 0.2111 - val_accuracy: 0.9214\n",
      "Epoch 260/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3406 - accuracy: 0.8440 - val_loss: 0.2638 - val_accuracy: 0.9082\n",
      "Epoch 261/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3901 - accuracy: 0.8125 - val_loss: 0.2187 - val_accuracy: 0.9233\n",
      "Epoch 262/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3543 - accuracy: 0.8418 - val_loss: 0.1900 - val_accuracy: 0.9197\n",
      "Epoch 263/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3376 - accuracy: 0.8370 - val_loss: 0.2044 - val_accuracy: 0.9190\n",
      "Epoch 264/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3813 - accuracy: 0.8347 - val_loss: 0.2203 - val_accuracy: 0.8872\n",
      "Epoch 265/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3599 - accuracy: 0.8155 - val_loss: 0.2003 - val_accuracy: 0.9152\n",
      "Epoch 266/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3970 - accuracy: 0.8102 - val_loss: 0.2396 - val_accuracy: 0.9118\n",
      "Epoch 267/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3435 - accuracy: 0.8300 - val_loss: 0.2266 - val_accuracy: 0.9127\n",
      "Epoch 268/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4016 - accuracy: 0.8027 - val_loss: 0.2338 - val_accuracy: 0.9233\n",
      "Epoch 269/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3515 - accuracy: 0.8460 - val_loss: 0.1905 - val_accuracy: 0.9201\n",
      "Epoch 270/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4024 - accuracy: 0.8238 - val_loss: 0.3267 - val_accuracy: 0.9053\n",
      "Epoch 271/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3736 - accuracy: 0.8325 - val_loss: 0.2214 - val_accuracy: 0.8901\n",
      "Epoch 272/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3971 - accuracy: 0.8345 - val_loss: 1.1827 - val_accuracy: 0.5866\n",
      "Epoch 273/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3861 - accuracy: 0.8198 - val_loss: 0.1885 - val_accuracy: 0.9194\n",
      "Epoch 274/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3284 - accuracy: 0.8380 - val_loss: 0.2221 - val_accuracy: 0.9186\n",
      "Epoch 275/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4252 - accuracy: 0.8055 - val_loss: 0.3357 - val_accuracy: 0.9153\n",
      "Epoch 276/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3915 - accuracy: 0.8232 - val_loss: 0.2046 - val_accuracy: 0.9040\n",
      "Epoch 277/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4337 - accuracy: 0.8183 - val_loss: 0.2336 - val_accuracy: 0.9118\n",
      "Epoch 278/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3615 - accuracy: 0.8188 - val_loss: 0.2521 - val_accuracy: 0.8735\n",
      "Epoch 279/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3711 - accuracy: 0.8087 - val_loss: 0.2119 - val_accuracy: 0.9182\n",
      "Epoch 280/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3877 - accuracy: 0.8267 - val_loss: 0.1999 - val_accuracy: 0.9045\n",
      "Epoch 281/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3569 - accuracy: 0.8235 - val_loss: 0.2058 - val_accuracy: 0.9053\n",
      "Epoch 282/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4095 - accuracy: 0.8077 - val_loss: 0.2062 - val_accuracy: 0.9220\n",
      "Epoch 283/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3917 - accuracy: 0.8365 - val_loss: 0.2038 - val_accuracy: 0.9058\n",
      "Epoch 284/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3400 - accuracy: 0.8422 - val_loss: 0.2519 - val_accuracy: 0.9245\n",
      "Epoch 285/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4066 - accuracy: 0.8280 - val_loss: 0.2121 - val_accuracy: 0.9001\n",
      "Epoch 286/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3574 - accuracy: 0.8202 - val_loss: 0.2415 - val_accuracy: 0.9201\n",
      "Epoch 287/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4072 - accuracy: 0.8263 - val_loss: 0.2362 - val_accuracy: 0.8706\n",
      "Epoch 288/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.3660 - accuracy: 0.8330 - val_loss: 0.2241 - val_accuracy: 0.9192\n",
      "Epoch 289/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3786 - accuracy: 0.8290 - val_loss: 0.1915 - val_accuracy: 0.9198\n",
      "Epoch 290/300\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4160 - accuracy: 0.8167 - val_loss: 0.2442 - val_accuracy: 0.9012\n",
      "Epoch 291/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3801 - accuracy: 0.8395 - val_loss: 0.2337 - val_accuracy: 0.9029\n",
      "Epoch 292/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3783 - accuracy: 0.8188 - val_loss: 0.2269 - val_accuracy: 0.8839\n",
      "Epoch 293/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3977 - accuracy: 0.8188 - val_loss: 0.2135 - val_accuracy: 0.9214\n",
      "Epoch 294/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4376 - accuracy: 0.8248 - val_loss: 0.2237 - val_accuracy: 0.9177\n",
      "Epoch 295/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3583 - accuracy: 0.8340 - val_loss: 0.2002 - val_accuracy: 0.9182\n",
      "Epoch 296/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3895 - accuracy: 0.8320 - val_loss: 0.2190 - val_accuracy: 0.8927\n",
      "Epoch 297/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3659 - accuracy: 0.8145 - val_loss: 0.2062 - val_accuracy: 0.9121\n",
      "Epoch 298/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3744 - accuracy: 0.8372 - val_loss: 0.2134 - val_accuracy: 0.9021\n",
      "Epoch 299/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4231 - accuracy: 0.8035 - val_loss: 0.2387 - val_accuracy: 0.8999\n",
      "Epoch 300/300\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4009 - accuracy: 0.8060 - val_loss: 0.2366 - val_accuracy: 0.9201\n"
     ]
    }
   ],
   "source": [
    "for i, (train, val) in enumerate(folds):\n",
    "    \n",
    "    model = createModel()\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    metrics = ['accuracy']\n",
    "    \n",
    "    model.compile(optimizer=opt, loss=loss, metrics=metrics)\n",
    "    \n",
    "    tboardCb = tf.keras.callbacks.TensorBoard(log_dir=f\"{logBasePath}/{logPrefix}_{i}\", histogram_freq=1, profile_batch=(2,10))\n",
    "    lrSchedule = tf.keras.callbacks.LearningRateScheduler(schedule)\n",
    "    \n",
    "    cbs = [tboardCb]\n",
    "    \n",
    "    model.evaluate(val)\n",
    "    model.fit(train, initial_epoch=START_EPOCH, epochs=END_EPOCH, steps_per_epoch=STEPS_PER_EPOCH, callbacks=cbs, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e841a27f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
