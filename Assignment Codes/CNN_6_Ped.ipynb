{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f19017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d782ddf",
   "metadata": {},
   "source": [
    "### Check Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03faa827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac4996",
   "metadata": {},
   "source": [
    "### GPU Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1e955b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 03:29:21.485844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 03:29:21.492301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 03:29:21.492784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2835bd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f935a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be867b6",
   "metadata": {},
   "source": [
    "### Pandas Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92db292",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_column', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0907c",
   "metadata": {},
   "source": [
    "### Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0fd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VAL_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc35c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_WIDTH = 227\n",
    "CROP_HEIGHT = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d40847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldFiles = [\"adience/unprocessed/fold_0_data.txt\",\n",
    "             \"adience/unprocessed/fold_1_data.txt\",\n",
    "             \"adience/unprocessed/fold_2_data.txt\",\n",
    "             \"adience/unprocessed/fold_3_data.txt\",\n",
    "             \"adience/unprocessed/fold_4_data.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f61c7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genderMap = defaultdict(lambda : np.NaN)\n",
    "genderMap['m'] = 0\n",
    "genderMap['f'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d26242",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = ['(0, 2)', '(4, 6)', '(8, 13)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
    "ageMap = defaultdict(lambda : np.NaN)\n",
    "for i,a in enumerate(ages):\n",
    "    ageMap[a] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b1fc3",
   "metadata": {},
   "source": [
    "### Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd634a3",
   "metadata": {},
   "source": [
    "Dataset generation pipeline:\n",
    "Input: \n",
    "- foldFile - Path to fold file. Fold file Describes which images are in the fold and its corresponding labels\n",
    "- imgBaseFolder - Base folder to search image from\n",
    "- imgPrefix - Prefix of image file\n",
    "- genderMap - Map from ['m', 'f', 'u', None], to one hot index\n",
    "- ageMap - Map from age category to one hot index\n",
    "- imgWidth - Resulting image width\n",
    "- imgHeigh - Resulting image height\n",
    "- batchSize - Int or None, batch size\n",
    "- configureDs - Function accepting dataset for performance configurations\n",
    "- preBatch - List of (name, functions) pair that will be mapped before batching. name is used as name parameters for tf graph \n",
    "- postBatch - List of (name, functions) that will be mapped after batching. name is used as name parameters for tf graph\n",
    "\n",
    "The processing functions should have signature function(img, label) -> (img, label)\n",
    "\n",
    "Pipeline\n",
    "\n",
    "Read Fold File -> Preprocess filename and labels (dataframe) -> Convert filename and labels to numpy array -> Convert filename and labels to tf dataset -> Parse images and labels -> Configure Dataset for performance -> Pre-Batching preprocessing -> Batch -> Post-Batching preprocessing -> Output\n",
    "\n",
    "Some preprocessing steps can only be done before and some can only be done after batching, thats why there are seperated pre and post batching list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0795464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, batchSize, configureDs=None, preBatch=[], postBatch=[]):\n",
    "    \n",
    "    def parseImage(filename):\n",
    "        img = tf.io.read_file(filename)\n",
    "        img = tf.image.decode_jpeg(img)\n",
    "        img = tf.image.resize(img, [imgHeight, imgWidth])\n",
    "         \n",
    "        return img\n",
    "    \n",
    "    # Read Fold File\n",
    "    foldData = []\n",
    "    for f in foldFiles:\n",
    "        foldData.append(pd.read_csv(f, sep=\"\\t\"))\n",
    "    foldData = pd.concat(foldData)\n",
    "    \n",
    "    # Form File Name\n",
    "    foldData['filename'] = foldData.apply(lambda r: os.path.join(imgBaseFolder, r['user_id'], f\"{imgPrefix}.{r['face_id']}.{r['original_image']}\"), axis=1)\n",
    "    \n",
    "    # Generate Label One Hot Index\n",
    "    foldData['gender_ind'] = foldData['gender'].map(genderMap)\n",
    "    foldData['age_ind'] = foldData['age'].map(ageMap)\n",
    "    \n",
    "    # Remove dirty data\n",
    "    foldData.dropna(subset=['gender_ind', 'age_ind'], inplace=True)\n",
    "    \n",
    "    # Dataframe to numpy\n",
    "    filenames = foldData['filename'].to_numpy()\n",
    "    \n",
    "    genderIndex = foldData['gender_ind'].to_numpy().astype(int)\n",
    "    ageIndex = foldData['age_ind'].to_numpy().astype(int)\n",
    "    \n",
    "    # Numpy to Dataset\n",
    "    fnDs = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    genderIndDs = tf.data.Dataset.from_tensor_slices(genderIndex)\n",
    "    ageIndDs = tf.data.Dataset.from_tensor_slices(ageIndex)\n",
    "    \n",
    "    # Parse Images\n",
    "    imageDs = fnDs.map(parseImage, num_parallel_calls=tf.data.AUTOTUNE, name=\"parse_image\")\n",
    "    \n",
    "    # Parse Labels\n",
    "    genderLabDs = genderIndDs.map(lambda x: tf.one_hot(x, genderDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"gender_one_hot\")\n",
    "    ageLabDs = ageIndDs.map(lambda x: tf.one_hot(x, ageDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"age_one_hot\")\n",
    "    \n",
    "    # Combine Labels\n",
    "    labelDs = tf.data.Dataset.zip((genderLabDs, ageLabDs), name=\"label_zip\")\n",
    "    labelDs = labelDs.map(lambda g,a: {\"gender\": g, \"age\": a}, num_parallel_calls=tf.data.AUTOTUNE, name='label_dict')\n",
    "    \n",
    "    # Combine Images and Labels into dataset\n",
    "    ds = tf.data.Dataset.zip((imageDs, labelDs))\n",
    "    \n",
    "    # Configure Performance\n",
    "    if(configureDs is not None):\n",
    "        ds = configureDs(ds)\n",
    "    \n",
    "    # Pre Batch Preprocessing\n",
    "    for n,f in preBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    # Batch\n",
    "    if(batchSize is not None):\n",
    "        ds = ds.batch(batchSize, name=\"ds_batch\")\n",
    "    \n",
    "    # Post Batch Preprocessing\n",
    "    for n,f in postBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320ed92",
   "metadata": {},
   "source": [
    "### Preprocessings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "472b7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=100)\n",
    "    ds = ds.repeat()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adf288f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc4fe2f",
   "metadata": {},
   "source": [
    "#### Preprocessing steps according to the reference paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7724a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainPreprocessA(img, lab):\n",
    "        \n",
    "        # img = tf.image.random_crop(img, [CROP_HEIGHT, CROP_WIDTH, 3])\n",
    "        \n",
    "        ud = tf.random.uniform([], dtype=tf.float32)\n",
    "        udCond = tf.less(ud, 0.5)\n",
    "        \n",
    "        img = tf.cond(udCond, lambda: tf.image.flip_up_down(img), lambda: img)\n",
    "        \n",
    "        lr = tf.random.uniform([], dtype=tf.float32)\n",
    "        lrCond = tf.less(lr, 0.5)\n",
    "        \n",
    "        img = tf.cond(lrCond, lambda: tf.image.flip_left_right(img), lambda: img)\n",
    "        \n",
    "        img = tf.image.random_brightness(img, 63/255)\n",
    "        \n",
    "        img = tf.image.random_contrast(img, 0.2, 1.8) \n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0402726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valPreprocessA(img, lab):\n",
    "        \n",
    "        img = tf.image.crop_to_bounding_box(img,\n",
    "                                            (IMG_HEIGHT-CROP_HEIGHT) // 2,\n",
    "                                            (IMG_WIDTH-CROP_WIDTH) // 2,\n",
    "                                            CROP_HEIGHT,\n",
    "                                            CROP_WIDTH)\n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f32b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageStandardize(img, lab):\n",
    "    \n",
    "    img = tf.image.per_image_standardization(img)\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f134a",
   "metadata": {},
   "source": [
    "#### Label extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "633c4277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractGenderLabel(img, lab):\n",
    "    \n",
    "    lab = lab['gender']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88b8b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAgeLabel(img, lab):\n",
    "    \n",
    "    lab = lab['age']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7778c",
   "metadata": {},
   "source": [
    "### Generate Folds for K-Folds validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4172d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFoldDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, valBatchSize, trainConfigureDs=None, trainPreBatch=[], trainPostBatch=[], valConfigureDs=None, valPreBatch=[], valPostBatch=[]):\n",
    "    '''\n",
    "        Returns list of (train, validation) datasets\n",
    "    '''\n",
    "    \n",
    "    N = len(foldFiles)\n",
    "    \n",
    "    folds = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        trainFiles = foldFiles[:i]\n",
    "        if(i < N-1):\n",
    "            trainFiles.extend(foldFiles[i+1:])\n",
    "            \n",
    "        valFiles = foldFiles[i]\n",
    "        \n",
    "        trainDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, configureDs=trainConfigureDs, preBatch=trainPreBatch, postBatch=trainPostBatch)\n",
    "        valDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, valBatchSize, configureDs=valConfigureDs, preBatch=valPreBatch, postBatch=valPostBatch)\n",
    "        \n",
    "        folds.append((trainDs, valDs))\n",
    "        \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beffce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPreBatch = [(\"train_process_a\", trainPreprocessA), \n",
    "                 (\"train_standardize\", imageStandardize), \n",
    "                 (\"train_extract_gender\", extractGenderLabel)]\n",
    "\n",
    "valPreBatch = [(\"val_standardize\", imageStandardize), \n",
    "               (\"val_extract_gender\", extractGenderLabel)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10474d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 03:29:21.741661: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 03:29:21.742310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 03:29:21.742575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 03:29:21.742820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 03:29:22.031756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 03:29:22.032001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 03:29:22.032226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 03:29:22.032423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3442 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:2d:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "folds = generateFoldDs(foldFiles, \"adience/faces\", \"coarse_tilt_aligned_face\", genderMap, ageMap, 2, 8, \n",
    "                       IMG_WIDTH, IMG_HEIGHT, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE, \n",
    "                       trainConfigureDs=trainConfigPerformance, trainPreBatch=trainPreBatch, \n",
    "                       valConfigureDs=valConfigPerformance, valPreBatch=valPreBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57d814af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7974f8fe",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b67fe33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in folds[0][0].take(1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8aa8d0d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 256, 256, 3), dtype=float32, numpy=\n",
       "array([[[[-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         ...,\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ]],\n",
       "\n",
       "        [[-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         ...,\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ]],\n",
       "\n",
       "        [[-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         ...,\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         ...,\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ]],\n",
       "\n",
       "        [[-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         ...,\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ]],\n",
       "\n",
       "        [[-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         ...,\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ],\n",
       "         [-1.2274075 , -1.3971285 , -1.2813267 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         ...,\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ]],\n",
       "\n",
       "        [[-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         ...,\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ]],\n",
       "\n",
       "        [[-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         ...,\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         ...,\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ]],\n",
       "\n",
       "        [[-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         ...,\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ]],\n",
       "\n",
       "        [[-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         ...,\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ],\n",
       "         [-1.5231512 , -1.5096076 , -1.4840492 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.7815851 , -0.6681796 , -0.48398653],\n",
       "         [-0.781132  , -0.6677265 , -0.48353344],\n",
       "         [-0.77024585, -0.6681726 , -0.48964572],\n",
       "         ...,\n",
       "         [-1.1845167 , -1.1848781 , -1.1571144 ],\n",
       "         [-1.1803244 , -1.1806858 , -1.152922  ],\n",
       "         [-1.177941  , -1.1783023 , -1.1505387 ]],\n",
       "\n",
       "        [[-0.74377096, -0.63080996, -0.44639462],\n",
       "         [-0.78783965, -0.6748786 , -0.49046332],\n",
       "         [-0.6983934 , -0.58543235, -0.4123493 ],\n",
       "         ...,\n",
       "         [-1.2042335 , -1.204595  , -1.1768312 ],\n",
       "         [-1.1717523 , -1.1721137 , -1.14435   ],\n",
       "         [-1.150447  , -1.1508085 , -1.1230447 ]],\n",
       "\n",
       "        [[-0.7444706 , -0.6595068 , -0.46109286],\n",
       "         [-0.7683155 , -0.68335176, -0.48493782],\n",
       "         [-0.69981515, -0.61485136, -0.42776975],\n",
       "         ...,\n",
       "         [-1.1587709 , -1.1591324 , -1.1313685 ],\n",
       "         [-1.1309959 , -1.1313572 , -1.1035935 ],\n",
       "         [-1.1423281 , -1.1426895 , -1.1149257 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.648988  ,  1.6912894 ,  1.5910654 ],\n",
       "         [ 1.659779  ,  1.7020799 ,  1.6018561 ],\n",
       "         [ 1.7142127 ,  1.7565141 ,  1.6562899 ],\n",
       "         ...,\n",
       "         [ 1.6032218 ,  1.5672717 ,  1.4072028 ],\n",
       "         [ 1.5570579 ,  1.5406528 ,  1.3846564 ],\n",
       "         [ 1.5027505 ,  1.4870571 ,  1.3492813 ]],\n",
       "\n",
       "        [[ 1.6546248 ,  1.696926  ,  1.596702  ],\n",
       "         [ 1.6753919 ,  1.717693  ,  1.6174692 ],\n",
       "         [ 1.693909  ,  1.7362105 ,  1.6359863 ],\n",
       "         ...,\n",
       "         [ 1.4874411 ,  1.4866354 ,  1.3153074 ],\n",
       "         [ 1.4475598 ,  1.4471811 ,  1.2758526 ],\n",
       "         [ 1.5502926 ,  1.5499315 ,  1.3790475 ]],\n",
       "\n",
       "        [[ 1.723073  ,  1.7653742 ,  1.6651503 ],\n",
       "         [ 1.7162229 ,  1.7585243 ,  1.6583    ],\n",
       "         [ 1.7223666 ,  1.7646676 ,  1.6644437 ],\n",
       "         ...,\n",
       "         [ 1.5914676 ,  1.5911064 ,  1.4197779 ],\n",
       "         [ 1.5664424 ,  1.5934116 ,  1.408418  ],\n",
       "         [ 1.5908322 ,  1.6189127 ,  1.4333637 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         ...,\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ]],\n",
       "\n",
       "        [[-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         ...,\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ]],\n",
       "\n",
       "        [[-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         ...,\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         ...,\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ]],\n",
       "\n",
       "        [[-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         ...,\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ]],\n",
       "\n",
       "        [[-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         ...,\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ],\n",
       "         [-1.3809772 , -1.0676011 , -0.9546003 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d84b1683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e25507c",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ee495a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    inp = tf.keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "    conv1 = tf.keras.layers.Conv2D(96, 7, strides=(4,4), activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='conv1')\n",
    "    pool1 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, name='pool1')\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv2D(256, 5, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='conv2')\n",
    "    pool2 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, name='pool2')\n",
    "\n",
    "    conv3 = tf.keras.layers.Conv2D(384, 3, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='conv3')\n",
    "    pool3 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, name='pool3')\n",
    "\n",
    "    flat1 = tf.keras.layers.Flatten(name='flat1')\n",
    "    fc1 = tf.keras.layers.Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc1')\n",
    "    do1 = tf.keras.layers.Dropout(0.5, name='do1')\n",
    "\n",
    "    fc2 = tf.keras.layers.Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc2')\n",
    "    do2 = tf.keras.layers.Dropout(0.5, name='do2')\n",
    "\n",
    "    fc3 = tf.keras.layers.Dense(2, activation='softmax', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='fc3')\n",
    "\n",
    "    o = conv1(inp)\n",
    "    o = pool1(o)\n",
    "    o = tf.nn.local_response_normalization(o, depth_radius=5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    o = tf.pad(o, [[0, 0], [2, 2], [2, 2], [0, 0]])\n",
    "    o = conv2(o)\n",
    "    o = pool2(o)\n",
    "    o = tf.nn.local_response_normalization(o, depth_radius=5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    o = tf.pad(o, [[0, 0], [1, 1], [1, 1], [0, 0]])\n",
    "    o = conv3(o)\n",
    "    o = pool3(o)\n",
    "    o = tf.nn.local_response_normalization(o, depth_radius=5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    o = flat1(o)\n",
    "    o = fc1(o)\n",
    "    o = do1(o)\n",
    "\n",
    "\n",
    "    o = fc2(o)\n",
    "    o = do2(o)\n",
    "\n",
    "    o = fc3(o)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=o, name='cnn_6')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea1227d",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c5f7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = 1000\n",
    "\n",
    "EPOCH = 300\n",
    "\n",
    "START_EPOCH = 0\n",
    "END_EPOCH = START_EPOCH + EPOCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96be5cb2",
   "metadata": {},
   "source": [
    "#### Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55ee49a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(epoch, lr):\n",
    "    if(epoch == 10000*50//STEPS_PER_EPOCH):\n",
    "        return lr * 0.1\n",
    "    else:\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f41e8947",
   "metadata": {},
   "outputs": [],
   "source": [
    "logBasePath = \"log/CNN_6\"\n",
    "logPrefix = \"log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75efb222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 03:29:28.455759: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-09 03:29:28.455778: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-09 03:29:28.455796: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1665] Profiler found 1 GPUs\n",
      "2022-11-09 03:29:28.566946: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-09 03:29:28.568345: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-11-09 03:29:29.120992: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  52/3528 [..............................] - ETA: 10s - loss: 0.6846 - accuracy: 0.6202  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 03:29:29.906417: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 10s 3ms/step - loss: 0.6957 - accuracy: 0.4768\n",
      "Epoch 1/300\n",
      "   1/1000 [..............................] - ETA: 7:45 - loss: 0.6534 - accuracy: 0.7500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 03:29:39.286868: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-09 03:29:39.286888: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  20/1000 [..............................] - ETA: 29s - loss: 0.7875 - accuracy: 0.6375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 03:29:39.693057: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-09 03:29:39.693710: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-11-09 03:29:39.717567: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 1635 callback api events and 1610 activity events. \n",
      "2022-11-09 03:29:39.734116: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-09 03:29:39.749305: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/CNN_6/log_0/plugins/profile/2022_11_09_03_29_39\n",
      "\n",
      "2022-11-09 03:29:39.775995: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/CNN_6/log_0/plugins/profile/2022_11_09_03_29_39/rachanon-pc1.trace.json.gz\n",
      "2022-11-09 03:29:39.800818: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/CNN_6/log_0/plugins/profile/2022_11_09_03_29_39\n",
      "\n",
      "2022-11-09 03:29:39.805199: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/CNN_6/log_0/plugins/profile/2022_11_09_03_29_39/rachanon-pc1.memory_profile.json.gz\n",
      "2022-11-09 03:29:39.805621: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/CNN_6/log_0/plugins/profile/2022_11_09_03_29_39\n",
      "Dumped tool data for xplane.pb to log/CNN_6/log_0/plugins/profile/2022_11_09_03_29_39/rachanon-pc1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/CNN_6/log_0/plugins/profile/2022_11_09_03_29_39/rachanon-pc1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/CNN_6/log_0/plugins/profile/2022_11_09_03_29_39/rachanon-pc1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/CNN_6/log_0/plugins/profile/2022_11_09_03_29_39/rachanon-pc1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/CNN_6/log_0/plugins/profile/2022_11_09_03_29_39/rachanon-pc1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 998/1000 [============================>.] - ETA: 0s - loss: 0.7309 - accuracy: 0.5649"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 03:29:53.404290: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.7308 - accuracy: 0.5648 - val_loss: 0.6952 - val_accuracy: 0.5232\n",
      "Epoch 2/300\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.6701 - accuracy: 0.5915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 03:30:07.339844: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6701 - accuracy: 0.5915 - val_loss: 0.6923 - val_accuracy: 0.5232\n",
      "Epoch 3/300\n",
      " 997/1000 [============================>.] - ETA: 0s - loss: 0.6650 - accuracy: 0.5777"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 03:30:21.179645: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6650 - accuracy: 0.5778 - val_loss: 0.6935 - val_accuracy: 0.4768\n",
      "Epoch 4/300\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 0.6799 - accuracy: 0.5783"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 03:30:35.096073: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6803 - accuracy: 0.5782 - val_loss: 0.7447 - val_accuracy: 0.5232\n",
      "Epoch 5/300\n",
      " 996/1000 [============================>.] - ETA: 0s - loss: 0.6961 - accuracy: 0.5050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 03:30:49.050615: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6960 - accuracy: 0.5055 - val_loss: 0.6922 - val_accuracy: 0.5232\n",
      "Epoch 6/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6641 - accuracy: 0.5943 - val_loss: 0.6937 - val_accuracy: 0.4768\n",
      "Epoch 7/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6866 - accuracy: 0.5447 - val_loss: 0.6985 - val_accuracy: 0.5232\n",
      "Epoch 8/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6945 - accuracy: 0.5085 - val_loss: 0.6924 - val_accuracy: 0.5232\n",
      "Epoch 9/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6832 - accuracy: 0.5412 - val_loss: 0.6988 - val_accuracy: 0.5232\n",
      "Epoch 10/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6738 - accuracy: 0.5705 - val_loss: 0.6921 - val_accuracy: 0.5232\n",
      "Epoch 11/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6846 - accuracy: 0.5497 - val_loss: 0.7042 - val_accuracy: 0.4768\n",
      "Epoch 12/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6963 - accuracy: 0.4920 - val_loss: 0.6921 - val_accuracy: 0.5232\n",
      "Epoch 13/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6672 - accuracy: 0.5962 - val_loss: 0.6952 - val_accuracy: 0.5232\n",
      "Epoch 14/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6856 - accuracy: 0.5543 - val_loss: 0.7049 - val_accuracy: 0.5232\n",
      "Epoch 15/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6960 - accuracy: 0.5113 - val_loss: 0.6930 - val_accuracy: 0.5232\n",
      "Epoch 16/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6855 - accuracy: 0.5385 - val_loss: 0.6966 - val_accuracy: 0.5232\n",
      "Epoch 17/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6703 - accuracy: 0.5813 - val_loss: 0.6945 - val_accuracy: 0.4768\n",
      "Epoch 18/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6868 - accuracy: 0.5450 - val_loss: 0.6943 - val_accuracy: 0.4768\n",
      "Epoch 19/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6965 - accuracy: 0.4890 - val_loss: 0.6960 - val_accuracy: 0.4768\n",
      "Epoch 20/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6683 - accuracy: 0.5913 - val_loss: 0.7434 - val_accuracy: 0.5232\n",
      "Epoch 21/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6913 - accuracy: 0.5340 - val_loss: 0.7496 - val_accuracy: 0.5232\n",
      "Epoch 22/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6954 - accuracy: 0.5000 - val_loss: 0.6925 - val_accuracy: 0.5232\n",
      "Epoch 23/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6921 - accuracy: 0.5228 - val_loss: 0.6921 - val_accuracy: 0.5232\n",
      "Epoch 24/300\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.6662 - accuracy: 0.5822 - val_loss: 0.7459 - val_accuracy: 0.4768\n",
      "Epoch 25/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6858 - accuracy: 0.5500 - val_loss: 0.6928 - val_accuracy: 0.5232\n",
      "Epoch 26/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6962 - accuracy: 0.4935 - val_loss: 0.7015 - val_accuracy: 0.4768\n",
      "Epoch 27/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6684 - accuracy: 0.5850 - val_loss: 0.7393 - val_accuracy: 0.5232\n",
      "Epoch 28/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6863 - accuracy: 0.5452 - val_loss: 0.7151 - val_accuracy: 0.5232\n",
      "Epoch 29/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6892 - accuracy: 0.5265 - val_loss: 0.6935 - val_accuracy: 0.4768\n",
      "Epoch 30/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6914 - accuracy: 0.5200 - val_loss: 0.7014 - val_accuracy: 0.5232\n",
      "Epoch 31/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6639 - accuracy: 0.5905 - val_loss: 0.6927 - val_accuracy: 0.5232\n",
      "Epoch 32/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6844 - accuracy: 0.5540 - val_loss: 0.6924 - val_accuracy: 0.5232\n",
      "Epoch 33/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6964 - accuracy: 0.4965 - val_loss: 0.7001 - val_accuracy: 0.4768\n",
      "Epoch 34/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6658 - accuracy: 0.5763 - val_loss: 1.0451 - val_accuracy: 0.5232\n",
      "Epoch 35/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6767 - accuracy: 0.5472 - val_loss: 0.6943 - val_accuracy: 0.5232\n",
      "Epoch 36/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6838 - accuracy: 0.5567 - val_loss: 0.6911 - val_accuracy: 0.5232\n",
      "Epoch 37/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6751 - accuracy: 0.5690 - val_loss: 0.7055 - val_accuracy: 0.4768\n",
      "Epoch 38/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6536 - accuracy: 0.5875 - val_loss: 0.6788 - val_accuracy: 0.5632\n",
      "Epoch 39/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6732 - accuracy: 0.5875 - val_loss: 0.7062 - val_accuracy: 0.4768\n",
      "Epoch 40/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6721 - accuracy: 0.5720 - val_loss: 0.6770 - val_accuracy: 0.5728\n",
      "Epoch 41/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6488 - accuracy: 0.6210 - val_loss: 0.6581 - val_accuracy: 0.6048\n",
      "Epoch 42/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6053 - accuracy: 0.6612 - val_loss: 0.6563 - val_accuracy: 0.6134\n",
      "Epoch 43/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6203 - accuracy: 0.6618 - val_loss: 0.6310 - val_accuracy: 0.6389\n",
      "Epoch 44/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5792 - accuracy: 0.6982 - val_loss: 0.8034 - val_accuracy: 0.5302\n",
      "Epoch 45/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5778 - accuracy: 0.6900 - val_loss: 0.6027 - val_accuracy: 0.6664\n",
      "Epoch 46/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6000 - accuracy: 0.6635 - val_loss: 0.6373 - val_accuracy: 0.6288\n",
      "Epoch 47/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5634 - accuracy: 0.7140 - val_loss: 0.5901 - val_accuracy: 0.6843\n",
      "Epoch 48/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5638 - accuracy: 0.7135 - val_loss: 0.5958 - val_accuracy: 0.6720\n",
      "Epoch 49/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5362 - accuracy: 0.7172 - val_loss: 0.5923 - val_accuracy: 0.6651\n",
      "Epoch 50/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5272 - accuracy: 0.7425 - val_loss: 0.5716 - val_accuracy: 0.7013\n",
      "Epoch 51/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5066 - accuracy: 0.7555 - val_loss: 0.6248 - val_accuracy: 0.6767\n",
      "Epoch 52/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4994 - accuracy: 0.7538 - val_loss: 0.5467 - val_accuracy: 0.6944\n",
      "Epoch 53/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5175 - accuracy: 0.7430 - val_loss: 0.5581 - val_accuracy: 0.7184\n",
      "Epoch 54/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4730 - accuracy: 0.7870 - val_loss: 0.7389 - val_accuracy: 0.6970\n",
      "Epoch 55/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4905 - accuracy: 0.7685 - val_loss: 0.4999 - val_accuracy: 0.7471\n",
      "Epoch 56/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5044 - accuracy: 0.7492 - val_loss: 0.5039 - val_accuracy: 0.7528\n",
      "Epoch 57/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4481 - accuracy: 0.7880 - val_loss: 0.4768 - val_accuracy: 0.7675\n",
      "Epoch 58/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4508 - accuracy: 0.7928 - val_loss: 0.7089 - val_accuracy: 0.6294\n",
      "Epoch 59/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4354 - accuracy: 0.7853 - val_loss: 0.5082 - val_accuracy: 0.7566\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4741 - accuracy: 0.7638 - val_loss: 0.4705 - val_accuracy: 0.7743\n",
      "Epoch 61/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4105 - accuracy: 0.8198 - val_loss: 0.4647 - val_accuracy: 0.7821\n",
      "Epoch 62/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4195 - accuracy: 0.8177 - val_loss: 0.4885 - val_accuracy: 0.7572\n",
      "Epoch 63/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4593 - accuracy: 0.7810 - val_loss: 0.5448 - val_accuracy: 0.7111\n",
      "Epoch 64/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3909 - accuracy: 0.8270 - val_loss: 0.4846 - val_accuracy: 0.7658\n",
      "Epoch 65/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3922 - accuracy: 0.8357 - val_loss: 0.4667 - val_accuracy: 0.7982\n",
      "Epoch 66/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4029 - accuracy: 0.8240 - val_loss: 0.4586 - val_accuracy: 0.7829\n",
      "Epoch 67/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4262 - accuracy: 0.8050 - val_loss: 0.4572 - val_accuracy: 0.8005\n",
      "Epoch 68/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3657 - accuracy: 0.8460 - val_loss: 0.4080 - val_accuracy: 0.8168\n",
      "Epoch 69/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3620 - accuracy: 0.8472 - val_loss: 0.4490 - val_accuracy: 0.8077\n",
      "Epoch 70/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4204 - accuracy: 0.8062 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
      "Epoch 71/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3603 - accuracy: 0.8422 - val_loss: 0.4291 - val_accuracy: 0.8189\n",
      "Epoch 72/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3378 - accuracy: 0.8610 - val_loss: 0.3838 - val_accuracy: 0.8282\n",
      "Epoch 73/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3778 - accuracy: 0.8317 - val_loss: 0.3898 - val_accuracy: 0.8239\n",
      "Epoch 74/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3959 - accuracy: 0.8202 - val_loss: 0.3973 - val_accuracy: 0.8221\n",
      "Epoch 75/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3295 - accuracy: 0.8570 - val_loss: 0.3938 - val_accuracy: 0.8174\n",
      "Epoch 76/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3320 - accuracy: 0.8568 - val_loss: 0.4520 - val_accuracy: 0.7916\n",
      "Epoch 77/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4037 - accuracy: 0.8185 - val_loss: 0.4068 - val_accuracy: 0.8118\n",
      "Epoch 78/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3146 - accuracy: 0.8673 - val_loss: 0.4725 - val_accuracy: 0.7669\n",
      "Epoch 79/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3081 - accuracy: 0.8700 - val_loss: 0.4299 - val_accuracy: 0.8345\n",
      "Epoch 80/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3394 - accuracy: 0.8525 - val_loss: 0.4517 - val_accuracy: 0.7930\n",
      "Epoch 81/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3653 - accuracy: 0.8413 - val_loss: 0.4549 - val_accuracy: 0.8277\n",
      "Epoch 82/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3048 - accuracy: 0.8765 - val_loss: 0.3864 - val_accuracy: 0.8338\n",
      "Epoch 83/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2941 - accuracy: 0.8802 - val_loss: 0.5661 - val_accuracy: 0.8022\n",
      "Epoch 84/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3576 - accuracy: 0.8397 - val_loss: 0.3602 - val_accuracy: 0.8455\n",
      "Epoch 85/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2938 - accuracy: 0.8785 - val_loss: 0.5817 - val_accuracy: 0.7377\n",
      "Epoch 86/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2930 - accuracy: 0.8808 - val_loss: 0.3579 - val_accuracy: 0.8535\n",
      "Epoch 87/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3155 - accuracy: 0.8717 - val_loss: 0.3265 - val_accuracy: 0.8639\n",
      "Epoch 88/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3385 - accuracy: 0.8565 - val_loss: 0.4018 - val_accuracy: 0.8549\n",
      "Epoch 89/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2620 - accuracy: 0.8947 - val_loss: 0.3902 - val_accuracy: 0.8499\n",
      "Epoch 90/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2707 - accuracy: 0.8915 - val_loss: 0.3741 - val_accuracy: 0.8615\n",
      "Epoch 91/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3327 - accuracy: 0.8610 - val_loss: 0.3304 - val_accuracy: 0.8532\n",
      "Epoch 92/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2752 - accuracy: 0.8865 - val_loss: 0.3873 - val_accuracy: 0.8439\n",
      "Epoch 93/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2690 - accuracy: 0.8900 - val_loss: 0.4504 - val_accuracy: 0.8045\n",
      "Epoch 94/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2869 - accuracy: 0.8860 - val_loss: 0.3294 - val_accuracy: 0.8584\n",
      "Epoch 95/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3167 - accuracy: 0.8635 - val_loss: 0.3948 - val_accuracy: 0.8571\n",
      "Epoch 96/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2457 - accuracy: 0.8963 - val_loss: 0.5996 - val_accuracy: 0.7510\n",
      "Epoch 97/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2839 - accuracy: 0.8838 - val_loss: 0.3846 - val_accuracy: 0.8566\n",
      "Epoch 98/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3008 - accuracy: 0.8708 - val_loss: 0.3334 - val_accuracy: 0.8547\n",
      "Epoch 99/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2587 - accuracy: 0.8928 - val_loss: 0.4623 - val_accuracy: 0.8230\n",
      "Epoch 100/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2468 - accuracy: 0.9007 - val_loss: 0.5605 - val_accuracy: 0.7734\n",
      "Epoch 101/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2725 - accuracy: 0.8915 - val_loss: 0.3533 - val_accuracy: 0.8595\n",
      "Epoch 102/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3085 - accuracy: 0.8675 - val_loss: 0.3317 - val_accuracy: 0.8733\n",
      "Epoch 103/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2293 - accuracy: 0.9118 - val_loss: 0.3084 - val_accuracy: 0.8819\n",
      "Epoch 104/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2582 - accuracy: 0.8988 - val_loss: 0.3164 - val_accuracy: 0.8617\n",
      "Epoch 105/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2694 - accuracy: 0.8890 - val_loss: 0.3571 - val_accuracy: 0.8387\n",
      "Epoch 106/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2573 - accuracy: 0.8970 - val_loss: 0.3982 - val_accuracy: 0.8731\n",
      "Epoch 107/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2438 - accuracy: 0.9045 - val_loss: 0.3706 - val_accuracy: 0.8756\n",
      "Epoch 108/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2567 - accuracy: 0.8965 - val_loss: 0.3460 - val_accuracy: 0.8524\n",
      "Epoch 109/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2739 - accuracy: 0.8882 - val_loss: 0.3179 - val_accuracy: 0.8752\n",
      "Epoch 110/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2257 - accuracy: 0.9125 - val_loss: 0.2842 - val_accuracy: 0.8887\n",
      "Epoch 111/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2364 - accuracy: 0.9082 - val_loss: 0.3449 - val_accuracy: 0.8642\n",
      "Epoch 112/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2321 - accuracy: 0.9093 - val_loss: 0.2825 - val_accuracy: 0.8825\n",
      "Epoch 113/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2534 - accuracy: 0.8942 - val_loss: 0.5553 - val_accuracy: 0.8515\n",
      "Epoch 114/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2277 - accuracy: 0.9120 - val_loss: 0.4942 - val_accuracy: 0.8554\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2435 - accuracy: 0.9087 - val_loss: 0.3109 - val_accuracy: 0.8870\n",
      "Epoch 116/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2637 - accuracy: 0.8913 - val_loss: 0.4206 - val_accuracy: 0.8460\n",
      "Epoch 117/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2064 - accuracy: 0.9222 - val_loss: 0.3168 - val_accuracy: 0.8721\n",
      "Epoch 118/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2295 - accuracy: 0.9075 - val_loss: 0.3832 - val_accuracy: 0.8255\n",
      "Epoch 119/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2248 - accuracy: 0.9160 - val_loss: 0.2999 - val_accuracy: 0.8780\n",
      "Epoch 120/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2606 - accuracy: 0.8913 - val_loss: 0.2404 - val_accuracy: 0.9024\n",
      "Epoch 121/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2009 - accuracy: 0.9235 - val_loss: 0.4447 - val_accuracy: 0.8247\n",
      "Epoch 122/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2288 - accuracy: 0.9075 - val_loss: 0.5106 - val_accuracy: 0.7924\n",
      "Epoch 123/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2579 - accuracy: 0.8947 - val_loss: 0.3065 - val_accuracy: 0.8721\n",
      "Epoch 124/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1842 - accuracy: 0.9308 - val_loss: 0.3330 - val_accuracy: 0.8731\n",
      "Epoch 125/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2257 - accuracy: 0.9097 - val_loss: 0.3646 - val_accuracy: 0.8461\n",
      "Epoch 126/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2226 - accuracy: 0.9128 - val_loss: 0.2554 - val_accuracy: 0.8924\n",
      "Epoch 127/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2462 - accuracy: 0.9053 - val_loss: 0.2383 - val_accuracy: 0.9126\n",
      "Epoch 128/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1706 - accuracy: 0.9365 - val_loss: 0.3294 - val_accuracy: 0.8691\n",
      "Epoch 129/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1972 - accuracy: 0.9230 - val_loss: 0.3631 - val_accuracy: 0.8558\n",
      "Epoch 130/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2422 - accuracy: 0.9053 - val_loss: 0.2489 - val_accuracy: 0.8990\n",
      "Epoch 131/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1938 - accuracy: 0.9240 - val_loss: 0.3439 - val_accuracy: 0.8890\n",
      "Epoch 132/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2082 - accuracy: 0.9180 - val_loss: 0.2893 - val_accuracy: 0.8904\n",
      "Epoch 133/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2023 - accuracy: 0.9245 - val_loss: 0.2693 - val_accuracy: 0.8895\n",
      "Epoch 134/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2333 - accuracy: 0.9050 - val_loss: 0.2670 - val_accuracy: 0.9036\n",
      "Epoch 135/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1730 - accuracy: 0.9330 - val_loss: 0.2292 - val_accuracy: 0.9077\n",
      "Epoch 136/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1736 - accuracy: 0.9323 - val_loss: 0.2643 - val_accuracy: 0.8985\n",
      "Epoch 137/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2256 - accuracy: 0.9158 - val_loss: 0.3460 - val_accuracy: 0.8568\n",
      "Epoch 138/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1766 - accuracy: 0.9365 - val_loss: 0.3036 - val_accuracy: 0.8975\n",
      "Epoch 139/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1894 - accuracy: 0.9273 - val_loss: 0.4634 - val_accuracy: 0.8666\n",
      "Epoch 140/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2111 - accuracy: 0.9175 - val_loss: 0.2924 - val_accuracy: 0.8775\n",
      "Epoch 141/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2270 - accuracy: 0.9122 - val_loss: 0.2408 - val_accuracy: 0.9073\n",
      "Epoch 142/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1725 - accuracy: 0.9377 - val_loss: 0.3063 - val_accuracy: 0.8671\n",
      "Epoch 143/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1657 - accuracy: 0.9365 - val_loss: 0.4024 - val_accuracy: 0.8407\n",
      "Epoch 144/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2140 - accuracy: 0.9168 - val_loss: 0.2954 - val_accuracy: 0.8873\n",
      "Epoch 145/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1756 - accuracy: 0.9305 - val_loss: 0.4433 - val_accuracy: 0.8147\n",
      "Epoch 146/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1779 - accuracy: 0.9327 - val_loss: 0.3037 - val_accuracy: 0.8993\n",
      "Epoch 147/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2010 - accuracy: 0.9265 - val_loss: 0.2686 - val_accuracy: 0.8908\n",
      "Epoch 148/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2018 - accuracy: 0.9243 - val_loss: 0.2334 - val_accuracy: 0.9223\n",
      "Epoch 149/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1582 - accuracy: 0.9425 - val_loss: 0.2152 - val_accuracy: 0.9128\n",
      "Epoch 150/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1697 - accuracy: 0.9350 - val_loss: 0.2310 - val_accuracy: 0.9159\n",
      "Epoch 151/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1947 - accuracy: 0.9243 - val_loss: 0.2924 - val_accuracy: 0.8814\n",
      "Epoch 152/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1749 - accuracy: 0.9345 - val_loss: 0.3040 - val_accuracy: 0.8890\n",
      "Epoch 153/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1792 - accuracy: 0.9333 - val_loss: 0.1987 - val_accuracy: 0.9240\n",
      "Epoch 154/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1884 - accuracy: 0.9277 - val_loss: 0.2052 - val_accuracy: 0.9211\n",
      "Epoch 155/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1869 - accuracy: 0.9255 - val_loss: 0.5160 - val_accuracy: 0.8666\n",
      "Epoch 156/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1572 - accuracy: 0.9395 - val_loss: 0.2500 - val_accuracy: 0.9043\n",
      "Epoch 157/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1780 - accuracy: 0.9348 - val_loss: 0.2022 - val_accuracy: 0.9184\n",
      "Epoch 158/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1997 - accuracy: 0.9233 - val_loss: 0.1638 - val_accuracy: 0.9361\n",
      "Epoch 159/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1599 - accuracy: 0.9415 - val_loss: 0.2407 - val_accuracy: 0.9211\n",
      "Epoch 160/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1745 - accuracy: 0.9385 - val_loss: 0.3652 - val_accuracy: 0.8571\n",
      "Epoch 161/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1715 - accuracy: 0.9350 - val_loss: 0.2364 - val_accuracy: 0.9123\n",
      "Epoch 162/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1868 - accuracy: 0.9258 - val_loss: 0.2008 - val_accuracy: 0.9337\n",
      "Epoch 163/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1458 - accuracy: 0.9482 - val_loss: 0.3541 - val_accuracy: 0.8631\n",
      "Epoch 164/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1557 - accuracy: 0.9420 - val_loss: 0.2038 - val_accuracy: 0.9276\n",
      "Epoch 165/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1826 - accuracy: 0.9295 - val_loss: 0.1799 - val_accuracy: 0.9308\n",
      "Epoch 166/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1555 - accuracy: 0.9417 - val_loss: 0.2908 - val_accuracy: 0.9033\n",
      "Epoch 167/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1684 - accuracy: 0.9398 - val_loss: 0.2252 - val_accuracy: 0.9129\n",
      "Epoch 168/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1607 - accuracy: 0.9405 - val_loss: 0.2323 - val_accuracy: 0.9133\n",
      "Epoch 169/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1782 - accuracy: 0.9327 - val_loss: 0.2331 - val_accuracy: 0.9146\n",
      "Epoch 170/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1262 - accuracy: 0.9528 - val_loss: 0.2152 - val_accuracy: 0.9271\n",
      "Epoch 171/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1798 - accuracy: 0.9355 - val_loss: 0.2155 - val_accuracy: 0.9175\n",
      "Epoch 172/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1711 - accuracy: 0.9312 - val_loss: 0.2086 - val_accuracy: 0.9317\n",
      "Epoch 173/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1489 - accuracy: 0.9450 - val_loss: 0.2683 - val_accuracy: 0.9089\n",
      "Epoch 174/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1405 - accuracy: 0.9488 - val_loss: 0.1863 - val_accuracy: 0.9282\n",
      "Epoch 175/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1528 - accuracy: 0.9398 - val_loss: 0.4570 - val_accuracy: 0.8279\n",
      "Epoch 176/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1789 - accuracy: 0.9310 - val_loss: 0.2664 - val_accuracy: 0.9012\n",
      "Epoch 177/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1265 - accuracy: 0.9540 - val_loss: 0.2498 - val_accuracy: 0.9169\n",
      "Epoch 178/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1655 - accuracy: 0.9423 - val_loss: 0.2547 - val_accuracy: 0.9004\n",
      "Epoch 179/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1507 - accuracy: 0.9400 - val_loss: 0.2247 - val_accuracy: 0.9111\n",
      "Epoch 180/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1609 - accuracy: 0.9327 - val_loss: 0.2393 - val_accuracy: 0.9178\n",
      "Epoch 181/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1520 - accuracy: 0.9408 - val_loss: 0.1930 - val_accuracy: 0.9302\n",
      "Epoch 182/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1800 - accuracy: 0.9302 - val_loss: 0.3619 - val_accuracy: 0.8675\n",
      "Epoch 183/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1733 - accuracy: 0.9348 - val_loss: 0.2007 - val_accuracy: 0.9253\n",
      "Epoch 184/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1181 - accuracy: 0.9570 - val_loss: 0.2854 - val_accuracy: 0.8977\n",
      "Epoch 185/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1619 - accuracy: 0.9430 - val_loss: 0.3844 - val_accuracy: 0.8564\n",
      "Epoch 186/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1460 - accuracy: 0.9467 - val_loss: 0.1839 - val_accuracy: 0.9340\n",
      "Epoch 187/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1538 - accuracy: 0.9392 - val_loss: 0.1891 - val_accuracy: 0.9319\n",
      "Epoch 188/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1377 - accuracy: 0.9500 - val_loss: 0.2842 - val_accuracy: 0.8933\n",
      "Epoch 189/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1516 - accuracy: 0.9473 - val_loss: 0.2523 - val_accuracy: 0.9116\n",
      "Epoch 190/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1690 - accuracy: 0.9367 - val_loss: 0.6438 - val_accuracy: 0.7733\n",
      "Epoch 191/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1223 - accuracy: 0.9580 - val_loss: 0.3785 - val_accuracy: 0.8654\n",
      "Epoch 192/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1496 - accuracy: 0.9488 - val_loss: 0.2172 - val_accuracy: 0.9183\n",
      "Epoch 193/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1501 - accuracy: 0.9460 - val_loss: 0.1934 - val_accuracy: 0.9269\n",
      "Epoch 194/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1599 - accuracy: 0.9425 - val_loss: 0.1606 - val_accuracy: 0.9425\n",
      "Epoch 195/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1179 - accuracy: 0.9560 - val_loss: 0.2203 - val_accuracy: 0.9164\n",
      "Epoch 196/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1363 - accuracy: 0.9517 - val_loss: 0.2303 - val_accuracy: 0.9201\n",
      "Epoch 197/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1690 - accuracy: 0.9350 - val_loss: 0.3791 - val_accuracy: 0.8552\n",
      "Epoch 198/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1353 - accuracy: 0.9498 - val_loss: 0.2504 - val_accuracy: 0.8999\n",
      "Epoch 199/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1558 - accuracy: 0.9463 - val_loss: 0.1666 - val_accuracy: 0.9366\n",
      "Epoch 200/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1487 - accuracy: 0.9473 - val_loss: 0.1851 - val_accuracy: 0.9272\n",
      "Epoch 201/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1414 - accuracy: 0.9477 - val_loss: 0.2082 - val_accuracy: 0.9388\n",
      "Epoch 202/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1500 - accuracy: 0.9480 - val_loss: 0.2031 - val_accuracy: 0.9196\n",
      "Epoch 203/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1247 - accuracy: 0.9557 - val_loss: 0.1794 - val_accuracy: 0.9435\n",
      "Epoch 204/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1565 - accuracy: 0.9430 - val_loss: 0.3178 - val_accuracy: 0.8868\n",
      "Epoch 205/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1174 - accuracy: 0.9578 - val_loss: 0.2904 - val_accuracy: 0.8882\n",
      "Epoch 206/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1456 - accuracy: 0.9490 - val_loss: 0.1647 - val_accuracy: 0.9437\n",
      "Epoch 207/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1286 - accuracy: 0.9515 - val_loss: 0.2562 - val_accuracy: 0.9065\n",
      "Epoch 208/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1490 - accuracy: 0.9450 - val_loss: 0.1690 - val_accuracy: 0.9462\n",
      "Epoch 209/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1150 - accuracy: 0.9613 - val_loss: 0.3207 - val_accuracy: 0.8855\n",
      "Epoch 210/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1270 - accuracy: 0.9540 - val_loss: 0.1827 - val_accuracy: 0.9439\n",
      "Epoch 211/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1515 - accuracy: 0.9452 - val_loss: 0.1410 - val_accuracy: 0.9486\n",
      "Epoch 212/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1112 - accuracy: 0.9575 - val_loss: 0.8584 - val_accuracy: 0.7256\n",
      "Epoch 213/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1384 - accuracy: 0.9510 - val_loss: 0.3367 - val_accuracy: 0.8740\n",
      "Epoch 214/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1345 - accuracy: 0.9520 - val_loss: 0.1753 - val_accuracy: 0.9386\n",
      "Epoch 215/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1348 - accuracy: 0.9540 - val_loss: 0.3010 - val_accuracy: 0.9230\n",
      "Epoch 216/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1184 - accuracy: 0.9597 - val_loss: 0.1846 - val_accuracy: 0.9327\n",
      "Epoch 217/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1117 - accuracy: 0.9592 - val_loss: 0.2419 - val_accuracy: 0.9165\n",
      "Epoch 218/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1384 - accuracy: 0.9510 - val_loss: 0.2605 - val_accuracy: 0.9000\n",
      "Epoch 219/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1179 - accuracy: 0.9567 - val_loss: 0.2766 - val_accuracy: 0.9077\n",
      "Epoch 220/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1428 - accuracy: 0.9503 - val_loss: 0.2566 - val_accuracy: 0.9004\n",
      "Epoch 221/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1268 - accuracy: 0.9540 - val_loss: 0.2530 - val_accuracy: 0.9172\n",
      "Epoch 222/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1510 - accuracy: 0.9420 - val_loss: 0.2183 - val_accuracy: 0.9357\n",
      "Epoch 223/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1139 - accuracy: 0.9570 - val_loss: 0.2980 - val_accuracy: 0.8957\n",
      "Epoch 224/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1306 - accuracy: 0.9490 - val_loss: 0.2093 - val_accuracy: 0.9348\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1398 - accuracy: 0.9460 - val_loss: 0.1743 - val_accuracy: 0.9343\n",
      "Epoch 226/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1255 - accuracy: 0.9538 - val_loss: 0.1876 - val_accuracy: 0.9475\n",
      "Epoch 227/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1464 - accuracy: 0.9490 - val_loss: 0.2083 - val_accuracy: 0.9211\n",
      "Epoch 228/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1299 - accuracy: 0.9530 - val_loss: 0.1866 - val_accuracy: 0.9391\n",
      "Epoch 229/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1441 - accuracy: 0.9473 - val_loss: 0.1574 - val_accuracy: 0.9529\n",
      "Epoch 230/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0993 - accuracy: 0.9657 - val_loss: 0.1919 - val_accuracy: 0.9309\n",
      "Epoch 231/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1398 - accuracy: 0.9525 - val_loss: 0.2450 - val_accuracy: 0.9119\n",
      "Epoch 232/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1355 - accuracy: 0.9515 - val_loss: 0.1451 - val_accuracy: 0.9462\n",
      "Epoch 233/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1231 - accuracy: 0.9545 - val_loss: 0.1619 - val_accuracy: 0.9510\n",
      "Epoch 234/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1208 - accuracy: 0.9550 - val_loss: 0.2367 - val_accuracy: 0.9119\n",
      "Epoch 235/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1402 - accuracy: 0.9467 - val_loss: 0.2047 - val_accuracy: 0.9206\n",
      "Epoch 236/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1268 - accuracy: 0.9532 - val_loss: 0.2556 - val_accuracy: 0.9060\n",
      "Epoch 237/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1045 - accuracy: 0.9628 - val_loss: 0.1485 - val_accuracy: 0.9500\n",
      "Epoch 238/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1134 - accuracy: 0.9578 - val_loss: 0.2647 - val_accuracy: 0.9062\n",
      "Epoch 239/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1219 - accuracy: 0.9585 - val_loss: 0.1350 - val_accuracy: 0.9539\n",
      "Epoch 240/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1246 - accuracy: 0.9530 - val_loss: 0.1499 - val_accuracy: 0.9477\n",
      "Epoch 241/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1226 - accuracy: 0.9538 - val_loss: 0.1355 - val_accuracy: 0.9531\n",
      "Epoch 242/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1284 - accuracy: 0.9545 - val_loss: 0.1967 - val_accuracy: 0.9306\n",
      "Epoch 243/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1319 - accuracy: 0.9525 - val_loss: 0.1683 - val_accuracy: 0.9436\n",
      "Epoch 244/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1155 - accuracy: 0.9548 - val_loss: 0.3684 - val_accuracy: 0.8569\n",
      "Epoch 245/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1338 - accuracy: 0.9530 - val_loss: 0.4665 - val_accuracy: 0.8216\n",
      "Epoch 246/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1152 - accuracy: 0.9540 - val_loss: 0.1821 - val_accuracy: 0.9316\n",
      "Epoch 247/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1263 - accuracy: 0.9535 - val_loss: 0.1508 - val_accuracy: 0.9487\n",
      "Epoch 248/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1040 - accuracy: 0.9643 - val_loss: 0.2180 - val_accuracy: 0.9240\n",
      "Epoch 249/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1127 - accuracy: 0.9617 - val_loss: 0.2144 - val_accuracy: 0.9262\n",
      "Epoch 250/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1351 - accuracy: 0.9513 - val_loss: 0.2311 - val_accuracy: 0.9379\n",
      "Epoch 251/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0963 - accuracy: 0.9660 - val_loss: 0.2259 - val_accuracy: 0.9291\n",
      "Epoch 252/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1324 - accuracy: 0.9538 - val_loss: 0.2687 - val_accuracy: 0.9023\n",
      "Epoch 253/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1185 - accuracy: 0.9572 - val_loss: 0.2641 - val_accuracy: 0.9050\n",
      "Epoch 254/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1239 - accuracy: 0.9538 - val_loss: 0.1814 - val_accuracy: 0.9510\n",
      "Epoch 255/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1294 - accuracy: 0.9515 - val_loss: 0.2355 - val_accuracy: 0.9104\n",
      "Epoch 256/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1393 - accuracy: 0.9498 - val_loss: 0.2030 - val_accuracy: 0.9308\n",
      "Epoch 257/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1409 - accuracy: 0.9452 - val_loss: 0.2529 - val_accuracy: 0.9107\n",
      "Epoch 258/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1153 - accuracy: 0.9615 - val_loss: 0.1890 - val_accuracy: 0.9335\n",
      "Epoch 259/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1346 - accuracy: 0.9520 - val_loss: 0.2081 - val_accuracy: 0.9238\n",
      "Epoch 260/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1288 - accuracy: 0.9532 - val_loss: 0.2465 - val_accuracy: 0.9112\n",
      "Epoch 261/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1175 - accuracy: 0.9565 - val_loss: 0.1292 - val_accuracy: 0.9598\n",
      "Epoch 262/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1212 - accuracy: 0.9572 - val_loss: 0.3161 - val_accuracy: 0.8843\n",
      "Epoch 263/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1119 - accuracy: 0.9617 - val_loss: 0.2607 - val_accuracy: 0.9043\n",
      "Epoch 264/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1502 - accuracy: 0.9448 - val_loss: 0.2665 - val_accuracy: 0.9002\n",
      "Epoch 265/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1217 - accuracy: 0.9570 - val_loss: 0.1935 - val_accuracy: 0.9322\n",
      "Epoch 266/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1098 - accuracy: 0.9585 - val_loss: 0.1452 - val_accuracy: 0.9497\n",
      "Epoch 267/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1013 - accuracy: 0.9620 - val_loss: 0.1271 - val_accuracy: 0.9588\n",
      "Epoch 268/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1340 - accuracy: 0.9523 - val_loss: 0.1162 - val_accuracy: 0.9612\n",
      "Epoch 269/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1169 - accuracy: 0.9620 - val_loss: 0.4316 - val_accuracy: 0.8506\n",
      "Epoch 270/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1118 - accuracy: 0.9605 - val_loss: 0.1383 - val_accuracy: 0.9507\n",
      "Epoch 271/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1301 - accuracy: 0.9505 - val_loss: 0.1652 - val_accuracy: 0.9409\n",
      "Epoch 272/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0922 - accuracy: 0.9712 - val_loss: 0.3365 - val_accuracy: 0.8854\n",
      "Epoch 273/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1472 - accuracy: 0.9480 - val_loss: 0.1638 - val_accuracy: 0.9422\n",
      "Epoch 274/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1482 - accuracy: 0.9507 - val_loss: 0.2052 - val_accuracy: 0.9194\n",
      "Epoch 275/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1431 - accuracy: 0.9482 - val_loss: 0.1503 - val_accuracy: 0.9455\n",
      "Epoch 276/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1054 - accuracy: 0.9632 - val_loss: 0.2322 - val_accuracy: 0.9142\n",
      "Epoch 277/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1319 - accuracy: 0.9532 - val_loss: 0.1593 - val_accuracy: 0.9432\n",
      "Epoch 278/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1362 - accuracy: 0.9513 - val_loss: 0.2952 - val_accuracy: 0.8942\n",
      "Epoch 279/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1118 - accuracy: 0.9607 - val_loss: 0.2637 - val_accuracy: 0.9051\n",
      "Epoch 280/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1342 - accuracy: 0.9513 - val_loss: 0.3641 - val_accuracy: 0.8727\n",
      "Epoch 281/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1051 - accuracy: 0.9605 - val_loss: 0.1521 - val_accuracy: 0.9472\n",
      "Epoch 282/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1448 - accuracy: 0.9477 - val_loss: 0.1134 - val_accuracy: 0.9633\n",
      "Epoch 283/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1043 - accuracy: 0.9617 - val_loss: 0.2446 - val_accuracy: 0.9053\n",
      "Epoch 284/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1495 - accuracy: 0.9488 - val_loss: 0.1780 - val_accuracy: 0.9447\n",
      "Epoch 285/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1391 - accuracy: 0.9465 - val_loss: 0.1491 - val_accuracy: 0.9455\n",
      "Epoch 286/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1039 - accuracy: 0.9663 - val_loss: 0.1328 - val_accuracy: 0.9560\n",
      "Epoch 287/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0973 - accuracy: 0.9693 - val_loss: 0.2703 - val_accuracy: 0.9036\n",
      "Epoch 288/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1150 - accuracy: 0.9595 - val_loss: 0.2148 - val_accuracy: 0.9266\n",
      "Epoch 289/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1361 - accuracy: 0.9510 - val_loss: 0.1744 - val_accuracy: 0.9513\n",
      "Epoch 290/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1147 - accuracy: 0.9557 - val_loss: 0.2756 - val_accuracy: 0.9018\n",
      "Epoch 291/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1299 - accuracy: 0.9542 - val_loss: 0.1640 - val_accuracy: 0.9454\n",
      "Epoch 292/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1253 - accuracy: 0.9585 - val_loss: 0.1673 - val_accuracy: 0.9333\n",
      "Epoch 293/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0988 - accuracy: 0.9630 - val_loss: 0.1628 - val_accuracy: 0.9530\n",
      "Epoch 294/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1121 - accuracy: 0.9638 - val_loss: 0.1406 - val_accuracy: 0.9480\n",
      "Epoch 295/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1295 - accuracy: 0.9545 - val_loss: 0.1998 - val_accuracy: 0.9241\n",
      "Epoch 296/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1569 - accuracy: 0.9425 - val_loss: 0.2209 - val_accuracy: 0.9171\n",
      "Epoch 297/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1002 - accuracy: 0.9655 - val_loss: 0.1421 - val_accuracy: 0.9516\n",
      "Epoch 298/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1126 - accuracy: 0.9605 - val_loss: 0.3065 - val_accuracy: 0.8913\n",
      "Epoch 299/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1309 - accuracy: 0.9545 - val_loss: 0.1222 - val_accuracy: 0.9551\n",
      "Epoch 300/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1111 - accuracy: 0.9638 - val_loss: 0.1380 - val_accuracy: 0.9517\n"
     ]
    }
   ],
   "source": [
    "for i, (train, val) in enumerate([folds[0]]):\n",
    "    \n",
    "    model = createModel()\n",
    "    \n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    metrics = ['accuracy']\n",
    "    \n",
    "    model.compile(optimizer=opt, loss=loss, metrics=metrics)\n",
    "    \n",
    "    tboardCb = tf.keras.callbacks.TensorBoard(log_dir=f\"{logBasePath}/{logPrefix}_{i}\", histogram_freq=1, profile_batch=(2,10))\n",
    "    lrSchedule = tf.keras.callbacks.LearningRateScheduler(schedule)\n",
    "    \n",
    "    cbs = [tboardCb]\n",
    "    \n",
    "    model.evaluate(val)\n",
    "    model.fit(train, initial_epoch=START_EPOCH, epochs=END_EPOCH, steps_per_epoch=STEPS_PER_EPOCH, callbacks=cbs, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae70be7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
