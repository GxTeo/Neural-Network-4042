{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f19017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d782ddf",
   "metadata": {},
   "source": [
    "### Check Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03faa827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac4996",
   "metadata": {},
   "source": [
    "### GPU Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1e955b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 02:33:58.024893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 02:33:58.034390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 02:33:58.034729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2835bd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f935a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be867b6",
   "metadata": {},
   "source": [
    "### Pandas Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92db292",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_column', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0907c",
   "metadata": {},
   "source": [
    "### Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0fd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VAL_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf19fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_WIDTH = 227\n",
    "CROP_HEIGHT = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d40847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldFiles = [\"adience/unprocessed/fold_0_data.txt\",\n",
    "             \"adience/unprocessed/fold_1_data.txt\",\n",
    "             \"adience/unprocessed/fold_2_data.txt\",\n",
    "             \"adience/unprocessed/fold_3_data.txt\",\n",
    "             \"adience/unprocessed/fold_4_data.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f61c7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genderMap = defaultdict(lambda : np.NaN)\n",
    "genderMap['m'] = 0\n",
    "genderMap['f'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d26242",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = ['(0, 2)', '(4, 6)', '(8, 13)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
    "ageMap = defaultdict(lambda : np.NaN)\n",
    "for i,a in enumerate(ages):\n",
    "    ageMap[a] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b1fc3",
   "metadata": {},
   "source": [
    "### Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd634a3",
   "metadata": {},
   "source": [
    "Dataset generation pipeline:\n",
    "Input: \n",
    "- foldFile - Path to fold file. Fold file Describes which images are in the fold and its corresponding labels\n",
    "- imgBaseFolder - Base folder to search image from\n",
    "- imgPrefix - Prefix of image file\n",
    "- genderMap - Map from ['m', 'f', 'u', None], to one hot index\n",
    "- ageMap - Map from age category to one hot index\n",
    "- imgWidth - Resulting image width\n",
    "- imgHeigh - Resulting image height\n",
    "- batchSize - Int or None, batch size\n",
    "- configureDs - Function accepting dataset for performance configurations\n",
    "- preBatch - List of (name, functions) pair that will be mapped before batching. name is used as name parameters for tf graph \n",
    "- postBatch - List of (name, functions) that will be mapped after batching. name is used as name parameters for tf graph\n",
    "\n",
    "The processing functions should have signature function(img, label) -> (img, label)\n",
    "\n",
    "Pipeline\n",
    "\n",
    "Read Fold File -> Preprocess filename and labels (dataframe) -> Convert filename and labels to numpy array -> Convert filename and labels to tf dataset -> Parse images and labels -> Configure Dataset for performance -> Pre-Batching preprocessing -> Batch -> Post-Batching preprocessing -> Output\n",
    "\n",
    "Some preprocessing steps can only be done before and some can only be done after batching, thats why there are seperated pre and post batching list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0795464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, batchSize, configureDs=None, preBatch=[], postBatch=[]):\n",
    "    \n",
    "    def parseImage(filename):\n",
    "        img = tf.io.read_file(filename)\n",
    "        img = tf.image.decode_jpeg(img)\n",
    "        img = tf.image.resize(img, [imgHeight, imgWidth])\n",
    "         \n",
    "        return img\n",
    "    \n",
    "    # Read Fold File\n",
    "    foldData = []\n",
    "    for f in foldFiles:\n",
    "        foldData.append(pd.read_csv(f, sep=\"\\t\"))\n",
    "    foldData = pd.concat(foldData)\n",
    "    \n",
    "    # Form File Name\n",
    "    foldData['filename'] = foldData.apply(lambda r: os.path.join(imgBaseFolder, r['user_id'], f\"{imgPrefix}.{r['face_id']}.{r['original_image']}\"), axis=1)\n",
    "    \n",
    "    # Generate Label One Hot Index\n",
    "    foldData['gender_ind'] = foldData['gender'].map(genderMap)\n",
    "    foldData['age_ind'] = foldData['age'].map(ageMap)\n",
    "    \n",
    "    # Remove dirty data\n",
    "    foldData.dropna(subset=['gender_ind', 'age_ind'], inplace=True)\n",
    "    \n",
    "    # Dataframe to numpy\n",
    "    filenames = foldData['filename'].to_numpy()\n",
    "    \n",
    "    genderIndex = foldData['gender_ind'].to_numpy().astype(int)\n",
    "    ageIndex = foldData['age_ind'].to_numpy().astype(int)\n",
    "    \n",
    "    # Numpy to Dataset\n",
    "    fnDs = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    genderIndDs = tf.data.Dataset.from_tensor_slices(genderIndex)\n",
    "    ageIndDs = tf.data.Dataset.from_tensor_slices(ageIndex)\n",
    "    \n",
    "    # Parse Images\n",
    "    imageDs = fnDs.map(parseImage, num_parallel_calls=tf.data.AUTOTUNE, name=\"parse_image\")\n",
    "    \n",
    "    # Parse Labels\n",
    "    genderLabDs = genderIndDs.map(lambda x: tf.one_hot(x, genderDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"gender_one_hot\")\n",
    "    ageLabDs = ageIndDs.map(lambda x: tf.one_hot(x, ageDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"age_one_hot\")\n",
    "    \n",
    "    # Combine Labels\n",
    "    labelDs = tf.data.Dataset.zip((genderLabDs, ageLabDs), name=\"label_zip\")\n",
    "    labelDs = labelDs.map(lambda g,a: {\"gender\": g, \"age\": a}, num_parallel_calls=tf.data.AUTOTUNE, name='label_dict')\n",
    "    \n",
    "    # Combine Images and Labels into dataset\n",
    "    ds = tf.data.Dataset.zip((imageDs, labelDs))\n",
    "    \n",
    "    # Configure Performance\n",
    "    if(configureDs is not None):\n",
    "        ds = configureDs(ds)\n",
    "    \n",
    "    # Pre Batch Preprocessing\n",
    "    for n,f in preBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    # Batch\n",
    "    if(batchSize is not None):\n",
    "        ds = ds.batch(batchSize, name=\"ds_batch\")\n",
    "    \n",
    "    # Post Batch Preprocessing\n",
    "    for n,f in postBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320ed92",
   "metadata": {},
   "source": [
    "### Preprocessings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "472b7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=100)\n",
    "    ds = ds.repeat()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adb98feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313da7f1",
   "metadata": {},
   "source": [
    "#### Preprocessing steps according to the reference paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7724a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainPreprocessA(img, lab):\n",
    "        \n",
    "        img = tf.image.random_crop(img, [CROP_HEIGHT, CROP_WIDTH, 3])\n",
    "        \n",
    "        ud = tf.random.uniform([], dtype=tf.float32)\n",
    "        udCond = tf.less(ud, 0.5)\n",
    "        \n",
    "        img = tf.cond(udCond, lambda: tf.image.flip_up_down(img), lambda: img)\n",
    "        \n",
    "        lr = tf.random.uniform([], dtype=tf.float32)\n",
    "        lrCond = tf.less(lr, 0.5)\n",
    "        \n",
    "        img = tf.cond(lrCond, lambda: tf.image.flip_left_right(img), lambda: img)\n",
    "        \n",
    "        img = tf.image.random_brightness(img, 63/255)\n",
    "        \n",
    "        img = tf.image.random_contrast(img, 0.2, 1.8) \n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14ee59ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valPreprocessA(img, lab):\n",
    "        \n",
    "        img = tf.image.crop_to_bounding_box(img,\n",
    "                                            (IMG_HEIGHT-CROP_HEIGHT) // 2,\n",
    "                                            (IMG_WIDTH-CROP_WIDTH) // 2,\n",
    "                                            CROP_HEIGHT,\n",
    "                                            CROP_WIDTH)\n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a03ab680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageStandardize(img, lab):\n",
    "    \n",
    "    img = tf.image.per_image_standardization(img)\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ec104",
   "metadata": {},
   "source": [
    "#### Label extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "294a2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractGenderLabel(img, lab):\n",
    "    \n",
    "    lab = lab['gender']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a98897ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAgeLabel(img, lab):\n",
    "    \n",
    "    lab = lab['age']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7778c",
   "metadata": {},
   "source": [
    "### Generate Folds for K-Folds validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4172d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFoldDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, valBatchSize, trainConfigureDs=None, trainPreBatch=[], trainPostBatch=[], valConfigureDs=None, valPreBatch=[], valPostBatch=[]):\n",
    "    '''\n",
    "        Returns list of (train, validation) datasets\n",
    "    '''\n",
    "    \n",
    "    N = len(foldFiles)\n",
    "    \n",
    "    folds = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        trainFiles = foldFiles[:i]\n",
    "        if(i < N-1):\n",
    "            trainFiles.extend(foldFiles[i+1:])\n",
    "            \n",
    "        valFiles = foldFiles[i]\n",
    "        \n",
    "        trainDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, configureDs=trainConfigureDs, preBatch=trainPreBatch, postBatch=trainPostBatch)\n",
    "        valDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, valBatchSize, configureDs=valConfigureDs, preBatch=valPreBatch, postBatch=valPostBatch)\n",
    "        \n",
    "        folds.append((trainDs, valDs))\n",
    "        \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4f43dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPreBatch = [(\"train_process_a\", trainPreprocessA), \n",
    "                 (\"train_standardize\", imageStandardize), \n",
    "                 (\"train_extract_gender\", extractGenderLabel)]\n",
    "\n",
    "valPreBatch = [(\"val_process_a\", valPreprocessA), \n",
    "               (\"val_standardize\", imageStandardize), \n",
    "               (\"val_extract_gender\", extractGenderLabel)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10474d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 02:33:58.273384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-29 02:33:58.274131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 02:33:58.274500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 02:33:58.274804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 02:33:58.593217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 02:33:58.593545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 02:33:58.593830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 02:33:58.594158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8865 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:2d:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "folds = generateFoldDs(foldFiles, \"adience/faces\", \"coarse_tilt_aligned_face\", genderMap, ageMap, 2, 8, \n",
    "                       IMG_WIDTH, IMG_HEIGHT, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE, \n",
    "                       trainConfigureDs=trainConfigPerformance, trainPreBatch=trainPreBatch, \n",
    "                       valConfigureDs=valConfigPerformance, valPreBatch=valPreBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57d814af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b5f9bc",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d0df0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in folds[0][0].take(1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c9e2833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 227, 227, 3), dtype=float32, numpy=\n",
       "array([[[[ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         ...,\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ]],\n",
       "\n",
       "        [[ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         ...,\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ]],\n",
       "\n",
       "        [[ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         ...,\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         ...,\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ]],\n",
       "\n",
       "        [[ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         ...,\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ]],\n",
       "\n",
       "        [[ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         ...,\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ],\n",
       "         [ 0.06113856, -0.85024065, -1.7913574 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.6488009 , -1.2786739 , -1.3432643 ],\n",
       "         [-0.6488009 , -1.2786739 , -1.3432643 ],\n",
       "         [-0.6488009 , -1.2786739 , -1.3432643 ],\n",
       "         ...,\n",
       "         [-0.6488009 , -1.2786739 , -1.3432643 ],\n",
       "         [-0.6488009 , -1.2786739 , -1.3432643 ],\n",
       "         [-0.6488009 , -1.2786739 , -1.3432643 ]],\n",
       "\n",
       "        [[-0.6488009 , -1.2786739 , -1.3432643 ],\n",
       "         [-0.6488009 , -1.2786739 , -1.3432643 ],\n",
       "         [-0.6488009 , -1.2786739 , -1.3432643 ],\n",
       "         ...,\n",
       "         [-0.6488009 , -1.257436  , -1.3432643 ],\n",
       "         [-0.6488009 , -1.257436  , -1.3432643 ],\n",
       "         [-0.6488009 , -1.257436  , -1.3432643 ]],\n",
       "\n",
       "        [[-0.6488009 , -1.2786739 , -1.3432643 ],\n",
       "         [-0.6488009 , -1.2786739 , -1.3432643 ],\n",
       "         [-0.6488009 , -1.2786739 , -1.3432643 ],\n",
       "         ...,\n",
       "         [-0.6285171 , -1.2583901 , -1.3432643 ],\n",
       "         [-0.6488009 , -1.2786739 , -1.3432643 ],\n",
       "         [-0.6478468 , -1.2777197 , -1.3432643 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.3416919 , -1.152891  , -1.2205925 ],\n",
       "         [-0.02105502, -0.91565335, -1.0216824 ],\n",
       "         [ 0.4893405 , -0.47506836, -0.6124563 ],\n",
       "         ...,\n",
       "         [ 0.10223203, -0.8674448 , -0.93203527],\n",
       "         [ 0.00825072, -0.94329935, -1.06227   ],\n",
       "         [ 0.11054467, -0.9016077 , -1.0086737 ]],\n",
       "\n",
       "        [[-0.6488009 , -1.257436  , -1.3432643 ],\n",
       "         [-0.64785904, -1.2786739 , -1.2989638 ],\n",
       "         [-0.6184369 , -1.2786739 , -1.3404846 ],\n",
       "         ...,\n",
       "         [ 0.16841455, -0.84373784, -0.9508039 ],\n",
       "         [ 0.14906974, -0.86308265, -1.012624  ],\n",
       "         [ 0.19286436, -0.83400846, -0.98354995]],\n",
       "\n",
       "        [[-0.6447772 , -1.2786739 , -1.3432643 ],\n",
       "         [-0.6488009 , -1.2507683 , -1.3148091 ],\n",
       "         [-0.6488009 , -1.2716638 , -1.3148091 ],\n",
       "         ...,\n",
       "         [ 0.31433752, -0.7190526 , -0.86859405],\n",
       "         [ 0.2831972 , -0.7501928 , -0.9422099 ],\n",
       "         [ 0.2671228 , -0.76626736, -0.9582843 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.350605  , -1.3389354 ],\n",
       "         ...,\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ]],\n",
       "\n",
       "        [[-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.350605  , -1.3389354 ],\n",
       "         ...,\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ]],\n",
       "\n",
       "        [[-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.350605  , -1.3389354 ],\n",
       "         ...,\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         ...,\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ]],\n",
       "\n",
       "        [[-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         ...,\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ]],\n",
       "\n",
       "        [[-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         ...,\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ],\n",
       "         [-1.6264153 , -1.3641579 , -1.3389354 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.9076696 , -0.87547547, -1.4132155 ],\n",
       "         [-0.9083642 , -0.8761696 , -1.4139096 ],\n",
       "         [-0.895407  , -0.8603592 , -1.3980992 ],\n",
       "         ...,\n",
       "         [-0.9011416 , -0.8065845 , -1.3950708 ],\n",
       "         [-0.8813061 , -0.786749  , -1.3752353 ],\n",
       "         [-0.91068864, -0.81613153, -1.4046178 ]],\n",
       "\n",
       "        [[-0.844501  , -0.8123069 , -1.3500469 ],\n",
       "         [-0.8258214 , -0.7936273 , -1.3313674 ],\n",
       "         [-0.8524556 , -0.82026154, -1.3580015 ],\n",
       "         ...,\n",
       "         [-0.8677888 , -0.77037793, -1.3602909 ],\n",
       "         [-0.923961  , -0.82655066, -1.4164636 ],\n",
       "         [-0.8390877 , -0.74167734, -1.3315903 ]],\n",
       "\n",
       "        [[-0.86709094, -0.8348968 , -1.3726368 ],\n",
       "         [-0.86945707, -0.837263  , -1.375003  ],\n",
       "         [-0.9068036 , -0.8746095 , -1.4123495 ],\n",
       "         ...,\n",
       "         [-0.875689  , -0.7782787 , -1.3681916 ],\n",
       "         [-0.8767939 , -0.77938354, -1.3692964 ],\n",
       "         [-0.86314875, -0.76573837, -1.3556513 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.4508983 , -1.4839205 , -2.09992   ],\n",
       "         [-1.4508983 , -1.4839205 , -2.09992   ],\n",
       "         [-1.4508983 , -1.4839205 , -2.09992   ],\n",
       "         ...,\n",
       "         [ 1.8751338 ,  1.8421124 ,  1.2261128 ],\n",
       "         [ 1.8751338 ,  1.8421124 ,  1.2261128 ],\n",
       "         [ 1.8751338 ,  1.8421124 ,  1.2261128 ]],\n",
       "\n",
       "        [[-1.4508983 , -1.4839205 , -2.09992   ],\n",
       "         [-1.4508983 , -1.4839205 , -2.09992   ],\n",
       "         [-1.4508983 , -1.4839205 , -2.09992   ],\n",
       "         ...,\n",
       "         [ 1.8751338 ,  1.8421124 ,  1.2261128 ],\n",
       "         [ 1.8751338 ,  1.8421124 ,  1.2261128 ],\n",
       "         [ 1.8751338 ,  1.8421124 ,  1.2261128 ]],\n",
       "\n",
       "        [[-1.4508983 , -1.4839205 , -2.09992   ],\n",
       "         [-1.4508983 , -1.4839205 , -2.09992   ],\n",
       "         [-1.4508983 , -1.4839205 , -2.09992   ],\n",
       "         ...,\n",
       "         [ 1.7865313 ,  1.7535092 ,  1.1375105 ],\n",
       "         [ 1.4085577 ,  1.3755345 ,  0.7595359 ],\n",
       "         [ 1.0701679 ,  1.0371457 ,  0.4211461 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "819ce578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78c5d50",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a70f6af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    inp = tf.keras.Input(shape=(CROP_HEIGHT, CROP_WIDTH, 3))\n",
    "\n",
    "    backbone = tf.keras.applications.resnet_v2.ResNet50V2(include_top=False, input_shape=(CROP_HEIGHT, CROP_WIDTH, 3))\n",
    "    backbone.trainable = False    \n",
    "    \n",
    "    flat1 = tf.keras.layers.Flatten(name='flat1')\n",
    "    fc1 = tf.keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc1')\n",
    "    do1 = tf.keras.layers.Dropout(0.5, name='do1')\n",
    "\n",
    "    fc2 = tf.keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc2')\n",
    "    do2 = tf.keras.layers.Dropout(0.5, name='do2')\n",
    "\n",
    "    fc3 = tf.keras.layers.Dense(2, activation='softmax', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='fc3')\n",
    "\n",
    "    o = tf.keras.applications.resnet_v2.preprocess_input(inp)\n",
    "    o = backbone(o, training=False)\n",
    "    o = flat1(o)\n",
    "    o = fc1(o)\n",
    "    o = do1(o)\n",
    "\n",
    "    o = fc2(o)\n",
    "    o = do2(o)\n",
    "\n",
    "    o = fc3(o)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=o, name='baseline_1')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e962234",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b73a21c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"baseline_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 227, 227, 3)]     0         \n",
      "                                                                 \n",
      " tf.math.truediv (TFOpLambda  (None, 227, 227, 3)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " tf.math.subtract (TFOpLambd  (None, 227, 227, 3)      0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 8, 8, 2048)        23564800  \n",
      "                                                                 \n",
      " flat1 (Flatten)             (None, 131072)            0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 128)               16777344  \n",
      "                                                                 \n",
      " do1 (Dropout)               (None, 128)               0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 128)               16512     \n",
      "                                                                 \n",
      " do2 (Dropout)               (None, 128)               0         \n",
      "                                                                 \n",
      " fc3 (Dense)                 (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,358,914\n",
      "Trainable params: 16,794,114\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fcc28d",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ffbbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = 1000\n",
    "EPOCH = 100\n",
    "\n",
    "START_EPOCH = 0\n",
    "END_EPOCH = START_EPOCH + EPOCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cc17f1",
   "metadata": {},
   "source": [
    "#### Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1ab143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(epoch, lr):\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "222f6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logBasePath = \"log/baseline_resnet_2\"\n",
    "logPrefix = \"log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1b72905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 02:34:02.674257: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-29 02:34:02.674280: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-10-29 02:34:02.674302: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1665] Profiler found 1 GPUs\n",
      "2022-10-29 02:34:02.766410: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-10-29 02:34:02.767615: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-10-29 02:34:03.836029: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  19/3528 [..............................] - ETA: 31s - loss: 0.7283 - accuracy: 0.3816  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 02:34:04.830774: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 30s 8ms/step - loss: 0.6945 - accuracy: 0.5232\n",
      "Epoch 1/100\n",
      "   1/1000 [..............................] - ETA: 22:25 - loss: 0.7995 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 02:34:34.177203: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-29 02:34:34.177220: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10/1000 [..............................] - ETA: 1:07 - loss: 7.5650 - accuracy: 0.5250  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 02:34:34.614461: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-10-29 02:34:34.615314: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-10-29 02:34:34.654513: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 3228 callback api events and 3203 activity events. \n",
      "2022-10-29 02:34:34.680391: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-10-29 02:34:34.707750: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_resnet_2/log_0/plugins/profile/2022_10_29_02_34_34\n",
      "\n",
      "2022-10-29 02:34:34.742403: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_resnet_2/log_0/plugins/profile/2022_10_29_02_34_34/rachanon-pc1.trace.json.gz\n",
      "2022-10-29 02:34:34.781218: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_resnet_2/log_0/plugins/profile/2022_10_29_02_34_34\n",
      "\n",
      "2022-10-29 02:34:34.785468: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_resnet_2/log_0/plugins/profile/2022_10_29_02_34_34/rachanon-pc1.memory_profile.json.gz\n",
      "2022-10-29 02:34:34.786500: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_resnet_2/log_0/plugins/profile/2022_10_29_02_34_34\n",
      "Dumped tool data for xplane.pb to log/baseline_resnet_2/log_0/plugins/profile/2022_10_29_02_34_34/rachanon-pc1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_resnet_2/log_0/plugins/profile/2022_10_29_02_34_34/rachanon-pc1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_resnet_2/log_0/plugins/profile/2022_10_29_02_34_34/rachanon-pc1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_resnet_2/log_0/plugins/profile/2022_10_29_02_34_34/rachanon-pc1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_resnet_2/log_0/plugins/profile/2022_10_29_02_34_34/rachanon-pc1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 996/1000 [============================>.] - ETA: 0s - loss: 0.8447 - accuracy: 0.5590"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 02:35:09.735159: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4026531840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 38s 36ms/step - loss: 0.8440 - accuracy: 0.5592 - val_loss: 0.7751 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 2/100\n",
      " 995/1000 [============================>.] - ETA: 0s - loss: 0.6560 - accuracy: 0.6304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 02:35:45.727194: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4026531840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6561 - accuracy: 0.6305 - val_loss: 0.6941 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 3/100\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 0.6616 - accuracy: 0.5812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 02:36:21.585340: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4026531840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6619 - accuracy: 0.5792 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 4/100\n",
      " 995/1000 [============================>.] - ETA: 0s - loss: 0.8103 - accuracy: 0.5791"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 02:36:57.742604: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4026531840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.8095 - accuracy: 0.5795 - val_loss: 0.7082 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.6957 - accuracy: 0.5278"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 02:37:33.569014: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4026531840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6957 - accuracy: 0.5278 - val_loss: 0.6955 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6558 - accuracy: 0.6168 - val_loss: 0.7010 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6839 - accuracy: 0.5573 - val_loss: 0.6968 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 1.1269 - accuracy: 0.5490 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6754 - accuracy: 0.5880 - val_loss: 0.7137 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6696 - accuracy: 0.5817 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6802 - accuracy: 0.5720 - val_loss: 0.7548 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6976 - accuracy: 0.5205 - val_loss: 0.7082 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6564 - accuracy: 0.6192 - val_loss: 0.6948 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6857 - accuracy: 0.5583 - val_loss: 0.7535 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6933 - accuracy: 0.5355 - val_loss: 0.7260 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6779 - accuracy: 0.5790 - val_loss: 0.7812 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6698 - accuracy: 0.5872 - val_loss: 0.7520 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6811 - accuracy: 0.5710 - val_loss: 0.7702 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6994 - accuracy: 0.5130 - val_loss: 0.7258 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6491 - accuracy: 0.6335 - val_loss: 0.8327 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 1.4904 - accuracy: 0.5550 - val_loss: 0.7746 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6938 - accuracy: 0.5412 - val_loss: 0.6925 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6828 - accuracy: 0.5592 - val_loss: 0.7059 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6631 - accuracy: 0.5980 - val_loss: 0.7631 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6830 - accuracy: 0.5645 - val_loss: 0.7031 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6969 - accuracy: 0.5185 - val_loss: 0.7123 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6538 - accuracy: 0.6145 - val_loss: 0.8476 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6893 - accuracy: 0.5483 - val_loss: 0.7106 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6864 - accuracy: 0.5595 - val_loss: 0.6985 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6808 - accuracy: 0.5585 - val_loss: 0.7346 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6691 - accuracy: 0.5882 - val_loss: 0.6925 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6806 - accuracy: 0.5725 - val_loss: 0.6951 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6956 - accuracy: 0.5240 - val_loss: 0.7352 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6598 - accuracy: 0.6093 - val_loss: 0.8566 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6850 - accuracy: 0.5487 - val_loss: 0.6976 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6849 - accuracy: 0.5627 - val_loss: 0.6940 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6846 - accuracy: 0.5562 - val_loss: 0.7353 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6664 - accuracy: 0.5918 - val_loss: 0.6964 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6799 - accuracy: 0.5745 - val_loss: 0.7322 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6979 - accuracy: 0.5235 - val_loss: 0.6935 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6749 - accuracy: 0.5897 - val_loss: 0.7070 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.7216 - accuracy: 0.5610 - val_loss: 0.6945 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6832 - accuracy: 0.5700 - val_loss: 0.6931 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6830 - accuracy: 0.5497 - val_loss: 0.8011 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6671 - accuracy: 0.5910 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6807 - accuracy: 0.5735 - val_loss: 0.7368 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6962 - accuracy: 0.5232 - val_loss: 0.7070 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6765 - accuracy: 0.5838 - val_loss: 0.6970 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6693 - accuracy: 0.5757 - val_loss: 0.7051 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6826 - accuracy: 0.5780 - val_loss: 0.7116 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6875 - accuracy: 0.5395 - val_loss: 0.8373 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6639 - accuracy: 0.6033 - val_loss: 0.7009 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6824 - accuracy: 0.5615 - val_loss: 0.7185 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6929 - accuracy: 0.5355 - val_loss: 0.7511 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6779 - accuracy: 0.5773 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6690 - accuracy: 0.5763 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6816 - accuracy: 0.5790 - val_loss: 0.7089 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6939 - accuracy: 0.5310 - val_loss: 0.7145 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6571 - accuracy: 0.6133 - val_loss: 0.6929 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6809 - accuracy: 0.5677 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6927 - accuracy: 0.5353 - val_loss: 0.7081 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6767 - accuracy: 0.5847 - val_loss: 0.6936 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6698 - accuracy: 0.5767 - val_loss: 0.7001 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6831 - accuracy: 0.5702 - val_loss: 0.6950 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6949 - accuracy: 0.5238 - val_loss: 0.6931 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6563 - accuracy: 0.6127 - val_loss: 0.7004 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6810 - accuracy: 0.5705 - val_loss: 0.7080 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.8283 - accuracy: 0.5263 - val_loss: 0.6980 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6794 - accuracy: 0.5810 - val_loss: 0.7001 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6684 - accuracy: 0.5767 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6815 - accuracy: 0.5740 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.6949 - accuracy: 0.5250 - val_loss: 0.7011 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6538 - accuracy: 0.6190 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6834 - accuracy: 0.5592 - val_loss: 0.7085 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6938 - accuracy: 0.5293 - val_loss: 0.6943 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6760 - accuracy: 0.5835 - val_loss: 0.7264 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6706 - accuracy: 0.5817 - val_loss: 0.7006 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6760 - accuracy: 0.5792 - val_loss: 0.8225 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.7033 - accuracy: 0.5140 - val_loss: 0.6939 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6518 - accuracy: 0.6260 - val_loss: 0.7217 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6831 - accuracy: 0.5560 - val_loss: 0.7485 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6933 - accuracy: 0.5408 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6771 - accuracy: 0.5735 - val_loss: 0.7387 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6669 - accuracy: 0.5928 - val_loss: 0.7691 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6841 - accuracy: 0.5567 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6966 - accuracy: 0.5255 - val_loss: 0.6989 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6498 - accuracy: 0.6265 - val_loss: 0.8290 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6872 - accuracy: 0.5535 - val_loss: 0.7609 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6912 - accuracy: 0.5480 - val_loss: 0.6949 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6818 - accuracy: 0.5655 - val_loss: 0.7220 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6665 - accuracy: 0.5893 - val_loss: 0.7140 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6808 - accuracy: 0.5707 - val_loss: 0.7040 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6956 - accuracy: 0.5263 - val_loss: 0.7468 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6563 - accuracy: 0.6173 - val_loss: 0.8600 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6893 - accuracy: 0.5430 - val_loss: 0.7115 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6851 - accuracy: 0.5602 - val_loss: 0.6938 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6860 - accuracy: 0.5510 - val_loss: 0.6937 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6658 - accuracy: 0.5990 - val_loss: 0.6941 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6817 - accuracy: 0.5715 - val_loss: 0.6931 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6969 - accuracy: 0.5245 - val_loss: 0.6997 - val_accuracy: 0.4768 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 03:34:58.545668: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-29 03:34:58.545689: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-10-29 03:34:58.760888: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-10-29 03:34:58.762265: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 29s 8ms/step - loss: 0.6923 - accuracy: 0.5232\n",
      "Epoch 1/100\n",
      "   1/1000 [..............................] - ETA: 25:06 - loss: 0.8076 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 03:35:29.073908: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-29 03:35:29.073930: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6/1000 [..............................] - ETA: 59s - loss: 7.6746 - accuracy: 0.4167    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 03:35:29.547424: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-10-29 03:35:29.550283: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-10-29 03:35:29.599261: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 3228 callback api events and 3203 activity events. \n",
      "2022-10-29 03:35:29.631598: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-10-29 03:35:29.665456: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_resnet_2/log_1/plugins/profile/2022_10_29_03_35_29\n",
      "\n",
      "2022-10-29 03:35:29.702030: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_resnet_2/log_1/plugins/profile/2022_10_29_03_35_29/rachanon-pc1.trace.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  28/1000 [..............................] - ETA: 31s - loss: 5.3873 - accuracy: 0.5446"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 03:35:29.750073: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_resnet_2/log_1/plugins/profile/2022_10_29_03_35_29\n",
      "\n",
      "2022-10-29 03:35:29.754501: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_resnet_2/log_1/plugins/profile/2022_10_29_03_35_29/rachanon-pc1.memory_profile.json.gz\n",
      "2022-10-29 03:35:29.755573: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_resnet_2/log_1/plugins/profile/2022_10_29_03_35_29\n",
      "Dumped tool data for xplane.pb to log/baseline_resnet_2/log_1/plugins/profile/2022_10_29_03_35_29/rachanon-pc1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_resnet_2/log_1/plugins/profile/2022_10_29_03_35_29/rachanon-pc1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_resnet_2/log_1/plugins/profile/2022_10_29_03_35_29/rachanon-pc1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_resnet_2/log_1/plugins/profile/2022_10_29_03_35_29/rachanon-pc1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_resnet_2/log_1/plugins/profile/2022_10_29_03_35_29/rachanon-pc1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 39s 37ms/step - loss: 1.1197 - accuracy: 0.5817 - val_loss: 0.7027 - val_accuracy: 0.4770 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.8618 - accuracy: 0.6177 - val_loss: 0.6942 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6633 - accuracy: 0.5790 - val_loss: 0.6945 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.7855 - accuracy: 0.5850 - val_loss: 0.8092 - val_accuracy: 0.5234 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6952 - accuracy: 0.5245 - val_loss: 0.7909 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.7356 - accuracy: 0.6155 - val_loss: 0.7254 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6865 - accuracy: 0.5635 - val_loss: 0.7045 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.8825 - accuracy: 0.5347 - val_loss: 0.6964 - val_accuracy: 0.5233 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6772 - accuracy: 0.5830 - val_loss: 0.7123 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6691 - accuracy: 0.5825 - val_loss: 0.6962 - val_accuracy: 0.5233 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6814 - accuracy: 0.5735 - val_loss: 0.7343 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6957 - accuracy: 0.5253 - val_loss: 0.7122 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6532 - accuracy: 0.6248 - val_loss: 0.6949 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6821 - accuracy: 0.5575 - val_loss: 0.7283 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6926 - accuracy: 0.5372 - val_loss: 0.6952 - val_accuracy: 0.5233 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6787 - accuracy: 0.5763 - val_loss: 0.7304 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6884 - accuracy: 0.5893 - val_loss: 0.7387 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6850 - accuracy: 0.5645 - val_loss: 0.7374 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6990 - accuracy: 0.5182 - val_loss: 0.6975 - val_accuracy: 0.5233 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6484 - accuracy: 0.6305 - val_loss: 0.8143 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6890 - accuracy: 0.5485 - val_loss: 0.7582 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6921 - accuracy: 0.5428 - val_loss: 0.6977 - val_accuracy: 0.5233 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6810 - accuracy: 0.5640 - val_loss: 0.7171 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6646 - accuracy: 0.5920 - val_loss: 0.7686 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6818 - accuracy: 0.5677 - val_loss: 0.7101 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6974 - accuracy: 0.5240 - val_loss: 0.7223 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6556 - accuracy: 0.6175 - val_loss: 0.8380 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6888 - accuracy: 0.5480 - val_loss: 0.7193 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6869 - accuracy: 0.5545 - val_loss: 0.7011 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6826 - accuracy: 0.5577 - val_loss: 0.7277 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6672 - accuracy: 0.5863 - val_loss: 0.6981 - val_accuracy: 0.5233 - lr: 0.0100\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6791 - accuracy: 0.5775 - val_loss: 0.7008 - val_accuracy: 0.5233 - lr: 0.0100\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6965 - accuracy: 0.5255 - val_loss: 0.7421 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6629 - accuracy: 0.6065 - val_loss: 0.8357 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6840 - accuracy: 0.5535 - val_loss: 0.7048 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6828 - accuracy: 0.5710 - val_loss: 0.7055 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6851 - accuracy: 0.5510 - val_loss: 0.7391 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6659 - accuracy: 0.5932 - val_loss: 0.7000 - val_accuracy: 0.5233 - lr: 0.0100\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.7727 - accuracy: 0.5652 - val_loss: 0.7108 - val_accuracy: 0.4767 - lr: 0.0100\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6983 - accuracy: 0.5205 - val_loss: 0.6939 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6740 - accuracy: 0.5878 - val_loss: 0.7127 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6713 - accuracy: 0.5692 - val_loss: 0.6946 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6839 - accuracy: 0.5608 - val_loss: 0.6938 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6814 - accuracy: 0.5570 - val_loss: 0.8305 - val_accuracy: 0.4767 - lr: 0.0100\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6695 - accuracy: 0.5895 - val_loss: 0.6949 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.7388 - accuracy: 0.5757 - val_loss: 0.7343 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6967 - accuracy: 0.5232 - val_loss: 0.7090 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6773 - accuracy: 0.5792 - val_loss: 0.6992 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6686 - accuracy: 0.5760 - val_loss: 0.7002 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6834 - accuracy: 0.5698 - val_loss: 0.7175 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6876 - accuracy: 0.5412 - val_loss: 0.8307 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6663 - accuracy: 0.5968 - val_loss: 0.6941 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.7431 - accuracy: 0.5663 - val_loss: 0.8743 - val_accuracy: 0.4785 - lr: 0.0100\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 1.0744 - accuracy: 0.5445 - val_loss: 0.7735 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6810 - accuracy: 0.5667 - val_loss: 0.6928 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6698 - accuracy: 0.5745 - val_loss: 0.6931 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6840 - accuracy: 0.5692 - val_loss: 0.6974 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6943 - accuracy: 0.5253 - val_loss: 0.7171 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6578 - accuracy: 0.6118 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6822 - accuracy: 0.5658 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 2.8908 - accuracy: 0.5325 - val_loss: 0.7063 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6785 - accuracy: 0.5780 - val_loss: 0.6929 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6692 - accuracy: 0.5805 - val_loss: 0.6959 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6828 - accuracy: 0.5742 - val_loss: 0.6952 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6946 - accuracy: 0.5280 - val_loss: 0.6962 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.7036 - accuracy: 0.6152 - val_loss: 0.6970 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6818 - accuracy: 0.5655 - val_loss: 0.6986 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6948 - accuracy: 0.5310 - val_loss: 0.6932 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6795 - accuracy: 0.5810 - val_loss: 0.6986 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6692 - accuracy: 0.5795 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6860 - accuracy: 0.5635 - val_loss: 0.6926 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6949 - accuracy: 0.5295 - val_loss: 0.7103 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6560 - accuracy: 0.6185 - val_loss: 0.6935 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6830 - accuracy: 0.5605 - val_loss: 0.7047 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6930 - accuracy: 0.5422 - val_loss: 0.6973 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6775 - accuracy: 0.5820 - val_loss: 0.7311 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6709 - accuracy: 0.5832 - val_loss: 0.6965 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6766 - accuracy: 0.5778 - val_loss: 0.8156 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.7017 - accuracy: 0.5128 - val_loss: 0.6945 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6520 - accuracy: 0.6277 - val_loss: 0.7254 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6824 - accuracy: 0.5577 - val_loss: 0.7419 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6927 - accuracy: 0.5403 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6764 - accuracy: 0.5723 - val_loss: 0.7447 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6672 - accuracy: 0.5893 - val_loss: 0.7820 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6850 - accuracy: 0.5595 - val_loss: 0.6929 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6971 - accuracy: 0.5250 - val_loss: 0.6993 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6478 - accuracy: 0.6283 - val_loss: 0.8546 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6902 - accuracy: 0.5495 - val_loss: 0.7551 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6907 - accuracy: 0.5422 - val_loss: 0.6940 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6825 - accuracy: 0.5595 - val_loss: 0.7231 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6669 - accuracy: 0.5905 - val_loss: 0.7123 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6863 - accuracy: 0.5738 - val_loss: 0.7004 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6951 - accuracy: 0.5325 - val_loss: 0.7493 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6591 - accuracy: 0.6122 - val_loss: 0.8572 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6878 - accuracy: 0.5460 - val_loss: 0.7118 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.8197 - accuracy: 0.5670 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6831 - accuracy: 0.5540 - val_loss: 0.6937 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6640 - accuracy: 0.5995 - val_loss: 0.6966 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6802 - accuracy: 0.5707 - val_loss: 0.6943 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6967 - accuracy: 0.5197 - val_loss: 0.6973 - val_accuracy: 0.4768 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 04:36:16.710778: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-29 04:36:16.710800: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-10-29 04:36:16.925474: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-10-29 04:36:16.928269: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 29s 8ms/step - loss: 0.6927 - accuracy: 0.5232\n",
      "Epoch 1/100\n",
      "   1/1000 [..............................] - ETA: 26:20 - loss: 0.6124 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 04:36:47.712532: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-29 04:36:47.712551: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   7/1000 [..............................] - ETA: 49s - loss: 10.2487 - accuracy: 0.5000 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 04:36:48.225616: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-10-29 04:36:48.237511: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-10-29 04:36:48.296545: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 3228 callback api events and 3203 activity events. \n",
      "2022-10-29 04:36:48.340859: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-10-29 04:36:48.382939: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_resnet_2/log_2/plugins/profile/2022_10_29_04_36_48\n",
      "\n",
      "2022-10-29 04:36:48.417656: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_resnet_2/log_2/plugins/profile/2022_10_29_04_36_48/rachanon-pc1.trace.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  27/1000 [..............................] - ETA: 35s - loss: 6.4425 - accuracy: 0.5556"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 04:36:48.476374: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_resnet_2/log_2/plugins/profile/2022_10_29_04_36_48\n",
      "\n",
      "2022-10-29 04:36:48.480841: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_resnet_2/log_2/plugins/profile/2022_10_29_04_36_48/rachanon-pc1.memory_profile.json.gz\n",
      "2022-10-29 04:36:48.482238: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_resnet_2/log_2/plugins/profile/2022_10_29_04_36_48\n",
      "Dumped tool data for xplane.pb to log/baseline_resnet_2/log_2/plugins/profile/2022_10_29_04_36_48/rachanon-pc1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_resnet_2/log_2/plugins/profile/2022_10_29_04_36_48/rachanon-pc1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_resnet_2/log_2/plugins/profile/2022_10_29_04_36_48/rachanon-pc1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_resnet_2/log_2/plugins/profile/2022_10_29_04_36_48/rachanon-pc1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_resnet_2/log_2/plugins/profile/2022_10_29_04_36_48/rachanon-pc1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 39s 37ms/step - loss: 0.9311 - accuracy: 0.5598 - val_loss: 0.7513 - val_accuracy: 0.4767 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6655 - accuracy: 0.6295 - val_loss: 0.7036 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6704 - accuracy: 0.5770 - val_loss: 0.6930 - val_accuracy: 0.5233 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6907 - accuracy: 0.6062 - val_loss: 0.7494 - val_accuracy: 0.5234 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6956 - accuracy: 0.5343 - val_loss: 0.6929 - val_accuracy: 0.5233 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.7145 - accuracy: 0.6183 - val_loss: 0.8436 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6820 - accuracy: 0.5663 - val_loss: 0.8176 - val_accuracy: 0.5233 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 1.2251 - accuracy: 0.5305 - val_loss: 0.6940 - val_accuracy: 0.4766 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6779 - accuracy: 0.5807 - val_loss: 0.7043 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6694 - accuracy: 0.5798 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.8336 - accuracy: 0.5845 - val_loss: 0.7441 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6966 - accuracy: 0.5268 - val_loss: 0.7052 - val_accuracy: 0.5234 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6553 - accuracy: 0.6215 - val_loss: 0.6944 - val_accuracy: 0.5233 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6824 - accuracy: 0.5592 - val_loss: 0.7135 - val_accuracy: 0.5234 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6982 - accuracy: 0.5330 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6767 - accuracy: 0.5763 - val_loss: 0.7501 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.7355 - accuracy: 0.5870 - val_loss: 0.7300 - val_accuracy: 0.4767 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6798 - accuracy: 0.5683 - val_loss: 0.7531 - val_accuracy: 0.4767 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6991 - accuracy: 0.5165 - val_loss: 0.6937 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6504 - accuracy: 0.6345 - val_loss: 0.7943 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6873 - accuracy: 0.5502 - val_loss: 0.7614 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6924 - accuracy: 0.5410 - val_loss: 0.6933 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6813 - accuracy: 0.5592 - val_loss: 0.7093 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6625 - accuracy: 0.5945 - val_loss: 0.7607 - val_accuracy: 0.4767 - lr: 0.0100\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.9303 - accuracy: 0.5713 - val_loss: 0.7021 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6960 - accuracy: 0.5270 - val_loss: 0.7148 - val_accuracy: 0.4767 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6520 - accuracy: 0.6205 - val_loss: 0.8507 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6893 - accuracy: 0.5510 - val_loss: 0.7173 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6878 - accuracy: 0.5525 - val_loss: 0.7036 - val_accuracy: 0.4767 - lr: 0.0100\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6834 - accuracy: 0.5583 - val_loss: 0.7275 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6681 - accuracy: 0.5860 - val_loss: 0.6938 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6920 - accuracy: 0.5822 - val_loss: 0.7045 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6961 - accuracy: 0.5295 - val_loss: 0.7343 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6613 - accuracy: 0.6055 - val_loss: 0.8483 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6846 - accuracy: 0.5485 - val_loss: 0.6993 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6839 - accuracy: 0.5670 - val_loss: 0.6974 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6840 - accuracy: 0.5510 - val_loss: 0.7363 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6658 - accuracy: 0.5928 - val_loss: 0.6947 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6791 - accuracy: 0.5748 - val_loss: 0.7359 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6997 - accuracy: 0.5138 - val_loss: 0.6922 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6746 - accuracy: 0.5867 - val_loss: 0.7125 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6711 - accuracy: 0.5683 - val_loss: 0.6921 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6828 - accuracy: 0.5705 - val_loss: 0.6921 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6819 - accuracy: 0.5548 - val_loss: 0.8224 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6689 - accuracy: 0.5895 - val_loss: 0.6937 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6806 - accuracy: 0.5707 - val_loss: 0.7325 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6957 - accuracy: 0.5293 - val_loss: 0.7140 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6761 - accuracy: 0.5807 - val_loss: 0.6942 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6692 - accuracy: 0.5773 - val_loss: 0.7048 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6837 - accuracy: 0.5717 - val_loss: 0.7116 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6858 - accuracy: 0.5408 - val_loss: 0.8487 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6637 - accuracy: 0.6030 - val_loss: 0.6947 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6827 - accuracy: 0.5673 - val_loss: 0.7142 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6921 - accuracy: 0.5368 - val_loss: 0.7722 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6808 - accuracy: 0.5725 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6699 - accuracy: 0.5760 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6823 - accuracy: 0.5755 - val_loss: 0.7043 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6945 - accuracy: 0.5268 - val_loss: 0.7202 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6559 - accuracy: 0.6145 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6828 - accuracy: 0.5645 - val_loss: 0.6930 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6933 - accuracy: 0.5285 - val_loss: 0.7017 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6796 - accuracy: 0.5788 - val_loss: 0.6930 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6699 - accuracy: 0.5753 - val_loss: 0.6979 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6829 - accuracy: 0.5723 - val_loss: 0.6945 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6931 - accuracy: 0.5305 - val_loss: 0.6971 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6546 - accuracy: 0.6168 - val_loss: 0.7072 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6811 - accuracy: 0.5675 - val_loss: 0.7022 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6935 - accuracy: 0.5318 - val_loss: 0.6932 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6757 - accuracy: 0.5835 - val_loss: 0.6970 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6709 - accuracy: 0.5757 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6832 - accuracy: 0.5730 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6959 - accuracy: 0.5222 - val_loss: 0.7046 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6553 - accuracy: 0.6183 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6826 - accuracy: 0.5612 - val_loss: 0.7112 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6940 - accuracy: 0.5345 - val_loss: 0.6942 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6761 - accuracy: 0.5853 - val_loss: 0.7394 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6704 - accuracy: 0.5780 - val_loss: 0.6983 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6784 - accuracy: 0.5745 - val_loss: 0.7995 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.7012 - accuracy: 0.5115 - val_loss: 0.6973 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6540 - accuracy: 0.6245 - val_loss: 0.7230 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6832 - accuracy: 0.5565 - val_loss: 0.7456 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6942 - accuracy: 0.5375 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6784 - accuracy: 0.5800 - val_loss: 0.7296 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6657 - accuracy: 0.5922 - val_loss: 0.7753 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6848 - accuracy: 0.5625 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6964 - accuracy: 0.5297 - val_loss: 0.7082 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6501 - accuracy: 0.6273 - val_loss: 0.8279 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6897 - accuracy: 0.5485 - val_loss: 0.7400 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6901 - accuracy: 0.5447 - val_loss: 0.6937 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6820 - accuracy: 0.5695 - val_loss: 0.7158 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6672 - accuracy: 0.5905 - val_loss: 0.7214 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 1.3498 - accuracy: 0.5702 - val_loss: 0.7020 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6969 - accuracy: 0.5230 - val_loss: 0.7455 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6580 - accuracy: 0.6095 - val_loss: 0.8654 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6898 - accuracy: 0.5468 - val_loss: 0.7169 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6857 - accuracy: 0.5570 - val_loss: 0.6928 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6837 - accuracy: 0.5560 - val_loss: 0.6926 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6637 - accuracy: 0.6015 - val_loss: 0.6938 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6808 - accuracy: 0.5680 - val_loss: 0.6952 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6984 - accuracy: 0.5215 - val_loss: 0.6982 - val_accuracy: 0.4768 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 05:37:40.765888: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-29 05:37:40.765914: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-10-29 05:37:40.985882: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-10-29 05:37:40.987316: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 29s 8ms/step - loss: 0.7106 - accuracy: 0.4768\n",
      "Epoch 1/100\n",
      "   1/1000 [..............................] - ETA: 26:08 - loss: 0.5929 - accuracy: 0.7500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 05:38:11.858724: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-29 05:38:11.858745: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   7/1000 [..............................] - ETA: 43s - loss: 9.9062 - accuracy: 0.7143 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 05:38:12.322444: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-10-29 05:38:12.336638: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-10-29 05:38:12.394217: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 3228 callback api events and 3203 activity events. \n",
      "2022-10-29 05:38:12.450250: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-10-29 05:38:12.504177: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_resnet_2/log_3/plugins/profile/2022_10_29_05_38_12\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  15/1000 [..............................] - ETA: 1:00 - loss: 14.1456 - accuracy: 0.6667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 05:38:12.537496: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_resnet_2/log_3/plugins/profile/2022_10_29_05_38_12/rachanon-pc1.trace.json.gz\n",
      "2022-10-29 05:38:12.624839: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_resnet_2/log_3/plugins/profile/2022_10_29_05_38_12\n",
      "\n",
      "2022-10-29 05:38:12.630399: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_resnet_2/log_3/plugins/profile/2022_10_29_05_38_12/rachanon-pc1.memory_profile.json.gz\n",
      "2022-10-29 05:38:12.631988: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_resnet_2/log_3/plugins/profile/2022_10_29_05_38_12\n",
      "Dumped tool data for xplane.pb to log/baseline_resnet_2/log_3/plugins/profile/2022_10_29_05_38_12/rachanon-pc1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_resnet_2/log_3/plugins/profile/2022_10_29_05_38_12/rachanon-pc1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_resnet_2/log_3/plugins/profile/2022_10_29_05_38_12/rachanon-pc1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_resnet_2/log_3/plugins/profile/2022_10_29_05_38_12/rachanon-pc1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_resnet_2/log_3/plugins/profile/2022_10_29_05_38_12/rachanon-pc1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 39s 37ms/step - loss: 1.2984 - accuracy: 0.5598 - val_loss: 0.7783 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6578 - accuracy: 0.6250 - val_loss: 0.6987 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6581 - accuracy: 0.5915 - val_loss: 0.6923 - val_accuracy: 0.5234 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6829 - accuracy: 0.5782 - val_loss: 0.7183 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6963 - accuracy: 0.5247 - val_loss: 0.6928 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.7195 - accuracy: 0.6265 - val_loss: 0.7176 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6919 - accuracy: 0.5605 - val_loss: 0.6982 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6943 - accuracy: 0.5290 - val_loss: 0.6927 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6760 - accuracy: 0.5865 - val_loss: 0.7062 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6700 - accuracy: 0.5807 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6808 - accuracy: 0.5715 - val_loss: 0.7339 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.7099 - accuracy: 0.5253 - val_loss: 0.7015 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6530 - accuracy: 0.6248 - val_loss: 0.6957 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6842 - accuracy: 0.5583 - val_loss: 0.7090 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.7036 - accuracy: 0.5490 - val_loss: 0.6924 - val_accuracy: 0.5233 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6779 - accuracy: 0.5775 - val_loss: 0.7376 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.8480 - accuracy: 0.5878 - val_loss: 0.7172 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6814 - accuracy: 0.5640 - val_loss: 0.7334 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.7029 - accuracy: 0.5182 - val_loss: 0.6921 - val_accuracy: 0.5233 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6523 - accuracy: 0.6292 - val_loss: 0.7747 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6850 - accuracy: 0.5537 - val_loss: 0.7757 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.9318 - accuracy: 0.5495 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6821 - accuracy: 0.5648 - val_loss: 0.7084 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6642 - accuracy: 0.5980 - val_loss: 0.7816 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6817 - accuracy: 0.5700 - val_loss: 0.7070 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6979 - accuracy: 0.5232 - val_loss: 0.7063 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6538 - accuracy: 0.6200 - val_loss: 0.8442 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6884 - accuracy: 0.5527 - val_loss: 0.7199 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.7226 - accuracy: 0.5502 - val_loss: 0.7023 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6837 - accuracy: 0.5573 - val_loss: 0.7230 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6679 - accuracy: 0.5840 - val_loss: 0.6933 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6803 - accuracy: 0.5710 - val_loss: 0.6953 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6965 - accuracy: 0.5265 - val_loss: 0.7214 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6604 - accuracy: 0.6075 - val_loss: 0.8582 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6830 - accuracy: 0.5583 - val_loss: 0.7007 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6848 - accuracy: 0.5673 - val_loss: 0.6972 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6832 - accuracy: 0.5575 - val_loss: 0.7381 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6664 - accuracy: 0.5930 - val_loss: 0.6946 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6792 - accuracy: 0.5780 - val_loss: 0.7183 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6984 - accuracy: 0.5155 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6769 - accuracy: 0.5900 - val_loss: 0.7090 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6714 - accuracy: 0.5692 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6840 - accuracy: 0.5670 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6800 - accuracy: 0.5602 - val_loss: 0.8282 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6690 - accuracy: 0.5918 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6780 - accuracy: 0.5798 - val_loss: 0.7513 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6961 - accuracy: 0.5295 - val_loss: 0.7133 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6767 - accuracy: 0.5857 - val_loss: 0.6974 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6689 - accuracy: 0.5785 - val_loss: 0.7041 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6835 - accuracy: 0.5692 - val_loss: 0.7017 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6866 - accuracy: 0.5412 - val_loss: 0.8217 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6621 - accuracy: 0.5993 - val_loss: 0.6944 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6805 - accuracy: 0.5692 - val_loss: 0.7205 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6899 - accuracy: 0.5415 - val_loss: 0.7833 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6821 - accuracy: 0.5688 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6692 - accuracy: 0.5775 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6832 - accuracy: 0.5780 - val_loss: 0.6994 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6929 - accuracy: 0.5332 - val_loss: 0.7208 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6551 - accuracy: 0.6133 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6813 - accuracy: 0.5667 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6930 - accuracy: 0.5380 - val_loss: 0.7053 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6777 - accuracy: 0.5830 - val_loss: 0.6925 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6670 - accuracy: 0.5753 - val_loss: 0.6972 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6831 - accuracy: 0.5710 - val_loss: 0.6973 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6949 - accuracy: 0.5232 - val_loss: 0.6955 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6547 - accuracy: 0.6177 - val_loss: 0.7033 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6818 - accuracy: 0.5638 - val_loss: 0.7035 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.7044 - accuracy: 0.5303 - val_loss: 0.6928 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6755 - accuracy: 0.5853 - val_loss: 0.7004 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6703 - accuracy: 0.5763 - val_loss: 0.6929 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6818 - accuracy: 0.5715 - val_loss: 0.6926 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6947 - accuracy: 0.5297 - val_loss: 0.7037 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6562 - accuracy: 0.6173 - val_loss: 0.6925 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6825 - accuracy: 0.5645 - val_loss: 0.7072 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6932 - accuracy: 0.5303 - val_loss: 0.6964 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6770 - accuracy: 0.5813 - val_loss: 0.7265 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6701 - accuracy: 0.5803 - val_loss: 0.6964 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6844 - accuracy: 0.5800 - val_loss: 0.8205 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.7034 - accuracy: 0.5132 - val_loss: 0.6944 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6551 - accuracy: 0.6235 - val_loss: 0.7152 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6818 - accuracy: 0.5577 - val_loss: 0.7581 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6927 - accuracy: 0.5393 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6779 - accuracy: 0.5753 - val_loss: 0.7342 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6679 - accuracy: 0.5888 - val_loss: 0.7739 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6842 - accuracy: 0.5615 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6968 - accuracy: 0.5270 - val_loss: 0.7024 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6514 - accuracy: 0.6227 - val_loss: 0.8248 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6910 - accuracy: 0.5445 - val_loss: 0.7427 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6904 - accuracy: 0.5430 - val_loss: 0.6929 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6832 - accuracy: 0.5600 - val_loss: 0.7127 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6641 - accuracy: 0.5932 - val_loss: 0.7211 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6804 - accuracy: 0.5698 - val_loss: 0.7047 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6966 - accuracy: 0.5265 - val_loss: 0.7414 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6587 - accuracy: 0.6097 - val_loss: 0.8601 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6871 - accuracy: 0.5490 - val_loss: 0.7199 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6868 - accuracy: 0.5558 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6847 - accuracy: 0.5493 - val_loss: 0.6938 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6651 - accuracy: 0.5950 - val_loss: 0.6929 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6804 - accuracy: 0.5665 - val_loss: 0.6940 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6974 - accuracy: 0.5235 - val_loss: 0.6957 - val_accuracy: 0.4768 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 06:39:06.763450: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-29 06:39:06.763471: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-10-29 06:39:06.979155: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-10-29 06:39:06.980586: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 28s 8ms/step - loss: 0.7055 - accuracy: 0.4768\n",
      "Epoch 1/100\n",
      "   1/1000 [..............................] - ETA: 31:43 - loss: 0.6167 - accuracy: 0.7500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 06:39:37.456984: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-29 06:39:37.457008: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   7/1000 [..............................] - ETA: 46s - loss: 6.2238 - accuracy: 0.6429  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 06:39:37.948959: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-10-29 06:39:37.964615: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-10-29 06:39:38.029921: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 3228 callback api events and 3203 activity events. \n",
      "2022-10-29 06:39:38.089111: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-10-29 06:39:38.144770: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_resnet_2/log_4/plugins/profile/2022_10_29_06_39_38\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  14/1000 [..............................] - ETA: 1:08 - loss: 9.5405 - accuracy: 0.6071"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 06:39:38.179091: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/baseline_resnet_2/log_4/plugins/profile/2022_10_29_06_39_38/rachanon-pc1.trace.json.gz\n",
      "2022-10-29 06:39:38.268701: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/baseline_resnet_2/log_4/plugins/profile/2022_10_29_06_39_38\n",
      "\n",
      "2022-10-29 06:39:38.274475: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/baseline_resnet_2/log_4/plugins/profile/2022_10_29_06_39_38/rachanon-pc1.memory_profile.json.gz\n",
      "2022-10-29 06:39:38.276151: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/baseline_resnet_2/log_4/plugins/profile/2022_10_29_06_39_38\n",
      "Dumped tool data for xplane.pb to log/baseline_resnet_2/log_4/plugins/profile/2022_10_29_06_39_38/rachanon-pc1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/baseline_resnet_2/log_4/plugins/profile/2022_10_29_06_39_38/rachanon-pc1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/baseline_resnet_2/log_4/plugins/profile/2022_10_29_06_39_38/rachanon-pc1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/baseline_resnet_2/log_4/plugins/profile/2022_10_29_06_39_38/rachanon-pc1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/baseline_resnet_2/log_4/plugins/profile/2022_10_29_06_39_38/rachanon-pc1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 40s 38ms/step - loss: 1.0081 - accuracy: 0.5725 - val_loss: 0.7752 - val_accuracy: 0.4772 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6591 - accuracy: 0.6180 - val_loss: 0.7206 - val_accuracy: 0.4771 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.7033 - accuracy: 0.5900 - val_loss: 0.6945 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6947 - accuracy: 0.5767 - val_loss: 0.7166 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6935 - accuracy: 0.5350 - val_loss: 0.6938 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6500 - accuracy: 0.6245 - val_loss: 0.7061 - val_accuracy: 0.4771 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6818 - accuracy: 0.5640 - val_loss: 0.7055 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.7048 - accuracy: 0.5430 - val_loss: 0.6970 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6780 - accuracy: 0.5840 - val_loss: 0.7140 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6692 - accuracy: 0.5820 - val_loss: 0.6989 - val_accuracy: 0.4770 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6809 - accuracy: 0.5750 - val_loss: 0.7537 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6967 - accuracy: 0.5242 - val_loss: 0.7282 - val_accuracy: 0.5230 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6544 - accuracy: 0.6185 - val_loss: 0.7177 - val_accuracy: 0.5230 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6833 - accuracy: 0.5515 - val_loss: 0.7441 - val_accuracy: 0.5230 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.7282 - accuracy: 0.5328 - val_loss: 0.6929 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6776 - accuracy: 0.5770 - val_loss: 0.7451 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6694 - accuracy: 0.5872 - val_loss: 0.7226 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6805 - accuracy: 0.5675 - val_loss: 0.7487 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.7000 - accuracy: 0.5170 - val_loss: 0.6926 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6498 - accuracy: 0.6308 - val_loss: 0.7859 - val_accuracy: 0.5232 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.8360 - accuracy: 0.5475 - val_loss: 0.7551 - val_accuracy: 0.5230 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6924 - accuracy: 0.5405 - val_loss: 0.7001 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6815 - accuracy: 0.5663 - val_loss: 0.7200 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6630 - accuracy: 0.5980 - val_loss: 0.7687 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6816 - accuracy: 0.5677 - val_loss: 0.7180 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6974 - accuracy: 0.5215 - val_loss: 0.7232 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6510 - accuracy: 0.6202 - val_loss: 0.8700 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.7374 - accuracy: 0.5465 - val_loss: 0.7137 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.7223 - accuracy: 0.5555 - val_loss: 0.7000 - val_accuracy: 0.4767 - lr: 0.0100\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6812 - accuracy: 0.5602 - val_loss: 0.7427 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6671 - accuracy: 0.5857 - val_loss: 0.6986 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6911 - accuracy: 0.5763 - val_loss: 0.7097 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6958 - accuracy: 0.5282 - val_loss: 0.7372 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6621 - accuracy: 0.6045 - val_loss: 0.8513 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6840 - accuracy: 0.5567 - val_loss: 0.7051 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6849 - accuracy: 0.5652 - val_loss: 0.7019 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6825 - accuracy: 0.5577 - val_loss: 0.7396 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6667 - accuracy: 0.5910 - val_loss: 0.6996 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.7182 - accuracy: 0.5715 - val_loss: 0.7139 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6963 - accuracy: 0.5278 - val_loss: 0.6965 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6731 - accuracy: 0.5922 - val_loss: 0.7121 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6719 - accuracy: 0.5702 - val_loss: 0.6952 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6841 - accuracy: 0.5645 - val_loss: 0.6952 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6814 - accuracy: 0.5573 - val_loss: 0.8398 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6684 - accuracy: 0.5880 - val_loss: 0.6964 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6797 - accuracy: 0.5713 - val_loss: 0.7363 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6962 - accuracy: 0.5232 - val_loss: 0.7095 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6765 - accuracy: 0.5847 - val_loss: 0.7034 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6695 - accuracy: 0.5767 - val_loss: 0.7078 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6943 - accuracy: 0.5748 - val_loss: 0.7161 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6879 - accuracy: 0.5385 - val_loss: 0.8174 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6609 - accuracy: 0.6047 - val_loss: 0.7019 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6831 - accuracy: 0.5633 - val_loss: 0.7236 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6921 - accuracy: 0.5343 - val_loss: 0.7628 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6791 - accuracy: 0.5732 - val_loss: 0.6994 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6976 - accuracy: 0.5745 - val_loss: 0.6985 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.8173 - accuracy: 0.5760 - val_loss: 0.7071 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6931 - accuracy: 0.5310 - val_loss: 0.7263 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6563 - accuracy: 0.6133 - val_loss: 0.6964 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6820 - accuracy: 0.5645 - val_loss: 0.6974 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.7635 - accuracy: 0.5337 - val_loss: 0.9218 - val_accuracy: 0.4774 - lr: 0.0100\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.9027 - accuracy: 0.5830 - val_loss: 0.6947 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6698 - accuracy: 0.5805 - val_loss: 0.7062 - val_accuracy: 0.4768 - lr: 0.0100\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.7463 - accuracy: 0.5715 - val_loss: 0.6987 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6944 - accuracy: 0.5318 - val_loss: 0.6977 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6571 - accuracy: 0.6160 - val_loss: 0.7043 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6820 - accuracy: 0.5638 - val_loss: 0.7099 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6939 - accuracy: 0.5290 - val_loss: 0.6967 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6757 - accuracy: 0.5853 - val_loss: 0.7071 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6695 - accuracy: 0.5727 - val_loss: 0.6971 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6817 - accuracy: 0.5738 - val_loss: 0.7007 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6955 - accuracy: 0.5240 - val_loss: 0.7137 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6570 - accuracy: 0.6185 - val_loss: 0.7008 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6831 - accuracy: 0.5580 - val_loss: 0.7209 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6929 - accuracy: 0.5345 - val_loss: 0.6996 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6764 - accuracy: 0.5842 - val_loss: 0.7308 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6699 - accuracy: 0.5828 - val_loss: 0.7097 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6768 - accuracy: 0.5760 - val_loss: 0.8248 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.7017 - accuracy: 0.5173 - val_loss: 0.7059 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6547 - accuracy: 0.6223 - val_loss: 0.7246 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6842 - accuracy: 0.5508 - val_loss: 0.7459 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6933 - accuracy: 0.5420 - val_loss: 0.6995 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6788 - accuracy: 0.5702 - val_loss: 0.7339 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6677 - accuracy: 0.5897 - val_loss: 0.7760 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6833 - accuracy: 0.5600 - val_loss: 0.6991 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6965 - accuracy: 0.5260 - val_loss: 0.7058 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6509 - accuracy: 0.6270 - val_loss: 0.8235 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6895 - accuracy: 0.5502 - val_loss: 0.7446 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6902 - accuracy: 0.5487 - val_loss: 0.6991 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6823 - accuracy: 0.5660 - val_loss: 0.7267 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6674 - accuracy: 0.5842 - val_loss: 0.7273 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6788 - accuracy: 0.5773 - val_loss: 0.7196 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6964 - accuracy: 0.5328 - val_loss: 0.7535 - val_accuracy: 0.4769 - lr: 0.0100\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6573 - accuracy: 0.6118 - val_loss: 0.8739 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6877 - accuracy: 0.5480 - val_loss: 0.7189 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6858 - accuracy: 0.5610 - val_loss: 0.6994 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 36s 37ms/step - loss: 0.6849 - accuracy: 0.5533 - val_loss: 0.7010 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6652 - accuracy: 0.5947 - val_loss: 0.7002 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 1.0542 - accuracy: 0.5680 - val_loss: 0.6949 - val_accuracy: 0.5231 - lr: 0.0100\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6974 - accuracy: 0.5207 - val_loss: 0.6973 - val_accuracy: 0.4768 - lr: 0.0100\n"
     ]
    }
   ],
   "source": [
    "for i, (train, val) in enumerate(folds):\n",
    "    \n",
    "    model = createModel()\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    metrics = ['accuracy']\n",
    "    \n",
    "    model.compile(optimizer=opt, loss=loss, metrics=metrics)\n",
    "    \n",
    "    tboardCb = tf.keras.callbacks.TensorBoard(log_dir=f\"{logBasePath}/{logPrefix}_{i}\", histogram_freq=1, profile_batch=(2,10))\n",
    "    lrSchedule = tf.keras.callbacks.LearningRateScheduler(schedule)\n",
    "    \n",
    "    cbs = [tboardCb, lrSchedule]\n",
    "    \n",
    "    model.evaluate(val)\n",
    "    model.fit(train, initial_epoch=START_EPOCH, epochs=END_EPOCH, steps_per_epoch=STEPS_PER_EPOCH, callbacks=cbs, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e841a27f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
