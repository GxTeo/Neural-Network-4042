{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f19017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d782ddf",
   "metadata": {},
   "source": [
    "### Check Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03faa827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac4996",
   "metadata": {},
   "source": [
    "### GPU Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1e955b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 00:20:56.950327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 00:20:56.956628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 00:20:56.957001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2835bd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f935a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be867b6",
   "metadata": {},
   "source": [
    "### Pandas Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92db292",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_column', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0907c",
   "metadata": {},
   "source": [
    "### Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0fd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VAL_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc35c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_WIDTH = 227\n",
    "CROP_HEIGHT = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d40847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldFiles = [\"adience/unprocessed/fold_0_data.txt\",\n",
    "             \"adience/unprocessed/fold_1_data.txt\",\n",
    "             \"adience/unprocessed/fold_2_data.txt\",\n",
    "             \"adience/unprocessed/fold_3_data.txt\",\n",
    "             \"adience/unprocessed/fold_4_data.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f61c7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genderMap = defaultdict(lambda : np.NaN)\n",
    "genderMap['m'] = 0\n",
    "genderMap['f'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d26242",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = ['(0, 2)', '(4, 6)', '(8, 13)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
    "ageMap = defaultdict(lambda : np.NaN)\n",
    "for i,a in enumerate(ages):\n",
    "    ageMap[a] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b1fc3",
   "metadata": {},
   "source": [
    "### Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd634a3",
   "metadata": {},
   "source": [
    "Dataset generation pipeline:\n",
    "Input: \n",
    "- foldFile - Path to fold file. Fold file Describes which images are in the fold and its corresponding labels\n",
    "- imgBaseFolder - Base folder to search image from\n",
    "- imgPrefix - Prefix of image file\n",
    "- genderMap - Map from ['m', 'f', 'u', None], to one hot index\n",
    "- ageMap - Map from age category to one hot index\n",
    "- imgWidth - Resulting image width\n",
    "- imgHeigh - Resulting image height\n",
    "- batchSize - Int or None, batch size\n",
    "- configureDs - Function accepting dataset for performance configurations\n",
    "- preBatch - List of (name, functions) pair that will be mapped before batching. name is used as name parameters for tf graph \n",
    "- postBatch - List of (name, functions) that will be mapped after batching. name is used as name parameters for tf graph\n",
    "\n",
    "The processing functions should have signature function(img, label) -> (img, label)\n",
    "\n",
    "Pipeline\n",
    "\n",
    "Read Fold File -> Preprocess filename and labels (dataframe) -> Convert filename and labels to numpy array -> Convert filename and labels to tf dataset -> Parse images and labels -> Configure Dataset for performance -> Pre-Batching preprocessing -> Batch -> Post-Batching preprocessing -> Output\n",
    "\n",
    "Some preprocessing steps can only be done before and some can only be done after batching, thats why there are seperated pre and post batching list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0795464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, batchSize, configureDs=None, preBatch=[], postBatch=[]):\n",
    "    \n",
    "    def parseImage(filename):\n",
    "        img = tf.io.read_file(filename)\n",
    "        img = tf.image.decode_jpeg(img)\n",
    "        img = tf.image.resize(img, [imgHeight, imgWidth])\n",
    "         \n",
    "        return img\n",
    "    \n",
    "    # Read Fold File\n",
    "    foldData = []\n",
    "    for f in foldFiles:\n",
    "        foldData.append(pd.read_csv(f, sep=\"\\t\"))\n",
    "    foldData = pd.concat(foldData)\n",
    "    \n",
    "    # Form File Name\n",
    "    foldData['filename'] = foldData.apply(lambda r: os.path.join(imgBaseFolder, r['user_id'], f\"{imgPrefix}.{r['face_id']}.{r['original_image']}\"), axis=1)\n",
    "    \n",
    "    # Generate Label One Hot Index\n",
    "    foldData['gender_ind'] = foldData['gender'].map(genderMap)\n",
    "    foldData['age_ind'] = foldData['age'].map(ageMap)\n",
    "    \n",
    "    # Remove dirty data\n",
    "    foldData.dropna(subset=['gender_ind', 'age_ind'], inplace=True)\n",
    "    \n",
    "    # Dataframe to numpy\n",
    "    filenames = foldData['filename'].to_numpy()\n",
    "    \n",
    "    genderIndex = foldData['gender_ind'].to_numpy().astype(int)\n",
    "    ageIndex = foldData['age_ind'].to_numpy().astype(int)\n",
    "    \n",
    "    # Numpy to Dataset\n",
    "    fnDs = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    genderIndDs = tf.data.Dataset.from_tensor_slices(genderIndex)\n",
    "    ageIndDs = tf.data.Dataset.from_tensor_slices(ageIndex)\n",
    "    \n",
    "    # Parse Images\n",
    "    imageDs = fnDs.map(parseImage, num_parallel_calls=tf.data.AUTOTUNE, name=\"parse_image\")\n",
    "    \n",
    "    # Parse Labels\n",
    "    genderLabDs = genderIndDs.map(lambda x: tf.one_hot(x, genderDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"gender_one_hot\")\n",
    "    ageLabDs = ageIndDs.map(lambda x: tf.one_hot(x, ageDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"age_one_hot\")\n",
    "    \n",
    "    # Combine Labels\n",
    "    labelDs = tf.data.Dataset.zip((genderLabDs, ageLabDs), name=\"label_zip\")\n",
    "    labelDs = labelDs.map(lambda g,a: {\"gender\": g, \"age\": a}, num_parallel_calls=tf.data.AUTOTUNE, name='label_dict')\n",
    "    \n",
    "    # Combine Images and Labels into dataset\n",
    "    ds = tf.data.Dataset.zip((imageDs, labelDs))\n",
    "    \n",
    "    # Configure Performance\n",
    "    if(configureDs is not None):\n",
    "        ds = configureDs(ds)\n",
    "    \n",
    "    # Pre Batch Preprocessing\n",
    "    for n,f in preBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    # Batch\n",
    "    if(batchSize is not None):\n",
    "        ds = ds.batch(batchSize, name=\"ds_batch\")\n",
    "    \n",
    "    # Post Batch Preprocessing\n",
    "    for n,f in postBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320ed92",
   "metadata": {},
   "source": [
    "### Preprocessings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "472b7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=100)\n",
    "    ds = ds.repeat()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adf288f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc4fe2f",
   "metadata": {},
   "source": [
    "#### Preprocessing steps according to the reference paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7724a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainPreprocessA(img, lab):\n",
    "        \n",
    "        # img = tf.image.random_crop(img, [CROP_HEIGHT, CROP_WIDTH, 3])\n",
    "        \n",
    "        ud = tf.random.uniform([], dtype=tf.float32)\n",
    "        udCond = tf.less(ud, 0.5)\n",
    "        \n",
    "        img = tf.cond(udCond, lambda: tf.image.flip_up_down(img), lambda: img)\n",
    "        \n",
    "        lr = tf.random.uniform([], dtype=tf.float32)\n",
    "        lrCond = tf.less(lr, 0.5)\n",
    "        \n",
    "        img = tf.cond(lrCond, lambda: tf.image.flip_left_right(img), lambda: img)\n",
    "        \n",
    "        img = tf.image.random_brightness(img, 63/255)\n",
    "        \n",
    "        img = tf.image.random_contrast(img, 0.2, 1.8) \n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0402726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valPreprocessA(img, lab):\n",
    "        \n",
    "        img = tf.image.crop_to_bounding_box(img,\n",
    "                                            (IMG_HEIGHT-CROP_HEIGHT) // 2,\n",
    "                                            (IMG_WIDTH-CROP_WIDTH) // 2,\n",
    "                                            CROP_HEIGHT,\n",
    "                                            CROP_WIDTH)\n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f32b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageStandardize(img, lab):\n",
    "    \n",
    "    img = tf.image.per_image_standardization(img)\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f134a",
   "metadata": {},
   "source": [
    "#### Label extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "633c4277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractGenderLabel(img, lab):\n",
    "    \n",
    "    lab = lab['gender']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88b8b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAgeLabel(img, lab):\n",
    "    \n",
    "    lab = lab['age']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7778c",
   "metadata": {},
   "source": [
    "### Generate Folds for K-Folds validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4172d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFoldDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, valBatchSize, trainConfigureDs=None, trainPreBatch=[], trainPostBatch=[], valConfigureDs=None, valPreBatch=[], valPostBatch=[]):\n",
    "    '''\n",
    "        Returns list of (train, validation) datasets\n",
    "    '''\n",
    "    \n",
    "    N = len(foldFiles)\n",
    "    \n",
    "    folds = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        trainFiles = foldFiles[:i]\n",
    "        if(i < N-1):\n",
    "            trainFiles.extend(foldFiles[i+1:])\n",
    "            \n",
    "        valFiles = foldFiles[i]\n",
    "        \n",
    "        trainDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, configureDs=trainConfigureDs, preBatch=trainPreBatch, postBatch=trainPostBatch)\n",
    "        valDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, valBatchSize, configureDs=valConfigureDs, preBatch=valPreBatch, postBatch=valPostBatch)\n",
    "        \n",
    "        folds.append((trainDs, valDs))\n",
    "        \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beffce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPreBatch = [(\"train_process_a\", trainPreprocessA), \n",
    "                 (\"train_standardize\", imageStandardize), \n",
    "                 (\"train_extract_gender\", extractGenderLabel)]\n",
    "\n",
    "valPreBatch = [(\"val_standardize\", imageStandardize), \n",
    "               (\"val_extract_gender\", extractGenderLabel)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10474d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 00:20:57.221038: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 00:20:57.221708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 00:20:57.222000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 00:20:57.222235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 00:20:57.504178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 00:20:57.504423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 00:20:57.504630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 00:20:57.504830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3432 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:2d:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "folds = generateFoldDs(foldFiles, \"adience/faces\", \"coarse_tilt_aligned_face\", genderMap, ageMap, 2, 8, \n",
    "                       IMG_WIDTH, IMG_HEIGHT, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE, \n",
    "                       trainConfigureDs=trainConfigPerformance, trainPreBatch=trainPreBatch, \n",
    "                       valConfigureDs=valConfigPerformance, valPreBatch=valPreBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57d814af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7974f8fe",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b67fe33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in folds[0][0].take(1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8aa8d0d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 256, 256, 3), dtype=float32, numpy=\n",
       "array([[[[-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         ...,\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ]],\n",
       "\n",
       "        [[-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         ...,\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ]],\n",
       "\n",
       "        [[-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         ...,\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         ...,\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ]],\n",
       "\n",
       "        [[-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         ...,\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ]],\n",
       "\n",
       "        [[-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         ...,\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ],\n",
       "         [-1.683838  , -1.4957672 , -1.374472  ]]],\n",
       "\n",
       "\n",
       "       [[[-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         ...,\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ]],\n",
       "\n",
       "        [[-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         ...,\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ]],\n",
       "\n",
       "        [[-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         ...,\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         ...,\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ]],\n",
       "\n",
       "        [[-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         ...,\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ]],\n",
       "\n",
       "        [[-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         ...,\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ],\n",
       "         [-1.5451914 , -1.5482388 , -1.5527908 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.7298833 , -1.1432546 , -0.99830747],\n",
       "         [-0.71191746, -1.1473491 , -0.9913717 ],\n",
       "         [-0.68508786, -1.1284261 , -0.96849537],\n",
       "         ...,\n",
       "         [ 1.8282547 ,  0.7996809 ,  0.39904597],\n",
       "         [ 1.8344556 ,  0.761809  ,  0.33708948],\n",
       "         [ 1.7141811 ,  0.7014686 ,  0.27704167]],\n",
       "\n",
       "        [[-0.7230647 , -1.1875614 , -1.0205779 ],\n",
       "         [-0.68081427, -1.1691031 , -0.9941889 ],\n",
       "         [-0.6687787 , -1.1570675 , -0.9821534 ],\n",
       "         ...,\n",
       "         [ 1.7376162 ,  0.7090424 ,  0.315047  ],\n",
       "         [ 1.7495275 ,  0.6732305 ,  0.2747382 ],\n",
       "         [ 1.6730877 ,  0.6603752 ,  0.25807732]],\n",
       "\n",
       "        [[-0.74363774, -1.2469102 , -1.1019632 ],\n",
       "         [-0.6921027 , -1.1953751 , -1.0504279 ],\n",
       "         [-0.69644177, -1.2060782 , -1.057949  ],\n",
       "         ...,\n",
       "         [ 1.7139292 ,  0.68535507,  0.31468755],\n",
       "         [ 1.5701332 ,  0.4825032 ,  0.11801036],\n",
       "         [ 1.4381151 ,  0.41448298,  0.05278302]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.6374405 ,  1.0183787 ,  1.0884081 ],\n",
       "         [-0.69530547,  0.96051395,  1.0305434 ],\n",
       "         [-0.72234887,  0.92572904,  0.9996292 ],\n",
       "         ...,\n",
       "         [-0.65572006, -0.60642403,  0.09265817],\n",
       "         [-0.86833566, -0.8539447 , -0.13816004],\n",
       "         [-0.9936529 , -0.9545915 , -0.23351005]],\n",
       "\n",
       "        [[-0.6597488 ,  1.009591  ,  1.0796201 ],\n",
       "         [-0.69559133,  0.9737483 ,  1.0437778 ],\n",
       "         [-0.65887094,  1.0038292 ,  1.0771785 ],\n",
       "         ...,\n",
       "         [-0.5948933 , -0.45346063,  0.28709483],\n",
       "         [-1.0828979 , -0.9501233 , -0.24488936],\n",
       "         [-0.87312335, -0.7153644 , -0.04774945]],\n",
       "\n",
       "        [[-0.62157565,  1.0477638 ,  1.1177936 ],\n",
       "         [-0.64354986,  1.0257896 ,  1.0958191 ],\n",
       "         [-0.67068964,  0.99865013,  1.0686793 ],\n",
       "         ...,\n",
       "         [-0.335829  , -0.09382999,  0.5716528 ],\n",
       "         [-0.7644742 , -0.52196234,  0.12056505],\n",
       "         [-0.7318364 , -0.46705735,  0.12704444]]],\n",
       "\n",
       "\n",
       "       [[[-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         ...,\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ]],\n",
       "\n",
       "        [[-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         ...,\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ]],\n",
       "\n",
       "        [[-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         ...,\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         ...,\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ]],\n",
       "\n",
       "        [[-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         ...,\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ]],\n",
       "\n",
       "        [[-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         ...,\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ],\n",
       "         [-1.5403124 , -1.3812686 , -1.2965058 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d84b1683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e25507c",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ee495a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    inp = tf.keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "    conv1 = tf.keras.layers.Conv2D(96, 7, strides=(4,4), activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='conv1')\n",
    "    pool1 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, name='pool1')\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv2D(256, 5, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='conv2')\n",
    "    pool2 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, name='pool2')\n",
    "\n",
    "    conv3 = tf.keras.layers.Conv2D(384, 3, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='conv3')\n",
    "    pool3 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, name='pool3')\n",
    "\n",
    "    flat1 = tf.keras.layers.Flatten(name='flat1')\n",
    "    fc1 = tf.keras.layers.Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc1')\n",
    "    do1 = tf.keras.layers.Dropout(0.5, name='do1')\n",
    "\n",
    "    fc2 = tf.keras.layers.Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc2')\n",
    "    do2 = tf.keras.layers.Dropout(0.5, name='do2')\n",
    "\n",
    "    fc3 = tf.keras.layers.Dense(2, activation='softmax', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='fc3')\n",
    "\n",
    "    o = conv1(inp)\n",
    "    o = pool1(o)\n",
    "    o = tf.nn.local_response_normalization(o, depth_radius=5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    o = tf.pad(o, [[0, 0], [2, 2], [2, 2], [0, 0]])\n",
    "    o = conv2(o)\n",
    "    o = pool2(o)\n",
    "    o = tf.nn.local_response_normalization(o, depth_radius=5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    o = tf.pad(o, [[0, 0], [1, 1], [1, 1], [0, 0]])\n",
    "    o = conv3(o)\n",
    "    o = pool3(o)\n",
    "    o = tf.nn.local_response_normalization(o, depth_radius=5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    o = flat1(o)\n",
    "    o = fc1(o)\n",
    "    o = do1(o)\n",
    "\n",
    "\n",
    "    o = fc2(o)\n",
    "    o = do2(o)\n",
    "\n",
    "    o = fc3(o)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=o, name='cnn_5')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea1227d",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c5f7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = 1000\n",
    "\n",
    "EPOCH = 300\n",
    "\n",
    "START_EPOCH = 0\n",
    "END_EPOCH = START_EPOCH + EPOCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96be5cb2",
   "metadata": {},
   "source": [
    "#### Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55ee49a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(epoch, lr):\n",
    "    if(epoch == 10000*50//STEPS_PER_EPOCH):\n",
    "        return lr * 0.1\n",
    "    else:\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f41e8947",
   "metadata": {},
   "outputs": [],
   "source": [
    "logBasePath = \"log/_6\"\n",
    "logPrefix = \"log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c32cf78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 00:20:59.904739: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-09 00:20:59.904757: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-09 00:20:59.904776: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1665] Profiler found 1 GPUs\n",
      "2022-11-09 00:20:59.987075: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-09 00:20:59.988360: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-11-09 00:21:00.529294: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  51/3528 [..............................] - ETA: 10s - loss: 0.6687 - accuracy: 0.6176  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 00:21:01.299407: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 10s 3ms/step - loss: 0.7121 - accuracy: 0.4768\n",
      "Epoch 1/625\n",
      "   1/1000 [..............................] - ETA: 7:43 - loss: 0.5939 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 00:21:10.710500: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-09 00:21:10.710521: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  20/1000 [..............................] - ETA: 29s - loss: 0.6915 - accuracy: 0.6625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 00:21:11.113715: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-09 00:21:11.114461: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-11-09 00:21:11.141117: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 1644 callback api events and 1619 activity events. \n",
      "2022-11-09 00:21:11.157752: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-09 00:21:11.173267: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/CNN_5/log_0/plugins/profile/2022_11_09_00_21_11\n",
      "\n",
      "2022-11-09 00:21:11.200510: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/CNN_5/log_0/plugins/profile/2022_11_09_00_21_11/rachanon-pc1.trace.json.gz\n",
      "2022-11-09 00:21:11.225588: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/CNN_5/log_0/plugins/profile/2022_11_09_00_21_11\n",
      "\n",
      "2022-11-09 00:21:11.229997: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/CNN_5/log_0/plugins/profile/2022_11_09_00_21_11/rachanon-pc1.memory_profile.json.gz\n",
      "2022-11-09 00:21:11.230416: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/CNN_5/log_0/plugins/profile/2022_11_09_00_21_11\n",
      "Dumped tool data for xplane.pb to log/CNN_5/log_0/plugins/profile/2022_11_09_00_21_11/rachanon-pc1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/CNN_5/log_0/plugins/profile/2022_11_09_00_21_11/rachanon-pc1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/CNN_5/log_0/plugins/profile/2022_11_09_00_21_11/rachanon-pc1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/CNN_5/log_0/plugins/profile/2022_11_09_00_21_11/rachanon-pc1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/CNN_5/log_0/plugins/profile/2022_11_09_00_21_11/rachanon-pc1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7266 - accuracy: 0.5701"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 00:21:25.008062: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.7267 - accuracy: 0.5698 - val_loss: 0.6932 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 2/625\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.6669 - accuracy: 0.6016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 00:21:39.483596: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6669 - accuracy: 0.6015 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 3/625\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.6635 - accuracy: 0.5895"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 00:21:53.882550: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6635 - accuracy: 0.5895 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 4/625\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 0.6823 - accuracy: 0.5624"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 00:22:07.854747: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6825 - accuracy: 0.5620 - val_loss: 0.7038 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 5/625\n",
      " 991/1000 [============================>.] - ETA: 0s - loss: 0.6946 - accuracy: 0.5151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 00:22:21.832451: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6947 - accuracy: 0.5145 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 6/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6615 - accuracy: 0.6077 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 7/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6787 - accuracy: 0.5660 - val_loss: 0.6982 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 8/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6939 - accuracy: 0.5148 - val_loss: 0.6925 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 9/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6823 - accuracy: 0.5497 - val_loss: 0.6934 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 10/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6650 - accuracy: 0.5790 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 11/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6838 - accuracy: 0.5638 - val_loss: 0.7005 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 12/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6947 - accuracy: 0.4980 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 13/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6629 - accuracy: 0.6115 - val_loss: 0.6969 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 14/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6820 - accuracy: 0.5615 - val_loss: 0.7090 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 15/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6952 - accuracy: 0.4980 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 16/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6837 - accuracy: 0.5375 - val_loss: 0.7093 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 17/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6680 - accuracy: 0.5780 - val_loss: 0.6959 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 18/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6884 - accuracy: 0.5405 - val_loss: 0.6994 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 19/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6970 - accuracy: 0.4925 - val_loss: 0.6966 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 20/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6635 - accuracy: 0.5940 - val_loss: 0.7178 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 21/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6869 - accuracy: 0.5455 - val_loss: 0.7613 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 22/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6939 - accuracy: 0.4983 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 23/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6914 - accuracy: 0.5175 - val_loss: 0.6937 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 24/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6662 - accuracy: 0.5955 - val_loss: 0.8033 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 25/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6849 - accuracy: 0.5560 - val_loss: 0.6947 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 26/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6974 - accuracy: 0.4942 - val_loss: 0.6999 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 27/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6530 - accuracy: 0.6102 - val_loss: 0.8963 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 28/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6886 - accuracy: 0.5372 - val_loss: 0.7154 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 29/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6891 - accuracy: 0.5320 - val_loss: 0.6928 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 30/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6878 - accuracy: 0.5357 - val_loss: 0.7185 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 31/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6594 - accuracy: 0.5888 - val_loss: 0.6919 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 32/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6841 - accuracy: 0.5605 - val_loss: 0.6914 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 33/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6935 - accuracy: 0.5067 - val_loss: 0.7078 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 34/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6450 - accuracy: 0.6252 - val_loss: 0.9779 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 35/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6654 - accuracy: 0.5960 - val_loss: 0.7704 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 36/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6417 - accuracy: 0.6430 - val_loss: 0.6371 - val_accuracy: 0.6433 - lr: 0.0010\n",
      "Epoch 37/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6013 - accuracy: 0.6883 - val_loss: 0.6524 - val_accuracy: 0.6524 - lr: 0.0010\n",
      "Epoch 38/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5786 - accuracy: 0.6883 - val_loss: 0.6466 - val_accuracy: 0.6196 - lr: 0.0010\n",
      "Epoch 39/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6069 - accuracy: 0.6718 - val_loss: 0.5871 - val_accuracy: 0.6859 - lr: 0.0010\n",
      "Epoch 40/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5734 - accuracy: 0.7038 - val_loss: 0.6108 - val_accuracy: 0.6617 - lr: 0.0010\n",
      "Epoch 41/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5716 - accuracy: 0.7072 - val_loss: 0.6696 - val_accuracy: 0.6194 - lr: 0.0010\n",
      "Epoch 42/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5563 - accuracy: 0.6992 - val_loss: 0.5721 - val_accuracy: 0.7049 - lr: 0.0010\n",
      "Epoch 43/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5344 - accuracy: 0.7383 - val_loss: 0.5645 - val_accuracy: 0.7041 - lr: 0.0010\n",
      "Epoch 44/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5152 - accuracy: 0.7505 - val_loss: 0.6265 - val_accuracy: 0.6664 - lr: 0.0010\n",
      "Epoch 45/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5290 - accuracy: 0.7325 - val_loss: 0.5513 - val_accuracy: 0.7133 - lr: 0.0010\n",
      "Epoch 46/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5203 - accuracy: 0.7385 - val_loss: 0.6233 - val_accuracy: 0.6703 - lr: 0.0010\n",
      "Epoch 47/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4943 - accuracy: 0.7642 - val_loss: 0.5187 - val_accuracy: 0.7396 - lr: 0.0010\n",
      "Epoch 48/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5074 - accuracy: 0.7548 - val_loss: 0.5097 - val_accuracy: 0.7471 - lr: 0.0010\n",
      "Epoch 49/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5131 - accuracy: 0.7400 - val_loss: 0.5213 - val_accuracy: 0.7315 - lr: 0.0010\n",
      "Epoch 50/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4659 - accuracy: 0.7795 - val_loss: 0.5452 - val_accuracy: 0.7408 - lr: 0.0010\n",
      "Epoch 51/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4549 - accuracy: 0.7900 - val_loss: 0.6846 - val_accuracy: 0.6566 - lr: 0.0010\n",
      "Epoch 52/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4702 - accuracy: 0.7745 - val_loss: 0.4867 - val_accuracy: 0.7626 - lr: 0.0010\n",
      "Epoch 53/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4796 - accuracy: 0.7690 - val_loss: 0.5080 - val_accuracy: 0.7605 - lr: 0.0010\n",
      "Epoch 54/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4228 - accuracy: 0.8152 - val_loss: 0.6214 - val_accuracy: 0.7476 - lr: 0.0010\n",
      "Epoch 55/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4432 - accuracy: 0.7947 - val_loss: 0.5382 - val_accuracy: 0.7139 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4620 - accuracy: 0.7770 - val_loss: 0.4706 - val_accuracy: 0.7755 - lr: 0.0010\n",
      "Epoch 57/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4004 - accuracy: 0.8210 - val_loss: 0.5970 - val_accuracy: 0.7067 - lr: 0.0010\n",
      "Epoch 58/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4071 - accuracy: 0.8192 - val_loss: 0.8056 - val_accuracy: 0.6014 - lr: 0.0010\n",
      "Epoch 59/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4063 - accuracy: 0.8080 - val_loss: 0.4629 - val_accuracy: 0.7897 - lr: 0.0010\n",
      "Epoch 60/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4266 - accuracy: 0.8030 - val_loss: 0.4282 - val_accuracy: 0.8145 - lr: 0.0010\n",
      "Epoch 61/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3663 - accuracy: 0.8480 - val_loss: 0.5330 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 62/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3849 - accuracy: 0.8263 - val_loss: 0.4531 - val_accuracy: 0.8019 - lr: 0.0010\n",
      "Epoch 63/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4241 - accuracy: 0.8020 - val_loss: 0.4994 - val_accuracy: 0.7588 - lr: 0.0010\n",
      "Epoch 64/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3463 - accuracy: 0.8530 - val_loss: 0.4360 - val_accuracy: 0.7980 - lr: 0.0010\n",
      "Epoch 65/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3614 - accuracy: 0.8447 - val_loss: 0.3863 - val_accuracy: 0.8233 - lr: 0.0010\n",
      "Epoch 66/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3770 - accuracy: 0.8320 - val_loss: 0.4537 - val_accuracy: 0.7937 - lr: 0.0010\n",
      "Epoch 67/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3984 - accuracy: 0.8242 - val_loss: 0.4062 - val_accuracy: 0.8243 - lr: 0.0010\n",
      "Epoch 68/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3318 - accuracy: 0.8585 - val_loss: 0.3667 - val_accuracy: 0.8369 - lr: 0.0010\n",
      "Epoch 69/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3321 - accuracy: 0.8637 - val_loss: 0.5009 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 70/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3989 - accuracy: 0.8220 - val_loss: 0.4869 - val_accuracy: 0.7643 - lr: 0.0010\n",
      "Epoch 71/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3187 - accuracy: 0.8622 - val_loss: 0.3635 - val_accuracy: 0.8371 - lr: 0.0010\n",
      "Epoch 72/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3211 - accuracy: 0.8645 - val_loss: 0.3566 - val_accuracy: 0.8388 - lr: 0.0010\n",
      "Epoch 73/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3593 - accuracy: 0.8432 - val_loss: 0.3972 - val_accuracy: 0.8111 - lr: 0.0010\n",
      "Epoch 74/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3622 - accuracy: 0.8418 - val_loss: 0.3638 - val_accuracy: 0.8400 - lr: 0.0010\n",
      "Epoch 75/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3068 - accuracy: 0.8760 - val_loss: 0.3418 - val_accuracy: 0.8461 - lr: 0.0010\n",
      "Epoch 76/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3121 - accuracy: 0.8680 - val_loss: 0.3813 - val_accuracy: 0.8247 - lr: 0.0010\n",
      "Epoch 77/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3740 - accuracy: 0.8298 - val_loss: 0.3942 - val_accuracy: 0.8241 - lr: 0.0010\n",
      "Epoch 78/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2896 - accuracy: 0.8763 - val_loss: 0.4552 - val_accuracy: 0.7935 - lr: 0.0010\n",
      "Epoch 79/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3027 - accuracy: 0.8748 - val_loss: 0.5880 - val_accuracy: 0.8048 - lr: 0.0010\n",
      "Epoch 80/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3209 - accuracy: 0.8668 - val_loss: 0.4638 - val_accuracy: 0.7858 - lr: 0.0010\n",
      "Epoch 81/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3444 - accuracy: 0.8545 - val_loss: 0.4712 - val_accuracy: 0.8254 - lr: 0.0010\n",
      "Epoch 82/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2664 - accuracy: 0.8917 - val_loss: 0.3511 - val_accuracy: 0.8522 - lr: 0.0010\n",
      "Epoch 83/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2864 - accuracy: 0.8823 - val_loss: 0.9293 - val_accuracy: 0.7428 - lr: 0.0010\n",
      "Epoch 84/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3538 - accuracy: 0.8453 - val_loss: 0.3407 - val_accuracy: 0.8532 - lr: 0.0010\n",
      "Epoch 85/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2740 - accuracy: 0.8848 - val_loss: 0.6596 - val_accuracy: 0.7038 - lr: 0.0010\n",
      "Epoch 86/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2729 - accuracy: 0.8907 - val_loss: 0.3083 - val_accuracy: 0.8736 - lr: 0.0010\n",
      "Epoch 87/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2836 - accuracy: 0.8832 - val_loss: 0.3439 - val_accuracy: 0.8551 - lr: 0.0010\n",
      "Epoch 88/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3245 - accuracy: 0.8593 - val_loss: 0.4209 - val_accuracy: 0.8506 - lr: 0.0010\n",
      "Epoch 89/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2467 - accuracy: 0.9040 - val_loss: 0.3721 - val_accuracy: 0.8514 - lr: 0.0010\n",
      "Epoch 90/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2724 - accuracy: 0.8910 - val_loss: 0.3209 - val_accuracy: 0.8652 - lr: 0.0010\n",
      "Epoch 91/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3108 - accuracy: 0.8668 - val_loss: 0.3255 - val_accuracy: 0.8598 - lr: 0.0010\n",
      "Epoch 92/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2499 - accuracy: 0.8947 - val_loss: 0.6533 - val_accuracy: 0.8269 - lr: 0.0010\n",
      "Epoch 93/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2649 - accuracy: 0.8953 - val_loss: 0.3409 - val_accuracy: 0.8579 - lr: 0.0010\n",
      "Epoch 94/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2823 - accuracy: 0.8870 - val_loss: 0.3026 - val_accuracy: 0.8714 - lr: 0.0010\n",
      "Epoch 95/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3145 - accuracy: 0.8665 - val_loss: 0.3228 - val_accuracy: 0.8724 - lr: 0.0010\n",
      "Epoch 96/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2363 - accuracy: 0.9072 - val_loss: 0.4977 - val_accuracy: 0.7936 - lr: 0.0010\n",
      "Epoch 97/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2495 - accuracy: 0.9000 - val_loss: 0.4936 - val_accuracy: 0.8339 - lr: 0.0010\n",
      "Epoch 98/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2913 - accuracy: 0.8763 - val_loss: 0.2669 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Epoch 99/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2695 - accuracy: 0.8820 - val_loss: 0.3746 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 100/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2295 - accuracy: 0.9075 - val_loss: 0.2998 - val_accuracy: 0.8795 - lr: 0.0010\n",
      "Epoch 101/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2512 - accuracy: 0.8972 - val_loss: 0.4394 - val_accuracy: 0.8433 - lr: 0.0010\n",
      "Epoch 102/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2856 - accuracy: 0.8785 - val_loss: 0.3136 - val_accuracy: 0.8853 - lr: 0.0010\n",
      "Epoch 103/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2165 - accuracy: 0.9147 - val_loss: 0.3145 - val_accuracy: 0.8812 - lr: 0.0010\n",
      "Epoch 104/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2375 - accuracy: 0.9090 - val_loss: 0.3321 - val_accuracy: 0.8722 - lr: 0.0010\n",
      "Epoch 105/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2647 - accuracy: 0.8903 - val_loss: 0.3071 - val_accuracy: 0.8668 - lr: 0.0010\n",
      "Epoch 106/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2469 - accuracy: 0.8955 - val_loss: 0.4245 - val_accuracy: 0.8500 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2311 - accuracy: 0.9093 - val_loss: 0.3099 - val_accuracy: 0.8712 - lr: 0.0010\n",
      "Epoch 108/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2460 - accuracy: 0.8985 - val_loss: 0.2821 - val_accuracy: 0.8771 - lr: 0.0010\n",
      "Epoch 109/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2629 - accuracy: 0.8890 - val_loss: 0.3311 - val_accuracy: 0.8586 - lr: 0.0010\n",
      "Epoch 110/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1992 - accuracy: 0.9202 - val_loss: 0.3408 - val_accuracy: 0.8612 - lr: 0.0010\n",
      "Epoch 111/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2296 - accuracy: 0.9112 - val_loss: 0.4137 - val_accuracy: 0.8369 - lr: 0.0010\n",
      "Epoch 112/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2377 - accuracy: 0.9013 - val_loss: 0.2590 - val_accuracy: 0.8900 - lr: 0.0010\n",
      "Epoch 113/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2292 - accuracy: 0.9115 - val_loss: 0.3429 - val_accuracy: 0.8792 - lr: 0.0010\n",
      "Epoch 114/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2176 - accuracy: 0.9145 - val_loss: 0.2789 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 115/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2391 - accuracy: 0.9068 - val_loss: 0.3067 - val_accuracy: 0.8695 - lr: 0.0010\n",
      "Epoch 116/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2687 - accuracy: 0.8935 - val_loss: 0.3270 - val_accuracy: 0.8748 - lr: 0.0010\n",
      "Epoch 117/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1901 - accuracy: 0.9285 - val_loss: 0.5638 - val_accuracy: 0.7683 - lr: 0.0010\n",
      "Epoch 118/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2218 - accuracy: 0.9158 - val_loss: 0.3762 - val_accuracy: 0.8493 - lr: 0.0010\n",
      "Epoch 119/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2054 - accuracy: 0.9180 - val_loss: 0.3057 - val_accuracy: 0.8791 - lr: 0.0010\n",
      "Epoch 120/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2420 - accuracy: 0.9010 - val_loss: 0.3152 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Epoch 121/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1895 - accuracy: 0.9295 - val_loss: 0.3088 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 122/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2244 - accuracy: 0.9137 - val_loss: 0.3099 - val_accuracy: 0.8637 - lr: 0.0010\n",
      "Epoch 123/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2416 - accuracy: 0.9030 - val_loss: 0.3056 - val_accuracy: 0.8774 - lr: 0.0010\n",
      "Epoch 124/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1728 - accuracy: 0.9335 - val_loss: 0.2804 - val_accuracy: 0.8983 - lr: 0.0010\n",
      "Epoch 125/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2177 - accuracy: 0.9170 - val_loss: 0.3647 - val_accuracy: 0.8458 - lr: 0.0010\n",
      "Epoch 126/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2055 - accuracy: 0.9215 - val_loss: 0.2799 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 127/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2518 - accuracy: 0.8972 - val_loss: 0.2538 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Epoch 128/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1825 - accuracy: 0.9295 - val_loss: 0.3701 - val_accuracy: 0.8493 - lr: 0.0010\n",
      "Epoch 129/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1716 - accuracy: 0.9342 - val_loss: 0.3060 - val_accuracy: 0.8820 - lr: 0.0010\n",
      "Epoch 130/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2538 - accuracy: 0.8982 - val_loss: 0.2827 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 131/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1871 - accuracy: 0.9305 - val_loss: 0.3790 - val_accuracy: 0.8529 - lr: 0.0010\n",
      "Epoch 132/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1930 - accuracy: 0.9265 - val_loss: 0.2637 - val_accuracy: 0.8963 - lr: 0.0010\n",
      "Epoch 133/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2063 - accuracy: 0.9202 - val_loss: 0.2369 - val_accuracy: 0.9106 - lr: 0.0010\n",
      "Epoch 134/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2336 - accuracy: 0.9100 - val_loss: 0.2326 - val_accuracy: 0.9120 - lr: 0.0010\n",
      "Epoch 135/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1767 - accuracy: 0.9273 - val_loss: 0.2376 - val_accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 136/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1753 - accuracy: 0.9312 - val_loss: 0.2846 - val_accuracy: 0.8847 - lr: 0.0010\n",
      "Epoch 137/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2314 - accuracy: 0.9093 - val_loss: 0.3688 - val_accuracy: 0.8511 - lr: 0.0010\n",
      "Epoch 138/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1702 - accuracy: 0.9375 - val_loss: 0.2401 - val_accuracy: 0.9091 - lr: 0.0010\n",
      "Epoch 139/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1719 - accuracy: 0.9345 - val_loss: 0.2953 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Epoch 140/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2010 - accuracy: 0.9260 - val_loss: 0.2088 - val_accuracy: 0.9187 - lr: 0.0010\n",
      "Epoch 141/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2144 - accuracy: 0.9143 - val_loss: 0.2241 - val_accuracy: 0.9126 - lr: 0.0010\n",
      "Epoch 142/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1735 - accuracy: 0.9355 - val_loss: 0.3683 - val_accuracy: 0.8431 - lr: 0.0010\n",
      "Epoch 143/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1688 - accuracy: 0.9380 - val_loss: 0.2259 - val_accuracy: 0.9140 - lr: 0.0010\n",
      "Epoch 144/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2160 - accuracy: 0.9210 - val_loss: 0.3009 - val_accuracy: 0.8780 - lr: 0.0010\n",
      "Epoch 145/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1632 - accuracy: 0.9408 - val_loss: 0.3198 - val_accuracy: 0.8770 - lr: 0.0010\n",
      "Epoch 146/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1592 - accuracy: 0.9430 - val_loss: 0.1986 - val_accuracy: 0.9305 - lr: 0.0010\n",
      "Epoch 147/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1727 - accuracy: 0.9327 - val_loss: 0.2689 - val_accuracy: 0.8925 - lr: 0.0010\n",
      "Epoch 148/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2045 - accuracy: 0.9187 - val_loss: 0.2940 - val_accuracy: 0.9111 - lr: 0.0010\n",
      "Epoch 149/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1527 - accuracy: 0.9420 - val_loss: 0.1969 - val_accuracy: 0.9238 - lr: 0.0010\n",
      "Epoch 150/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1716 - accuracy: 0.9398 - val_loss: 0.2371 - val_accuracy: 0.9096 - lr: 0.0010\n",
      "Epoch 151/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1967 - accuracy: 0.9218 - val_loss: 0.2522 - val_accuracy: 0.8984 - lr: 0.0010\n",
      "Epoch 152/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1552 - accuracy: 0.9405 - val_loss: 0.3076 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 153/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1726 - accuracy: 0.9385 - val_loss: 0.2238 - val_accuracy: 0.9145 - lr: 0.0010\n",
      "Epoch 154/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1652 - accuracy: 0.9367 - val_loss: 0.2410 - val_accuracy: 0.9134 - lr: 0.0010\n",
      "Epoch 155/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1920 - accuracy: 0.9235 - val_loss: 0.2521 - val_accuracy: 0.9106 - lr: 0.0010\n",
      "Epoch 156/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1392 - accuracy: 0.9485 - val_loss: 0.2131 - val_accuracy: 0.9243 - lr: 0.0010\n",
      "Epoch 157/625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1655 - accuracy: 0.9425 - val_loss: 0.1874 - val_accuracy: 0.9310 - lr: 0.0010\n",
      "Epoch 158/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1737 - accuracy: 0.9348 - val_loss: 0.1986 - val_accuracy: 0.9201 - lr: 0.0010\n",
      "Epoch 159/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1477 - accuracy: 0.9423 - val_loss: 0.2896 - val_accuracy: 0.9100 - lr: 0.0010\n",
      "Epoch 160/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1565 - accuracy: 0.9430 - val_loss: 0.2730 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Epoch 161/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1727 - accuracy: 0.9345 - val_loss: 0.2065 - val_accuracy: 0.9264 - lr: 0.0010\n",
      "Epoch 162/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1812 - accuracy: 0.9360 - val_loss: 0.2570 - val_accuracy: 0.9191 - lr: 0.0010\n",
      "Epoch 163/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1498 - accuracy: 0.9440 - val_loss: 0.2913 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 164/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1667 - accuracy: 0.9385 - val_loss: 0.3597 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Epoch 165/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1631 - accuracy: 0.9360 - val_loss: 0.2550 - val_accuracy: 0.8973 - lr: 0.0010\n",
      "Epoch 166/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1561 - accuracy: 0.9392 - val_loss: 0.3499 - val_accuracy: 0.8992 - lr: 0.0010\n",
      "Epoch 167/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1584 - accuracy: 0.9402 - val_loss: 0.2331 - val_accuracy: 0.9182 - lr: 0.0010\n",
      "Epoch 168/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1660 - accuracy: 0.9385 - val_loss: 0.2598 - val_accuracy: 0.9070 - lr: 0.0010\n",
      "Epoch 169/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1613 - accuracy: 0.9377 - val_loss: 0.1993 - val_accuracy: 0.9266 - lr: 0.0010\n",
      "Epoch 170/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1397 - accuracy: 0.9517 - val_loss: 0.2010 - val_accuracy: 0.9274 - lr: 0.0010\n",
      "Epoch 171/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1682 - accuracy: 0.9380 - val_loss: 0.3195 - val_accuracy: 0.8872 - lr: 0.0010\n",
      "Epoch 172/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1515 - accuracy: 0.9438 - val_loss: 0.1518 - val_accuracy: 0.9438 - lr: 0.0010\n",
      "Epoch 173/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1646 - accuracy: 0.9348 - val_loss: 0.2242 - val_accuracy: 0.9303 - lr: 0.0010\n",
      "Epoch 174/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1407 - accuracy: 0.9500 - val_loss: 0.2003 - val_accuracy: 0.9322 - lr: 0.0010\n",
      "Epoch 175/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1601 - accuracy: 0.9385 - val_loss: 0.2855 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Epoch 176/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1744 - accuracy: 0.9333 - val_loss: 0.2190 - val_accuracy: 0.9191 - lr: 0.0010\n",
      "Epoch 177/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1258 - accuracy: 0.9535 - val_loss: 0.2166 - val_accuracy: 0.9172 - lr: 0.0010\n",
      "Epoch 178/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1639 - accuracy: 0.9390 - val_loss: 0.3234 - val_accuracy: 0.8817 - lr: 0.0010\n",
      "Epoch 179/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1553 - accuracy: 0.9415 - val_loss: 0.1725 - val_accuracy: 0.9422 - lr: 0.0010\n",
      "Epoch 180/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1385 - accuracy: 0.9488 - val_loss: 0.2217 - val_accuracy: 0.9257 - lr: 0.0010\n",
      "Epoch 181/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1497 - accuracy: 0.9470 - val_loss: 0.1805 - val_accuracy: 0.9383 - lr: 0.0010\n",
      "Epoch 182/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1520 - accuracy: 0.9433 - val_loss: 0.2534 - val_accuracy: 0.9013 - lr: 0.0010\n",
      "Epoch 183/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1537 - accuracy: 0.9430 - val_loss: 0.2247 - val_accuracy: 0.9109 - lr: 0.0010\n",
      "Epoch 184/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1168 - accuracy: 0.9532 - val_loss: 0.2301 - val_accuracy: 0.9136 - lr: 0.0010\n",
      "Epoch 185/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1439 - accuracy: 0.9485 - val_loss: 0.4303 - val_accuracy: 0.8401 - lr: 0.0010\n",
      "Epoch 186/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1278 - accuracy: 0.9510 - val_loss: 0.2226 - val_accuracy: 0.9152 - lr: 0.0010\n",
      "Epoch 187/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1664 - accuracy: 0.9377 - val_loss: 0.2496 - val_accuracy: 0.9186 - lr: 0.0010\n",
      "Epoch 188/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1205 - accuracy: 0.9545 - val_loss: 0.2848 - val_accuracy: 0.8933 - lr: 0.0010\n",
      "Epoch 189/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1411 - accuracy: 0.9498 - val_loss: 0.1985 - val_accuracy: 0.9270 - lr: 0.0010\n",
      "Epoch 190/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1866 - accuracy: 0.9308 - val_loss: 0.3923 - val_accuracy: 0.8436 - lr: 0.0010\n",
      "Epoch 191/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1058 - accuracy: 0.9628 - val_loss: 0.2040 - val_accuracy: 0.9292 - lr: 0.0010\n",
      "Epoch 192/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1446 - accuracy: 0.9445 - val_loss: 0.1915 - val_accuracy: 0.9314 - lr: 0.0010\n",
      "Epoch 193/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1579 - accuracy: 0.9425 - val_loss: 0.2001 - val_accuracy: 0.9218 - lr: 0.0010\n",
      "Epoch 194/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1639 - accuracy: 0.9360 - val_loss: 0.1889 - val_accuracy: 0.9378 - lr: 0.0010\n",
      "Epoch 195/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1429 - accuracy: 0.9477 - val_loss: 0.1490 - val_accuracy: 0.9457 - lr: 0.0010\n",
      "Epoch 196/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1285 - accuracy: 0.9553 - val_loss: 0.2076 - val_accuracy: 0.9247 - lr: 0.0010\n",
      "Epoch 197/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1531 - accuracy: 0.9442 - val_loss: 0.3818 - val_accuracy: 0.8559 - lr: 0.0010\n",
      "Epoch 198/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1044 - accuracy: 0.9600 - val_loss: 0.2713 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Epoch 199/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1342 - accuracy: 0.9503 - val_loss: 0.2414 - val_accuracy: 0.9303 - lr: 0.0010\n",
      "Epoch 200/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1398 - accuracy: 0.9510 - val_loss: 0.1383 - val_accuracy: 0.9492 - lr: 0.0010\n",
      "Epoch 201/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1510 - accuracy: 0.9470 - val_loss: 0.2927 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Epoch 202/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1257 - accuracy: 0.9575 - val_loss: 0.1832 - val_accuracy: 0.9293 - lr: 0.0010\n",
      "Epoch 203/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1258 - accuracy: 0.9542 - val_loss: 0.2052 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "Epoch 204/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1416 - accuracy: 0.9460 - val_loss: 0.2302 - val_accuracy: 0.9099 - lr: 0.0010\n",
      "Epoch 205/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1140 - accuracy: 0.9578 - val_loss: 0.4168 - val_accuracy: 0.8537 - lr: 0.0010\n",
      "Epoch 206/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1431 - accuracy: 0.9460 - val_loss: 0.1859 - val_accuracy: 0.9376 - lr: 0.0010\n",
      "Epoch 207/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1376 - accuracy: 0.9492 - val_loss: 0.3038 - val_accuracy: 0.8887 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1421 - accuracy: 0.9490 - val_loss: 0.1978 - val_accuracy: 0.9312 - lr: 0.0010\n",
      "Epoch 209/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1185 - accuracy: 0.9553 - val_loss: 0.2038 - val_accuracy: 0.9251 - lr: 0.0010\n",
      "Epoch 210/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1210 - accuracy: 0.9557 - val_loss: 0.1721 - val_accuracy: 0.9365 - lr: 0.0010\n",
      "Epoch 211/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1549 - accuracy: 0.9470 - val_loss: 0.2405 - val_accuracy: 0.9098 - lr: 0.0010\n",
      "Epoch 212/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1119 - accuracy: 0.9590 - val_loss: 0.3860 - val_accuracy: 0.8658 - lr: 0.0010\n",
      "Epoch 213/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1021 - accuracy: 0.9632 - val_loss: 0.2161 - val_accuracy: 0.9221 - lr: 0.0010\n",
      "Epoch 214/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1366 - accuracy: 0.9517 - val_loss: 0.1728 - val_accuracy: 0.9488 - lr: 0.0010\n",
      "Epoch 215/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1520 - accuracy: 0.9430 - val_loss: 0.1657 - val_accuracy: 0.9432 - lr: 0.0010\n",
      "Epoch 216/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1107 - accuracy: 0.9615 - val_loss: 0.2321 - val_accuracy: 0.9136 - lr: 0.0010\n",
      "Epoch 217/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1371 - accuracy: 0.9498 - val_loss: 0.1965 - val_accuracy: 0.9246 - lr: 0.0010\n",
      "Epoch 218/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1484 - accuracy: 0.9455 - val_loss: 0.2903 - val_accuracy: 0.8894 - lr: 0.0010\n",
      "Epoch 219/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1280 - accuracy: 0.9503 - val_loss: 0.2641 - val_accuracy: 0.9208 - lr: 0.0010\n",
      "Epoch 220/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1258 - accuracy: 0.9553 - val_loss: 0.3391 - val_accuracy: 0.8793 - lr: 0.0010\n",
      "Epoch 221/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1331 - accuracy: 0.9538 - val_loss: 0.1329 - val_accuracy: 0.9537 - lr: 0.0010\n",
      "Epoch 222/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1428 - accuracy: 0.9503 - val_loss: 0.2335 - val_accuracy: 0.9149 - lr: 0.0010\n",
      "Epoch 223/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1108 - accuracy: 0.9582 - val_loss: 0.4334 - val_accuracy: 0.8376 - lr: 0.0010\n",
      "Epoch 224/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1128 - accuracy: 0.9632 - val_loss: 0.2599 - val_accuracy: 0.9330 - lr: 0.0010\n",
      "Epoch 225/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1564 - accuracy: 0.9455 - val_loss: 0.1438 - val_accuracy: 0.9448 - lr: 0.0010\n",
      "Epoch 226/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1312 - accuracy: 0.9553 - val_loss: 0.1824 - val_accuracy: 0.9436 - lr: 0.0010\n",
      "Epoch 227/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1139 - accuracy: 0.9617 - val_loss: 0.2742 - val_accuracy: 0.9004 - lr: 0.0010\n",
      "Epoch 228/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1352 - accuracy: 0.9532 - val_loss: 0.1835 - val_accuracy: 0.9346 - lr: 0.0010\n",
      "Epoch 229/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1524 - accuracy: 0.9448 - val_loss: 0.1534 - val_accuracy: 0.9453 - lr: 0.0010\n",
      "Epoch 230/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1069 - accuracy: 0.9610 - val_loss: 0.2009 - val_accuracy: 0.9272 - lr: 0.0010\n",
      "Epoch 231/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1312 - accuracy: 0.9528 - val_loss: 0.2839 - val_accuracy: 0.8999 - lr: 0.0010\n",
      "Epoch 232/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1346 - accuracy: 0.9507 - val_loss: 0.2867 - val_accuracy: 0.8935 - lr: 0.0010\n",
      "Epoch 233/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1270 - accuracy: 0.9530 - val_loss: 0.1491 - val_accuracy: 0.9552 - lr: 0.0010\n",
      "Epoch 234/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1174 - accuracy: 0.9597 - val_loss: 0.1825 - val_accuracy: 0.9320 - lr: 0.0010\n",
      "Epoch 235/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1230 - accuracy: 0.9555 - val_loss: 0.1791 - val_accuracy: 0.9303 - lr: 0.0010\n",
      "Epoch 236/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1374 - accuracy: 0.9507 - val_loss: 0.1617 - val_accuracy: 0.9432 - lr: 0.0010\n",
      "Epoch 237/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1048 - accuracy: 0.9630 - val_loss: 0.1850 - val_accuracy: 0.9420 - lr: 0.0010\n",
      "Epoch 238/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1166 - accuracy: 0.9578 - val_loss: 0.1881 - val_accuracy: 0.9348 - lr: 0.0010\n",
      "Epoch 239/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1245 - accuracy: 0.9560 - val_loss: 0.1551 - val_accuracy: 0.9482 - lr: 0.0010\n",
      "Epoch 240/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1350 - accuracy: 0.9538 - val_loss: 0.1446 - val_accuracy: 0.9566 - lr: 0.0010\n",
      "Epoch 241/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1310 - accuracy: 0.9550 - val_loss: 0.1520 - val_accuracy: 0.9493 - lr: 0.0010\n",
      "Epoch 242/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1189 - accuracy: 0.9585 - val_loss: 0.2046 - val_accuracy: 0.9276 - lr: 0.0010\n",
      "Epoch 243/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1512 - accuracy: 0.9467 - val_loss: 0.1896 - val_accuracy: 0.9295 - lr: 0.0010\n",
      "Epoch 244/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1000 - accuracy: 0.9630 - val_loss: 0.2052 - val_accuracy: 0.9245 - lr: 0.0010\n",
      "Epoch 245/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1297 - accuracy: 0.9525 - val_loss: 0.2572 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 246/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1319 - accuracy: 0.9540 - val_loss: 0.2089 - val_accuracy: 0.9233 - lr: 0.0010\n",
      "Epoch 247/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1172 - accuracy: 0.9563 - val_loss: 0.1564 - val_accuracy: 0.9526 - lr: 0.0010\n",
      "Epoch 248/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1068 - accuracy: 0.9635 - val_loss: 0.1392 - val_accuracy: 0.9469 - lr: 0.0010\n",
      "Epoch 249/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1220 - accuracy: 0.9605 - val_loss: 0.4200 - val_accuracy: 0.8603 - lr: 0.0010\n",
      "Epoch 250/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1310 - accuracy: 0.9523 - val_loss: 0.2718 - val_accuracy: 0.8999 - lr: 0.0010\n",
      "Epoch 251/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0844 - accuracy: 0.9712 - val_loss: 0.2434 - val_accuracy: 0.9120 - lr: 0.0010\n",
      "Epoch 252/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1269 - accuracy: 0.9535 - val_loss: 0.2029 - val_accuracy: 0.9235 - lr: 0.0010\n",
      "Epoch 253/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1196 - accuracy: 0.9555 - val_loss: 0.2714 - val_accuracy: 0.9058 - lr: 0.0010\n",
      "Epoch 254/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1397 - accuracy: 0.9500 - val_loss: 0.1354 - val_accuracy: 0.9554 - lr: 0.0010\n",
      "Epoch 255/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1164 - accuracy: 0.9585 - val_loss: 0.2504 - val_accuracy: 0.9115 - lr: 0.0010\n",
      "Epoch 256/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1176 - accuracy: 0.9605 - val_loss: 0.1776 - val_accuracy: 0.9394 - lr: 0.0010\n",
      "Epoch 257/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1381 - accuracy: 0.9482 - val_loss: 0.2667 - val_accuracy: 0.9101 - lr: 0.0010\n",
      "Epoch 258/625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1029 - accuracy: 0.9672 - val_loss: 0.1576 - val_accuracy: 0.9495 - lr: 0.0010\n",
      "Epoch 259/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1237 - accuracy: 0.9565 - val_loss: 0.2499 - val_accuracy: 0.9114 - lr: 0.0010\n",
      "Epoch 260/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1188 - accuracy: 0.9572 - val_loss: 0.2942 - val_accuracy: 0.8941 - lr: 0.0010\n",
      "Epoch 261/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1431 - accuracy: 0.9445 - val_loss: 0.2456 - val_accuracy: 0.9072 - lr: 0.0010\n",
      "Epoch 262/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1276 - accuracy: 0.9542 - val_loss: 0.2260 - val_accuracy: 0.9139 - lr: 0.0010\n",
      "Epoch 263/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1112 - accuracy: 0.9625 - val_loss: 0.2148 - val_accuracy: 0.9217 - lr: 0.0010\n",
      "Epoch 264/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1441 - accuracy: 0.9490 - val_loss: 0.3094 - val_accuracy: 0.8882 - lr: 0.0010\n",
      "Epoch 265/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1023 - accuracy: 0.9638 - val_loss: 0.2397 - val_accuracy: 0.9157 - lr: 0.0010\n",
      "Epoch 266/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1247 - accuracy: 0.9553 - val_loss: 0.1791 - val_accuracy: 0.9344 - lr: 0.0010\n",
      "Epoch 267/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1226 - accuracy: 0.9567 - val_loss: 0.1954 - val_accuracy: 0.9269 - lr: 0.0010\n",
      "Epoch 268/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1134 - accuracy: 0.9595 - val_loss: 0.1238 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 269/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1218 - accuracy: 0.9557 - val_loss: 0.5075 - val_accuracy: 0.8278 - lr: 0.0010\n",
      "Epoch 270/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1032 - accuracy: 0.9635 - val_loss: 0.1495 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 271/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1391 - accuracy: 0.9528 - val_loss: 0.3071 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Epoch 272/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0947 - accuracy: 0.9635 - val_loss: 0.3949 - val_accuracy: 0.8664 - lr: 0.0010\n",
      "Epoch 273/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1203 - accuracy: 0.9548 - val_loss: 0.1355 - val_accuracy: 0.9507 - lr: 0.0010\n",
      "Epoch 274/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1187 - accuracy: 0.9545 - val_loss: 0.1452 - val_accuracy: 0.9519 - lr: 0.0010\n",
      "Epoch 275/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1272 - accuracy: 0.9572 - val_loss: 0.1357 - val_accuracy: 0.9605 - lr: 0.0010\n",
      "Epoch 276/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0860 - accuracy: 0.9715 - val_loss: 0.1689 - val_accuracy: 0.9430 - lr: 0.0010\n",
      "Epoch 277/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1148 - accuracy: 0.9617 - val_loss: 0.2183 - val_accuracy: 0.9242 - lr: 0.0010\n",
      "Epoch 278/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1344 - accuracy: 0.9500 - val_loss: 0.3633 - val_accuracy: 0.8686 - lr: 0.0010\n",
      "Epoch 279/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1229 - accuracy: 0.9597 - val_loss: 0.2719 - val_accuracy: 0.8969 - lr: 0.0010\n",
      "Epoch 280/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1124 - accuracy: 0.9597 - val_loss: 0.1993 - val_accuracy: 0.9239 - lr: 0.0010\n",
      "Epoch 281/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1325 - accuracy: 0.9507 - val_loss: 0.1605 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 282/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1287 - accuracy: 0.9580 - val_loss: 0.1560 - val_accuracy: 0.9551 - lr: 0.0010\n",
      "Epoch 283/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0970 - accuracy: 0.9657 - val_loss: 0.2123 - val_accuracy: 0.9177 - lr: 0.0010\n",
      "Epoch 284/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1077 - accuracy: 0.9628 - val_loss: 0.1710 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 285/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1158 - accuracy: 0.9560 - val_loss: 0.2054 - val_accuracy: 0.9251 - lr: 0.0010\n",
      "Epoch 286/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1147 - accuracy: 0.9572 - val_loss: 0.1923 - val_accuracy: 0.9325 - lr: 0.0010\n",
      "Epoch 287/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1330 - accuracy: 0.9548 - val_loss: 0.5518 - val_accuracy: 0.8009 - lr: 0.0010\n",
      "Epoch 288/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1196 - accuracy: 0.9595 - val_loss: 0.1503 - val_accuracy: 0.9506 - lr: 0.0010\n",
      "Epoch 289/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1438 - accuracy: 0.9492 - val_loss: 0.1365 - val_accuracy: 0.9553 - lr: 0.0010\n",
      "Epoch 290/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0961 - accuracy: 0.9665 - val_loss: 0.1464 - val_accuracy: 0.9461 - lr: 0.0010\n",
      "Epoch 291/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1019 - accuracy: 0.9655 - val_loss: 0.1317 - val_accuracy: 0.9631 - lr: 0.0010\n",
      "Epoch 292/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1195 - accuracy: 0.9575 - val_loss: 0.1302 - val_accuracy: 0.9501 - lr: 0.0010\n",
      "Epoch 293/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1019 - accuracy: 0.9653 - val_loss: 0.1369 - val_accuracy: 0.9605 - lr: 0.0010\n",
      "Epoch 294/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1297 - accuracy: 0.9588 - val_loss: 0.1786 - val_accuracy: 0.9337 - lr: 0.0010\n",
      "Epoch 295/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1158 - accuracy: 0.9643 - val_loss: 0.1677 - val_accuracy: 0.9430 - lr: 0.0010\n",
      "Epoch 296/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1079 - accuracy: 0.9595 - val_loss: 0.1501 - val_accuracy: 0.9490 - lr: 0.0010\n",
      "Epoch 297/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0887 - accuracy: 0.9703 - val_loss: 0.1995 - val_accuracy: 0.9302 - lr: 0.0010\n",
      "Epoch 298/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1301 - accuracy: 0.9548 - val_loss: 0.2028 - val_accuracy: 0.9254 - lr: 0.0010\n",
      "Epoch 299/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1193 - accuracy: 0.9580 - val_loss: 0.0876 - val_accuracy: 0.9694 - lr: 0.0010\n",
      "Epoch 300/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1187 - accuracy: 0.9610 - val_loss: 0.2405 - val_accuracy: 0.9478 - lr: 0.0010\n",
      "Epoch 301/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1149 - accuracy: 0.9605 - val_loss: 0.1243 - val_accuracy: 0.9659 - lr: 0.0010\n",
      "Epoch 302/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1324 - accuracy: 0.9567 - val_loss: 0.2668 - val_accuracy: 0.9003 - lr: 0.0010\n",
      "Epoch 303/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1199 - accuracy: 0.9590 - val_loss: 0.1967 - val_accuracy: 0.9380 - lr: 0.0010\n",
      "Epoch 304/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1255 - accuracy: 0.9605 - val_loss: 0.2136 - val_accuracy: 0.9218 - lr: 0.0010\n",
      "Epoch 305/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1274 - accuracy: 0.9563 - val_loss: 0.2885 - val_accuracy: 0.8950 - lr: 0.0010\n",
      "Epoch 306/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1098 - accuracy: 0.9610 - val_loss: 0.1000 - val_accuracy: 0.9652 - lr: 0.0010\n",
      "Epoch 307/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1391 - accuracy: 0.9507 - val_loss: 0.1312 - val_accuracy: 0.9589 - lr: 0.0010\n",
      "Epoch 308/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1063 - accuracy: 0.9655 - val_loss: 0.2104 - val_accuracy: 0.9219 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1407 - accuracy: 0.9523 - val_loss: 0.2599 - val_accuracy: 0.9125 - lr: 0.0010\n",
      "Epoch 310/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1488 - accuracy: 0.9460 - val_loss: 0.1542 - val_accuracy: 0.9410 - lr: 0.0010\n",
      "Epoch 311/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1065 - accuracy: 0.9675 - val_loss: 0.4679 - val_accuracy: 0.8350 - lr: 0.0010\n",
      "Epoch 312/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1113 - accuracy: 0.9603 - val_loss: 0.1691 - val_accuracy: 0.9385 - lr: 0.0010\n",
      "Epoch 313/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1206 - accuracy: 0.9617 - val_loss: 0.2353 - val_accuracy: 0.9076 - lr: 0.0010\n",
      "Epoch 314/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1376 - accuracy: 0.9505 - val_loss: 0.1406 - val_accuracy: 0.9490 - lr: 0.0010\n",
      "Epoch 315/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1103 - accuracy: 0.9620 - val_loss: 0.2535 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 316/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1203 - accuracy: 0.9572 - val_loss: 0.1804 - val_accuracy: 0.9330 - lr: 0.0010\n",
      "Epoch 317/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1432 - accuracy: 0.9507 - val_loss: 0.2640 - val_accuracy: 0.9022 - lr: 0.0010\n",
      "Epoch 318/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1199 - accuracy: 0.9563 - val_loss: 0.1720 - val_accuracy: 0.9414 - lr: 0.0010\n",
      "Epoch 319/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1274 - accuracy: 0.9538 - val_loss: 0.2441 - val_accuracy: 0.9130 - lr: 0.0010\n",
      "Epoch 320/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1050 - accuracy: 0.9592 - val_loss: 0.2137 - val_accuracy: 0.9218 - lr: 0.0010\n",
      "Epoch 321/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1385 - accuracy: 0.9505 - val_loss: 0.1120 - val_accuracy: 0.9631 - lr: 0.0010\n",
      "Epoch 322/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1262 - accuracy: 0.9578 - val_loss: 0.2124 - val_accuracy: 0.9221 - lr: 0.0010\n",
      "Epoch 323/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1405 - accuracy: 0.9532 - val_loss: 0.3163 - val_accuracy: 0.8894 - lr: 0.0010\n",
      "Epoch 324/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1556 - accuracy: 0.9438 - val_loss: 0.2351 - val_accuracy: 0.9127 - lr: 0.0010\n",
      "Epoch 325/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1007 - accuracy: 0.9643 - val_loss: 0.1355 - val_accuracy: 0.9508 - lr: 0.0010\n",
      "Epoch 326/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1573 - accuracy: 0.9517 - val_loss: 0.2515 - val_accuracy: 0.9028 - lr: 0.0010\n",
      "Epoch 327/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1420 - accuracy: 0.9525 - val_loss: 0.1020 - val_accuracy: 0.9632 - lr: 0.0010\n",
      "Epoch 328/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1431 - accuracy: 0.9538 - val_loss: 0.1326 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 329/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1073 - accuracy: 0.9635 - val_loss: 0.1332 - val_accuracy: 0.9495 - lr: 0.0010\n",
      "Epoch 330/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1192 - accuracy: 0.9615 - val_loss: 0.1058 - val_accuracy: 0.9645 - lr: 0.0010\n",
      "Epoch 331/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1521 - accuracy: 0.9480 - val_loss: 0.1182 - val_accuracy: 0.9555 - lr: 0.0010\n",
      "Epoch 332/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1303 - accuracy: 0.9557 - val_loss: 0.3687 - val_accuracy: 0.8717 - lr: 0.0010\n",
      "Epoch 333/625\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1060 - accuracy: 0.9635 - val_loss: 0.1144 - val_accuracy: 0.9597 - lr: 0.0010\n",
      "Epoch 334/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1110 - accuracy: 0.9645 - val_loss: 0.1546 - val_accuracy: 0.9434 - lr: 0.0010\n",
      "Epoch 335/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1338 - accuracy: 0.9520 - val_loss: 0.1029 - val_accuracy: 0.9651 - lr: 0.0010\n",
      "Epoch 336/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0915 - accuracy: 0.9693 - val_loss: 0.1354 - val_accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 337/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1075 - accuracy: 0.9643 - val_loss: 0.1388 - val_accuracy: 0.9626 - lr: 0.0010\n",
      "Epoch 338/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1542 - accuracy: 0.9477 - val_loss: 0.1405 - val_accuracy: 0.9484 - lr: 0.0010\n",
      "Epoch 339/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1112 - accuracy: 0.9645 - val_loss: 0.6193 - val_accuracy: 0.7892 - lr: 0.0010\n",
      "Epoch 340/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1235 - accuracy: 0.9572 - val_loss: 0.1676 - val_accuracy: 0.9374 - lr: 0.0010\n",
      "Epoch 341/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1150 - accuracy: 0.9603 - val_loss: 0.1734 - val_accuracy: 0.9493 - lr: 0.0010\n",
      "Epoch 342/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1423 - accuracy: 0.9535 - val_loss: 0.2049 - val_accuracy: 0.9505 - lr: 0.0010\n",
      "Epoch 343/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1288 - accuracy: 0.9582 - val_loss: 0.2280 - val_accuracy: 0.9143 - lr: 0.0010\n",
      "Epoch 344/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0926 - accuracy: 0.9685 - val_loss: 0.1317 - val_accuracy: 0.9600 - lr: 0.0010\n",
      "Epoch 345/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1701 - accuracy: 0.9425 - val_loss: 0.1293 - val_accuracy: 0.9537 - lr: 0.0010\n",
      "Epoch 346/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1419 - accuracy: 0.9538 - val_loss: 0.1606 - val_accuracy: 0.9396 - lr: 0.0010\n",
      "Epoch 347/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1247 - accuracy: 0.9548 - val_loss: 0.2193 - val_accuracy: 0.9207 - lr: 0.0010\n",
      "Epoch 348/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1365 - accuracy: 0.9532 - val_loss: 0.1420 - val_accuracy: 0.9498 - lr: 0.0010\n",
      "Epoch 349/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1451 - accuracy: 0.9548 - val_loss: 0.1211 - val_accuracy: 0.9592 - lr: 0.0010\n",
      "Epoch 350/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1482 - accuracy: 0.9523 - val_loss: 0.2832 - val_accuracy: 0.8984 - lr: 0.0010\n",
      "Epoch 351/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1341 - accuracy: 0.9565 - val_loss: 0.1848 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 352/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1373 - accuracy: 0.9520 - val_loss: 0.1367 - val_accuracy: 0.9501 - lr: 0.0010\n",
      "Epoch 353/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1037 - accuracy: 0.9638 - val_loss: 0.1081 - val_accuracy: 0.9658 - lr: 0.0010\n",
      "Epoch 354/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1321 - accuracy: 0.9538 - val_loss: 0.1417 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 355/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1407 - accuracy: 0.9517 - val_loss: 0.1818 - val_accuracy: 0.9371 - lr: 0.0010\n",
      "Epoch 356/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1832 - accuracy: 0.9370 - val_loss: 0.1416 - val_accuracy: 0.9503 - lr: 0.0010\n",
      "Epoch 357/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1317 - accuracy: 0.9590 - val_loss: 0.2247 - val_accuracy: 0.9216 - lr: 0.0010\n",
      "Epoch 358/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1149 - accuracy: 0.9592 - val_loss: 0.2385 - val_accuracy: 0.9153 - lr: 0.0010\n",
      "Epoch 359/625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1349 - accuracy: 0.9538 - val_loss: 0.1582 - val_accuracy: 0.9409 - lr: 0.0010\n",
      "Epoch 360/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1345 - accuracy: 0.9542 - val_loss: 0.1217 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 361/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1227 - accuracy: 0.9615 - val_loss: 0.1426 - val_accuracy: 0.9481 - lr: 0.0010\n",
      "Epoch 362/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1294 - accuracy: 0.9575 - val_loss: 0.1981 - val_accuracy: 0.9288 - lr: 0.0010\n",
      "Epoch 363/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1286 - accuracy: 0.9582 - val_loss: 0.2260 - val_accuracy: 0.9175 - lr: 0.0010\n",
      "Epoch 364/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1146 - accuracy: 0.9610 - val_loss: 0.2024 - val_accuracy: 0.9258 - lr: 0.0010\n",
      "Epoch 365/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1556 - accuracy: 0.9515 - val_loss: 0.3163 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 366/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1364 - accuracy: 0.9578 - val_loss: 0.1425 - val_accuracy: 0.9474 - lr: 0.0010\n",
      "Epoch 367/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1433 - accuracy: 0.9513 - val_loss: 0.1638 - val_accuracy: 0.9442 - lr: 0.0010\n",
      "Epoch 368/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1458 - accuracy: 0.9538 - val_loss: 0.1474 - val_accuracy: 0.9496 - lr: 0.0010\n",
      "Epoch 369/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1340 - accuracy: 0.9532 - val_loss: 0.1854 - val_accuracy: 0.9330 - lr: 0.0010\n",
      "Epoch 370/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1738 - accuracy: 0.9415 - val_loss: 0.1758 - val_accuracy: 0.9364 - lr: 0.0010\n",
      "Epoch 371/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1166 - accuracy: 0.9625 - val_loss: 0.2664 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Epoch 372/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1743 - accuracy: 0.9452 - val_loss: 0.3586 - val_accuracy: 0.8680 - lr: 0.0010\n",
      "Epoch 373/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1412 - accuracy: 0.9500 - val_loss: 0.2134 - val_accuracy: 0.9178 - lr: 0.0010\n",
      "Epoch 374/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1637 - accuracy: 0.9420 - val_loss: 0.1368 - val_accuracy: 0.9565 - lr: 0.0010\n",
      "Epoch 375/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1268 - accuracy: 0.9592 - val_loss: 0.2794 - val_accuracy: 0.8972 - lr: 0.0010\n",
      "Epoch 376/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1350 - accuracy: 0.9548 - val_loss: 0.2745 - val_accuracy: 0.8916 - lr: 0.0010\n",
      "Epoch 377/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1345 - accuracy: 0.9517 - val_loss: 0.2776 - val_accuracy: 0.8987 - lr: 0.0010\n",
      "Epoch 378/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1246 - accuracy: 0.9592 - val_loss: 0.2147 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 379/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1470 - accuracy: 0.9517 - val_loss: 0.1865 - val_accuracy: 0.9325 - lr: 0.0010\n",
      "Epoch 380/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1266 - accuracy: 0.9575 - val_loss: 0.2819 - val_accuracy: 0.8980 - lr: 0.0010\n",
      "Epoch 381/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1469 - accuracy: 0.9473 - val_loss: 0.1793 - val_accuracy: 0.9490 - lr: 0.0010\n",
      "Epoch 382/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1408 - accuracy: 0.9563 - val_loss: 0.1987 - val_accuracy: 0.9300 - lr: 0.0010\n",
      "Epoch 383/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1442 - accuracy: 0.9517 - val_loss: 0.2586 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Epoch 384/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1927 - accuracy: 0.9335 - val_loss: 0.3697 - val_accuracy: 0.8644 - lr: 0.0010\n",
      "Epoch 385/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1426 - accuracy: 0.9498 - val_loss: 0.2392 - val_accuracy: 0.9166 - lr: 0.0010\n",
      "Epoch 386/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1703 - accuracy: 0.9448 - val_loss: 0.1689 - val_accuracy: 0.9385 - lr: 0.0010\n",
      "Epoch 387/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1599 - accuracy: 0.9475 - val_loss: 0.2461 - val_accuracy: 0.9044 - lr: 0.0010\n",
      "Epoch 388/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1647 - accuracy: 0.9445 - val_loss: 0.1291 - val_accuracy: 0.9602 - lr: 0.0010\n",
      "Epoch 389/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1511 - accuracy: 0.9555 - val_loss: 0.2879 - val_accuracy: 0.8923 - lr: 0.0010\n",
      "Epoch 390/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1707 - accuracy: 0.9452 - val_loss: 0.2895 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Epoch 391/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1656 - accuracy: 0.9415 - val_loss: 0.1875 - val_accuracy: 0.9359 - lr: 0.0010\n",
      "Epoch 392/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1426 - accuracy: 0.9513 - val_loss: 0.2124 - val_accuracy: 0.9206 - lr: 0.0010\n",
      "Epoch 393/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1651 - accuracy: 0.9470 - val_loss: 0.2377 - val_accuracy: 0.9126 - lr: 0.0010\n",
      "Epoch 394/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1804 - accuracy: 0.9385 - val_loss: 0.2282 - val_accuracy: 0.9121 - lr: 0.0010\n",
      "Epoch 395/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1661 - accuracy: 0.9423 - val_loss: 0.1460 - val_accuracy: 0.9618 - lr: 0.0010\n",
      "Epoch 396/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1207 - accuracy: 0.9603 - val_loss: 0.2894 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Epoch 397/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1243 - accuracy: 0.9600 - val_loss: 0.1394 - val_accuracy: 0.9571 - lr: 0.0010\n",
      "Epoch 398/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2012 - accuracy: 0.9370 - val_loss: 0.2448 - val_accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 399/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1438 - accuracy: 0.9507 - val_loss: 0.5663 - val_accuracy: 0.8013 - lr: 0.0010\n",
      "Epoch 400/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1382 - accuracy: 0.9525 - val_loss: 0.1672 - val_accuracy: 0.9438 - lr: 0.0010\n",
      "Epoch 401/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1412 - accuracy: 0.9535 - val_loss: 0.2565 - val_accuracy: 0.9073 - lr: 0.0010\n",
      "Epoch 402/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1884 - accuracy: 0.9362 - val_loss: 0.1362 - val_accuracy: 0.9563 - lr: 0.0010\n",
      "Epoch 403/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1343 - accuracy: 0.9548 - val_loss: 0.1845 - val_accuracy: 0.9339 - lr: 0.0010\n",
      "Epoch 404/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1477 - accuracy: 0.9532 - val_loss: 0.1607 - val_accuracy: 0.9406 - lr: 0.0010\n",
      "Epoch 405/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1996 - accuracy: 0.9337 - val_loss: 0.3632 - val_accuracy: 0.8644 - lr: 0.0010\n",
      "Epoch 406/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1478 - accuracy: 0.9470 - val_loss: 0.1817 - val_accuracy: 0.9378 - lr: 0.0010\n",
      "Epoch 407/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1864 - accuracy: 0.9445 - val_loss: 0.2482 - val_accuracy: 0.9063 - lr: 0.0010\n",
      "Epoch 408/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1410 - accuracy: 0.9463 - val_loss: 0.1553 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 409/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1601 - accuracy: 0.9467 - val_loss: 0.1510 - val_accuracy: 0.9620 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 410/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1074 - accuracy: 0.9672 - val_loss: 0.4813 - val_accuracy: 0.8295 - lr: 0.0010\n",
      "Epoch 411/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1651 - accuracy: 0.9503 - val_loss: 0.1552 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 412/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2053 - accuracy: 0.9350 - val_loss: 0.2985 - val_accuracy: 0.8845 - lr: 0.0010\n",
      "Epoch 413/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1475 - accuracy: 0.9510 - val_loss: 0.2098 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 414/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1530 - accuracy: 0.9505 - val_loss: 0.4232 - val_accuracy: 0.8430 - lr: 0.0010\n",
      "Epoch 415/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1682 - accuracy: 0.9433 - val_loss: 0.2182 - val_accuracy: 0.9160 - lr: 0.0010\n",
      "Epoch 416/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1904 - accuracy: 0.9333 - val_loss: 0.1287 - val_accuracy: 0.9624 - lr: 0.0010\n",
      "Epoch 417/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1650 - accuracy: 0.9517 - val_loss: 0.1834 - val_accuracy: 0.9352 - lr: 0.0010\n",
      "Epoch 418/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1588 - accuracy: 0.9480 - val_loss: 0.1476 - val_accuracy: 0.9506 - lr: 0.0010\n",
      "Epoch 419/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1580 - accuracy: 0.9463 - val_loss: 0.1351 - val_accuracy: 0.9515 - lr: 0.0010\n",
      "Epoch 420/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1694 - accuracy: 0.9450 - val_loss: 0.1802 - val_accuracy: 0.9359 - lr: 0.0010\n",
      "Epoch 421/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1652 - accuracy: 0.9460 - val_loss: 0.2863 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Epoch 422/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2098 - accuracy: 0.9337 - val_loss: 0.3130 - val_accuracy: 0.8839 - lr: 0.0010\n",
      "Epoch 423/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1939 - accuracy: 0.9380 - val_loss: 0.2737 - val_accuracy: 0.8962 - lr: 0.0010\n",
      "Epoch 424/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1596 - accuracy: 0.9492 - val_loss: 0.1993 - val_accuracy: 0.9237 - lr: 0.0010\n",
      "Epoch 425/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1894 - accuracy: 0.9433 - val_loss: 0.2493 - val_accuracy: 0.9072 - lr: 0.0010\n",
      "Epoch 426/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1714 - accuracy: 0.9410 - val_loss: 0.1534 - val_accuracy: 0.9478 - lr: 0.0010\n",
      "Epoch 427/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1877 - accuracy: 0.9377 - val_loss: 0.1522 - val_accuracy: 0.9570 - lr: 0.0010\n",
      "Epoch 428/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2236 - accuracy: 0.9348 - val_loss: 0.1932 - val_accuracy: 0.9229 - lr: 0.0010\n",
      "Epoch 429/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2059 - accuracy: 0.9333 - val_loss: 0.2061 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 430/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2224 - accuracy: 0.9237 - val_loss: 0.1693 - val_accuracy: 0.9414 - lr: 0.0010\n",
      "Epoch 431/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1632 - accuracy: 0.9452 - val_loss: 0.3845 - val_accuracy: 0.8514 - lr: 0.0010\n",
      "Epoch 432/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1541 - accuracy: 0.9532 - val_loss: 0.3776 - val_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 433/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2069 - accuracy: 0.9355 - val_loss: 0.2331 - val_accuracy: 0.9106 - lr: 0.0010\n",
      "Epoch 434/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2074 - accuracy: 0.9298 - val_loss: 0.1628 - val_accuracy: 0.9426 - lr: 0.0010\n",
      "Epoch 435/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1450 - accuracy: 0.9565 - val_loss: 0.1717 - val_accuracy: 0.9352 - lr: 0.0010\n",
      "Epoch 436/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2106 - accuracy: 0.9337 - val_loss: 0.4064 - val_accuracy: 0.8435 - lr: 0.0010\n",
      "Epoch 437/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2212 - accuracy: 0.9262 - val_loss: 0.2883 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Epoch 438/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1819 - accuracy: 0.9415 - val_loss: 0.3592 - val_accuracy: 0.8643 - lr: 0.0010\n",
      "Epoch 439/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2007 - accuracy: 0.9340 - val_loss: 0.3840 - val_accuracy: 0.8509 - lr: 0.0010\n",
      "Epoch 440/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2214 - accuracy: 0.9280 - val_loss: 0.3990 - val_accuracy: 0.8392 - lr: 0.0010\n",
      "Epoch 441/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2238 - accuracy: 0.9218 - val_loss: 0.1709 - val_accuracy: 0.9468 - lr: 0.0010\n",
      "Epoch 442/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1955 - accuracy: 0.9398 - val_loss: 0.1695 - val_accuracy: 0.9365 - lr: 0.0010\n",
      "Epoch 443/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2065 - accuracy: 0.9383 - val_loss: 0.2558 - val_accuracy: 0.9132 - lr: 0.0010\n",
      "Epoch 444/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2313 - accuracy: 0.9193 - val_loss: 0.3328 - val_accuracy: 0.8647 - lr: 0.0010\n",
      "Epoch 445/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1745 - accuracy: 0.9442 - val_loss: 0.3412 - val_accuracy: 0.8646 - lr: 0.0010\n",
      "Epoch 446/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2273 - accuracy: 0.9298 - val_loss: 0.2589 - val_accuracy: 0.8969 - lr: 0.0010\n",
      "Epoch 447/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1989 - accuracy: 0.9325 - val_loss: 0.2204 - val_accuracy: 0.9145 - lr: 0.0010\n",
      "Epoch 448/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2057 - accuracy: 0.9320 - val_loss: 0.2103 - val_accuracy: 0.9505 - lr: 0.0010\n",
      "Epoch 449/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1824 - accuracy: 0.9410 - val_loss: 0.2605 - val_accuracy: 0.8989 - lr: 0.0010\n",
      "Epoch 450/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2394 - accuracy: 0.9270 - val_loss: 0.2534 - val_accuracy: 0.9035 - lr: 0.0010\n",
      "Epoch 451/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2406 - accuracy: 0.9180 - val_loss: 0.2651 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 452/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1662 - accuracy: 0.9408 - val_loss: 0.1897 - val_accuracy: 0.9414 - lr: 0.0010\n",
      "Epoch 453/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2353 - accuracy: 0.9330 - val_loss: 0.2023 - val_accuracy: 0.9225 - lr: 0.0010\n",
      "Epoch 454/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2573 - accuracy: 0.9187 - val_loss: 0.4086 - val_accuracy: 0.8170 - lr: 0.0010\n",
      "Epoch 455/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3031 - accuracy: 0.8960 - val_loss: 0.2392 - val_accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 456/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1838 - accuracy: 0.9448 - val_loss: 0.3428 - val_accuracy: 0.8612 - lr: 0.0010\n",
      "Epoch 457/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1918 - accuracy: 0.9380 - val_loss: 0.2480 - val_accuracy: 0.9150 - lr: 0.0010\n",
      "Epoch 458/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3225 - accuracy: 0.8960 - val_loss: 0.4159 - val_accuracy: 0.8264 - lr: 0.0010\n",
      "Epoch 459/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2301 - accuracy: 0.9275 - val_loss: 0.3850 - val_accuracy: 0.8439 - lr: 0.0010\n",
      "Epoch 460/625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2042 - accuracy: 0.9385 - val_loss: 0.1728 - val_accuracy: 0.9396 - lr: 0.0010\n",
      "Epoch 461/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2215 - accuracy: 0.9265 - val_loss: 0.3251 - val_accuracy: 0.8625 - lr: 0.0010\n",
      "Epoch 462/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3367 - accuracy: 0.8938 - val_loss: 0.2821 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Epoch 463/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2324 - accuracy: 0.9243 - val_loss: 0.2937 - val_accuracy: 0.8757 - lr: 0.0010\n",
      "Epoch 464/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2453 - accuracy: 0.9265 - val_loss: 0.2215 - val_accuracy: 0.9314 - lr: 0.0010\n",
      "Epoch 465/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2428 - accuracy: 0.9185 - val_loss: 0.2054 - val_accuracy: 0.9172 - lr: 0.0010\n",
      "Epoch 466/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2587 - accuracy: 0.9168 - val_loss: 0.4749 - val_accuracy: 0.8014 - lr: 0.0010\n",
      "Epoch 467/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2474 - accuracy: 0.9210 - val_loss: 0.3785 - val_accuracy: 0.8419 - lr: 0.0010\n",
      "Epoch 468/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2426 - accuracy: 0.9220 - val_loss: 0.6169 - val_accuracy: 0.8965 - lr: 0.0010\n",
      "Epoch 469/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4112 - accuracy: 0.8608 - val_loss: 0.3780 - val_accuracy: 0.9275 - lr: 0.0010\n",
      "Epoch 470/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2516 - accuracy: 0.9202 - val_loss: 0.3923 - val_accuracy: 0.8342 - lr: 0.0010\n",
      "Epoch 471/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2848 - accuracy: 0.9085 - val_loss: 0.3633 - val_accuracy: 0.8491 - lr: 0.0010\n",
      "Epoch 472/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3353 - accuracy: 0.8802 - val_loss: 0.5091 - val_accuracy: 0.7592 - lr: 0.0010\n",
      "Epoch 473/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3073 - accuracy: 0.8967 - val_loss: 0.3177 - val_accuracy: 0.8648 - lr: 0.0010\n",
      "Epoch 474/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2562 - accuracy: 0.9215 - val_loss: 0.5117 - val_accuracy: 0.7793 - lr: 0.0010\n",
      "Epoch 475/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2727 - accuracy: 0.9080 - val_loss: 0.2702 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Epoch 476/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2804 - accuracy: 0.9062 - val_loss: 0.1759 - val_accuracy: 0.9378 - lr: 0.0010\n",
      "Epoch 477/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2322 - accuracy: 0.9240 - val_loss: 0.3925 - val_accuracy: 0.8375 - lr: 0.0010\n",
      "Epoch 478/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2584 - accuracy: 0.9195 - val_loss: 0.3173 - val_accuracy: 0.9004 - lr: 0.0010\n",
      "Epoch 479/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3529 - accuracy: 0.8852 - val_loss: 0.2624 - val_accuracy: 0.8958 - lr: 0.0010\n",
      "Epoch 480/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3818 - accuracy: 0.8823 - val_loss: 0.3205 - val_accuracy: 0.8709 - lr: 0.0010\n",
      "Epoch 481/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3774 - accuracy: 0.8800 - val_loss: 0.4867 - val_accuracy: 0.7699 - lr: 0.0010\n",
      "Epoch 482/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3656 - accuracy: 0.8725 - val_loss: 0.2753 - val_accuracy: 0.8948 - lr: 0.0010\n",
      "Epoch 483/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3418 - accuracy: 0.8775 - val_loss: 0.3076 - val_accuracy: 0.8678 - lr: 0.0010\n",
      "Epoch 484/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3157 - accuracy: 0.8985 - val_loss: 0.2973 - val_accuracy: 0.8860 - lr: 0.0010\n",
      "Epoch 485/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2855 - accuracy: 0.9057 - val_loss: 0.2895 - val_accuracy: 0.8848 - lr: 0.0010\n",
      "Epoch 486/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4622 - accuracy: 0.8428 - val_loss: 0.7660 - val_accuracy: 0.5751 - lr: 0.0010\n",
      "Epoch 487/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4528 - accuracy: 0.8245 - val_loss: 0.3501 - val_accuracy: 0.8619 - lr: 0.0010\n",
      "Epoch 488/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3637 - accuracy: 0.8825 - val_loss: 0.4359 - val_accuracy: 0.7992 - lr: 0.0010\n",
      "Epoch 489/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3665 - accuracy: 0.8675 - val_loss: 0.4972 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 490/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3816 - accuracy: 0.8650 - val_loss: 0.3824 - val_accuracy: 0.8252 - lr: 0.0010\n",
      "Epoch 491/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3544 - accuracy: 0.8813 - val_loss: 0.2810 - val_accuracy: 0.8934 - lr: 0.0010\n",
      "Epoch 492/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4254 - accuracy: 0.8717 - val_loss: 0.5016 - val_accuracy: 0.7647 - lr: 0.0010\n",
      "Epoch 493/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4158 - accuracy: 0.8292 - val_loss: 0.3811 - val_accuracy: 0.8244 - lr: 0.0010\n",
      "Epoch 494/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3692 - accuracy: 0.8680 - val_loss: 0.3453 - val_accuracy: 0.8560 - lr: 0.0010\n",
      "Epoch 495/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3414 - accuracy: 0.8827 - val_loss: 0.2752 - val_accuracy: 0.8904 - lr: 0.0010\n",
      "Epoch 496/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4661 - accuracy: 0.8472 - val_loss: 0.5112 - val_accuracy: 0.7448 - lr: 0.0010\n",
      "Epoch 497/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4093 - accuracy: 0.8430 - val_loss: 0.4927 - val_accuracy: 0.8621 - lr: 0.0010\n",
      "Epoch 498/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3421 - accuracy: 0.8840 - val_loss: 0.5659 - val_accuracy: 0.7262 - lr: 0.0010\n",
      "Epoch 499/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4912 - accuracy: 0.8207 - val_loss: 0.5883 - val_accuracy: 0.6894 - lr: 0.0010\n",
      "Epoch 500/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4382 - accuracy: 0.8438 - val_loss: 0.4976 - val_accuracy: 0.7475 - lr: 0.0010\n",
      "Epoch 501/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4151 - accuracy: 0.8240 - val_loss: 0.3295 - val_accuracy: 0.8603 - lr: 1.0000e-04\n",
      "Epoch 502/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3305 - accuracy: 0.8895 - val_loss: 0.3307 - val_accuracy: 0.8556 - lr: 1.0000e-04\n",
      "Epoch 503/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3171 - accuracy: 0.8842 - val_loss: 0.2986 - val_accuracy: 0.8773 - lr: 1.0000e-04\n",
      "Epoch 504/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3220 - accuracy: 0.8888 - val_loss: 0.3440 - val_accuracy: 0.8467 - lr: 1.0000e-04\n",
      "Epoch 505/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2883 - accuracy: 0.8915 - val_loss: 0.2529 - val_accuracy: 0.9032 - lr: 1.0000e-04\n",
      "Epoch 506/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2520 - accuracy: 0.9202 - val_loss: 0.2686 - val_accuracy: 0.8896 - lr: 1.0000e-04\n",
      "Epoch 507/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2370 - accuracy: 0.9208 - val_loss: 0.2777 - val_accuracy: 0.8854 - lr: 1.0000e-04\n",
      "Epoch 508/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2630 - accuracy: 0.9065 - val_loss: 0.2209 - val_accuracy: 0.9198 - lr: 1.0000e-04\n",
      "Epoch 509/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2291 - accuracy: 0.9330 - val_loss: 0.2719 - val_accuracy: 0.8861 - lr: 1.0000e-04\n",
      "Epoch 510/625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2230 - accuracy: 0.9240 - val_loss: 0.2388 - val_accuracy: 0.9046 - lr: 1.0000e-04\n",
      "Epoch 511/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2232 - accuracy: 0.9265 - val_loss: 0.2191 - val_accuracy: 0.9147 - lr: 1.0000e-04\n",
      "Epoch 512/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2096 - accuracy: 0.9308 - val_loss: 0.1987 - val_accuracy: 0.9282 - lr: 1.0000e-04\n",
      "Epoch 513/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2100 - accuracy: 0.9377 - val_loss: 0.2227 - val_accuracy: 0.9107 - lr: 1.0000e-04\n",
      "Epoch 514/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1928 - accuracy: 0.9340 - val_loss: 0.2169 - val_accuracy: 0.9152 - lr: 1.0000e-04\n",
      "Epoch 515/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2378 - accuracy: 0.9233 - val_loss: 0.2005 - val_accuracy: 0.9235 - lr: 1.0000e-04\n",
      "Epoch 516/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1752 - accuracy: 0.9467 - val_loss: 0.2389 - val_accuracy: 0.9007 - lr: 1.0000e-04\n",
      "Epoch 517/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1785 - accuracy: 0.9410 - val_loss: 0.1949 - val_accuracy: 0.9258 - lr: 1.0000e-04\n",
      "Epoch 518/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2116 - accuracy: 0.9290 - val_loss: 0.2046 - val_accuracy: 0.9202 - lr: 1.0000e-04\n",
      "Epoch 519/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1670 - accuracy: 0.9477 - val_loss: 0.1866 - val_accuracy: 0.9295 - lr: 1.0000e-04\n",
      "Epoch 520/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1585 - accuracy: 0.9492 - val_loss: 0.1785 - val_accuracy: 0.9336 - lr: 1.0000e-04\n",
      "Epoch 521/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1721 - accuracy: 0.9467 - val_loss: 0.1898 - val_accuracy: 0.9283 - lr: 1.0000e-04\n",
      "Epoch 522/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2087 - accuracy: 0.9300 - val_loss: 0.1492 - val_accuracy: 0.9472 - lr: 1.0000e-04\n",
      "Epoch 523/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1550 - accuracy: 0.9595 - val_loss: 0.1978 - val_accuracy: 0.9215 - lr: 1.0000e-04\n",
      "Epoch 524/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1617 - accuracy: 0.9488 - val_loss: 0.1501 - val_accuracy: 0.9462 - lr: 1.0000e-04\n",
      "Epoch 525/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1709 - accuracy: 0.9442 - val_loss: 0.1834 - val_accuracy: 0.9285 - lr: 1.0000e-04\n",
      "Epoch 526/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1630 - accuracy: 0.9482 - val_loss: 0.1703 - val_accuracy: 0.9359 - lr: 1.0000e-04\n",
      "Epoch 527/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1529 - accuracy: 0.9523 - val_loss: 0.1919 - val_accuracy: 0.9250 - lr: 1.0000e-04\n",
      "Epoch 528/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1496 - accuracy: 0.9473 - val_loss: 0.1538 - val_accuracy: 0.9436 - lr: 1.0000e-04\n",
      "Epoch 529/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1820 - accuracy: 0.9408 - val_loss: 0.1308 - val_accuracy: 0.9549 - lr: 1.0000e-04\n",
      "Epoch 530/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1216 - accuracy: 0.9625 - val_loss: 0.1665 - val_accuracy: 0.9359 - lr: 1.0000e-04\n",
      "Epoch 531/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1415 - accuracy: 0.9540 - val_loss: 0.1412 - val_accuracy: 0.9490 - lr: 1.0000e-04\n",
      "Epoch 532/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1443 - accuracy: 0.9490 - val_loss: 0.1491 - val_accuracy: 0.9445 - lr: 1.0000e-04\n",
      "Epoch 533/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1388 - accuracy: 0.9528 - val_loss: 0.1271 - val_accuracy: 0.9544 - lr: 1.0000e-04\n",
      "Epoch 534/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1238 - accuracy: 0.9640 - val_loss: 0.1631 - val_accuracy: 0.9373 - lr: 1.0000e-04\n",
      "Epoch 535/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1251 - accuracy: 0.9585 - val_loss: 0.1422 - val_accuracy: 0.9475 - lr: 1.0000e-04\n",
      "Epoch 536/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1569 - accuracy: 0.9480 - val_loss: 0.1420 - val_accuracy: 0.9469 - lr: 1.0000e-04\n",
      "Epoch 537/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1085 - accuracy: 0.9672 - val_loss: 0.1413 - val_accuracy: 0.9478 - lr: 1.0000e-04\n",
      "Epoch 538/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1433 - accuracy: 0.9595 - val_loss: 0.1436 - val_accuracy: 0.9457 - lr: 1.0000e-04\n",
      "Epoch 539/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1269 - accuracy: 0.9592 - val_loss: 0.1428 - val_accuracy: 0.9473 - lr: 1.0000e-04\n",
      "Epoch 540/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1321 - accuracy: 0.9567 - val_loss: 0.1096 - val_accuracy: 0.9628 - lr: 1.0000e-04\n",
      "Epoch 541/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1298 - accuracy: 0.9595 - val_loss: 0.1396 - val_accuracy: 0.9478 - lr: 1.0000e-04\n",
      "Epoch 542/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1373 - accuracy: 0.9540 - val_loss: 0.1503 - val_accuracy: 0.9439 - lr: 1.0000e-04\n",
      "Epoch 543/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1395 - accuracy: 0.9545 - val_loss: 0.1483 - val_accuracy: 0.9439 - lr: 1.0000e-04\n",
      "Epoch 544/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1138 - accuracy: 0.9617 - val_loss: 0.1340 - val_accuracy: 0.9498 - lr: 1.0000e-04\n",
      "Epoch 545/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1133 - accuracy: 0.9640 - val_loss: 0.1398 - val_accuracy: 0.9478 - lr: 1.0000e-04\n",
      "Epoch 546/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1247 - accuracy: 0.9588 - val_loss: 0.1284 - val_accuracy: 0.9529 - lr: 1.0000e-04\n",
      "Epoch 547/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1188 - accuracy: 0.9620 - val_loss: 0.0926 - val_accuracy: 0.9702 - lr: 1.0000e-04\n",
      "Epoch 548/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0968 - accuracy: 0.9703 - val_loss: 0.1287 - val_accuracy: 0.9519 - lr: 1.0000e-04\n",
      "Epoch 549/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1074 - accuracy: 0.9665 - val_loss: 0.1361 - val_accuracy: 0.9488 - lr: 1.0000e-04\n",
      "Epoch 550/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1209 - accuracy: 0.9590 - val_loss: 0.1334 - val_accuracy: 0.9499 - lr: 1.0000e-04\n",
      "Epoch 551/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1056 - accuracy: 0.9678 - val_loss: 0.1202 - val_accuracy: 0.9559 - lr: 1.0000e-04\n",
      "Epoch 552/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0914 - accuracy: 0.9720 - val_loss: 0.1154 - val_accuracy: 0.9588 - lr: 1.0000e-04\n",
      "Epoch 553/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1113 - accuracy: 0.9640 - val_loss: 0.1282 - val_accuracy: 0.9525 - lr: 1.0000e-04\n",
      "Epoch 554/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1365 - accuracy: 0.9600 - val_loss: 0.0850 - val_accuracy: 0.9729 - lr: 1.0000e-04\n",
      "Epoch 555/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0949 - accuracy: 0.9720 - val_loss: 0.1234 - val_accuracy: 0.9544 - lr: 1.0000e-04\n",
      "Epoch 556/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1035 - accuracy: 0.9643 - val_loss: 0.1029 - val_accuracy: 0.9639 - lr: 1.0000e-04\n",
      "Epoch 557/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1216 - accuracy: 0.9622 - val_loss: 0.1289 - val_accuracy: 0.9518 - lr: 1.0000e-04\n",
      "Epoch 558/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0950 - accuracy: 0.9700 - val_loss: 0.1050 - val_accuracy: 0.9627 - lr: 1.0000e-04\n",
      "Epoch 559/625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0941 - accuracy: 0.9753 - val_loss: 0.1357 - val_accuracy: 0.9481 - lr: 1.0000e-04\n",
      "Epoch 560/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1000 - accuracy: 0.9678 - val_loss: 0.1135 - val_accuracy: 0.9588 - lr: 1.0000e-04\n",
      "Epoch 561/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1074 - accuracy: 0.9630 - val_loss: 0.0854 - val_accuracy: 0.9716 - lr: 1.0000e-04\n",
      "Epoch 562/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0984 - accuracy: 0.9718 - val_loss: 0.1285 - val_accuracy: 0.9514 - lr: 1.0000e-04\n",
      "Epoch 563/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1043 - accuracy: 0.9685 - val_loss: 0.0950 - val_accuracy: 0.9670 - lr: 1.0000e-04\n",
      "Epoch 564/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1040 - accuracy: 0.9670 - val_loss: 0.1385 - val_accuracy: 0.9461 - lr: 1.0000e-04\n",
      "Epoch 565/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0830 - accuracy: 0.9725 - val_loss: 0.0795 - val_accuracy: 0.9743 - lr: 1.0000e-04\n",
      "Epoch 566/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1009 - accuracy: 0.9710 - val_loss: 0.1191 - val_accuracy: 0.9549 - lr: 1.0000e-04\n",
      "Epoch 567/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0962 - accuracy: 0.9695 - val_loss: 0.1279 - val_accuracy: 0.9519 - lr: 1.0000e-04\n",
      "Epoch 568/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1134 - accuracy: 0.9647 - val_loss: 0.0726 - val_accuracy: 0.9768 - lr: 1.0000e-04\n",
      "Epoch 569/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0753 - accuracy: 0.9805 - val_loss: 0.1160 - val_accuracy: 0.9572 - lr: 1.0000e-04\n",
      "Epoch 570/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0933 - accuracy: 0.9712 - val_loss: 0.0881 - val_accuracy: 0.9697 - lr: 1.0000e-04\n",
      "Epoch 571/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1026 - accuracy: 0.9678 - val_loss: 0.1054 - val_accuracy: 0.9614 - lr: 1.0000e-04\n",
      "Epoch 572/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0854 - accuracy: 0.9728 - val_loss: 0.0882 - val_accuracy: 0.9687 - lr: 1.0000e-04\n",
      "Epoch 573/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0807 - accuracy: 0.9778 - val_loss: 0.1030 - val_accuracy: 0.9621 - lr: 1.0000e-04\n",
      "Epoch 574/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0859 - accuracy: 0.9732 - val_loss: 0.0964 - val_accuracy: 0.9649 - lr: 1.0000e-04\n",
      "Epoch 575/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1077 - accuracy: 0.9688 - val_loss: 0.0777 - val_accuracy: 0.9740 - lr: 1.0000e-04\n",
      "Epoch 576/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0681 - accuracy: 0.9822 - val_loss: 0.1275 - val_accuracy: 0.9510 - lr: 1.0000e-04\n",
      "Epoch 577/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0779 - accuracy: 0.9765 - val_loss: 0.0779 - val_accuracy: 0.9738 - lr: 1.0000e-04\n",
      "Epoch 578/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0994 - accuracy: 0.9663 - val_loss: 0.0874 - val_accuracy: 0.9690 - lr: 1.0000e-04\n",
      "Epoch 579/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0859 - accuracy: 0.9755 - val_loss: 0.0783 - val_accuracy: 0.9734 - lr: 1.0000e-04\n",
      "Epoch 580/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0779 - accuracy: 0.9775 - val_loss: 0.0953 - val_accuracy: 0.9658 - lr: 1.0000e-04\n",
      "Epoch 581/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0725 - accuracy: 0.9768 - val_loss: 0.0888 - val_accuracy: 0.9695 - lr: 1.0000e-04\n",
      "Epoch 582/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0942 - accuracy: 0.9665 - val_loss: 0.0752 - val_accuracy: 0.9750 - lr: 1.0000e-04\n",
      "Epoch 583/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0710 - accuracy: 0.9818 - val_loss: 0.1368 - val_accuracy: 0.9467 - lr: 1.0000e-04\n",
      "Epoch 584/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0864 - accuracy: 0.9750 - val_loss: 0.0862 - val_accuracy: 0.9690 - lr: 1.0000e-04\n",
      "Epoch 585/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0868 - accuracy: 0.9718 - val_loss: 0.0881 - val_accuracy: 0.9690 - lr: 1.0000e-04\n",
      "Epoch 586/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0780 - accuracy: 0.9765 - val_loss: 0.0778 - val_accuracy: 0.9728 - lr: 1.0000e-04\n",
      "Epoch 587/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0661 - accuracy: 0.9805 - val_loss: 0.0850 - val_accuracy: 0.9699 - lr: 1.0000e-04\n",
      "Epoch 588/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0769 - accuracy: 0.9745 - val_loss: 0.0732 - val_accuracy: 0.9748 - lr: 1.0000e-04\n",
      "Epoch 589/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0900 - accuracy: 0.9735 - val_loss: 0.0667 - val_accuracy: 0.9785 - lr: 1.0000e-04\n",
      "Epoch 590/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0547 - accuracy: 0.9843 - val_loss: 0.1009 - val_accuracy: 0.9634 - lr: 1.0000e-04\n",
      "Epoch 591/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0679 - accuracy: 0.9810 - val_loss: 0.0858 - val_accuracy: 0.9692 - lr: 1.0000e-04\n",
      "Epoch 592/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0834 - accuracy: 0.9732 - val_loss: 0.0849 - val_accuracy: 0.9697 - lr: 1.0000e-04\n",
      "Epoch 593/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0749 - accuracy: 0.9758 - val_loss: 0.0582 - val_accuracy: 0.9818 - lr: 1.0000e-04\n",
      "Epoch 594/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0671 - accuracy: 0.9812 - val_loss: 0.0880 - val_accuracy: 0.9685 - lr: 1.0000e-04\n",
      "Epoch 595/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0613 - accuracy: 0.9810 - val_loss: 0.0719 - val_accuracy: 0.9758 - lr: 1.0000e-04\n",
      "Epoch 596/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0916 - accuracy: 0.9720 - val_loss: 0.0736 - val_accuracy: 0.9750 - lr: 1.0000e-04\n",
      "Epoch 597/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0490 - accuracy: 0.9870 - val_loss: 0.0957 - val_accuracy: 0.9653 - lr: 1.0000e-04\n",
      "Epoch 598/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0682 - accuracy: 0.9790 - val_loss: 0.0712 - val_accuracy: 0.9756 - lr: 1.0000e-04\n",
      "Epoch 599/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0778 - accuracy: 0.9765 - val_loss: 0.0788 - val_accuracy: 0.9721 - lr: 1.0000e-04\n",
      "Epoch 600/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0747 - accuracy: 0.9783 - val_loss: 0.0551 - val_accuracy: 0.9836 - lr: 1.0000e-04\n",
      "Epoch 601/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0563 - accuracy: 0.9825 - val_loss: 0.0823 - val_accuracy: 0.9721 - lr: 1.0000e-04\n",
      "Epoch 602/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0597 - accuracy: 0.9820 - val_loss: 0.0657 - val_accuracy: 0.9791 - lr: 1.0000e-04\n",
      "Epoch 603/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0790 - accuracy: 0.9780 - val_loss: 0.0968 - val_accuracy: 0.9647 - lr: 1.0000e-04\n",
      "Epoch 604/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0561 - accuracy: 0.9833 - val_loss: 0.0737 - val_accuracy: 0.9751 - lr: 1.0000e-04\n",
      "Epoch 605/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0712 - accuracy: 0.9793 - val_loss: 0.0806 - val_accuracy: 0.9720 - lr: 1.0000e-04\n",
      "Epoch 606/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0740 - accuracy: 0.9770 - val_loss: 0.0787 - val_accuracy: 0.9731 - lr: 1.0000e-04\n",
      "Epoch 607/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0661 - accuracy: 0.9790 - val_loss: 0.0494 - val_accuracy: 0.9852 - lr: 1.0000e-04\n",
      "Epoch 608/625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0485 - accuracy: 0.9868 - val_loss: 0.0718 - val_accuracy: 0.9756 - lr: 1.0000e-04\n",
      "Epoch 609/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0574 - accuracy: 0.9820 - val_loss: 0.0699 - val_accuracy: 0.9758 - lr: 1.0000e-04\n",
      "Epoch 610/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0801 - accuracy: 0.9737 - val_loss: 0.0685 - val_accuracy: 0.9773 - lr: 1.0000e-04\n",
      "Epoch 611/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0549 - accuracy: 0.9825 - val_loss: 0.0571 - val_accuracy: 0.9814 - lr: 1.0000e-04\n",
      "Epoch 612/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0545 - accuracy: 0.9840 - val_loss: 0.0786 - val_accuracy: 0.9726 - lr: 1.0000e-04\n",
      "Epoch 613/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0650 - accuracy: 0.9797 - val_loss: 0.0600 - val_accuracy: 0.9811 - lr: 1.0000e-04\n",
      "Epoch 614/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0569 - accuracy: 0.9822 - val_loss: 0.0511 - val_accuracy: 0.9838 - lr: 1.0000e-04\n",
      "Epoch 615/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0459 - accuracy: 0.9887 - val_loss: 0.0719 - val_accuracy: 0.9757 - lr: 1.0000e-04\n",
      "Epoch 616/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0593 - accuracy: 0.9818 - val_loss: 0.0727 - val_accuracy: 0.9753 - lr: 1.0000e-04\n",
      "Epoch 617/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0559 - accuracy: 0.9833 - val_loss: 0.0686 - val_accuracy: 0.9763 - lr: 1.0000e-04\n",
      "Epoch 618/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0535 - accuracy: 0.9830 - val_loss: 0.0533 - val_accuracy: 0.9833 - lr: 1.0000e-04\n",
      "Epoch 619/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0542 - accuracy: 0.9840 - val_loss: 0.0777 - val_accuracy: 0.9726 - lr: 1.0000e-04\n",
      "Epoch 620/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0619 - accuracy: 0.9795 - val_loss: 0.0582 - val_accuracy: 0.9807 - lr: 1.0000e-04\n",
      "Epoch 621/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0603 - accuracy: 0.9812 - val_loss: 0.0424 - val_accuracy: 0.9870 - lr: 1.0000e-04\n",
      "Epoch 622/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0487 - accuracy: 0.9862 - val_loss: 0.0826 - val_accuracy: 0.9700 - lr: 1.0000e-04\n",
      "Epoch 623/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0682 - accuracy: 0.9815 - val_loss: 0.0806 - val_accuracy: 0.9707 - lr: 1.0000e-04\n",
      "Epoch 624/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0572 - accuracy: 0.9795 - val_loss: 0.0627 - val_accuracy: 0.9782 - lr: 1.0000e-04\n",
      "Epoch 625/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0436 - accuracy: 0.9865 - val_loss: 0.0489 - val_accuracy: 0.9847 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 02:48:11.928649: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-09 02:48:11.928670: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-09 02:48:12.305850: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-09 02:48:12.308911: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 9s 2ms/step - loss: 0.7111 - accuracy: 0.4768\n",
      "Epoch 1/625\n",
      "   1/1000 [..............................] - ETA: 6:05 - loss: 0.7005 - accuracy: 0.2500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 02:48:21.736252: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-09 02:48:21.736279: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "   2/1000 [..............................] - ETA: 6:38 - loss: 0.6056 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 02:48:22.219694: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-09 02:48:22.221442: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-11-09 02:48:22.289358: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 1644 callback api events and 1619 activity events. \n",
      "2022-11-09 02:48:22.319122: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-09 02:48:22.345847: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/CNN_5/log_1/plugins/profile/2022_11_09_02_48_22\n",
      "\n",
      "2022-11-09 02:48:22.373826: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/CNN_5/log_1/plugins/profile/2022_11_09_02_48_22/rachanon-pc1.trace.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  37/1000 [>.............................] - ETA: 23s - loss: 0.8806 - accuracy: 0.5743"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 02:48:22.431508: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/CNN_5/log_1/plugins/profile/2022_11_09_02_48_22\n",
      "\n",
      "2022-11-09 02:48:22.438271: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/CNN_5/log_1/plugins/profile/2022_11_09_02_48_22/rachanon-pc1.memory_profile.json.gz\n",
      "2022-11-09 02:48:22.439695: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/CNN_5/log_1/plugins/profile/2022_11_09_02_48_22\n",
      "Dumped tool data for xplane.pb to log/CNN_5/log_1/plugins/profile/2022_11_09_02_48_22/rachanon-pc1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/CNN_5/log_1/plugins/profile/2022_11_09_02_48_22/rachanon-pc1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/CNN_5/log_1/plugins/profile/2022_11_09_02_48_22/rachanon-pc1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/CNN_5/log_1/plugins/profile/2022_11_09_02_48_22/rachanon-pc1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/CNN_5/log_1/plugins/profile/2022_11_09_02_48_22/rachanon-pc1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.7296 - accuracy: 0.5595 - val_loss: 0.6942 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 2/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6756 - accuracy: 0.5803 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 3/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6628 - accuracy: 0.5740 - val_loss: 0.6928 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 4/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6855 - accuracy: 0.5635 - val_loss: 0.6925 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 5/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6961 - accuracy: 0.4918 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 6/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6576 - accuracy: 0.6187 - val_loss: 0.7036 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 7/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6819 - accuracy: 0.5630 - val_loss: 0.6988 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 8/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6948 - accuracy: 0.4995 - val_loss: 0.6930 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 9/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6876 - accuracy: 0.5295 - val_loss: 0.7016 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 10/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6758 - accuracy: 0.5770 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 11/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6876 - accuracy: 0.5577 - val_loss: 0.6972 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 12/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6934 - accuracy: 0.5125 - val_loss: 0.6966 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 13/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6609 - accuracy: 0.6028 - val_loss: 0.6991 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 14/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6874 - accuracy: 0.5430 - val_loss: 0.7023 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 15/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6949 - accuracy: 0.5013 - val_loss: 0.6926 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 16/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6862 - accuracy: 0.5408 - val_loss: 0.7031 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 17/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6671 - accuracy: 0.5745 - val_loss: 0.6985 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 18/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6870 - accuracy: 0.5450 - val_loss: 0.6949 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 19/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6962 - accuracy: 0.4983 - val_loss: 0.6964 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 20/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6660 - accuracy: 0.5945 - val_loss: 0.7275 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 21/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6913 - accuracy: 0.5368 - val_loss: 0.7688 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 22/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6946 - accuracy: 0.5120 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 23/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6929 - accuracy: 0.5155 - val_loss: 0.6926 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 24/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6620 - accuracy: 0.5895 - val_loss: 0.7748 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 25/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6850 - accuracy: 0.5555 - val_loss: 0.6965 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 26/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6961 - accuracy: 0.4988 - val_loss: 0.7012 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 27/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6664 - accuracy: 0.5903 - val_loss: 0.7631 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 28/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6901 - accuracy: 0.5372 - val_loss: 0.7000 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 29/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6898 - accuracy: 0.5322 - val_loss: 0.6935 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 30/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6899 - accuracy: 0.5192 - val_loss: 0.6939 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 31/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6625 - accuracy: 0.5910 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 32/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6830 - accuracy: 0.5577 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 33/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6947 - accuracy: 0.5190 - val_loss: 0.7080 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 34/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6551 - accuracy: 0.6058 - val_loss: 0.8674 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 35/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6789 - accuracy: 0.5510 - val_loss: 0.7088 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 36/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6798 - accuracy: 0.5575 - val_loss: 0.6901 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 37/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6640 - accuracy: 0.6090 - val_loss: 0.6852 - val_accuracy: 0.5463 - lr: 0.0010\n",
      "Epoch 38/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6126 - accuracy: 0.6492 - val_loss: 0.6482 - val_accuracy: 0.6095 - lr: 0.0010\n",
      "Epoch 39/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6239 - accuracy: 0.6520 - val_loss: 0.6336 - val_accuracy: 0.6387 - lr: 0.0010\n",
      "Epoch 40/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6105 - accuracy: 0.6643 - val_loss: 0.6380 - val_accuracy: 0.6284 - lr: 0.0010\n",
      "Epoch 41/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5872 - accuracy: 0.6862 - val_loss: 0.6617 - val_accuracy: 0.6127 - lr: 0.0010\n",
      "Epoch 42/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5794 - accuracy: 0.6835 - val_loss: 0.6760 - val_accuracy: 0.6109 - lr: 0.0010\n",
      "Epoch 43/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5720 - accuracy: 0.7048 - val_loss: 0.5738 - val_accuracy: 0.7035 - lr: 0.0010\n",
      "Epoch 44/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5297 - accuracy: 0.7408 - val_loss: 0.8186 - val_accuracy: 0.5316 - lr: 0.0010\n",
      "Epoch 45/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5233 - accuracy: 0.7318 - val_loss: 0.5580 - val_accuracy: 0.7126 - lr: 0.0010\n",
      "Epoch 46/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5285 - accuracy: 0.7232 - val_loss: 0.5273 - val_accuracy: 0.7383 - lr: 0.0010\n",
      "Epoch 47/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5129 - accuracy: 0.7565 - val_loss: 0.5366 - val_accuracy: 0.7278 - lr: 0.0010\n",
      "Epoch 48/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5137 - accuracy: 0.7495 - val_loss: 0.5539 - val_accuracy: 0.7267 - lr: 0.0010\n",
      "Epoch 49/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5039 - accuracy: 0.7445 - val_loss: 0.5468 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 50/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4854 - accuracy: 0.7750 - val_loss: 0.5249 - val_accuracy: 0.7447 - lr: 0.0010\n",
      "Epoch 51/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4710 - accuracy: 0.7793 - val_loss: 0.6721 - val_accuracy: 0.6552 - lr: 0.0010\n",
      "Epoch 52/625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4743 - accuracy: 0.7722 - val_loss: 0.4840 - val_accuracy: 0.7648 - lr: 0.0010\n",
      "Epoch 53/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4811 - accuracy: 0.7632 - val_loss: 0.5124 - val_accuracy: 0.7726 - lr: 0.0010\n",
      "Epoch 54/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4300 - accuracy: 0.8123 - val_loss: 0.8131 - val_accuracy: 0.7038 - lr: 0.0010\n",
      "Epoch 55/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4562 - accuracy: 0.7887 - val_loss: 0.5436 - val_accuracy: 0.7606 - lr: 0.0010\n",
      "Epoch 56/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4797 - accuracy: 0.7638 - val_loss: 0.5122 - val_accuracy: 0.7645 - lr: 0.0010\n",
      "Epoch 57/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4115 - accuracy: 0.8175 - val_loss: 0.5332 - val_accuracy: 0.7409 - lr: 0.0010\n",
      "Epoch 58/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4212 - accuracy: 0.8070 - val_loss: 0.7148 - val_accuracy: 0.6097 - lr: 0.0010\n",
      "Epoch 59/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3996 - accuracy: 0.8183 - val_loss: 0.5017 - val_accuracy: 0.7580 - lr: 0.0010\n",
      "Epoch 60/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4436 - accuracy: 0.7933 - val_loss: 0.5192 - val_accuracy: 0.7883 - lr: 0.0010\n",
      "Epoch 61/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3811 - accuracy: 0.8310 - val_loss: 0.4239 - val_accuracy: 0.8081 - lr: 0.0010\n",
      "Epoch 62/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3942 - accuracy: 0.8280 - val_loss: 0.4300 - val_accuracy: 0.8029 - lr: 0.0010\n",
      "Epoch 63/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4306 - accuracy: 0.7947 - val_loss: 0.4633 - val_accuracy: 0.7789 - lr: 0.0010\n",
      "Epoch 64/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3604 - accuracy: 0.8400 - val_loss: 0.4230 - val_accuracy: 0.8083 - lr: 0.0010\n",
      "Epoch 65/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3635 - accuracy: 0.8522 - val_loss: 0.4395 - val_accuracy: 0.7958 - lr: 0.0010\n",
      "Epoch 66/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3726 - accuracy: 0.8440 - val_loss: 0.4005 - val_accuracy: 0.8205 - lr: 0.0010\n",
      "Epoch 67/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4001 - accuracy: 0.8155 - val_loss: 0.3981 - val_accuracy: 0.8145 - lr: 0.0010\n",
      "Epoch 68/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3466 - accuracy: 0.8515 - val_loss: 0.3922 - val_accuracy: 0.8227 - lr: 0.0010\n",
      "Epoch 69/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3318 - accuracy: 0.8633 - val_loss: 0.4409 - val_accuracy: 0.7931 - lr: 0.0010\n",
      "Epoch 70/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3897 - accuracy: 0.8225 - val_loss: 0.4943 - val_accuracy: 0.7678 - lr: 0.0010\n",
      "Epoch 71/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3326 - accuracy: 0.8518 - val_loss: 0.4019 - val_accuracy: 0.8167 - lr: 0.0010\n",
      "Epoch 72/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3246 - accuracy: 0.8655 - val_loss: 0.4377 - val_accuracy: 0.8162 - lr: 0.0010\n",
      "Epoch 73/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3574 - accuracy: 0.8462 - val_loss: 0.3939 - val_accuracy: 0.8162 - lr: 0.0010\n",
      "Epoch 74/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3611 - accuracy: 0.8388 - val_loss: 0.3829 - val_accuracy: 0.8291 - lr: 0.0010\n",
      "Epoch 75/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3003 - accuracy: 0.8815 - val_loss: 0.3475 - val_accuracy: 0.8498 - lr: 0.0010\n",
      "Epoch 76/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3007 - accuracy: 0.8727 - val_loss: 0.4967 - val_accuracy: 0.7968 - lr: 0.0010\n",
      "Epoch 77/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3660 - accuracy: 0.8353 - val_loss: 0.4990 - val_accuracy: 0.7605 - lr: 0.0010\n",
      "Epoch 78/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2948 - accuracy: 0.8777 - val_loss: 0.3880 - val_accuracy: 0.8202 - lr: 0.0010\n",
      "Epoch 79/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2977 - accuracy: 0.8750 - val_loss: 0.7938 - val_accuracy: 0.7454 - lr: 0.0010\n",
      "Epoch 80/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3215 - accuracy: 0.8577 - val_loss: 0.4185 - val_accuracy: 0.8066 - lr: 0.0010\n",
      "Epoch 81/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3557 - accuracy: 0.8428 - val_loss: 0.4885 - val_accuracy: 0.8255 - lr: 0.0010\n",
      "Epoch 82/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2766 - accuracy: 0.8903 - val_loss: 0.3359 - val_accuracy: 0.8527 - lr: 0.0010\n",
      "Epoch 83/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2853 - accuracy: 0.8802 - val_loss: 0.5275 - val_accuracy: 0.8254 - lr: 0.0010\n",
      "Epoch 84/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3410 - accuracy: 0.8528 - val_loss: 0.3210 - val_accuracy: 0.8577 - lr: 0.0010\n",
      "Epoch 85/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2845 - accuracy: 0.8808 - val_loss: 0.6531 - val_accuracy: 0.7131 - lr: 0.0010\n",
      "Epoch 86/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2851 - accuracy: 0.8867 - val_loss: 0.3175 - val_accuracy: 0.8617 - lr: 0.0010\n",
      "Epoch 87/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2839 - accuracy: 0.8835 - val_loss: 0.3394 - val_accuracy: 0.8708 - lr: 0.0010\n",
      "Epoch 88/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3281 - accuracy: 0.8577 - val_loss: 0.3021 - val_accuracy: 0.8746 - lr: 0.0010\n",
      "Epoch 89/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2520 - accuracy: 0.9030 - val_loss: 0.3835 - val_accuracy: 0.8534 - lr: 0.0010\n",
      "Epoch 90/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2665 - accuracy: 0.8935 - val_loss: 0.3185 - val_accuracy: 0.8691 - lr: 0.0010\n",
      "Epoch 91/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3145 - accuracy: 0.8652 - val_loss: 0.3797 - val_accuracy: 0.8265 - lr: 0.0010\n",
      "Epoch 92/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2452 - accuracy: 0.8928 - val_loss: 0.4220 - val_accuracy: 0.8536 - lr: 0.0010\n",
      "Epoch 93/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2540 - accuracy: 0.8980 - val_loss: 0.4074 - val_accuracy: 0.8201 - lr: 0.0010\n",
      "Epoch 94/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2737 - accuracy: 0.8875 - val_loss: 0.2810 - val_accuracy: 0.8876 - lr: 0.0010\n",
      "Epoch 95/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2946 - accuracy: 0.8715 - val_loss: 0.4019 - val_accuracy: 0.8558 - lr: 0.0010\n",
      "Epoch 96/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2205 - accuracy: 0.9158 - val_loss: 0.3588 - val_accuracy: 0.8486 - lr: 0.0010\n",
      "Epoch 97/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2520 - accuracy: 0.9015 - val_loss: 0.4089 - val_accuracy: 0.8572 - lr: 0.0010\n",
      "Epoch 98/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2842 - accuracy: 0.8763 - val_loss: 0.2950 - val_accuracy: 0.8768 - lr: 0.0010\n",
      "Epoch 99/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2399 - accuracy: 0.9022 - val_loss: 0.4234 - val_accuracy: 0.8357 - lr: 0.0010\n",
      "Epoch 100/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2465 - accuracy: 0.8972 - val_loss: 0.3050 - val_accuracy: 0.8726 - lr: 0.0010\n",
      "Epoch 101/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2571 - accuracy: 0.8970 - val_loss: 0.3458 - val_accuracy: 0.8676 - lr: 0.0010\n",
      "Epoch 102/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2789 - accuracy: 0.8857 - val_loss: 0.2561 - val_accuracy: 0.8944 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2041 - accuracy: 0.9222 - val_loss: 0.3104 - val_accuracy: 0.8872 - lr: 0.0010\n",
      "Epoch 104/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2418 - accuracy: 0.9043 - val_loss: 0.3332 - val_accuracy: 0.8687 - lr: 0.0010\n",
      "Epoch 105/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2466 - accuracy: 0.9022 - val_loss: 0.4663 - val_accuracy: 0.7914 - lr: 0.0010\n",
      "Epoch 106/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2326 - accuracy: 0.9032 - val_loss: 0.3175 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Epoch 107/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2348 - accuracy: 0.9057 - val_loss: 0.2958 - val_accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 108/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2325 - accuracy: 0.9082 - val_loss: 0.4856 - val_accuracy: 0.7829 - lr: 0.0010\n",
      "Epoch 109/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2711 - accuracy: 0.8880 - val_loss: 0.3389 - val_accuracy: 0.8598 - lr: 0.0010\n",
      "Epoch 110/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2043 - accuracy: 0.9212 - val_loss: 0.2697 - val_accuracy: 0.8956 - lr: 0.0010\n",
      "Epoch 111/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2120 - accuracy: 0.9200 - val_loss: 0.3423 - val_accuracy: 0.8595 - lr: 0.0010\n",
      "Epoch 112/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2264 - accuracy: 0.9107 - val_loss: 0.2935 - val_accuracy: 0.8783 - lr: 0.0010\n",
      "Epoch 113/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2306 - accuracy: 0.9053 - val_loss: 0.3508 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Epoch 114/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2096 - accuracy: 0.9202 - val_loss: 0.2662 - val_accuracy: 0.9055 - lr: 0.0010\n",
      "Epoch 115/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2280 - accuracy: 0.9122 - val_loss: 0.2919 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 116/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2493 - accuracy: 0.8970 - val_loss: 0.2693 - val_accuracy: 0.8941 - lr: 0.0010\n",
      "Epoch 117/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1828 - accuracy: 0.9275 - val_loss: 0.4525 - val_accuracy: 0.8216 - lr: 0.0010\n",
      "Epoch 118/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2055 - accuracy: 0.9222 - val_loss: 0.4170 - val_accuracy: 0.8249 - lr: 0.0010\n",
      "Epoch 119/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2005 - accuracy: 0.9218 - val_loss: 0.2698 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 120/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2363 - accuracy: 0.9015 - val_loss: 0.2933 - val_accuracy: 0.9018 - lr: 0.0010\n",
      "Epoch 121/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1775 - accuracy: 0.9320 - val_loss: 0.2849 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Epoch 122/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2017 - accuracy: 0.9197 - val_loss: 0.2718 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 123/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2368 - accuracy: 0.9068 - val_loss: 0.3447 - val_accuracy: 0.8678 - lr: 0.0010\n",
      "Epoch 124/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1634 - accuracy: 0.9367 - val_loss: 0.3364 - val_accuracy: 0.8594 - lr: 0.0010\n",
      "Epoch 125/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2001 - accuracy: 0.9215 - val_loss: 0.2556 - val_accuracy: 0.8931 - lr: 0.0010\n",
      "Epoch 126/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1952 - accuracy: 0.9237 - val_loss: 0.2747 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Epoch 127/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2282 - accuracy: 0.9100 - val_loss: 0.2976 - val_accuracy: 0.8860 - lr: 0.0010\n",
      "Epoch 128/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1748 - accuracy: 0.9330 - val_loss: 0.2460 - val_accuracy: 0.9158 - lr: 0.0010\n",
      "Epoch 129/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1700 - accuracy: 0.9367 - val_loss: 0.3059 - val_accuracy: 0.8817 - lr: 0.0010\n",
      "Epoch 130/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2209 - accuracy: 0.9158 - val_loss: 0.5804 - val_accuracy: 0.7790 - lr: 0.0010\n",
      "Epoch 131/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1526 - accuracy: 0.9400 - val_loss: 0.3271 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 132/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1899 - accuracy: 0.9268 - val_loss: 0.3105 - val_accuracy: 0.8824 - lr: 0.0010\n",
      "Epoch 133/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1932 - accuracy: 0.9298 - val_loss: 0.2917 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 134/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2065 - accuracy: 0.9187 - val_loss: 0.2479 - val_accuracy: 0.9081 - lr: 0.0010\n",
      "Epoch 135/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1607 - accuracy: 0.9388 - val_loss: 0.2274 - val_accuracy: 0.9104 - lr: 0.0010\n",
      "Epoch 136/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1678 - accuracy: 0.9340 - val_loss: 0.2860 - val_accuracy: 0.8886 - lr: 0.0010\n",
      "Epoch 137/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2240 - accuracy: 0.9070 - val_loss: 0.4269 - val_accuracy: 0.8253 - lr: 0.0010\n",
      "Epoch 138/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1652 - accuracy: 0.9370 - val_loss: 0.2980 - val_accuracy: 0.9055 - lr: 0.0010\n",
      "Epoch 139/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1850 - accuracy: 0.9305 - val_loss: 0.2653 - val_accuracy: 0.9101 - lr: 0.0010\n",
      "Epoch 140/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1860 - accuracy: 0.9262 - val_loss: 0.2084 - val_accuracy: 0.9201 - lr: 0.0010\n",
      "Epoch 141/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1939 - accuracy: 0.9265 - val_loss: 0.2238 - val_accuracy: 0.9138 - lr: 0.0010\n",
      "Epoch 142/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1461 - accuracy: 0.9482 - val_loss: 0.5706 - val_accuracy: 0.7744 - lr: 0.0010\n",
      "Epoch 143/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1632 - accuracy: 0.9408 - val_loss: 0.2248 - val_accuracy: 0.9220 - lr: 0.0010\n",
      "Epoch 144/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1996 - accuracy: 0.9227 - val_loss: 0.2383 - val_accuracy: 0.9086 - lr: 0.0010\n",
      "Epoch 145/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1631 - accuracy: 0.9400 - val_loss: 0.6308 - val_accuracy: 0.7539 - lr: 0.0010\n",
      "Epoch 146/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1671 - accuracy: 0.9367 - val_loss: 0.2453 - val_accuracy: 0.9137 - lr: 0.0010\n",
      "Epoch 147/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1641 - accuracy: 0.9388 - val_loss: 0.2997 - val_accuracy: 0.8819 - lr: 0.0010\n",
      "Epoch 148/625\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1798 - accuracy: 0.9315 - val_loss: 0.2427 - val_accuracy: 0.9045 - lr: 0.0010\n",
      "Epoch 149/625\n",
      " 996/1000 [============================>.] - ETA: 0s - loss: 0.1605 - accuracy: 0.9398"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m cbs \u001b[38;5;241m=\u001b[39m [tboardCb, lrSchedule]\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(val)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTART_EPOCH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEND_EPOCH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTEPS_PER_EPOCH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:1445\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1432\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1433\u001b[0m       x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1434\u001b[0m       y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1443\u001b[0m       model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1444\u001b[0m       steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution)\n\u001b[0;32m-> 1445\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1447\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1448\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1450\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1454\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1457\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m   1458\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:1756\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1755\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1756\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1757\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1758\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, (train, val) in enumerate(folds[0]):\n",
    "    \n",
    "    model = createModel()\n",
    "    \n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    metrics = ['accuracy']\n",
    "    \n",
    "    model.compile(optimizer=opt, loss=loss, metrics=metrics)\n",
    "    \n",
    "    tboardCb = tf.keras.callbacks.TensorBoard(log_dir=f\"{logBasePath}/{logPrefix}_{i}\", histogram_freq=1, profile_batch=(2,10))\n",
    "    lrSchedule = tf.keras.callbacks.LearningRateScheduler(schedule)\n",
    "    \n",
    "    cbs = [tboardCb, lrSchedule]\n",
    "    \n",
    "    model.evaluate(val)\n",
    "    model.fit(train, initial_epoch=START_EPOCH, epochs=END_EPOCH, steps_per_epoch=STEPS_PER_EPOCH, callbacks=cbs, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75efb222",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
