{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f19017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d782ddf",
   "metadata": {},
   "source": [
    "### Check Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03faa827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac4996",
   "metadata": {},
   "source": [
    "### GPU Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1e955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2835bd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f935a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be867b6",
   "metadata": {},
   "source": [
    "### Pandas Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92db292",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_column', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0907c",
   "metadata": {},
   "source": [
    "### Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0fd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VAL_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf19fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_WIDTH = 227\n",
    "CROP_HEIGHT = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d40847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldFiles = [\"../adience/unprocessed/fold_0_data.txt\",\n",
    "             \"../adience/unprocessed/fold_1_data.txt\",\n",
    "             \"../adience/unprocessed/fold_2_data.txt\",\n",
    "             \"../adience/unprocessed/fold_3_data.txt\",\n",
    "             \"../adience/unprocessed/fold_4_data.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f61c7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genderMap = defaultdict(lambda : np.NaN)\n",
    "genderMap['m'] = 0\n",
    "genderMap['f'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d26242",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = ['(0, 2)', '(4, 6)', '(8, 13)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
    "ageMap = defaultdict(lambda : np.NaN)\n",
    "for i,a in enumerate(ages):\n",
    "    ageMap[a] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b1fc3",
   "metadata": {},
   "source": [
    "### Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd634a3",
   "metadata": {},
   "source": [
    "Dataset generation pipeline:\n",
    "Input: \n",
    "- foldFile - Path to fold file. Fold file Describes which images are in the fold and its corresponding labels\n",
    "- imgBaseFolder - Base folder to search image from\n",
    "- imgPrefix - Prefix of image file\n",
    "- genderMap - Map from ['m', 'f', 'u', None], to one hot index\n",
    "- ageMap - Map from age category to one hot index\n",
    "- imgWidth - Resulting image width\n",
    "- imgHeigh - Resulting image height\n",
    "- batchSize - Int or None, batch size\n",
    "- configureDs - Function accepting dataset for performance configurations\n",
    "- preBatch - List of (name, functions) pair that will be mapped before batching. name is used as name parameters for tf graph \n",
    "- postBatch - List of (name, functions) that will be mapped after batching. name is used as name parameters for tf graph\n",
    "\n",
    "The processing functions should have signature function(img, label) -> (img, label)\n",
    "\n",
    "Pipeline\n",
    "\n",
    "Read Fold File -> Preprocess filename and labels (dataframe) -> Convert filename and labels to numpy array -> Convert filename and labels to tf dataset -> Parse images and labels -> Configure Dataset for performance -> Pre-Batching preprocessing -> Batch -> Post-Batching preprocessing -> Output\n",
    "\n",
    "Some preprocessing steps can only be done before and some can only be done after batching, thats why there are seperated pre and post batching list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0795464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, batchSize, configureDs=None, preBatch=[], postBatch=[]):\n",
    "    \n",
    "    def parseImage(filename):\n",
    "        img = tf.io.read_file(filename)\n",
    "        img = tf.image.decode_jpeg(img)\n",
    "        img = tf.image.resize(img, [imgHeight, imgWidth])\n",
    "         \n",
    "        return img\n",
    "    \n",
    "    # Read Fold File\n",
    "    foldData = []\n",
    "    for f in foldFiles:\n",
    "        foldData.append(pd.read_csv(f, sep=\"\\t\"))\n",
    "    foldData = pd.concat(foldData)\n",
    "    \n",
    "    # Form File Name\n",
    "    foldData['filename'] = foldData.apply(lambda r: os.path.join(imgBaseFolder, r['user_id'], f\"{imgPrefix}.{r['face_id']}.{r['original_image']}\"), axis=1)\n",
    "    \n",
    "    # Generate Label One Hot Index\n",
    "    foldData['gender_ind'] = foldData['gender'].map(genderMap)\n",
    "    foldData['age_ind'] = foldData['age'].map(ageMap)\n",
    "    \n",
    "    # Remove dirty data\n",
    "    foldData.dropna(subset=['gender_ind', 'age_ind'], inplace=True)\n",
    "    \n",
    "    # Dataframe to numpy\n",
    "    filenames = foldData['filename'].to_numpy()\n",
    "    \n",
    "    genderIndex = foldData['gender_ind'].to_numpy().astype(int)\n",
    "    ageIndex = foldData['age_ind'].to_numpy().astype(int)\n",
    "    \n",
    "    # Numpy to Dataset\n",
    "    fnDs = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    genderIndDs = tf.data.Dataset.from_tensor_slices(genderIndex)\n",
    "    ageIndDs = tf.data.Dataset.from_tensor_slices(ageIndex)\n",
    "    \n",
    "    # Parse Images\n",
    "    imageDs = fnDs.map(parseImage, num_parallel_calls=tf.data.AUTOTUNE, name=\"parse_image\")\n",
    "    \n",
    "    # Parse Labels\n",
    "    genderLabDs = genderIndDs.map(lambda x: tf.one_hot(x, genderDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"gender_one_hot\")\n",
    "    ageLabDs = ageIndDs.map(lambda x: tf.one_hot(x, ageDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"age_one_hot\")\n",
    "    \n",
    "    # Combine Labels\n",
    "    labelDs = tf.data.Dataset.zip((genderLabDs, ageLabDs), name=\"label_zip\")\n",
    "    labelDs = labelDs.map(lambda g,a: {\"gender\": g, \"age\": a}, num_parallel_calls=tf.data.AUTOTUNE, name='label_dict')\n",
    "    \n",
    "    # Combine Images and Labels into dataset\n",
    "    ds = tf.data.Dataset.zip((imageDs, labelDs))\n",
    "    \n",
    "    # Configure Performance\n",
    "    if(configureDs is not None):\n",
    "        ds = configureDs(ds)\n",
    "    \n",
    "    # Pre Batch Preprocessing\n",
    "    for n,f in preBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    # Batch\n",
    "    if(batchSize is not None):\n",
    "        ds = ds.batch(batchSize, name=\"ds_batch\")\n",
    "    \n",
    "    # Post Batch Preprocessing\n",
    "    for n,f in postBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320ed92",
   "metadata": {},
   "source": [
    "### Preprocessings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "472b7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=100)\n",
    "    ds = ds.repeat()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adb98feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313da7f1",
   "metadata": {},
   "source": [
    "#### Preprocessing steps according to the reference paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7724a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainPreprocessA(img, lab):\n",
    "        \n",
    "        img = tf.image.random_crop(img, [CROP_HEIGHT, CROP_WIDTH, 3])\n",
    "        \n",
    "        ud = tf.random.uniform([], dtype=tf.float32)\n",
    "        udCond = tf.less(ud, 0.5)\n",
    "        \n",
    "        img = tf.cond(udCond, lambda: tf.image.flip_up_down(img), lambda: img)\n",
    "        \n",
    "        lr = tf.random.uniform([], dtype=tf.float32)\n",
    "        lrCond = tf.less(lr, 0.5)\n",
    "        \n",
    "        img = tf.cond(lrCond, lambda: tf.image.flip_left_right(img), lambda: img)\n",
    "        \n",
    "        img = tf.image.random_brightness(img, 63/255)\n",
    "        \n",
    "        img = tf.image.random_contrast(img, 0.2, 1.8) \n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14ee59ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valPreprocessA(img, lab):\n",
    "        \n",
    "        img = tf.image.crop_to_bounding_box(img,\n",
    "                                            (IMG_HEIGHT-CROP_HEIGHT) // 2,\n",
    "                                            (IMG_WIDTH-CROP_WIDTH) // 2,\n",
    "                                            CROP_HEIGHT,\n",
    "                                            CROP_WIDTH)\n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a03ab680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageStandardize(img, lab):\n",
    "    \n",
    "    img = tf.image.per_image_standardization(img)\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ec104",
   "metadata": {},
   "source": [
    "#### Label extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "294a2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractGenderLabel(img, lab):\n",
    "    \n",
    "    lab = lab['gender']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a98897ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAgeLabel(img, lab):\n",
    "    \n",
    "    lab = lab['age']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7778c",
   "metadata": {},
   "source": [
    "### Generate Folds for K-Folds validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4172d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFoldDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, valBatchSize, trainConfigureDs=None, trainPreBatch=[], trainPostBatch=[], valConfigureDs=None, valPreBatch=[], valPostBatch=[]):\n",
    "    '''\n",
    "        Returns list of (train, validation) datasets\n",
    "    '''\n",
    "    \n",
    "    N = len(foldFiles)\n",
    "    \n",
    "    folds = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        trainFiles = foldFiles[:i]\n",
    "        if(i < N-1):\n",
    "            trainFiles.extend(foldFiles[i+1:])\n",
    "            \n",
    "        valFiles = foldFiles[i]\n",
    "        \n",
    "        trainDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, configureDs=trainConfigureDs, preBatch=trainPreBatch, postBatch=trainPostBatch)\n",
    "        valDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, valBatchSize, configureDs=valConfigureDs, preBatch=valPreBatch, postBatch=valPostBatch)\n",
    "        \n",
    "        folds.append((trainDs, valDs))\n",
    "        \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4f43dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPreBatch = [(\"train_process_a\", trainPreprocessA), \n",
    "                 (\"train_standardize\", imageStandardize), \n",
    "                 (\"train_extract_gender\", extractGenderLabel)]\n",
    "\n",
    "valPreBatch = [(\"val_process_a\", valPreprocessA), \n",
    "               (\"val_standardize\", imageStandardize), \n",
    "               (\"val_extract_gender\", extractGenderLabel)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10474d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = generateFoldDs(foldFiles, \"../adience/faces\", \"coarse_tilt_aligned_face\", genderMap, ageMap, 2, 8, \n",
    "                       IMG_WIDTH, IMG_HEIGHT, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE, \n",
    "                       trainConfigureDs=trainConfigPerformance, trainPreBatch=trainPreBatch, \n",
    "                       valConfigureDs=valConfigPerformance, valPreBatch=valPreBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57d814af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b5f9bc",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d0df0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in folds[0][0].take(1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c9e2833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 227, 227, 3), dtype=float32, numpy=\n",
       "array([[[[-1.4863087 , -1.8302673 , -1.4793264 ],\n",
       "         [-1.5747051 , -1.8950176 , -1.4905803 ],\n",
       "         [-1.6859891 , -1.9078356 , -1.4676329 ],\n",
       "         ...,\n",
       "         [-0.36721116, -0.9105968 , -1.2757267 ],\n",
       "         [-0.21444346, -0.7415455 , -1.112103  ],\n",
       "         [-0.07169902, -0.5988011 , -0.94263643]],\n",
       "\n",
       "        [[-1.571606  , -1.8622584 , -1.5360149 ],\n",
       "         [-1.7426621 , -1.9854382 , -1.6040175 ],\n",
       "         [-1.7133646 , -1.8396342 , -1.4223055 ],\n",
       "         ...,\n",
       "         [-0.35388905, -0.8809911 , -1.2624046 ],\n",
       "         [-0.29768914, -0.8247912 , -1.195349  ],\n",
       "         [-0.21024127, -0.7373433 , -1.1079007 ]],\n",
       "\n",
       "        [[-1.5711715 , -1.8046052 , -1.4269422 ],\n",
       "         [-1.8048999 , -1.9770981 , -1.5689552 ],\n",
       "         [-1.9267863 , -1.9996115 , -1.5952263 ],\n",
       "         ...,\n",
       "         [-0.410058  , -0.93716   , -1.361162  ],\n",
       "         [-0.29407915, -0.8211809 , -1.1917386 ],\n",
       "         [-0.23303936, -0.76014113, -1.1306989 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.12268791, -1.2952449 , -1.4520253 ],\n",
       "         [-0.10644732, -1.2876797 , -1.4363647 ],\n",
       "         [-0.13666385, -1.4057481 , -1.4940143 ],\n",
       "         ...,\n",
       "         [ 1.2230687 ,  0.05463434, -0.3693675 ],\n",
       "         [ 0.8156241 , -0.40625432, -0.83025646],\n",
       "         [ 0.22057456, -1.0013036 , -1.4253057 ]],\n",
       "\n",
       "        [[-0.00734672, -1.4163845 , -1.4929985 ],\n",
       "         [-0.01779973, -1.3962387 , -1.4747386 ],\n",
       "         [ 0.00810215, -1.333558  , -1.4442798 ],\n",
       "         ...,\n",
       "         [ 1.1444728 , -0.02396153, -0.4479634 ],\n",
       "         [ 1.0188692 , -0.2297313 , -0.5735667 ],\n",
       "         [ 1.0122647 , -0.236336  , -0.5801714 ]],\n",
       "\n",
       "        [[-0.1650179 , -1.3575644 , -1.4341784 ],\n",
       "         [-0.20191754, -1.375153  , -1.5196773 ],\n",
       "         [-0.22293518, -1.3192402 , -1.5603312 ],\n",
       "         ...,\n",
       "         [ 1.2299627 ,  0.06152869, -0.30902904],\n",
       "         [ 1.0748578 , -0.09357619, -0.46413392],\n",
       "         [ 1.3881346 ,  0.21970053, -0.12413487]]],\n",
       "\n",
       "\n",
       "       [[[-0.41430664, -0.35980895, -0.33815002],\n",
       "         [-0.67625356, -0.6217559 , -0.60009694],\n",
       "         [-0.89244777, -0.8379501 , -0.81629115],\n",
       "         ...,\n",
       "         [ 0.8165806 ,  0.2615031 ,  0.00308697],\n",
       "         [ 0.8038663 ,  0.24878883, -0.00962731],\n",
       "         [ 0.75326693,  0.19818929, -0.06022676]],\n",
       "\n",
       "        [[-0.41878736, -0.3642897 , -0.30968073],\n",
       "         [-0.6895953 , -0.6350976 , -0.61343867],\n",
       "         [-0.86333495, -0.80883735, -0.7871784 ],\n",
       "         ...,\n",
       "         [ 0.8060222 ,  0.20151979, -0.04042142],\n",
       "         [ 0.83717436,  0.23267177, -0.00926935],\n",
       "         [ 0.832046  ,  0.27001807,  0.01391875]],\n",
       "\n",
       "        [[-0.3933629 , -0.32239023, -0.26778126],\n",
       "         [-0.61623   , -0.56173235, -0.5400734 ],\n",
       "         [-0.89986473, -0.8124171 , -0.8072332 ],\n",
       "         ...,\n",
       "         [ 0.8775896 ,  0.273087  ,  0.03114588],\n",
       "         [ 0.8775132 ,  0.27301055,  0.03106952],\n",
       "         [ 0.86343133,  0.32396814,  0.05658645]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.5557598 ,  1.5163829 ,  0.6483915 ],\n",
       "         [ 0.6472413 ,  1.6078641 ,  0.70692277],\n",
       "         [ 0.7826049 ,  1.7432278 ,  0.8422865 ],\n",
       "         ...,\n",
       "         [-0.31644198, -0.58624375, -0.6891247 ],\n",
       "         [ 0.66991854,  0.20159206, -0.00868606],\n",
       "         [ 0.9903646 ,  0.510957  ,  0.31998146]],\n",
       "\n",
       "        [[ 0.43998832,  1.4080765 ,  0.54008526],\n",
       "         [ 0.5861396 ,  1.5467628 ,  0.6458213 ],\n",
       "         [ 0.6773153 ,  1.6379381 ,  0.736997  ],\n",
       "         ...,\n",
       "         [-1.2185692 , -1.3059232 , -1.3457919 ],\n",
       "         [-0.6428933 , -0.90431273, -0.9681179 ],\n",
       "         [-0.01728957, -0.37355694, -0.49393454]],\n",
       "\n",
       "        [[ 0.43605056,  1.426277  ,  0.5189002 ],\n",
       "         [ 0.46607652,  1.4266994 ,  0.525758  ],\n",
       "         [ 0.613901  ,  1.5745238 ,  0.6735827 ],\n",
       "         ...,\n",
       "         [-1.5719774 , -1.525323  , -1.5064353 ],\n",
       "         [-1.4512786 , -1.4647685 , -1.4113703 ],\n",
       "         [-1.0209777 , -1.2022787 , -1.2256243 ]]],\n",
       "\n",
       "\n",
       "       [[[-2.0201583 , -2.0807889 , -2.0842302 ],\n",
       "         [-2.0201583 , -2.0741894 , -2.097429  ],\n",
       "         [-2.0201583 , -2.0724926 , -2.097429  ],\n",
       "         ...,\n",
       "         [-2.0201583 , -2.0727074 , -2.097429  ],\n",
       "         [-2.0201583 , -2.0727074 , -2.097429  ],\n",
       "         [-2.0201583 , -2.0862567 , -2.097429  ]],\n",
       "\n",
       "        [[-2.0066087 , -2.0862567 , -2.097429  ],\n",
       "         [-2.0066087 , -2.0862567 , -2.097429  ],\n",
       "         [-2.0057156 , -2.0862567 , -2.097429  ],\n",
       "         ...,\n",
       "         [-2.0201583 , -2.0727074 , -2.097429  ],\n",
       "         [-2.0201583 , -2.0727074 , -2.097429  ],\n",
       "         [-2.0201583 , -2.0862567 , -2.097429  ]],\n",
       "\n",
       "        [[-2.0201583 , -2.0727074 , -2.097429  ],\n",
       "         [-2.0201583 , -2.0669913 , -2.097429  ],\n",
       "         [-2.0201583 , -2.068599  , -2.097429  ],\n",
       "         ...,\n",
       "         [-2.0201583 , -2.078847  , -2.097429  ],\n",
       "         [-2.0201583 , -2.0862567 , -2.097429  ],\n",
       "         [-2.0201583 , -2.0862567 , -2.097429  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.0201583 , -2.0862567 , -2.097429  ],\n",
       "         [-2.0201583 , -2.0862567 , -2.097429  ],\n",
       "         [-2.0201583 , -2.0862567 , -2.097429  ],\n",
       "         ...,\n",
       "         [-2.0201583 , -2.0862567 , -2.097429  ],\n",
       "         [-2.0201583 , -2.0862567 , -2.097429  ],\n",
       "         [-2.0201583 , -2.0862567 , -2.097429  ]],\n",
       "\n",
       "        [[-2.0201583 , -2.0862567 , -2.097429  ],\n",
       "         [-2.0201583 , -2.0862567 , -2.097429  ],\n",
       "         [-2.0201583 , -2.0862567 , -2.097429  ],\n",
       "         ...,\n",
       "         [-2.0201583 , -2.0862567 , -2.097429  ],\n",
       "         [-2.0201583 , -2.0862567 , -2.097429  ],\n",
       "         [-2.0201583 , -2.0862567 , -2.097429  ]],\n",
       "\n",
       "        [[-2.0201583 , -2.0862567 , -2.097429  ],\n",
       "         [-2.0201583 , -2.0862567 , -2.097429  ],\n",
       "         [-2.0201583 , -2.0862567 , -2.097429  ],\n",
       "         ...,\n",
       "         [-2.0201583 , -2.0862567 , -2.097429  ],\n",
       "         [-2.0201583 , -2.0862567 , -2.097429  ],\n",
       "         [-2.0201583 , -2.0862567 , -2.097429  ]]],\n",
       "\n",
       "\n",
       "       [[[-0.9280945 , -1.2615055 , -1.2981306 ],\n",
       "         [-0.9280945 , -1.2382416 , -1.2981306 ],\n",
       "         [-0.9145998 , -1.2615055 , -1.2981306 ],\n",
       "         ...,\n",
       "         [ 2.348045  ,  0.95090556,  0.5631875 ],\n",
       "         [ 2.2786696 ,  0.9449147 ,  0.52838975],\n",
       "         [ 2.1570888 ,  0.8497781 ,  0.40444586]],\n",
       "\n",
       "        [[-0.9280945 , -1.2615055 , -1.2981306 ],\n",
       "         [-0.9280945 , -1.2385947 , -1.2981306 ],\n",
       "         [-0.9052807 , -1.2615055 , -1.2981306 ],\n",
       "         ...,\n",
       "         [ 2.366785  ,  0.96323884,  0.57552075],\n",
       "         [ 2.2463303 ,  0.85803694,  0.4441066 ],\n",
       "         [ 2.2213185 ,  0.88756377,  0.45545378]],\n",
       "\n",
       "        [[-0.9280945 , -1.2615055 , -1.2981306 ],\n",
       "         [-0.9280945 , -1.2392867 , -1.2981306 ],\n",
       "         [-0.89133584, -1.2615055 , -1.2981306 ],\n",
       "         ...,\n",
       "         [ 2.2680593 ,  0.820121  ,  0.45353124],\n",
       "         [ 2.2680278 ,  0.8555019 ,  0.44665572],\n",
       "         [ 2.2349362 ,  0.83139   ,  0.42254385]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9280945 , -1.2615055 , -1.2981306 ],\n",
       "         [-0.9280945 , -1.2615055 , -1.2981306 ],\n",
       "         [-0.9280945 , -1.2615055 , -1.2981306 ],\n",
       "         ...,\n",
       "         [-0.88583803, -1.2303494 , -1.1760447 ],\n",
       "         [-0.9280945 , -1.2615055 , -1.2981306 ],\n",
       "         [-0.9280945 , -1.2615055 , -1.2981306 ]],\n",
       "\n",
       "        [[-0.9280945 , -1.2615055 , -1.2981306 ],\n",
       "         [-0.9280945 , -1.2615055 , -1.2981306 ],\n",
       "         [-0.9280945 , -1.2615055 , -1.2981306 ],\n",
       "         ...,\n",
       "         [-0.879772  , -1.2131827 , -1.2498078 ],\n",
       "         [-0.9280945 , -1.2615055 , -1.2981306 ],\n",
       "         [-0.9280945 , -1.2615055 , -1.2981306 ]],\n",
       "\n",
       "        [[-0.9280945 , -1.2615055 , -1.2981306 ],\n",
       "         [-0.9280945 , -1.2615055 , -1.2981306 ],\n",
       "         [-0.9280945 , -1.2615055 , -1.2981306 ],\n",
       "         ...,\n",
       "         [-0.88583803, -1.2192489 , -1.2981306 ],\n",
       "         [-0.9280945 , -1.2615055 , -1.2981306 ],\n",
       "         [-0.9280945 , -1.2615055 , -1.2981306 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "819ce578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78c5d50",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a70f6af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    inp = tf.keras.Input(shape=(CROP_HEIGHT, CROP_WIDTH, 3))\n",
    "\n",
    "    conv1 = tf.keras.layers.Conv2D(96, 7, strides=(4,4), activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='conv1')\n",
    "    pool1 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, name='pool1')\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv2D(256, 5, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='conv2')\n",
    "    pool2 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, name='pool2')\n",
    "\n",
    "    conv3 = tf.keras.layers.Conv2D(384, 3, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='conv3')\n",
    "    pool3 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, name='pool3')\n",
    "\n",
    "    flat1 = tf.keras.layers.Flatten(name='flat1')\n",
    "    fc1 = tf.keras.layers.Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc1')\n",
    "    do1 = tf.keras.layers.Dropout(0.5, name='do1')\n",
    "\n",
    "    fc2 = tf.keras.layers.Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc2')\n",
    "    do2 = tf.keras.layers.Dropout(0.5, name='do2')\n",
    "\n",
    "    fc3 = tf.keras.layers.Dense(2, activation='softmax', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='fc3')\n",
    "\n",
    "    o = conv1(inp)\n",
    "    o = pool1(o)\n",
    "    o = tf.nn.local_response_normalization(o, depth_radius=5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    o = tf.pad(o, [[0, 0], [2, 2], [2, 2], [0, 0]])\n",
    "    o = conv2(o)\n",
    "    o = pool2(o)\n",
    "    o = tf.nn.local_response_normalization(o, depth_radius=5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    o = tf.pad(o, [[0, 0], [1, 1], [1, 1], [0, 0]])\n",
    "    o = conv3(o)\n",
    "    o = pool3(o)\n",
    "    o = tf.nn.local_response_normalization(o, depth_radius=5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    o = flat1(o)\n",
    "    o = fc1(o)\n",
    "    o = do1(o)\n",
    "\n",
    "\n",
    "    o = fc2(o)\n",
    "    o = do2(o)\n",
    "\n",
    "    o = fc3(o)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=o, name='baseline_1')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fcc28d",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ffbbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = 1000\n",
    "\n",
    "ITERATIONS = 50000*50 // TRAIN_BATCH_SIZE\n",
    "\n",
    "EPOCH = ITERATIONS // STEPS_PER_EPOCH\n",
    "\n",
    "START_EPOCH = 0\n",
    "END_EPOCH = START_EPOCH + EPOCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cc17f1",
   "metadata": {},
   "source": [
    "#### Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1ab143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(epoch, lr):\n",
    "    if(epoch == 10000*50//STEPS_PER_EPOCH):\n",
    "        return lr * 0.1\n",
    "    else:\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "222f6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logBasePath = \"log/baseline_2\"\n",
    "logPrefix = \"log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1b72905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 31s 8ms/step - loss: 0.7031 - accuracy: 0.4768\n",
      "Epoch 1/625\n",
      "1000/1000 [==============================] - 59s 50ms/step - loss: 0.7687 - accuracy: 0.5595 - val_loss: 0.6920 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 2/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.6718 - accuracy: 0.5870 - val_loss: 0.6920 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 3/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6691 - accuracy: 0.5558 - val_loss: 0.6936 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 4/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6886 - accuracy: 0.5575 - val_loss: 0.7162 - val_accuracy: 0.4498 - lr: 0.0010\n",
      "Epoch 5/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6973 - accuracy: 0.5033 - val_loss: 0.6964 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 6/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6749 - accuracy: 0.5907 - val_loss: 0.6952 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 7/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6878 - accuracy: 0.5497 - val_loss: 0.7047 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 8/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.7021 - accuracy: 0.4870 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 9/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6957 - accuracy: 0.5253 - val_loss: 0.7135 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 10/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6802 - accuracy: 0.5720 - val_loss: 0.6982 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 11/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6904 - accuracy: 0.5443 - val_loss: 0.7302 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 12/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.7047 - accuracy: 0.4708 - val_loss: 0.6938 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 13/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6721 - accuracy: 0.5960 - val_loss: 0.7229 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 14/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6905 - accuracy: 0.5387 - val_loss: 0.7243 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 15/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.7019 - accuracy: 0.4880 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 16/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6951 - accuracy: 0.5207 - val_loss: 0.7190 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 17/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6791 - accuracy: 0.5773 - val_loss: 0.7280 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 18/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6831 - accuracy: 0.5587 - val_loss: 1.0932 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 19/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.7030 - accuracy: 0.4850 - val_loss: 0.6989 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 20/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6570 - accuracy: 0.6093 - val_loss: 0.7988 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 21/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6929 - accuracy: 0.5328 - val_loss: 0.7288 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 22/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.7004 - accuracy: 0.5027 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 23/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6943 - accuracy: 0.5157 - val_loss: 0.6932 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 24/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6758 - accuracy: 0.5842 - val_loss: 0.7126 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 25/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6901 - accuracy: 0.5470 - val_loss: 0.6967 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 26/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.7070 - accuracy: 0.4723 - val_loss: 0.7089 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 27/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6706 - accuracy: 0.5867 - val_loss: 0.7993 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 28/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6986 - accuracy: 0.5347 - val_loss: 0.7014 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 29/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6972 - accuracy: 0.5092 - val_loss: 0.6935 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 30/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6996 - accuracy: 0.5092 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 31/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6740 - accuracy: 0.5857 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 32/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6872 - accuracy: 0.5512 - val_loss: 0.6927 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 33/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7043 - accuracy: 0.4845 - val_loss: 0.6993 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 34/625\n",
      "1000/1000 [==============================] - 41s 42ms/step - loss: 0.6724 - accuracy: 0.5795 - val_loss: 0.7503 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 35/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6899 - accuracy: 0.5487 - val_loss: 0.6936 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 36/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6949 - accuracy: 0.5205 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 37/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6930 - accuracy: 0.5180 - val_loss: 0.7672 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 38/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6806 - accuracy: 0.5673 - val_loss: 0.6935 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 39/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6879 - accuracy: 0.5525 - val_loss: 0.7185 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 40/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.7067 - accuracy: 0.4705 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 41/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6895 - accuracy: 0.5477 - val_loss: 0.6978 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 42/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6802 - accuracy: 0.5510 - val_loss: 0.6925 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 43/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6938 - accuracy: 0.5232 - val_loss: 0.6937 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 44/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6925 - accuracy: 0.5125 - val_loss: 0.7802 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 45/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6841 - accuracy: 0.5652 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 46/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6870 - accuracy: 0.5537 - val_loss: 0.7316 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 47/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7047 - accuracy: 0.4692 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 48/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6912 - accuracy: 0.5415 - val_loss: 0.6956 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 49/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6820 - accuracy: 0.5640 - val_loss: 0.6941 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 50/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6942 - accuracy: 0.5272 - val_loss: 0.7072 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 51/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6972 - accuracy: 0.5017 - val_loss: 0.7459 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 52/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6783 - accuracy: 0.5855 - val_loss: 0.6926 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 53/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6887 - accuracy: 0.5508 - val_loss: 0.6942 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 54/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7003 - accuracy: 0.4947 - val_loss: 0.7300 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 55/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6962 - accuracy: 0.5220 - val_loss: 0.6926 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 56/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6798 - accuracy: 0.5677 - val_loss: 0.6936 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 57/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6928 - accuracy: 0.5545 - val_loss: 0.7027 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 58/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7014 - accuracy: 0.4818 - val_loss: 0.6934 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 59/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6753 - accuracy: 0.5918 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 60/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6876 - accuracy: 0.5555 - val_loss: 0.6971 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 61/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7022 - accuracy: 0.4767 - val_loss: 0.6931 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 62/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6964 - accuracy: 0.5257 - val_loss: 0.6944 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 63/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6795 - accuracy: 0.5740 - val_loss: 0.6962 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 64/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6934 - accuracy: 0.5238 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 65/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6994 - accuracy: 0.4940 - val_loss: 0.6958 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 66/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6761 - accuracy: 0.5880 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 67/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6863 - accuracy: 0.5510 - val_loss: 0.7047 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 68/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7024 - accuracy: 0.4945 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 69/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6940 - accuracy: 0.5365 - val_loss: 0.6991 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 70/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6804 - accuracy: 0.5683 - val_loss: 0.6944 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 71/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6922 - accuracy: 0.5355 - val_loss: 0.7003 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 72/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7006 - accuracy: 0.4835 - val_loss: 0.6975 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 73/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6733 - accuracy: 0.5918 - val_loss: 0.7102 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 74/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6898 - accuracy: 0.5362 - val_loss: 0.7174 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 75/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7029 - accuracy: 0.4845 - val_loss: 0.6934 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 76/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6941 - accuracy: 0.5312 - val_loss: 0.7172 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 77/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6803 - accuracy: 0.5700 - val_loss: 0.7139 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 78/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6892 - accuracy: 0.5393 - val_loss: 0.7352 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 79/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7060 - accuracy: 0.4745 - val_loss: 0.6934 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 80/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6651 - accuracy: 0.6090 - val_loss: 0.7533 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 81/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6918 - accuracy: 0.5357 - val_loss: 0.7289 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 82/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.7008 - accuracy: 0.5042 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 83/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6951 - accuracy: 0.5242 - val_loss: 0.7088 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 84/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6795 - accuracy: 0.5800 - val_loss: 0.7277 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 85/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6913 - accuracy: 0.5420 - val_loss: 0.6929 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 86/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.7047 - accuracy: 0.4840 - val_loss: 0.7059 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 87/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.6671 - accuracy: 0.5905 - val_loss: 0.8063 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 88/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6984 - accuracy: 0.5357 - val_loss: 0.7169 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 89/625\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.6970 - accuracy: 0.5153 - val_loss: 0.6939 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 90/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6991 - accuracy: 0.5075 - val_loss: 0.6958 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 91/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6756 - accuracy: 0.5767 - val_loss: 0.6949 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 92/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6887 - accuracy: 0.5527 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 93/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7049 - accuracy: 0.4705 - val_loss: 0.7139 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 94/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6751 - accuracy: 0.5788 - val_loss: 0.7910 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 95/625\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.6961 - accuracy: 0.5370 - val_loss: 0.6991 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 96/625\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.6940 - accuracy: 0.5240 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 97/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6829 - accuracy: 0.5378 - val_loss: 1.2679 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 98/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6793 - accuracy: 0.5813 - val_loss: 0.6949 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 99/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6894 - accuracy: 0.5497 - val_loss: 0.7054 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 100/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7060 - accuracy: 0.4737 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 101/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6771 - accuracy: 0.5732 - val_loss: 0.7208 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 102/625\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.6866 - accuracy: 0.5465 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 103/625\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.6942 - accuracy: 0.5322 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 104/625\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.6884 - accuracy: 0.5293 - val_loss: 0.7968 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 105/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6858 - accuracy: 0.5702 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 106/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6866 - accuracy: 0.5562 - val_loss: 0.7242 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 107/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7074 - accuracy: 0.4700 - val_loss: 0.6934 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 108/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6913 - accuracy: 0.5445 - val_loss: 0.6949 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 109/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.6808 - accuracy: 0.5577 - val_loss: 0.6950 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 110/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.6938 - accuracy: 0.5272 - val_loss: 0.6969 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 111/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6939 - accuracy: 0.5105 - val_loss: 0.7702 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 112/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6791 - accuracy: 0.5805 - val_loss: 0.6932 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 113/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6885 - accuracy: 0.5470 - val_loss: 0.7038 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 114/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.7053 - accuracy: 0.4775 - val_loss: 0.7016 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 115/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6893 - accuracy: 0.5447 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 116/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6803 - accuracy: 0.5595 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 117/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6925 - accuracy: 0.5318 - val_loss: 0.7011 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 118/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6999 - accuracy: 0.4972 - val_loss: 0.7146 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 119/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6756 - accuracy: 0.5872 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 120/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.6881 - accuracy: 0.5500 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 121/625\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.7007 - accuracy: 0.4990 - val_loss: 0.7123 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 122/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6965 - accuracy: 0.5235 - val_loss: 0.6941 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 123/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6805 - accuracy: 0.5667 - val_loss: 0.7008 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 124/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6938 - accuracy: 0.5235 - val_loss: 0.6928 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 125/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7002 - accuracy: 0.4978 - val_loss: 0.6931 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 126/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6760 - accuracy: 0.5880 - val_loss: 0.6930 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 127/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6852 - accuracy: 0.5548 - val_loss: 0.7051 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 128/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7042 - accuracy: 0.4827 - val_loss: 0.6929 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 129/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6973 - accuracy: 0.5232 - val_loss: 0.6985 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 130/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6794 - accuracy: 0.5665 - val_loss: 0.6939 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 131/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6923 - accuracy: 0.5330 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 132/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7005 - accuracy: 0.4950 - val_loss: 0.6962 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 133/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6758 - accuracy: 0.5918 - val_loss: 0.6939 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 134/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6871 - accuracy: 0.5462 - val_loss: 0.7071 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 135/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7021 - accuracy: 0.4888 - val_loss: 0.6928 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 136/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6969 - accuracy: 0.5175 - val_loss: 0.7091 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 137/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6791 - accuracy: 0.5745 - val_loss: 0.6988 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 138/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6897 - accuracy: 0.5425 - val_loss: 0.7225 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 139/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.7033 - accuracy: 0.4697 - val_loss: 0.6937 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 140/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6730 - accuracy: 0.5982 - val_loss: 0.7198 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 141/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6889 - accuracy: 0.5412 - val_loss: 0.7212 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 142/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.7013 - accuracy: 0.4992 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 143/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6948 - accuracy: 0.5220 - val_loss: 0.7169 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 144/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6778 - accuracy: 0.5830 - val_loss: 0.7304 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 145/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6915 - accuracy: 0.5337 - val_loss: 0.6990 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 146/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.7047 - accuracy: 0.4767 - val_loss: 0.6971 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 147/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6668 - accuracy: 0.5972 - val_loss: 0.7943 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 148/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6966 - accuracy: 0.5255 - val_loss: 0.7310 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 149/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.7029 - accuracy: 0.4933 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 150/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6996 - accuracy: 0.5020 - val_loss: 0.6975 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 151/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6748 - accuracy: 0.5842 - val_loss: 0.7147 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 152/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6897 - accuracy: 0.5465 - val_loss: 0.6956 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 153/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.7071 - accuracy: 0.4742 - val_loss: 0.7153 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 154/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6702 - accuracy: 0.5882 - val_loss: 0.8066 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 155/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6986 - accuracy: 0.5328 - val_loss: 0.7013 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 156/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6976 - accuracy: 0.5038 - val_loss: 0.6940 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 157/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.7008 - accuracy: 0.5025 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 158/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6755 - accuracy: 0.5803 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 159/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6895 - accuracy: 0.5500 - val_loss: 0.6937 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 160/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.7049 - accuracy: 0.4723 - val_loss: 0.7029 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 161/625\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6799 - accuracy: 0.5720 - val_loss: 0.7529 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 162/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6920 - accuracy: 0.5405 - val_loss: 0.6938 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 163/625\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.6949 - accuracy: 0.5192 - val_loss: 0.6934 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 164/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.6938 - accuracy: 0.5210 - val_loss: 0.7590 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 165/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6798 - accuracy: 0.5795 - val_loss: 0.6944 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 166/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6880 - accuracy: 0.5485 - val_loss: 0.7200 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 167/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7070 - accuracy: 0.4667 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 168/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6882 - accuracy: 0.5548 - val_loss: 0.7010 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 169/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6836 - accuracy: 0.5490 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 170/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6942 - accuracy: 0.5312 - val_loss: 0.6935 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 171/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6912 - accuracy: 0.5217 - val_loss: 0.7893 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 172/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6832 - accuracy: 0.5665 - val_loss: 0.6927 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 173/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6870 - accuracy: 0.5562 - val_loss: 0.7190 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 174/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7056 - accuracy: 0.4712 - val_loss: 0.6920 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 175/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6915 - accuracy: 0.5412 - val_loss: 0.6945 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 176/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6803 - accuracy: 0.5670 - val_loss: 0.6957 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 177/625\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.6928 - accuracy: 0.5303 - val_loss: 0.7033 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 178/625\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.6974 - accuracy: 0.4978 - val_loss: 0.7467 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 179/625\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.6792 - accuracy: 0.5782 - val_loss: 0.6934 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 180/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6885 - accuracy: 0.5468 - val_loss: 0.6943 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 181/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6999 - accuracy: 0.4863 - val_loss: 0.7294 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 182/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6961 - accuracy: 0.5235 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 183/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6801 - accuracy: 0.5633 - val_loss: 0.6946 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 184/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6937 - accuracy: 0.5300 - val_loss: 0.6947 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 185/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7010 - accuracy: 0.4852 - val_loss: 0.6942 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 186/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6753 - accuracy: 0.5945 - val_loss: 0.6928 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 187/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6874 - accuracy: 0.5502 - val_loss: 0.6962 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 188/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7023 - accuracy: 0.4815 - val_loss: 0.6936 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 189/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6954 - accuracy: 0.5340 - val_loss: 0.6970 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 190/625\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6805 - accuracy: 0.5640 - val_loss: 0.6966 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 191/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6941 - accuracy: 0.5257 - val_loss: 0.6927 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 192/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7002 - accuracy: 0.4925 - val_loss: 0.6943 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 193/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6765 - accuracy: 0.5865 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 194/625\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.6871 - accuracy: 0.5450 - val_loss: 0.7051 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 195/625\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.7032 - accuracy: 0.4870 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 196/625\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.6956 - accuracy: 0.5203 - val_loss: 0.7022 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 197/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6800 - accuracy: 0.5640 - val_loss: 0.6955 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 198/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6920 - accuracy: 0.5380 - val_loss: 0.6990 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 199/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6998 - accuracy: 0.4960 - val_loss: 0.6957 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 200/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6725 - accuracy: 0.5975 - val_loss: 0.7120 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 201/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6904 - accuracy: 0.5362 - val_loss: 0.7135 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 202/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6998 - accuracy: 0.4997 - val_loss: 0.6926 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 203/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6944 - accuracy: 0.5257 - val_loss: 0.7195 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 204/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6809 - accuracy: 0.5740 - val_loss: 0.7112 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 205/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6871 - accuracy: 0.5472 - val_loss: 0.7327 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 206/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7064 - accuracy: 0.4745 - val_loss: 0.6926 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 207/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6684 - accuracy: 0.6020 - val_loss: 0.7449 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 208/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6899 - accuracy: 0.5400 - val_loss: 0.7354 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 209/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7035 - accuracy: 0.4890 - val_loss: 0.6930 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 210/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6953 - accuracy: 0.5203 - val_loss: 0.7083 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 211/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6769 - accuracy: 0.5820 - val_loss: 0.7326 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 212/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6916 - accuracy: 0.5372 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 213/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7039 - accuracy: 0.4890 - val_loss: 0.7065 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 214/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6654 - accuracy: 0.5993 - val_loss: 0.8090 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 215/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6996 - accuracy: 0.5290 - val_loss: 0.7178 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 216/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6994 - accuracy: 0.5035 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 217/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6987 - accuracy: 0.5042 - val_loss: 0.6969 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 218/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6768 - accuracy: 0.5750 - val_loss: 0.6955 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 219/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.6887 - accuracy: 0.5512 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 220/625\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.7035 - accuracy: 0.4700 - val_loss: 0.7152 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 221/625\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.6742 - accuracy: 0.5775 - val_loss: 0.7909 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 222/625\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.6964 - accuracy: 0.5350 - val_loss: 0.7050 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 223/625\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.6968 - accuracy: 0.5105 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 224/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6977 - accuracy: 0.4990 - val_loss: 0.7076 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 225/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6742 - accuracy: 0.5795 - val_loss: 0.6936 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 226/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6905 - accuracy: 0.5405 - val_loss: 0.7069 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 227/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7051 - accuracy: 0.4725 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 228/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6835 - accuracy: 0.5677 - val_loss: 0.7227 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 229/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6870 - accuracy: 0.5430 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 230/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6940 - accuracy: 0.5228 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 231/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6889 - accuracy: 0.5228 - val_loss: 0.7928 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 232/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6841 - accuracy: 0.5648 - val_loss: 0.6929 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 233/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6868 - accuracy: 0.5562 - val_loss: 0.7274 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 234/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7070 - accuracy: 0.4793 - val_loss: 0.6934 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 235/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6907 - accuracy: 0.5403 - val_loss: 0.6954 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 236/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6818 - accuracy: 0.5635 - val_loss: 0.6955 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 237/625\n",
      "1000/1000 [==============================] - 41s 42ms/step - loss: 0.6939 - accuracy: 0.5253 - val_loss: 0.6972 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 238/625\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.6944 - accuracy: 0.5120 - val_loss: 0.7728 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 239/625\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.6817 - accuracy: 0.5755 - val_loss: 0.6926 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 240/625\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.6892 - accuracy: 0.5502 - val_loss: 0.7025 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 241/625\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.7048 - accuracy: 0.4890 - val_loss: 0.7059 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 242/625\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.6931 - accuracy: 0.5397 - val_loss: 0.6932 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 243/625\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.6798 - accuracy: 0.5623 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 244/625\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.6937 - accuracy: 0.5285 - val_loss: 0.6982 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 245/625\n",
      "1000/1000 [==============================] - 55s 56ms/step - loss: 0.6992 - accuracy: 0.4945 - val_loss: 0.7117 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 246/625\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.6761 - accuracy: 0.5835 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 247/625\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.6888 - accuracy: 0.5493 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 248/625\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.7003 - accuracy: 0.4955 - val_loss: 0.7139 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 249/625\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.6972 - accuracy: 0.5240 - val_loss: 0.6940 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 250/625\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.6807 - accuracy: 0.5680 - val_loss: 0.6994 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 251/625\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.6938 - accuracy: 0.5240 - val_loss: 0.6925 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 252/625\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.7001 - accuracy: 0.4910 - val_loss: 0.6938 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 253/625\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.6765 - accuracy: 0.5840 - val_loss: 0.6932 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 254/625\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.6849 - accuracy: 0.5642 - val_loss: 0.7058 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 255/625\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.7030 - accuracy: 0.4848 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 256/625\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.6957 - accuracy: 0.5297 - val_loss: 0.6969 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 257/625\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.6794 - accuracy: 0.5680 - val_loss: 0.6937 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 258/625\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.6948 - accuracy: 0.5300 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 259/625\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.7002 - accuracy: 0.4942 - val_loss: 0.6963 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 260/625\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.6771 - accuracy: 0.5872 - val_loss: 0.6935 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 261/625\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.6875 - accuracy: 0.5525 - val_loss: 0.7051 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 262/625\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.7024 - accuracy: 0.4848 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 263/625\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.6930 - accuracy: 0.5315 - val_loss: 0.7104 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 264/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6706 - accuracy: 0.5623 - val_loss: 0.6999 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 265/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6898 - accuracy: 0.5437 - val_loss: 0.7281 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 266/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.7033 - accuracy: 0.4812 - val_loss: 0.6955 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 267/625\n",
      "1000/1000 [==============================] - 42s 43ms/step - loss: 0.6734 - accuracy: 0.5945 - val_loss: 0.7172 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 268/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6912 - accuracy: 0.5370 - val_loss: 0.7180 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 269/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.7010 - accuracy: 0.5048 - val_loss: 0.6908 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 270/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6957 - accuracy: 0.5173 - val_loss: 0.7235 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 271/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6785 - accuracy: 0.5730 - val_loss: 0.7266 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 272/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6872 - accuracy: 0.5527 - val_loss: 0.8548 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 273/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6942 - accuracy: 0.5205 - val_loss: 0.6955 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 274/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6667 - accuracy: 0.6008 - val_loss: 0.7902 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 275/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6950 - accuracy: 0.5393 - val_loss: 0.7220 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 276/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6997 - accuracy: 0.5002 - val_loss: 0.6901 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 277/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6940 - accuracy: 0.5278 - val_loss: 0.6973 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 278/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6695 - accuracy: 0.5867 - val_loss: 0.7194 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 279/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6893 - accuracy: 0.5362 - val_loss: 0.6937 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 280/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7044 - accuracy: 0.4775 - val_loss: 0.7128 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 281/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6697 - accuracy: 0.5897 - val_loss: 0.8129 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 282/625\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6979 - accuracy: 0.5280 - val_loss: 0.6991 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 283/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6948 - accuracy: 0.5110 - val_loss: 0.6932 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 284/625\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.6930 - accuracy: 0.5265 - val_loss: 0.6858 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 285/625\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.6570 - accuracy: 0.5860 - val_loss: 0.6797 - val_accuracy: 0.6396 - lr: 0.0010\n",
      "Epoch 286/625\n",
      "1000/1000 [==============================] - 42s 43ms/step - loss: 0.6607 - accuracy: 0.6130 - val_loss: 0.7264 - val_accuracy: 0.5515 - lr: 0.0010\n",
      "Epoch 287/625\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.6597 - accuracy: 0.6008 - val_loss: 0.8144 - val_accuracy: 0.4792 - lr: 0.0010\n",
      "Epoch 288/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.6365 - accuracy: 0.6357 - val_loss: 0.9521 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 289/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.6297 - accuracy: 0.6352 - val_loss: 0.6875 - val_accuracy: 0.5587 - lr: 0.0010\n",
      "Epoch 290/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.6491 - accuracy: 0.6242 - val_loss: 0.6612 - val_accuracy: 0.6494 - lr: 0.0010\n",
      "Epoch 291/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.6208 - accuracy: 0.6720 - val_loss: 0.6569 - val_accuracy: 0.5952 - lr: 0.0010\n",
      "Epoch 292/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.5905 - accuracy: 0.6870 - val_loss: 0.6150 - val_accuracy: 0.6533 - lr: 0.0010\n",
      "Epoch 293/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.6030 - accuracy: 0.6690 - val_loss: 0.6054 - val_accuracy: 0.7034 - lr: 0.0010\n",
      "Epoch 294/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.5755 - accuracy: 0.6995 - val_loss: 0.6110 - val_accuracy: 0.6710 - lr: 0.0010\n",
      "Epoch 295/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.6035 - accuracy: 0.6795 - val_loss: 0.6784 - val_accuracy: 0.6653 - lr: 0.0010\n",
      "Epoch 296/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.5802 - accuracy: 0.6795 - val_loss: 0.5596 - val_accuracy: 0.7028 - lr: 0.0010\n",
      "Epoch 297/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.5683 - accuracy: 0.7243 - val_loss: 0.6154 - val_accuracy: 0.6469 - lr: 0.0010\n",
      "Epoch 298/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.5542 - accuracy: 0.7308 - val_loss: 0.7601 - val_accuracy: 0.5637 - lr: 0.0010\n",
      "Epoch 299/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.5405 - accuracy: 0.7215 - val_loss: 0.5742 - val_accuracy: 0.6885 - lr: 0.0010\n",
      "Epoch 300/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.5447 - accuracy: 0.7230 - val_loss: 0.5095 - val_accuracy: 0.7507 - lr: 0.0010\n",
      "Epoch 301/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.5259 - accuracy: 0.7550 - val_loss: 0.5454 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 302/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.5482 - accuracy: 0.7287 - val_loss: 0.5224 - val_accuracy: 0.7440 - lr: 0.0010\n",
      "Epoch 303/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.5261 - accuracy: 0.7312 - val_loss: 0.5079 - val_accuracy: 0.7440 - lr: 0.0010\n",
      "Epoch 304/625\n",
      "1000/1000 [==============================] - 42s 43ms/step - loss: 0.4950 - accuracy: 0.7663 - val_loss: 0.5799 - val_accuracy: 0.6969 - lr: 0.0010\n",
      "Epoch 305/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.4769 - accuracy: 0.7832 - val_loss: 0.6426 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 306/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.5076 - accuracy: 0.7465 - val_loss: 0.5647 - val_accuracy: 0.7343 - lr: 0.0010\n",
      "Epoch 307/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.5120 - accuracy: 0.7500 - val_loss: 0.5367 - val_accuracy: 0.7678 - lr: 0.0010\n",
      "Epoch 308/625\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.4483 - accuracy: 0.8045 - val_loss: 0.7126 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 309/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.4995 - accuracy: 0.7625 - val_loss: 0.8512 - val_accuracy: 0.4964 - lr: 0.0010\n",
      "Epoch 310/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.5254 - accuracy: 0.7360 - val_loss: 0.4901 - val_accuracy: 0.7710 - lr: 0.0010\n",
      "Epoch 311/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.4576 - accuracy: 0.7983 - val_loss: 0.6082 - val_accuracy: 0.6642 - lr: 0.0010\n",
      "Epoch 312/625\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.4652 - accuracy: 0.7908 - val_loss: 0.8602 - val_accuracy: 0.5593 - lr: 0.0010\n",
      "Epoch 313/625\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.5029 - accuracy: 0.7620 - val_loss: 0.4725 - val_accuracy: 0.7728 - lr: 0.0010\n",
      "Epoch 314/625\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.5001 - accuracy: 0.7575 - val_loss: 0.4970 - val_accuracy: 0.7937 - lr: 0.0010\n",
      "Epoch 315/625\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 0.4195 - accuracy: 0.8166"
     ]
    }
   ],
   "source": [
    "for i, (train, val) in enumerate(folds):\n",
    "    \n",
    "    model = createModel()\n",
    "    \n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.95)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    metrics = ['accuracy']\n",
    "    \n",
    "    model.compile(optimizer=opt, loss=loss, metrics=metrics)\n",
    "    \n",
    "    tboardCb = tf.keras.callbacks.TensorBoard(log_dir=f\"{logBasePath}/{logPrefix}_{i}\", histogram_freq=1, profile_batch=(2,10))\n",
    "    lrSchedule = tf.keras.callbacks.LearningRateScheduler(schedule)\n",
    "    \n",
    "    cbs = [tboardCb, lrSchedule]\n",
    "    \n",
    "    model.evaluate(val)\n",
    "    model.fit(train, initial_epoch=START_EPOCH, epochs=END_EPOCH, steps_per_epoch=STEPS_PER_EPOCH, callbacks=cbs, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e841a27f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e20b04dd985343179d8656fb1930f451adca8610422f13b5e4759b9499c407bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
