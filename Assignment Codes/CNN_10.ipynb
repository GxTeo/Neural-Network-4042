{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f19017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d782ddf",
   "metadata": {},
   "source": [
    "### Check Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03faa827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac4996",
   "metadata": {},
   "source": [
    "### GPU Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1e955b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 04:24:51.509935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 04:24:51.515951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 04:24:51.516250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2835bd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f935a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be867b6",
   "metadata": {},
   "source": [
    "### Pandas Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92db292",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_column', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0907c",
   "metadata": {},
   "source": [
    "### Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0fd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VAL_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc35c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_WIDTH = 227\n",
    "CROP_HEIGHT = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d40847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldFiles = [\"adience/unprocessed/fold_0_data.txt\",\n",
    "             \"adience/unprocessed/fold_1_data.txt\",\n",
    "             \"adience/unprocessed/fold_2_data.txt\",\n",
    "             \"adience/unprocessed/fold_3_data.txt\",\n",
    "             \"adience/unprocessed/fold_4_data.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f61c7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genderMap = defaultdict(lambda : np.NaN)\n",
    "genderMap['m'] = 0\n",
    "genderMap['f'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d26242",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = ['(0, 2)', '(4, 6)', '(8, 13)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
    "ageMap = defaultdict(lambda : np.NaN)\n",
    "for i,a in enumerate(ages):\n",
    "    ageMap[a] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b1fc3",
   "metadata": {},
   "source": [
    "### Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd634a3",
   "metadata": {},
   "source": [
    "Dataset generation pipeline:\n",
    "Input: \n",
    "- foldFile - Path to fold file. Fold file Describes which images are in the fold and its corresponding labels\n",
    "- imgBaseFolder - Base folder to search image from\n",
    "- imgPrefix - Prefix of image file\n",
    "- genderMap - Map from ['m', 'f', 'u', None], to one hot index\n",
    "- ageMap - Map from age category to one hot index\n",
    "- imgWidth - Resulting image width\n",
    "- imgHeigh - Resulting image height\n",
    "- batchSize - Int or None, batch size\n",
    "- configureDs - Function accepting dataset for performance configurations\n",
    "- preBatch - List of (name, functions) pair that will be mapped before batching. name is used as name parameters for tf graph \n",
    "- postBatch - List of (name, functions) that will be mapped after batching. name is used as name parameters for tf graph\n",
    "\n",
    "The processing functions should have signature function(img, label) -> (img, label)\n",
    "\n",
    "Pipeline\n",
    "\n",
    "Read Fold File -> Preprocess filename and labels (dataframe) -> Convert filename and labels to numpy array -> Convert filename and labels to tf dataset -> Parse images and labels -> Configure Dataset for performance -> Pre-Batching preprocessing -> Batch -> Post-Batching preprocessing -> Output\n",
    "\n",
    "Some preprocessing steps can only be done before and some can only be done after batching, thats why there are seperated pre and post batching list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0795464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, batchSize, configureDs=None, preBatch=[], postBatch=[]):\n",
    "    \n",
    "    def parseImage(filename):\n",
    "        img = tf.io.read_file(filename)\n",
    "        img = tf.image.decode_jpeg(img)\n",
    "        img = tf.image.resize(img, [imgHeight, imgWidth])\n",
    "         \n",
    "        return img\n",
    "    \n",
    "    # Read Fold File\n",
    "    foldData = []\n",
    "    for f in foldFiles:\n",
    "        foldData.append(pd.read_csv(f, sep=\"\\t\"))\n",
    "    foldData = pd.concat(foldData)\n",
    "    \n",
    "    # Form File Name\n",
    "    foldData['filename'] = foldData.apply(lambda r: os.path.join(imgBaseFolder, r['user_id'], f\"{imgPrefix}.{r['face_id']}.{r['original_image']}\"), axis=1)\n",
    "    \n",
    "    # Generate Label One Hot Index\n",
    "    foldData['gender_ind'] = foldData['gender'].map(genderMap)\n",
    "    foldData['age_ind'] = foldData['age'].map(ageMap)\n",
    "    \n",
    "    # Remove dirty data\n",
    "    foldData.dropna(subset=['gender_ind', 'age_ind'], inplace=True)\n",
    "    \n",
    "    # Dataframe to numpy\n",
    "    filenames = foldData['filename'].to_numpy()\n",
    "    \n",
    "    genderIndex = foldData['gender_ind'].to_numpy().astype(int)\n",
    "    ageIndex = foldData['age_ind'].to_numpy().astype(int)\n",
    "    \n",
    "    # Numpy to Dataset\n",
    "    fnDs = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    genderIndDs = tf.data.Dataset.from_tensor_slices(genderIndex)\n",
    "    ageIndDs = tf.data.Dataset.from_tensor_slices(ageIndex)\n",
    "    \n",
    "    # Parse Images\n",
    "    imageDs = fnDs.map(parseImage, num_parallel_calls=tf.data.AUTOTUNE, name=\"parse_image\")\n",
    "    \n",
    "    # Parse Labels\n",
    "    genderLabDs = genderIndDs.map(lambda x: tf.one_hot(x, genderDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"gender_one_hot\")\n",
    "    ageLabDs = ageIndDs.map(lambda x: tf.one_hot(x, ageDepth), num_parallel_calls=tf.data.AUTOTUNE, name=\"age_one_hot\")\n",
    "    \n",
    "    # Combine Labels\n",
    "    labelDs = tf.data.Dataset.zip((genderLabDs, ageLabDs), name=\"label_zip\")\n",
    "    labelDs = labelDs.map(lambda g,a: {\"gender\": g, \"age\": a}, num_parallel_calls=tf.data.AUTOTUNE, name='label_dict')\n",
    "    \n",
    "    # Combine Images and Labels into dataset\n",
    "    ds = tf.data.Dataset.zip((imageDs, labelDs))\n",
    "    \n",
    "    # Configure Performance\n",
    "    if(configureDs is not None):\n",
    "        ds = configureDs(ds)\n",
    "    \n",
    "    # Pre Batch Preprocessing\n",
    "    for n,f in preBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    # Batch\n",
    "    if(batchSize is not None):\n",
    "        ds = ds.batch(batchSize, name=\"ds_batch\")\n",
    "    \n",
    "    # Post Batch Preprocessing\n",
    "    for n,f in postBatch:\n",
    "        ds = ds.map(f, num_parallel_calls=tf.data.AUTOTUNE, name=n)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320ed92",
   "metadata": {},
   "source": [
    "### Preprocessings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "472b7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=100)\n",
    "    ds = ds.repeat()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adf288f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valConfigPerformance(ds):\n",
    "    #ds = ds.cache()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc4fe2f",
   "metadata": {},
   "source": [
    "#### Preprocessing steps according to the reference paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7724a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainPreprocessA(img, lab):\n",
    "        \n",
    "        # img = tf.image.random_crop(img, [CROP_HEIGHT, CROP_WIDTH, 3])\n",
    "        \n",
    "        ud = tf.random.uniform([], dtype=tf.float32)\n",
    "        udCond = tf.less(ud, 0.5)\n",
    "        \n",
    "        img = tf.cond(udCond, lambda: tf.image.flip_up_down(img), lambda: img)\n",
    "        \n",
    "        lr = tf.random.uniform([], dtype=tf.float32)\n",
    "        lrCond = tf.less(lr, 0.5)\n",
    "        \n",
    "        img = tf.cond(lrCond, lambda: tf.image.flip_left_right(img), lambda: img)\n",
    "        \n",
    "        img = tf.image.random_brightness(img, 63/255)\n",
    "        \n",
    "        img = tf.image.random_contrast(img, 0.2, 1.8) \n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0402726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valPreprocessA(img, lab):\n",
    "        \n",
    "        img = tf.image.crop_to_bounding_box(img,\n",
    "                                            (IMG_HEIGHT-CROP_HEIGHT) // 2,\n",
    "                                            (IMG_WIDTH-CROP_WIDTH) // 2,\n",
    "                                            CROP_HEIGHT,\n",
    "                                            CROP_WIDTH)\n",
    "        \n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f32b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageStandardize(img, lab):\n",
    "    \n",
    "    img = tf.image.per_image_standardization(img)\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f134a",
   "metadata": {},
   "source": [
    "#### Label extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "633c4277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractGenderLabel(img, lab):\n",
    "    \n",
    "    lab = lab['gender']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88b8b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAgeLabel(img, lab):\n",
    "    \n",
    "    lab = lab['age']\n",
    "    \n",
    "    return img, lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7778c",
   "metadata": {},
   "source": [
    "### Generate Folds for K-Folds validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4172d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFoldDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, valBatchSize, trainConfigureDs=None, trainPreBatch=[], trainPostBatch=[], valConfigureDs=None, valPreBatch=[], valPostBatch=[]):\n",
    "    '''\n",
    "        Returns list of (train, validation) datasets\n",
    "    '''\n",
    "    \n",
    "    N = len(foldFiles)\n",
    "    \n",
    "    folds = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        trainFiles = foldFiles[:i]\n",
    "        if(i < N-1):\n",
    "            trainFiles.extend(foldFiles[i+1:])\n",
    "            \n",
    "        valFiles = foldFiles[i]\n",
    "        \n",
    "        trainDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, trainBatchSize, configureDs=trainConfigureDs, preBatch=trainPreBatch, postBatch=trainPostBatch)\n",
    "        valDs = generateDs(foldFiles, imgBaseFolder, imgPrefix, genderMap, ageMap, genderDepth, ageDepth, imgWidth, imgHeight, valBatchSize, configureDs=valConfigureDs, preBatch=valPreBatch, postBatch=valPostBatch)\n",
    "        \n",
    "        folds.append((trainDs, valDs))\n",
    "        \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beffce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPreBatch = [(\"train_process_a\", trainPreprocessA),\n",
    "                 (\"train_extract_gender\", extractGenderLabel)]\n",
    "\n",
    "valPreBatch = [(\"val_extract_gender\", extractGenderLabel)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10474d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 04:24:51.764387: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-10 04:24:51.765151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 04:24:51.765392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 04:24:51.765587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 04:24:52.037983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 04:24:52.038197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 04:24:52.038370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 04:24:52.038535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 663 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:2d:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "folds = generateFoldDs(foldFiles, \"adience/faces\", \"coarse_tilt_aligned_face\", genderMap, ageMap, 2, 8, \n",
    "                       IMG_WIDTH, IMG_HEIGHT, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE, \n",
    "                       trainConfigureDs=trainConfigPerformance, trainPreBatch=trainPreBatch, \n",
    "                       valConfigureDs=valConfigPerformance, valPreBatch=valPreBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57d814af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7974f8fe",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b67fe33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in folds[0][0].take(1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8aa8d0d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 256, 256, 3), dtype=float32, numpy=\n",
       "array([[[[159.72015  , 150.28152  , 148.81667  ],\n",
       "         [158.30792  , 148.8693   , 147.40443  ],\n",
       "         [158.3232   , 148.88457  , 147.41972  ],\n",
       "         ...,\n",
       "         [161.32281  , 154.92259  , 157.10382  ],\n",
       "         [161.30641  , 154.90619  , 157.08743  ],\n",
       "         [159.92096  , 153.52074  , 155.70197  ]],\n",
       "\n",
       "        [[157.13528  , 147.69191  , 146.22705  ],\n",
       "         [158.1836   , 148.74022  , 147.27536  ],\n",
       "         [157.46635  , 148.02298  , 146.55812  ],\n",
       "         ...,\n",
       "         [162.79521  , 156.39499  , 158.57622  ],\n",
       "         [160.234    , 153.83377  , 156.01501  ],\n",
       "         [161.05673  , 154.65651  , 156.83774  ]],\n",
       "\n",
       "        [[156.27933  , 146.53685  , 145.07199  ],\n",
       "         [156.98195  , 147.23949  , 145.77463  ],\n",
       "         [155.19955  , 145.45709  , 143.99223  ],\n",
       "         ...,\n",
       "         [163.05402  , 156.6538   , 158.83504  ],\n",
       "         [161.542    , 154.9473   , 157.22577  ],\n",
       "         [159.92868  , 153.31006  , 155.6005   ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 93.5125   ,  92.55766  , 119.76302  ],\n",
       "         [ 93.87085  ,  92.36531  , 119.66563  ],\n",
       "         [ 94.81331  ,  93.57838  , 120.066864 ],\n",
       "         ...,\n",
       "         [146.58015  , 139.27791  , 142.214    ],\n",
       "         [147.53197  , 140.4576   , 143.27974  ],\n",
       "         [146.80804  , 139.80014  , 142.58905  ]],\n",
       "\n",
       "        [[ 93.57473  ,  92.94748  , 120.04364  ],\n",
       "         [ 93.85958  ,  93.218605 , 120.31796  ],\n",
       "         [ 93.84941  ,  92.750015 , 119.990906 ],\n",
       "         ...,\n",
       "         [145.93436  , 138.6321   , 141.56819  ],\n",
       "         [144.03972  , 136.96535  , 139.7875   ],\n",
       "         [145.66107  , 138.65317  , 141.44208  ]],\n",
       "\n",
       "        [[ 94.24502  ,  93.61777  , 121.01778  ],\n",
       "         [ 94.02048  ,  93.39323  , 120.48939  ],\n",
       "         [ 94.27128  ,  93.64403  , 120.74019  ],\n",
       "         ...,\n",
       "         [146.53825  , 139.236    , 142.17209  ],\n",
       "         [144.64177  , 137.5674   , 140.38954  ],\n",
       "         [145.4645   , 138.45659  , 141.24551  ]]],\n",
       "\n",
       "\n",
       "       [[[-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         ...,\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ]],\n",
       "\n",
       "        [[-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         ...,\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ]],\n",
       "\n",
       "        [[-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         ...,\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         ...,\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ]],\n",
       "\n",
       "        [[-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         ...,\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ]],\n",
       "\n",
       "        [[-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         ...,\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ],\n",
       "         [-21.18084  , -17.602379 , -14.498077 ]]],\n",
       "\n",
       "\n",
       "       [[[ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         ...,\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ]],\n",
       "\n",
       "        [[ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         ...,\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ]],\n",
       "\n",
       "        [[ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         ...,\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         ...,\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ]],\n",
       "\n",
       "        [[ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         ...,\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ]],\n",
       "\n",
       "        [[ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         ...,\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ],\n",
       "         [ 55.324753 ,  45.825863 ,  34.785286 ]]],\n",
       "\n",
       "\n",
       "       [[[ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         ...,\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ]],\n",
       "\n",
       "        [[ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         ...,\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ]],\n",
       "\n",
       "        [[ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         ...,\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         ...,\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ]],\n",
       "\n",
       "        [[ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         ...,\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ]],\n",
       "\n",
       "        [[ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         ...,\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ],\n",
       "         [ -5.5579147,  -4.814415 ,  -3.937584 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d84b1683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e25507c",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ee495a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    inp = tf.keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "    conv1 = tf.keras.layers.Conv2D(96, 7, strides=(4,4), activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='conv1')\n",
    "    pool1 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, name='pool1')\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv2D(256, 5, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='conv2')\n",
    "    pool2 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, name='pool2')\n",
    "\n",
    "    conv3 = tf.keras.layers.Conv2D(384, 3, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='conv3')\n",
    "    pool3 = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, name='pool3')\n",
    "\n",
    "    flat1 = tf.keras.layers.Flatten(name='flat1')\n",
    "    fc1 = tf.keras.layers.Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc1')\n",
    "    do1 = tf.keras.layers.Dropout(0.5, name='do1')\n",
    "\n",
    "    fc2 = tf.keras.layers.Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.005), bias_initializer='ones', name='fc2')\n",
    "    do2 = tf.keras.layers.Dropout(0.5, name='do2')\n",
    "\n",
    "    fc3 = tf.keras.layers.Dense(2, activation='softmax', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), name='fc3')\n",
    "\n",
    "    o = tf.keras.layers.Rescaling(1.0/255.0, name='pre_rescale')(inp)\n",
    "    o = tf.keras.layers.Normalization(axis=3, name='pre_norm')(o)\n",
    "    o = conv1(o)\n",
    "    o = pool1(o)\n",
    "    o = tf.nn.local_response_normalization(o, depth_radius=5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    o = tf.pad(o, [[0, 0], [2, 2], [2, 2], [0, 0]])\n",
    "    o = conv2(o)\n",
    "    o = pool2(o)\n",
    "    o = tf.nn.local_response_normalization(o, depth_radius=5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    o = tf.pad(o, [[0, 0], [1, 1], [1, 1], [0, 0]])\n",
    "    o = conv3(o)\n",
    "    o = pool3(o)\n",
    "    o = tf.nn.local_response_normalization(o, depth_radius=5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    o = flat1(o)\n",
    "    o = fc1(o)\n",
    "    o = do1(o)\n",
    "\n",
    "\n",
    "    o = fc2(o)\n",
    "    o = do2(o)\n",
    "\n",
    "    o = fc3(o)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=o, name='cnn_10')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e962234",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b73a21c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " pre_rescale (Rescaling)     (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " pre_norm (Normalization)    (None, 256, 256, 3)       7         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 63, 63, 96)        14208     \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 31, 31, 96)        0         \n",
      "                                                                 \n",
      " tf.nn.local_response_normal  (None, 31, 31, 96)       0         \n",
      " ization (TFOpLambda)                                            \n",
      "                                                                 \n",
      " tf.compat.v1.pad (TFOpLambd  (None, 35, 35, 96)       0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 31, 31, 256)       614656    \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 15, 15, 256)       0         \n",
      "                                                                 \n",
      " tf.nn.local_response_normal  (None, 15, 15, 256)      0         \n",
      " ization_1 (TFOpLambda)                                          \n",
      "                                                                 \n",
      " tf.compat.v1.pad_1 (TFOpLam  (None, 17, 17, 256)      0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 15, 15, 384)       885120    \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 7, 7, 384)         0         \n",
      "                                                                 \n",
      " tf.nn.local_response_normal  (None, 7, 7, 384)        0         \n",
      " ization_2 (TFOpLambda)                                          \n",
      "                                                                 \n",
      " flat1 (Flatten)             (None, 18816)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 512)               9634304   \n",
      "                                                                 \n",
      " do1 (Dropout)               (None, 512)               0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 512)               262656    \n",
      "                                                                 \n",
      " do2 (Dropout)               (None, 512)               0         \n",
      "                                                                 \n",
      " fc3 (Dense)                 (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,411,977\n",
      "Trainable params: 11,411,970\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea1227d",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c5f7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = 1000\n",
    "\n",
    "EPOCH = 300\n",
    "\n",
    "START_EPOCH = 0\n",
    "END_EPOCH = START_EPOCH + EPOCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96be5cb2",
   "metadata": {},
   "source": [
    "#### Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55ee49a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(epoch, lr):\n",
    "    if(epoch == 10000*50//STEPS_PER_EPOCH):\n",
    "        return lr * 0.1\n",
    "    else:\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f41e8947",
   "metadata": {},
   "outputs": [],
   "source": [
    "logBasePath = \"log/CNN_10\"\n",
    "logPrefix = \"log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75efb222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 04:24:54.365293: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-10 04:24:54.365317: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-10 04:24:54.365339: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1665] Profiler found 1 GPUs\n",
      "2022-11-10 04:24:54.445791: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-10 04:24:54.447159: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-11-10 04:24:55.001113: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  54/3528 [..............................] - ETA: 10s - loss: 0.7475 - accuracy: 0.3889  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 04:24:55.793212: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 822.72MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-10 04:24:55.793345: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 822.72MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-10 04:24:55.802883: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 843.88MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-10 04:24:55.802902: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 843.88MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-10 04:24:55.804301: W tensorflow/core/common_runtime/bfc_allocator.cc:360] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2022-11-10 04:24:55.828324: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528/3528 [==============================] - 11s 3ms/step - loss: 0.7003 - accuracy: 0.5232\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 04:25:05.351712: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 819.62MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-10 04:25:05.351752: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 819.62MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-10 04:25:05.360519: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 841.75MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-10 04:25:05.360546: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 841.75MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "   1/1000 [..............................] - ETA: 7:41 - loss: 0.6197 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 04:25:05.830688: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 848.12MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-10 04:25:05.830726: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 848.12MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-11-10 04:25:05.871786: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-10 04:25:05.871804: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  19/1000 [..............................] - ETA: 35s - loss: 0.7524 - accuracy: 0.5526 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 04:25:06.346126: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-10 04:25:06.346799: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-11-10 04:25:06.371789: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 1680 callback api events and 1655 activity events. \n",
      "2022-11-10 04:25:06.388444: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-10 04:25:06.404558: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/CNN_10/log_0/plugins/profile/2022_11_10_04_25_06\n",
      "\n",
      "2022-11-10 04:25:06.431211: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to log/CNN_10/log_0/plugins/profile/2022_11_10_04_25_06/rachanon-pc1.trace.json.gz\n",
      "2022-11-10 04:25:06.457168: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: log/CNN_10/log_0/plugins/profile/2022_11_10_04_25_06\n",
      "\n",
      "2022-11-10 04:25:06.461423: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to log/CNN_10/log_0/plugins/profile/2022_11_10_04_25_06/rachanon-pc1.memory_profile.json.gz\n",
      "2022-11-10 04:25:06.461907: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: log/CNN_10/log_0/plugins/profile/2022_11_10_04_25_06\n",
      "Dumped tool data for xplane.pb to log/CNN_10/log_0/plugins/profile/2022_11_10_04_25_06/rachanon-pc1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to log/CNN_10/log_0/plugins/profile/2022_11_10_04_25_06/rachanon-pc1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to log/CNN_10/log_0/plugins/profile/2022_11_10_04_25_06/rachanon-pc1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to log/CNN_10/log_0/plugins/profile/2022_11_10_04_25_06/rachanon-pc1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to log/CNN_10/log_0/plugins/profile/2022_11_10_04_25_06/rachanon-pc1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 995/1000 [============================>.] - ETA: 0s - loss: 0.7247 - accuracy: 0.5749"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 04:25:20.668175: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 16s 15ms/step - loss: 0.7246 - accuracy: 0.5745 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 2/300\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 0.6666 - accuracy: 0.6047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 04:25:35.449509: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6667 - accuracy: 0.6040 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 3/300\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 0.6612 - accuracy: 0.5889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 04:25:50.030179: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6614 - accuracy: 0.5878 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 4/300\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 0.6790 - accuracy: 0.5864"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 04:26:04.750335: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6788 - accuracy: 0.5867 - val_loss: 0.7192 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 5/300\n",
      " 991/1000 [============================>.] - ETA: 0s - loss: 0.6957 - accuracy: 0.5116"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 04:26:19.400822: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2312110080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6955 - accuracy: 0.5128 - val_loss: 0.6928 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6614 - accuracy: 0.6050 - val_loss: 0.7020 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6831 - accuracy: 0.5535 - val_loss: 0.6967 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6952 - accuracy: 0.5155 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6829 - accuracy: 0.5380 - val_loss: 0.6951 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6690 - accuracy: 0.5648 - val_loss: 0.6928 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6860 - accuracy: 0.5558 - val_loss: 0.7004 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6958 - accuracy: 0.4967 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6586 - accuracy: 0.6133 - val_loss: 0.6946 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6840 - accuracy: 0.5500 - val_loss: 0.7018 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6959 - accuracy: 0.5015 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6886 - accuracy: 0.5378 - val_loss: 0.6954 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6709 - accuracy: 0.5770 - val_loss: 0.6966 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6872 - accuracy: 0.5418 - val_loss: 0.6946 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6958 - accuracy: 0.5050 - val_loss: 0.6966 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6568 - accuracy: 0.6045 - val_loss: 0.7188 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6865 - accuracy: 0.5380 - val_loss: 0.7554 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6931 - accuracy: 0.5173 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6874 - accuracy: 0.5255 - val_loss: 0.6957 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6726 - accuracy: 0.5828 - val_loss: 0.8137 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6890 - accuracy: 0.5405 - val_loss: 0.6929 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6972 - accuracy: 0.4880 - val_loss: 0.6994 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6703 - accuracy: 0.5853 - val_loss: 0.7678 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6908 - accuracy: 0.5357 - val_loss: 0.6985 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6915 - accuracy: 0.5228 - val_loss: 0.6935 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6903 - accuracy: 0.5185 - val_loss: 0.7443 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6764 - accuracy: 0.5855 - val_loss: 0.6926 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6859 - accuracy: 0.5470 - val_loss: 0.6931 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6932 - accuracy: 0.5070 - val_loss: 0.6998 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6797 - accuracy: 0.5667 - val_loss: 0.8016 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6872 - accuracy: 0.5452 - val_loss: 0.6935 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6880 - accuracy: 0.5450 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 37/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6887 - accuracy: 0.5238 - val_loss: 0.7081 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 38/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6692 - accuracy: 0.5857 - val_loss: 0.6938 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 39/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6846 - accuracy: 0.5483 - val_loss: 0.7030 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 40/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6976 - accuracy: 0.4793 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 41/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6876 - accuracy: 0.5485 - val_loss: 0.6956 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 42/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6796 - accuracy: 0.5537 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 43/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6877 - accuracy: 0.5365 - val_loss: 0.6934 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 44/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6892 - accuracy: 0.5235 - val_loss: 0.7599 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 45/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6784 - accuracy: 0.5702 - val_loss: 0.6936 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 46/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6884 - accuracy: 0.5340 - val_loss: 0.6964 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 47/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6960 - accuracy: 0.4927 - val_loss: 0.6925 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 48/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6831 - accuracy: 0.5485 - val_loss: 0.6955 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 49/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6776 - accuracy: 0.5605 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 50/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6908 - accuracy: 0.5263 - val_loss: 0.6991 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 51/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6934 - accuracy: 0.5023 - val_loss: 0.7257 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 52/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6723 - accuracy: 0.5853 - val_loss: 0.6933 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 53/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6877 - accuracy: 0.5418 - val_loss: 0.7110 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 54/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6901 - accuracy: 0.5245 - val_loss: 0.7077 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 55/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6911 - accuracy: 0.5225 - val_loss: 0.6922 - val_accuracy: 0.5232 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6800 - accuracy: 0.5617 - val_loss: 0.6944 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 57/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6886 - accuracy: 0.5403 - val_loss: 0.6955 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 58/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6957 - accuracy: 0.4893 - val_loss: 0.6943 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 59/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6664 - accuracy: 0.6005 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 60/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6857 - accuracy: 0.5590 - val_loss: 0.6934 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 61/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6954 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5471 - lr: 0.0010\n",
      "Epoch 62/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6867 - accuracy: 0.5540 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 63/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6676 - accuracy: 0.5770 - val_loss: 0.6938 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 64/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6822 - accuracy: 0.5773 - val_loss: 0.6930 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 65/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6933 - accuracy: 0.5225 - val_loss: 0.6924 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 66/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6602 - accuracy: 0.6015 - val_loss: 0.6838 - val_accuracy: 0.5611 - lr: 0.0010\n",
      "Epoch 67/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6799 - accuracy: 0.5727 - val_loss: 0.7068 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 68/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6970 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 69/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6862 - accuracy: 0.5365 - val_loss: 0.6940 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 70/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6641 - accuracy: 0.5962 - val_loss: 0.6931 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 71/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6724 - accuracy: 0.5925 - val_loss: 0.7934 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 72/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6723 - accuracy: 0.5880 - val_loss: 0.6987 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 73/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6385 - accuracy: 0.6417 - val_loss: 0.6978 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 74/300\n",
      "1000/1000 [==============================] - 14s 15ms/step - loss: 0.6741 - accuracy: 0.5847 - val_loss: 0.6973 - val_accuracy: 0.5230 - lr: 0.0010\n",
      "Epoch 75/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6750 - accuracy: 0.5665 - val_loss: 0.6873 - val_accuracy: 0.5459 - lr: 0.0010\n",
      "Epoch 76/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6490 - accuracy: 0.6342 - val_loss: 0.6980 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 77/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6634 - accuracy: 0.5968 - val_loss: 0.6905 - val_accuracy: 0.5234 - lr: 0.0010\n",
      "Epoch 78/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6645 - accuracy: 0.6087 - val_loss: 0.7665 - val_accuracy: 0.4818 - lr: 0.0010\n",
      "Epoch 79/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6692 - accuracy: 0.5803 - val_loss: 0.6999 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 80/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6401 - accuracy: 0.6325 - val_loss: 0.6888 - val_accuracy: 0.5235 - lr: 0.0010\n",
      "Epoch 81/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6727 - accuracy: 0.5903 - val_loss: 0.7414 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 82/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6688 - accuracy: 0.5882 - val_loss: 0.6920 - val_accuracy: 0.5231 - lr: 0.0010\n",
      "Epoch 83/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6704 - accuracy: 0.5828 - val_loss: 0.7670 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 84/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6668 - accuracy: 0.6055 - val_loss: 0.6972 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 85/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6864 - accuracy: 0.5462 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 86/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6946 - accuracy: 0.5023 - val_loss: 0.6997 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 87/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6712 - accuracy: 0.5863 - val_loss: 0.7472 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 88/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6980 - accuracy: 0.5263 - val_loss: 0.6999 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 89/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6936 - accuracy: 0.5065 - val_loss: 0.6925 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 90/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6933 - accuracy: 0.5123 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 91/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6789 - accuracy: 0.5785 - val_loss: 0.6923 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 92/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6892 - accuracy: 0.5362 - val_loss: 0.6921 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 93/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6959 - accuracy: 0.4888 - val_loss: 0.7031 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 94/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6689 - accuracy: 0.5815 - val_loss: 0.8061 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 95/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6679 - accuracy: 0.5918 - val_loss: 0.7034 - val_accuracy: 0.5308 - lr: 0.0010\n",
      "Epoch 96/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6677 - accuracy: 0.6075 - val_loss: 0.7271 - val_accuracy: 0.5098 - lr: 0.0010\n",
      "Epoch 97/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6359 - accuracy: 0.6435 - val_loss: 0.8747 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 98/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6377 - accuracy: 0.6455 - val_loss: 0.6683 - val_accuracy: 0.5931 - lr: 0.0010\n",
      "Epoch 99/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6621 - accuracy: 0.6125 - val_loss: 0.7015 - val_accuracy: 0.5240 - lr: 0.0010\n",
      "Epoch 100/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6461 - accuracy: 0.6148 - val_loss: 0.6816 - val_accuracy: 0.5967 - lr: 0.0010\n",
      "Epoch 101/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6376 - accuracy: 0.6478 - val_loss: 0.8065 - val_accuracy: 0.5234 - lr: 0.0010\n",
      "Epoch 102/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6306 - accuracy: 0.6467 - val_loss: 0.6450 - val_accuracy: 0.6292 - lr: 0.0010\n",
      "Epoch 103/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6394 - accuracy: 0.6378 - val_loss: 0.6523 - val_accuracy: 0.6121 - lr: 0.0010\n",
      "Epoch 104/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6135 - accuracy: 0.6735 - val_loss: 0.7290 - val_accuracy: 0.5577 - lr: 0.0010\n",
      "Epoch 105/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6040 - accuracy: 0.6800 - val_loss: 0.6362 - val_accuracy: 0.6317 - lr: 0.0010\n",
      "Epoch 106/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6421 - accuracy: 0.6345 - val_loss: 0.6984 - val_accuracy: 0.5198 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6222 - accuracy: 0.6557 - val_loss: 0.6719 - val_accuracy: 0.5687 - lr: 0.0010\n",
      "Epoch 108/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6236 - accuracy: 0.6700 - val_loss: 0.6402 - val_accuracy: 0.6345 - lr: 0.0010\n",
      "Epoch 109/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5933 - accuracy: 0.6917 - val_loss: 0.6503 - val_accuracy: 0.6228 - lr: 0.0010\n",
      "Epoch 110/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6073 - accuracy: 0.6752 - val_loss: 0.6202 - val_accuracy: 0.6481 - lr: 0.0010\n",
      "Epoch 111/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5882 - accuracy: 0.6865 - val_loss: 0.6652 - val_accuracy: 0.6496 - lr: 0.0010\n",
      "Epoch 112/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5927 - accuracy: 0.6850 - val_loss: 0.6213 - val_accuracy: 0.6479 - lr: 0.0010\n",
      "Epoch 113/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6043 - accuracy: 0.6690 - val_loss: 0.6151 - val_accuracy: 0.6809 - lr: 0.0010\n",
      "Epoch 114/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5689 - accuracy: 0.7020 - val_loss: 0.7536 - val_accuracy: 0.5394 - lr: 0.0010\n",
      "Epoch 115/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5834 - accuracy: 0.6995 - val_loss: 0.6373 - val_accuracy: 0.5893 - lr: 0.0010\n",
      "Epoch 116/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5641 - accuracy: 0.7038 - val_loss: 0.5932 - val_accuracy: 0.6725 - lr: 0.0010\n",
      "Epoch 117/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5541 - accuracy: 0.7255 - val_loss: 0.6829 - val_accuracy: 0.6546 - lr: 0.0010\n",
      "Epoch 118/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5475 - accuracy: 0.7210 - val_loss: 1.2202 - val_accuracy: 0.5484 - lr: 0.0010\n",
      "Epoch 119/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5498 - accuracy: 0.7235 - val_loss: 0.5793 - val_accuracy: 0.6850 - lr: 0.0010\n",
      "Epoch 120/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5733 - accuracy: 0.7020 - val_loss: 0.5948 - val_accuracy: 0.7027 - lr: 0.0010\n",
      "Epoch 121/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5137 - accuracy: 0.7442 - val_loss: 0.9081 - val_accuracy: 0.6513 - lr: 0.0010\n",
      "Epoch 122/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5430 - accuracy: 0.7318 - val_loss: 0.5394 - val_accuracy: 0.7329 - lr: 0.0010\n",
      "Epoch 123/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5538 - accuracy: 0.7095 - val_loss: 0.5790 - val_accuracy: 0.7010 - lr: 0.0010\n",
      "Epoch 124/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5020 - accuracy: 0.7515 - val_loss: 0.5487 - val_accuracy: 0.7169 - lr: 0.0010\n",
      "Epoch 125/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5137 - accuracy: 0.7435 - val_loss: 0.5801 - val_accuracy: 0.7072 - lr: 0.0010\n",
      "Epoch 126/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5157 - accuracy: 0.7473 - val_loss: 0.5413 - val_accuracy: 0.7307 - lr: 0.0010\n",
      "Epoch 127/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5407 - accuracy: 0.7293 - val_loss: 0.6879 - val_accuracy: 0.6137 - lr: 0.0010\n",
      "Epoch 128/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4953 - accuracy: 0.7598 - val_loss: 0.5179 - val_accuracy: 0.7501 - lr: 0.0010\n",
      "Epoch 129/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4939 - accuracy: 0.7688 - val_loss: 0.6794 - val_accuracy: 0.7099 - lr: 0.0010\n",
      "Epoch 130/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5256 - accuracy: 0.7395 - val_loss: 0.5040 - val_accuracy: 0.7464 - lr: 0.0010\n",
      "Epoch 131/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4741 - accuracy: 0.7768 - val_loss: 0.5635 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 132/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4835 - accuracy: 0.7703 - val_loss: 0.4934 - val_accuracy: 0.7532 - lr: 0.0010\n",
      "Epoch 133/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5063 - accuracy: 0.7582 - val_loss: 0.5393 - val_accuracy: 0.7403 - lr: 0.0010\n",
      "Epoch 134/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5050 - accuracy: 0.7517 - val_loss: 0.4841 - val_accuracy: 0.7636 - lr: 0.0010\n",
      "Epoch 135/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4810 - accuracy: 0.7642 - val_loss: 0.5026 - val_accuracy: 0.7515 - lr: 0.0010\n",
      "Epoch 136/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4663 - accuracy: 0.7815 - val_loss: 0.5360 - val_accuracy: 0.7444 - lr: 0.0010\n",
      "Epoch 137/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4985 - accuracy: 0.7567 - val_loss: 0.4868 - val_accuracy: 0.7593 - lr: 0.0010\n",
      "Epoch 138/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4589 - accuracy: 0.7843 - val_loss: 0.5769 - val_accuracy: 0.6837 - lr: 0.0010\n",
      "Epoch 139/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4483 - accuracy: 0.7972 - val_loss: 0.4801 - val_accuracy: 0.7606 - lr: 0.0010\n",
      "Epoch 140/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4819 - accuracy: 0.7757 - val_loss: 0.4780 - val_accuracy: 0.7651 - lr: 0.0010\n",
      "Epoch 141/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4923 - accuracy: 0.7617 - val_loss: 0.4866 - val_accuracy: 0.7577 - lr: 0.0010\n",
      "Epoch 142/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4258 - accuracy: 0.8018 - val_loss: 0.4814 - val_accuracy: 0.7744 - lr: 0.0010\n",
      "Epoch 143/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4424 - accuracy: 0.7968 - val_loss: 0.4783 - val_accuracy: 0.7647 - lr: 0.0010\n",
      "Epoch 144/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4838 - accuracy: 0.7648 - val_loss: 0.4450 - val_accuracy: 0.7929 - lr: 0.0010\n",
      "Epoch 145/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4299 - accuracy: 0.7993 - val_loss: 0.6319 - val_accuracy: 0.7116 - lr: 0.0010\n",
      "Epoch 146/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4249 - accuracy: 0.8045 - val_loss: 0.4831 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 147/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4578 - accuracy: 0.7843 - val_loss: 0.4393 - val_accuracy: 0.7879 - lr: 0.0010\n",
      "Epoch 148/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4671 - accuracy: 0.7793 - val_loss: 0.5294 - val_accuracy: 0.7502 - lr: 0.0010\n",
      "Epoch 149/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4055 - accuracy: 0.8192 - val_loss: 0.4623 - val_accuracy: 0.7820 - lr: 0.0010\n",
      "Epoch 150/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4317 - accuracy: 0.8073 - val_loss: 0.5230 - val_accuracy: 0.7437 - lr: 0.0010\n",
      "Epoch 151/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4574 - accuracy: 0.7847 - val_loss: 0.4548 - val_accuracy: 0.7777 - lr: 0.0010\n",
      "Epoch 152/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4032 - accuracy: 0.8165 - val_loss: 0.4954 - val_accuracy: 0.7587 - lr: 0.0010\n",
      "Epoch 153/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3898 - accuracy: 0.8263 - val_loss: 0.4228 - val_accuracy: 0.7996 - lr: 0.0010\n",
      "Epoch 154/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4401 - accuracy: 0.8015 - val_loss: 0.5240 - val_accuracy: 0.7222 - lr: 0.0010\n",
      "Epoch 155/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4311 - accuracy: 0.8040 - val_loss: 0.5549 - val_accuracy: 0.7442 - lr: 0.0010\n",
      "Epoch 156/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3770 - accuracy: 0.8315 - val_loss: 0.4806 - val_accuracy: 0.8018 - lr: 0.0010\n",
      "Epoch 157/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4000 - accuracy: 0.8267 - val_loss: 0.4348 - val_accuracy: 0.7929 - lr: 0.0010\n",
      "Epoch 158/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4375 - accuracy: 0.8005 - val_loss: 0.3921 - val_accuracy: 0.8211 - lr: 0.0010\n",
      "Epoch 159/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3795 - accuracy: 0.8278 - val_loss: 0.5050 - val_accuracy: 0.7787 - lr: 0.0010\n",
      "Epoch 160/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3731 - accuracy: 0.8440 - val_loss: 0.5123 - val_accuracy: 0.7613 - lr: 0.0010\n",
      "Epoch 161/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4056 - accuracy: 0.8195 - val_loss: 0.5973 - val_accuracy: 0.6935 - lr: 0.0010\n",
      "Epoch 162/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4175 - accuracy: 0.8087 - val_loss: 0.4082 - val_accuracy: 0.8089 - lr: 0.0010\n",
      "Epoch 163/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3528 - accuracy: 0.8475 - val_loss: 0.4112 - val_accuracy: 0.8260 - lr: 0.0010\n",
      "Epoch 164/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3764 - accuracy: 0.8393 - val_loss: 0.5039 - val_accuracy: 0.7530 - lr: 0.0010\n",
      "Epoch 165/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4124 - accuracy: 0.8190 - val_loss: 0.4009 - val_accuracy: 0.8126 - lr: 0.0010\n",
      "Epoch 166/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3690 - accuracy: 0.8370 - val_loss: 0.4636 - val_accuracy: 0.7870 - lr: 0.0010\n",
      "Epoch 167/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3700 - accuracy: 0.8388 - val_loss: 0.3938 - val_accuracy: 0.8230 - lr: 0.0010\n",
      "Epoch 168/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3954 - accuracy: 0.8248 - val_loss: 0.4248 - val_accuracy: 0.7936 - lr: 0.0010\n",
      "Epoch 169/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4060 - accuracy: 0.8183 - val_loss: 0.3752 - val_accuracy: 0.8302 - lr: 0.0010\n",
      "Epoch 170/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3357 - accuracy: 0.8510 - val_loss: 0.3708 - val_accuracy: 0.8391 - lr: 0.0010\n",
      "Epoch 171/300\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3541 - accuracy: 0.8505 - val_loss: 0.3868 - val_accuracy: 0.8228 - lr: 0.0010\n",
      "Epoch 172/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3821 - accuracy: 0.8320 - val_loss: 0.3745 - val_accuracy: 0.8331 - lr: 0.0010\n",
      "Epoch 173/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3685 - accuracy: 0.8300 - val_loss: 0.4163 - val_accuracy: 0.8308 - lr: 0.0010\n",
      "Epoch 174/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3426 - accuracy: 0.8500 - val_loss: 0.4123 - val_accuracy: 0.8184 - lr: 0.0010\n",
      "Epoch 175/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3764 - accuracy: 0.8353 - val_loss: 0.3696 - val_accuracy: 0.8325 - lr: 0.0010\n",
      "Epoch 176/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3834 - accuracy: 0.8267 - val_loss: 0.3687 - val_accuracy: 0.8370 - lr: 0.0010\n",
      "Epoch 177/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3219 - accuracy: 0.8627 - val_loss: 0.3687 - val_accuracy: 0.8418 - lr: 0.0010\n",
      "Epoch 178/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3301 - accuracy: 0.8597 - val_loss: 0.7375 - val_accuracy: 0.7047 - lr: 0.0010\n",
      "Epoch 179/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3673 - accuracy: 0.8382 - val_loss: 0.4201 - val_accuracy: 0.8011 - lr: 0.0010\n",
      "Epoch 180/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3650 - accuracy: 0.8367 - val_loss: 0.3754 - val_accuracy: 0.8318 - lr: 0.0010\n",
      "Epoch 181/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3143 - accuracy: 0.8685 - val_loss: 0.3784 - val_accuracy: 0.8373 - lr: 0.0010\n",
      "Epoch 182/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3480 - accuracy: 0.8465 - val_loss: 0.3445 - val_accuracy: 0.8513 - lr: 0.0010\n",
      "Epoch 183/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3742 - accuracy: 0.8325 - val_loss: 0.4104 - val_accuracy: 0.8120 - lr: 0.0010\n",
      "Epoch 184/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3009 - accuracy: 0.8710 - val_loss: 0.3853 - val_accuracy: 0.8348 - lr: 0.0010\n",
      "Epoch 185/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3142 - accuracy: 0.8665 - val_loss: 0.4658 - val_accuracy: 0.8140 - lr: 0.0010\n",
      "Epoch 186/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3449 - accuracy: 0.8535 - val_loss: 0.3520 - val_accuracy: 0.8477 - lr: 0.0010\n",
      "Epoch 187/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3603 - accuracy: 0.8418 - val_loss: 0.3330 - val_accuracy: 0.8549 - lr: 0.0010\n",
      "Epoch 188/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2946 - accuracy: 0.8773 - val_loss: 0.4154 - val_accuracy: 0.8554 - lr: 0.0010\n",
      "Epoch 189/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3126 - accuracy: 0.8643 - val_loss: 0.3795 - val_accuracy: 0.8279 - lr: 0.0010\n",
      "Epoch 190/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3835 - accuracy: 0.8340 - val_loss: 0.4678 - val_accuracy: 0.7928 - lr: 0.0010\n",
      "Epoch 191/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3088 - accuracy: 0.8685 - val_loss: 0.3420 - val_accuracy: 0.8477 - lr: 0.0010\n",
      "Epoch 192/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3025 - accuracy: 0.8770 - val_loss: 0.3518 - val_accuracy: 0.8401 - lr: 0.0010\n",
      "Epoch 193/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3302 - accuracy: 0.8577 - val_loss: 0.3400 - val_accuracy: 0.8546 - lr: 0.0010\n",
      "Epoch 194/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3502 - accuracy: 0.8520 - val_loss: 0.5179 - val_accuracy: 0.7387 - lr: 0.0010\n",
      "Epoch 195/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2886 - accuracy: 0.8790 - val_loss: 0.3439 - val_accuracy: 0.8512 - lr: 0.0010\n",
      "Epoch 196/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3014 - accuracy: 0.8740 - val_loss: 0.3137 - val_accuracy: 0.8607 - lr: 0.0010\n",
      "Epoch 197/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3676 - accuracy: 0.8395 - val_loss: 0.3981 - val_accuracy: 0.8177 - lr: 0.0010\n",
      "Epoch 198/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3020 - accuracy: 0.8725 - val_loss: 0.3086 - val_accuracy: 0.8623 - lr: 0.0010\n",
      "Epoch 199/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2859 - accuracy: 0.8810 - val_loss: 0.3428 - val_accuracy: 0.8595 - lr: 0.0010\n",
      "Epoch 200/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3169 - accuracy: 0.8660 - val_loss: 0.3061 - val_accuracy: 0.8646 - lr: 0.0010\n",
      "Epoch 201/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3225 - accuracy: 0.8510 - val_loss: 0.3127 - val_accuracy: 0.8593 - lr: 0.0010\n",
      "Epoch 202/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2818 - accuracy: 0.8813 - val_loss: 0.2881 - val_accuracy: 0.8763 - lr: 0.0010\n",
      "Epoch 203/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2761 - accuracy: 0.8898 - val_loss: 0.3727 - val_accuracy: 0.8284 - lr: 0.0010\n",
      "Epoch 204/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3397 - accuracy: 0.8550 - val_loss: 0.3111 - val_accuracy: 0.8674 - lr: 0.0010\n",
      "Epoch 205/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2671 - accuracy: 0.8880 - val_loss: 0.2997 - val_accuracy: 0.8735 - lr: 0.0010\n",
      "Epoch 206/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2714 - accuracy: 0.8898 - val_loss: 0.3595 - val_accuracy: 0.8387 - lr: 0.0010\n",
      "Epoch 207/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3132 - accuracy: 0.8710 - val_loss: 0.3412 - val_accuracy: 0.8503 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3318 - accuracy: 0.8533 - val_loss: 0.3610 - val_accuracy: 0.8366 - lr: 0.0010\n",
      "Epoch 209/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2616 - accuracy: 0.8873 - val_loss: 0.4461 - val_accuracy: 0.7862 - lr: 0.0010\n",
      "Epoch 210/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2651 - accuracy: 0.8947 - val_loss: 0.4989 - val_accuracy: 0.7879 - lr: 0.0010\n",
      "Epoch 211/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3297 - accuracy: 0.8575 - val_loss: 0.3025 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 212/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2574 - accuracy: 0.8950 - val_loss: 0.4232 - val_accuracy: 0.8414 - lr: 0.0010\n",
      "Epoch 213/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2719 - accuracy: 0.8888 - val_loss: 0.2832 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Epoch 214/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2809 - accuracy: 0.8855 - val_loss: 0.2880 - val_accuracy: 0.8735 - lr: 0.0010\n",
      "Epoch 215/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3068 - accuracy: 0.8692 - val_loss: 0.3552 - val_accuracy: 0.8483 - lr: 0.0010\n",
      "Epoch 216/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2340 - accuracy: 0.9078 - val_loss: 0.2974 - val_accuracy: 0.8778 - lr: 0.0010\n",
      "Epoch 217/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2653 - accuracy: 0.8928 - val_loss: 0.2695 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Epoch 218/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3177 - accuracy: 0.8645 - val_loss: 0.3065 - val_accuracy: 0.8688 - lr: 0.0010\n",
      "Epoch 219/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2575 - accuracy: 0.8957 - val_loss: 0.3650 - val_accuracy: 0.8453 - lr: 0.0010\n",
      "Epoch 220/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2628 - accuracy: 0.8923 - val_loss: 0.2644 - val_accuracy: 0.8894 - lr: 0.0010\n",
      "Epoch 221/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2877 - accuracy: 0.8827 - val_loss: 0.2725 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Epoch 222/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2955 - accuracy: 0.8798 - val_loss: 0.3636 - val_accuracy: 0.8403 - lr: 0.0010\n",
      "Epoch 223/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2334 - accuracy: 0.9055 - val_loss: 0.3646 - val_accuracy: 0.8746 - lr: 0.0010\n",
      "Epoch 224/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2652 - accuracy: 0.8920 - val_loss: 0.3271 - val_accuracy: 0.8587 - lr: 0.0010\n",
      "Epoch 225/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2950 - accuracy: 0.8788 - val_loss: 0.2883 - val_accuracy: 0.8734 - lr: 0.0010\n",
      "Epoch 226/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2495 - accuracy: 0.8975 - val_loss: 0.3829 - val_accuracy: 0.8481 - lr: 0.0010\n",
      "Epoch 227/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2444 - accuracy: 0.8985 - val_loss: 0.3403 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 228/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2796 - accuracy: 0.8827 - val_loss: 0.3970 - val_accuracy: 0.8141 - lr: 0.0010\n",
      "Epoch 229/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2933 - accuracy: 0.8770 - val_loss: 0.3574 - val_accuracy: 0.8433 - lr: 0.0010\n",
      "Epoch 230/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2415 - accuracy: 0.9020 - val_loss: 0.2513 - val_accuracy: 0.9029 - lr: 0.0010\n",
      "Epoch 231/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2398 - accuracy: 0.9055 - val_loss: 0.2849 - val_accuracy: 0.8812 - lr: 0.0010\n",
      "Epoch 232/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2888 - accuracy: 0.8810 - val_loss: 0.2670 - val_accuracy: 0.8882 - lr: 0.0010\n",
      "Epoch 233/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2288 - accuracy: 0.9055 - val_loss: 0.3533 - val_accuracy: 0.8601 - lr: 0.0010\n",
      "Epoch 234/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2439 - accuracy: 0.9038 - val_loss: 0.2484 - val_accuracy: 0.8963 - lr: 0.0010\n",
      "Epoch 235/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2689 - accuracy: 0.8907 - val_loss: 0.2410 - val_accuracy: 0.9036 - lr: 0.0010\n",
      "Epoch 236/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2739 - accuracy: 0.8885 - val_loss: 0.2552 - val_accuracy: 0.8966 - lr: 0.0010\n",
      "Epoch 237/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2311 - accuracy: 0.9080 - val_loss: 0.2923 - val_accuracy: 0.8744 - lr: 0.0010\n",
      "Epoch 238/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2193 - accuracy: 0.9118 - val_loss: 0.4118 - val_accuracy: 0.8541 - lr: 0.0010\n",
      "Epoch 239/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2493 - accuracy: 0.9015 - val_loss: 0.2725 - val_accuracy: 0.8892 - lr: 0.0010\n",
      "Epoch 240/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2444 - accuracy: 0.8967 - val_loss: 0.3949 - val_accuracy: 0.8371 - lr: 0.0010\n",
      "Epoch 241/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2320 - accuracy: 0.9082 - val_loss: 0.5690 - val_accuracy: 0.7580 - lr: 0.0010\n",
      "Epoch 242/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2443 - accuracy: 0.8995 - val_loss: 0.2523 - val_accuracy: 0.8950 - lr: 0.0010\n",
      "Epoch 243/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2662 - accuracy: 0.8947 - val_loss: 0.3552 - val_accuracy: 0.8519 - lr: 0.0010\n",
      "Epoch 244/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2005 - accuracy: 0.9155 - val_loss: 0.4737 - val_accuracy: 0.8554 - lr: 0.0010\n",
      "Epoch 245/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2270 - accuracy: 0.9107 - val_loss: 0.2633 - val_accuracy: 0.8951 - lr: 0.0010\n",
      "Epoch 246/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2327 - accuracy: 0.9047 - val_loss: 0.2546 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Epoch 247/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2634 - accuracy: 0.8910 - val_loss: 0.3183 - val_accuracy: 0.8655 - lr: 0.0010\n",
      "Epoch 248/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2143 - accuracy: 0.9155 - val_loss: 0.2975 - val_accuracy: 0.8987 - lr: 0.0010\n",
      "Epoch 249/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2359 - accuracy: 0.9022 - val_loss: 0.2413 - val_accuracy: 0.9033 - lr: 0.0010\n",
      "Epoch 250/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2748 - accuracy: 0.8780 - val_loss: 0.2459 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 251/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2071 - accuracy: 0.9137 - val_loss: 0.2509 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Epoch 252/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2234 - accuracy: 0.9110 - val_loss: 0.2333 - val_accuracy: 0.9077 - lr: 0.0010\n",
      "Epoch 253/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2353 - accuracy: 0.9068 - val_loss: 0.2437 - val_accuracy: 0.9065 - lr: 0.0010\n",
      "Epoch 254/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2732 - accuracy: 0.8857 - val_loss: 0.4169 - val_accuracy: 0.8152 - lr: 0.0010\n",
      "Epoch 255/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1958 - accuracy: 0.9262 - val_loss: 0.2298 - val_accuracy: 0.9111 - lr: 0.0010\n",
      "Epoch 256/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2032 - accuracy: 0.9212 - val_loss: 0.2339 - val_accuracy: 0.8997 - lr: 0.0010\n",
      "Epoch 257/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2574 - accuracy: 0.8928 - val_loss: 0.2398 - val_accuracy: 0.9021 - lr: 0.0010\n",
      "Epoch 258/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1924 - accuracy: 0.9275 - val_loss: 0.3390 - val_accuracy: 0.8551 - lr: 0.0010\n",
      "Epoch 259/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1991 - accuracy: 0.9230 - val_loss: 0.2421 - val_accuracy: 0.9026 - lr: 0.0010\n",
      "Epoch 260/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2425 - accuracy: 0.9062 - val_loss: 0.2342 - val_accuracy: 0.9079 - lr: 0.0010\n",
      "Epoch 261/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2407 - accuracy: 0.9038 - val_loss: 0.2353 - val_accuracy: 0.9052 - lr: 0.0010\n",
      "Epoch 262/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1887 - accuracy: 0.9293 - val_loss: 0.2228 - val_accuracy: 0.9106 - lr: 0.0010\n",
      "Epoch 263/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1915 - accuracy: 0.9252 - val_loss: 0.2490 - val_accuracy: 0.9026 - lr: 0.0010\n",
      "Epoch 264/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2446 - accuracy: 0.8997 - val_loss: 0.2222 - val_accuracy: 0.9081 - lr: 0.0010\n",
      "Epoch 265/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1880 - accuracy: 0.9260 - val_loss: 0.2489 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 266/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1890 - accuracy: 0.9237 - val_loss: 0.2892 - val_accuracy: 0.8804 - lr: 0.0010\n",
      "Epoch 267/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2214 - accuracy: 0.9140 - val_loss: 0.2892 - val_accuracy: 0.8766 - lr: 0.0010\n",
      "Epoch 268/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2400 - accuracy: 0.9022 - val_loss: 0.2012 - val_accuracy: 0.9196 - lr: 0.0010\n",
      "Epoch 269/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1827 - accuracy: 0.9268 - val_loss: 0.1962 - val_accuracy: 0.9181 - lr: 0.0010\n",
      "Epoch 270/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1847 - accuracy: 0.9302 - val_loss: 0.2097 - val_accuracy: 0.9218 - lr: 0.0010\n",
      "Epoch 271/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2502 - accuracy: 0.8990 - val_loss: 0.2369 - val_accuracy: 0.9074 - lr: 0.0010\n",
      "Epoch 272/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1954 - accuracy: 0.9240 - val_loss: 0.3721 - val_accuracy: 0.8688 - lr: 0.0010\n",
      "Epoch 273/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1947 - accuracy: 0.9250 - val_loss: 0.2315 - val_accuracy: 0.9046 - lr: 0.0010\n",
      "Epoch 274/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2050 - accuracy: 0.9205 - val_loss: 0.2622 - val_accuracy: 0.8976 - lr: 0.0010\n",
      "Epoch 275/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2432 - accuracy: 0.9003 - val_loss: 0.3339 - val_accuracy: 0.8692 - lr: 0.0010\n",
      "Epoch 276/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1948 - accuracy: 0.9268 - val_loss: 0.2059 - val_accuracy: 0.9211 - lr: 0.0010\n",
      "Epoch 277/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1893 - accuracy: 0.9258 - val_loss: 0.2251 - val_accuracy: 0.9225 - lr: 0.0010\n",
      "Epoch 278/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2523 - accuracy: 0.9000 - val_loss: 0.2416 - val_accuracy: 0.9058 - lr: 0.0010\n",
      "Epoch 279/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1824 - accuracy: 0.9268 - val_loss: 0.3009 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Epoch 280/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1899 - accuracy: 0.9268 - val_loss: 0.1912 - val_accuracy: 0.9281 - lr: 0.0010\n",
      "Epoch 281/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1961 - accuracy: 0.9200 - val_loss: 0.1671 - val_accuracy: 0.9332 - lr: 0.0010\n",
      "Epoch 282/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2164 - accuracy: 0.9147 - val_loss: 0.2220 - val_accuracy: 0.9113 - lr: 0.0010\n",
      "Epoch 283/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1835 - accuracy: 0.9265 - val_loss: 0.1990 - val_accuracy: 0.9207 - lr: 0.0010\n",
      "Epoch 284/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1946 - accuracy: 0.9243 - val_loss: 0.2918 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 285/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2174 - accuracy: 0.9122 - val_loss: 0.1938 - val_accuracy: 0.9245 - lr: 0.0010\n",
      "Epoch 286/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1868 - accuracy: 0.9273 - val_loss: 0.2286 - val_accuracy: 0.9079 - lr: 0.0010\n",
      "Epoch 287/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1684 - accuracy: 0.9352 - val_loss: 0.3605 - val_accuracy: 0.8940 - lr: 0.0010\n",
      "Epoch 288/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1920 - accuracy: 0.9290 - val_loss: 0.2138 - val_accuracy: 0.9100 - lr: 0.0010\n",
      "Epoch 289/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2092 - accuracy: 0.9150 - val_loss: 0.2079 - val_accuracy: 0.9150 - lr: 0.0010\n",
      "Epoch 290/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1672 - accuracy: 0.9373 - val_loss: 0.2093 - val_accuracy: 0.9214 - lr: 0.0010\n",
      "Epoch 291/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1890 - accuracy: 0.9258 - val_loss: 0.2071 - val_accuracy: 0.9128 - lr: 0.0010\n",
      "Epoch 292/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2121 - accuracy: 0.9227 - val_loss: 0.1818 - val_accuracy: 0.9293 - lr: 0.0010\n",
      "Epoch 293/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1665 - accuracy: 0.9345 - val_loss: 0.2832 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Epoch 294/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1748 - accuracy: 0.9362 - val_loss: 0.2145 - val_accuracy: 0.9192 - lr: 0.0010\n",
      "Epoch 295/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1991 - accuracy: 0.9210 - val_loss: 0.1724 - val_accuracy: 0.9302 - lr: 0.0010\n",
      "Epoch 296/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2098 - accuracy: 0.9197 - val_loss: 0.1482 - val_accuracy: 0.9459 - lr: 0.0010\n",
      "Epoch 297/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1530 - accuracy: 0.9450 - val_loss: 0.2159 - val_accuracy: 0.9154 - lr: 0.0010\n",
      "Epoch 298/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1734 - accuracy: 0.9333 - val_loss: 0.2563 - val_accuracy: 0.9169 - lr: 0.0010\n",
      "Epoch 299/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1859 - accuracy: 0.9280 - val_loss: 0.1979 - val_accuracy: 0.9179 - lr: 0.0010\n",
      "Epoch 300/300\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1656 - accuracy: 0.9358 - val_loss: 0.2649 - val_accuracy: 0.8973 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "for i, (train, val) in enumerate([folds[0]]):\n",
    "    \n",
    "    model = createModel()\n",
    "    \n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    metrics = ['accuracy']\n",
    "    \n",
    "    model.compile(optimizer=opt, loss=loss, metrics=metrics)\n",
    "    \n",
    "    tboardCb = tf.keras.callbacks.TensorBoard(log_dir=f\"{logBasePath}/{logPrefix}_{i}\", histogram_freq=1, profile_batch=(2,10))\n",
    "    lrSchedule = tf.keras.callbacks.LearningRateScheduler(schedule)\n",
    "    \n",
    "    cbs = [tboardCb, lrSchedule]\n",
    "    \n",
    "    model.evaluate(val)\n",
    "    model.fit(train, initial_epoch=START_EPOCH, epochs=END_EPOCH, steps_per_epoch=STEPS_PER_EPOCH, callbacks=cbs, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae70be7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
